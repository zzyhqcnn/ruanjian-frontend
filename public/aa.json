{"nodes": ["Bilen_Dynamic_Image_Networks_CVPR_2016_paper.pdf", "\u5e73\u5747\u56fe\u6a21\u578b", "Bilen_Dynamic_Image_Networks_CVPR_2016_paper.pdf", "video descriptor", "Bilen_Dynamic_Image_Networks_CVPR_2016_paper.pdf", "Hu-\u52a8\u4f5c\u8bc6\u522b", "Bilen_Dynamic_Image_Networks_CVPR_2016_paper.pdf", "Dynamick Image Networks", "Bilen_Dynamic_Image_Networks_CVPR_2016_paper.pdf", "\u975e\u7ebf\u6027(I)operator", "Bilen_Dynamic_Image_Networks_CVPR_2016_paper.pdf", "Simonyan et al. ", "Bilen_Dynamic_Image_Networks_CVPR_2016_paper.pdf", "motion patterns", "Bilen_Dynamic_Image_Networks_CVPR_2016_paper.pdf", "\u6df1\u5ea6\u5b66\u4e60 CNN", "Bilen_Dynamic_Image_Networks_CVPR_2016_paper.pdf", "Dense trajectories", "Bilen_Dynamic_Image_Networks_CVPR_2016_paper.pdf", "RankPool", "Bilen_Dynamic_Image_Networks_CVPR_2016_paper.pdf", "\u6700\u5927 epochranking scores", "Bilen_Dynamic_Image_Networks_CVPR_2016_paper.pdf", "summarization", "Bilen_Dynamic_Image_Networks_CVPR_2016_paper.pdf", "tensorflow", "Bilen_Dynamic_Image_Networks_CVPR_2016_paper.pdf", "human actionsdentyity function", "Bilen_Dynamic_Image_Networks_CVPR_2016_paper.pdf", "temporal pooling", "Bilen_Dynamic_Image_Networks_CVPR_2016_paper.pdf", "CNNvideo data", "Bilen_Dynamic_Image_Networks_CVPR_2016_paper.pdf", "SoccererJuggling", "Bilen_Dynamic_Image_Networks_CVPR_2016_paper.pdf", "Ranked-Classifier", "Bilen_Dynamic_Image_Networks_CVPR_2016_paper.pdf", "\u4eba\u5de5\u667a\u80fd", "Bilen_Dynamic_Image_Networks_CVPR_2016_paper.pdf", "\u6df1\u5ea6 CNN \u6a21\u578bclassification", "Bilen_Dynamic_Image_Networks_CVPR_2016_paper.pdf", "\u52a8\u6001\u5efa\u6a21", "Bilen_Dynamic_Image_Networks_CVPR_2016_paper.pdf", "ReLU\u5c42", "Bilen_Dynamic_Image_Networks_CVPR_2016_paper.pdf", "3D filters", "Bilen_Dynamic_Image_Networks_CVPR_2016_paper.pdf", "Hellingerkernel", "Bilen_Dynamic_Image_Networks_CVPR_2016_paper.pdf", "L1\u957f\u77ed\u8bb0\u5fc6face identi\ufb01cat", "Bilen_Dynamic_Image_Networks_CVPR_2016_paper.pdf", "multi-stream architecture", "Bilen_Dynamic_Image_Networks_CVPR_2016_paper.pdf", "\u957f\u671f\u91cd\u590d\u5377\u79ef\u795e\u7ecf\u7f51\u7edc", "Bilen_Dynamic_Image_Networks_CVPR_2016_paper.pdf", "\u56db\u6b21\u65b9\u6b63\u5219\u5316", "Bilen_Dynamic_Image_Networks_CVPR_2016_paper.pdf", "end-to-end\u8bad\u7ec3", "Bilen_Dynamic_Image_Networks_CVPR_2016_paper.pdf", "\u53cd\u590d\u795e\u7ecf\u7f51\u7edc", "Bilen_Dynamic_Image_Networks_CVPR_2016_paper.pdf", "neural network encoder", "Bilen_Dynamic_Image_Networks_CVPR_2016_paper.pdf", "\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc", "Bilen_Dynamic_Image_Networks_CVPR_2016_paper.pdf", "_signal\u4e2d\u95f4\u7f51\u7edc\u5c42", "Bilen_Dynamic_Image_Networks_CVPR_2016_paper.pdf", "video\u7406\u89e3", "Bilen_Dynamic_Image_Networks_CVPR_2016_paper.pdf", "Fully convolutional networks", "Bilen_Dynamic_Image_Networks_CVPR_2016_paper.pdf", "human action categorization", "Bilen_Dynamic_Image_Networks_CVPR_2016_paper.pdf", "dense labeling", "Bilen_Dynamic_Image_Networks_CVPR_2016_paper.pdf", "max-pooling", "Bilen_Dynamic_Image_Networks_CVPR_2016_paper.pdf", "cvpr", "Bilen_Dynamic_Image_Networks_CVPR_2016_paper.pdf", "pooling", "Bilen_Dynamic_Image_Networks_CVPR_2016_paper.pdf", "CNN Architectures", "Bilen_Dynamic_Image_Networks_CVPR_2016_paper.pdf", "image features", "Bilen_Dynamic_Image_Networks_CVPR_2016_paper.pdf", "Optimally Represented ImageNet", "Bilen_Dynamic_Image_Networks_CVPR_2016_paper.pdf", "\u53ef\u79fb\u690d\u7684\u5377\u79ef\u5c42", "Bilen_Dynamic_Image_Networks_CVPR_2016_paper.pdf", "fine-tuning", "Bilen_Dynamic_Image_Networks_CVPR_2016_paper.pdf", "Score distribution", "Bilen_Dynamic_Image_Networks_CVPR_2016_paper.pdf", "vector", "Bilen_Dynamic_Image_Networks_CVPR_2016_paper.pdf", "LSTM", "Bilen_Dynamic_Image_Networks_CVPR_2016_paper.pdf", "\u6df1\u5ea6\u5377\u79ef\u7f51\u7edc", "Bilen_Dynamic_Image_Networks_CVPR_2016_paper.pdf", "\u9759\u6001\u795e\u7ecf\u7f51\u7edc\u67b6\u6784\uff0c\u8c10\u6570", "d2l-zh-pytorch.pdf", "torch.ones", "d2l-zh-pytorch.pdf", "\u968f\u673a\u68af\u5ea6\u4e0b\u964d\u6cd5", "d2l-zh-pytorch.pdf", "tensorflow", "d2l-zh-pytorch.pdf", "\u4eba\u5de5\u667a\u80fd", "d2l-zh-pytorch.pdf", "\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc", "d2l-zh-pytorch.pdf", "pooling", "d2l-zh-pytorch.pdf", "fine-tuning", "d2l-zh-pytorch.pdf", "LSTM", "d2l-zh-pytorch.pdf", "\u8fb9\u7f18\u68c0\u6d4b", "d2l-zh-pytorch.pdf", "LSTM\u7f51\u7edc", "d2l-zh-pytorch.pdf", "\u4eba\u8138\u8bc6\u522b", "d2l-zh-pytorch.pdf", "NVMe SSD", "d2l-zh-pytorch.pdf", "\u6df1\u5ea6\u5377\u79ef\u795e\u7ecf\u7f51\u7edc", "d2l-zh-pytorch.pdf", "Fashion\u2010MNIST", "d2l-zh-pytorch.pdf", "\u51b3\u7b56\u6811", "d2l-zh-pytorch.pdf", "CNN", "d2l-zh-pytorch.pdf", "semantic segmentation", "d2l-zh-pytorch.pdf", "IntelOptane", "d2l-zh-pytorch.pdf", "\u795e\u7ecf\u7f51\u7edc", "d2l-zh-pytorch.pdf", "\u68af\u5ea6", "d2l-zh-pytorch.pdf", "train_func", "d2l-zh-pytorch.pdf", "DenseNet", "d2l-zh-pytorch.pdf", "\u652f\u6301\u5411\u91cf\u673a", "d2l-zh-pytorch.pdf", "\u591a\u7a0b\u5e8f\u6267\u884c", "d2l-zh-pytorch.pdf", "\u521d\u59cb\u5316\u53c2\u6570\u7ba1\u7406", "d2l-zh-pytorch.pdf", "SGD\u4f18\u5316\u5668", "d2l-zh-pytorch.pdf", "\u6570\u636e\u589e\u5f3a", "d2l-zh-pytorch.pdf", "AlexNet", "d2l-zh-pytorch.pdf", "random_gradient_descent", "d2l-zh-pytorch.pdf", "\u6df1\u5ea6\u5b66\u4e60", "d2l-zh-pytorch.pdf", "\u2202J/\u2202z", "d2l-zh-pytorch.pdf", "ReLU\u6fc0\u6d3b\u51fd\u6570", "d2l-zh-pytorch.pdf", "\u72ec\u70ed\u7f16\u7801", "d2l-zh-pytorch.pdf", "\u53cd\u5411\u4f20\u64ad", "d2l-zh-pytorch.pdf", "Dualog\u66f2\u6b63\u5207", "d2l-zh-pytorch.pdf", "\u663e\u5b58\u6269\u5c55", "d2l-zh-pytorch.pdf", "\u8d1f\u8f7d\u5747\u8861", "d2l-zh-pytorch.pdf", "Kubernetes", "d2l-zh-pytorch.pdf", "Performance", "d2l-zh-pytorch.pdf", "NLP", "d2l-zh-pytorch.pdf", "ultivariateNormal", "d2l-zh-pytorch.pdf", "embeddings", "d2l-zh-pytorch.pdf", "\u4e8c\u5143\u51fd\u6570", "d2l-zh-pytorch.pdf", "CBOW\u6a21\u578b", "d2l-zh-pytorch.pdf", "git", "d2l-zh-pytorch.pdf", "\u67b6\u6784\u5b58\u50a8", "d2l-zh-pytorch.pdf", "tanh", "d2l-zh-pytorch.pdf", "\u5bc6\u5ea6\u4f30\u8ba1", "d2l-zh-pytorch.pdf", "kaggle_house_pred_train", "d2l-zh-pytorch.pdf", "Tensor Processing Unit", "cp08-\u6837\u7ae0\u793a\u4f8b-TensorFlow Lite", "TFLite\u6a21\u578b", "cp08-\u6837\u7ae0\u793a\u4f8b-TensorFlow Lite", "Python", "cp08-\u6837\u7ae0\u793a\u4f8b-TensorFlow Lite", "hardware accelerator delegate", "cp08-\u6837\u7ae0\u793a\u4f8b-TensorFlow Lite", "Dense", "cp08-\u6837\u7ae0\u793a\u4f8b-TensorFlow Lite", "Flow.js", "cp08-\u6837\u7ae0\u793a\u4f8b-TensorFlow Lite", "Keras H5", "cp08-\u6837\u7ae0\u793a\u4f8b-TensorFlow Lite", "global_average_pooling2d (GlobalAveragePooling2D)", "cp08-\u6837\u7ae0\u793a\u4f8b-TensorFlow Lite", "SavedModelTensorFlow Lite", "cp08-\u6837\u7ae0\u793a\u4f8b-TensorFlow Lite", "tf_*_API", "cp08-\u6837\u7ae0\u793a\u4f8b-TensorFlow Lite", "Arm64", "cp08-\u6837\u7ae0\u793a\u4f8b-TensorFlow Lite", "github", "cp08-\u6837\u7ae0\u793a\u4f8b-TensorFlow Lite", "inceptionv3", "cp08-\u6837\u7ae0\u793a\u4f8b-TensorFlow Lite", "train_generator", "cp08-\u6837\u7ae0\u793a\u4f8b-TensorFlow Lite", "repositories", "cp08-\u6837\u7ae0\u793a\u4f8b-TensorFlow Lite", "\u7f16\u8bd1\u4f18\u5316", "cp08-\u6837\u7ae0\u793a\u4f8b-TensorFlow Lite", "mean_squared_error", "cp08-\u6837\u7ae0\u793a\u4f8b-TensorFlow Lite", "prediction process(tf.keras model)", "cp08-\u6837\u7ae0\u793a\u4f8b-TensorFlow Lite", "MobileNetV2", "cp08-\u6837\u7ae0\u793a\u4f8b-TensorFlow Lite", "\u7269\u8054\u7f51", "cp08-\u6837\u7ae0\u793a\u4f8b-TensorFlow Lite", "buildscript", "cp08-\u6837\u7ae0\u793a\u4f8b-TensorFlow Lite", "recognizeImage", "cp08-\u6837\u7ae0\u793a\u4f8b-TensorFlow Lite", "\u5168\u8fde\u63a5\u5206\u7c7b\u5668", "cp08-\u6837\u7ae0\u793a\u4f8b-TensorFlow Lite", "GpuDelegate", "cp08-\u6837\u7ae0\u793a\u4f8b-TensorFlow Lite", "ImageProcessor", "cp08-\u6837\u7ae0\u793a\u4f8b-TensorFlow Lite", "MobileNet V2\u57fa\u7840\u6a21\u578b", "cp08-\u6837\u7ae0\u793a\u4f8b-TensorFlow Lite", "Java", "cp08-\u6837\u7ae0\u793a\u4f8b-TensorFlow Lite", "tflite_convert", "cp08-\u6837\u7ae0\u793a\u4f8b-TensorFlow Lite", "Tf.keras model", "cp08-\u6837\u7ae0\u793a\u4f8b-TensorFlow Lite", "\u8ba1\u7b97\u673a\u6444\u50cf\u5934", "cp08-\u6837\u7ae0\u793a\u4f8b-TensorFlow Lite", "tf.lite.Optimize.OPTIMIZE_FOR_SIZE", "cp08-\u6837\u7ae0\u793a\u4f8b-TensorFlow Lite", "\u5d4c\u5165\u5f0f\u8bbe\u5907", "cp08-\u6837\u7ae0\u793a\u4f8b-TensorFlow Lite", "device deployment", "cp08-\u6837\u7ae0\u793a\u4f8b-TensorFlow Lite", "TensorFlow Serving", "cp08-\u6837\u7ae0\u793a\u4f8b-TensorFlow Lite", "Interpreter", "cp08-\u6837\u7ae0\u793a\u4f8b-TensorFlow Lite", "maven", "cp08-\u6837\u7ae0\u793a\u4f8b-TensorFlow Lite", "datagen.flow_from_directory", "cp08-\u6837\u7ae0\u793a\u4f8b-TensorFlow Lite", "migration learning", "cp08-\u6837\u7ae0\u793a\u4f8b-TensorFlow Lite", "Android StudioAndroid Studio Project", "cp08-\u6837\u7ae0\u793a\u4f8b-TensorFlow Lite", "global_average_pooling2d", "cp08-\u6837\u7ae0\u793a\u4f8b-TensorFlow Lite", "Live Caption", "cp08-\u6837\u7ae0\u793a\u4f8b-TensorFlow Lite", "model.save", "cp08-\u6837\u7ae0\u793a\u4f8b-TensorFlow Lite", "\u50cf\u7d20\u7f29\u653e", "cp08-\u6837\u7ae0\u793a\u4f8b-TensorFlow Lite", "noCcompress\"TFLite\"", "cp08-\u6837\u7ae0\u793a\u4f8b-TensorFlow Lite", "\u7c7b\u522b\u4ea4\u53c9\u71b5", "cp08-\u6837\u7ae0\u793a\u4f8b-TensorFlow Lite", "\u62df\u8bbe\u5907\u7ba1\u7406\u5668", "cp08-\u6837\u7ae0\u793a\u4f8b-TensorFlow Lite", "Training", "cp08-\u6837\u7ae0\u793a\u4f8b-TensorFlow Lite", "pooling\u5c42", "cp08-\u6837\u7ae0\u793a\u4f8b-TensorFlow Lite", "TensorFlow \u6a21\u578b", "cp08-\u6837\u7ae0\u793a\u4f8b-TensorFlow Lite", "TFLiteConverter", "cp08-\u6837\u7ae0\u793a\u4f8b-TensorFlow Lite", "tf.lite", "\u300a\u9e1f\u54e5\u7684Linux\u79c1\u623f\u83dc\u300b", "RAID-0", "\u300a\u9e1f\u54e5\u7684Linux\u79c1\u623f\u83dc\u300b", "startup_scripts", "\u300a\u9e1f\u54e5\u7684Linux\u79c1\u623f\u83dc\u300b", "Realtek\u7f51\u5361", "\u300a\u9e1f\u54e5\u7684Linux\u79c1\u623f\u83dc\u300b", "dhcp-client", "\u300a\u9e1f\u54e5\u7684Linux\u79c1\u623f\u83dc\u300b", "Matrox g200/g400", "\u300a\u9e1f\u54e5\u7684Linux\u79c1\u623f\u83dc\u300b", "I/AGP\u603b\u7ebf", "\u300a\u9e1f\u54e5\u7684Linux\u79c1\u623f\u83dc\u300b", "DNS\u7ba1\u7406", "\u300a\u9e1f\u54e5\u7684Linux\u79c1\u623f\u83dc\u300b", "suite", "\u300a\u9e1f\u54e5\u7684Linux\u79c1\u623f\u83dc\u300b", "\u7a0b\u5e8f\u5f00\u53d1\u5e73\u53f0", "\u300a\u9e1f\u54e5\u7684Linux\u79c1\u623f\u83dc\u300b", "NIS-server\uff0cNIS\u5ba2\u6237", "\u300a\u9e1f\u54e5\u7684Linux\u79c1\u623f\u83dc\u300b", "bash shell sccript", "\u300a\u9e1f\u54e5\u7684Linux\u79c1\u623f\u83dc\u300b", "internet_interfaces", "\u300a\u9e1f\u54e5\u7684Linux\u79c1\u623f\u83dc\u300b", "Userspace Events", "\u300a\u9e1f\u54e5\u7684Linux\u79c1\u623f\u83dc\u300b", "Email\u4fe1\u7bb1", "\u300a\u9e1f\u54e5\u7684Linux\u79c1\u623f\u83dc\u300b", "bash", "\u300a\u9e1f\u54e5\u7684Linux\u79c1\u623f\u83dc\u300b", "2.6_linux_kernel", "\u300a\u9e1f\u54e5\u7684Linux\u79c1\u623f\u83dc\u300b", "\u660e\u7801\u4f20\u8f93\u7f51\u7edc\u8054\u673a\u6570\u636e\u5b89\u5168\u98ce\u9669", "\u300a\u9e1f\u54e5\u7684Linux\u79c1\u623f\u83dc\u300b", "equal cost multipath", "\u300a\u9e1f\u54e5\u7684Linux\u79c1\u623f\u83dc\u300b", "allow-transfer", "\u300a\u9e1f\u54e5\u7684Linux\u79c1\u623f\u83dc\u300b", "RPM\u5305\u7ba1\u7406", "\u300a\u9e1f\u54e5\u7684Linux\u79c1\u623f\u83dc\u300b", "Bcast", "\u300a\u9e1f\u54e5\u7684Linux\u79c1\u623f\u83dc\u300b", "Secure Socket Layer", "\u300a\u9e1f\u54e5\u7684Linux\u79c1\u623f\u83dc\u300b", "Linux \u78c1\u76d8\u9635\u5217", "\u300a\u9e1f\u54e5\u7684Linux\u79c1\u623f\u83dc\u300b", "learning", "\u300a\u9e1f\u54e5\u7684Linux\u79c1\u623f\u83dc\u300b", "major", "\u300a\u9e1f\u54e5\u7684Linux\u79c1\u623f\u83dc\u300b", "tethereal", "\u300a\u9e1f\u54e5\u7684Linux\u79c1\u623f\u83dc\u300b", "SMBus", "\u300a\u9e1f\u54e5\u7684Linux\u79c1\u623f\u83dc\u300b", "PCI\u9002\u914d\u5361", "\u300a\u9e1f\u54e5\u7684Linux\u79c1\u623f\u83dc\u300b", "pam_listfile.so", "\u300a\u9e1f\u54e5\u7684Linux\u79c1\u623f\u83dc\u300b", "NFS server over TCP\u652f\u6301", "\u300a\u9e1f\u54e5\u7684Linux\u79c1\u623f\u83dc\u300b", "Info reader", "\u300a\u9e1f\u54e5\u7684Linux\u79c1\u623f\u83dc\u300b", "SATA \u63d2\u69fd", "\u300a\u9e1f\u54e5\u7684Linux\u79c1\u623f\u83dc\u300b", "CIFS/remote\u8ba1\u7b97\u673a\u767b\u5f55\u4fe1\u606f\u8bb0\u5f55", "\u300a\u9e1f\u54e5\u7684Linux\u79c1\u623f\u83dc\u300b", "proftpd", "\u300a\u9e1f\u54e5\u7684Linux\u79c1\u623f\u83dc\u300b", "NS\u670d\u52a1", "\u300a\u9e1f\u54e5\u7684Linux\u79c1\u623f\u83dc\u300b", "operator", "\u300a\u9e1f\u54e5\u7684Linux\u79c1\u623f\u83dc\u300b", "smtpd_sasl_application_name", "\u300a\u9e1f\u54e5\u7684Linux\u79c1\u623f\u83dc\u300b", "Docker\u7f51\u7edc\u5361", "\u300a\u9e1f\u54e5\u7684Linux\u79c1\u623f\u83dc\u300b", "Start of Authority", "\u300a\u9e1f\u54e5\u7684Linux\u79c1\u623f\u83dc\u300b", "pwcheck_meth", "\u300a\u9e1f\u54e5\u7684Linux\u79c1\u623f\u83dc\u300b", "Screentheme", "\u300a\u9e1f\u54e5\u7684Linux\u79c1\u623f\u83dc\u300b", "boot/initrd-2.6.11-1.1", "\u300a\u9e1f\u54e5\u7684Linux\u79c1\u623f\u83dc\u300b", "dns resolver", "\u300a\u9e1f\u54e5\u7684Linux\u79c1\u623f\u83dc\u300b", "noip-2.1.3.http\u73af\u5883\u8bbe\u5b9a", "\u300a\u9e1f\u54e5\u7684Linux\u79c1\u623f\u83dc\u300b", "stage1", "\u300a\u9e1f\u54e5\u7684Linux\u79c1\u623f\u83dc\u300b", "\u7535\u529b\u8282\u7ea6", "\u300a\u9e1f\u54e5\u7684Linux\u79c1\u623f\u83dc\u300b", "Primary IDE\u63a5\u53e3", "\u300a\u9e1f\u54e5\u7684Linux\u79c1\u623f\u83dc\u300b", "Postfix Mail \u670d\u52a1\u5668ific", "\u300a\u9e1f\u54e5\u7684Linux\u79c1\u623f\u83dc\u300b", "optimization", "\u300a\u9e1f\u54e5\u7684Linux\u79c1\u623f\u83dc\u300b", "BIOS Time", "DCNN based human activity recognition framework with depth vision guiding.pdf", "\u4eba\u5de5\u667a\u80fd", "DCNN based human activity recognition framework with depth vision guiding.pdf", "ReLU\u5c42", "DCNN based human activity recognition framework with depth vision guiding.pdf", "\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc", "DCNN based human activity recognition framework with depth vision guiding.pdf", "LSTM", "DCNN based human activity recognition framework with depth vision guiding.pdf", "segmentation", "DCNN based human activity recognition framework with depth vision guiding.pdf", "action recognition", "DCNN based human activity recognition framework with depth vision guiding.pdf", "CNN", "DCNN based human activity recognition framework with depth vision guiding.pdf", "SVM", "DCNN based human activity recognition framework with depth vision guiding.pdf", "\u795e\u7ecf\u7f51\u7edc", "DCNN based human activity recognition framework with depth vision guiding.pdf", "\u652f\u6301\u5411\u91cf\u673a", "DCNN based human activity recognition framework with depth vision guiding.pdf", "\u4eba\u673a\u4ea4\u4e92", "DCNN based human activity recognition framework with depth vision guiding.pdf", "\u6df1\u5ea6\u5b66\u4e60", "DCNN based human activity recognition framework with depth vision guiding.pdf", "\u673a\u5668\u5b66\u4e60", "DCNN based human activity recognition framework with depth vision guiding.pdf", "batch normalization", "DCNN based human activity recognition framework with depth vision guiding.pdf", "ReLU", "DCNN based human activity recognition framework with depth vision guiding.pdf", "classifier", "DCNN based human activity recognition framework with depth vision guiding.pdf", "IoT", "DCNN based human activity recognition framework with depth vision guiding.pdf", "DNN", "DCNN based human activity recognition framework with depth vision guiding.pdf", "\u6807\u51c6\u5dee", "DCNN based human activity recognition framework with depth vision guiding.pdf", "predictive modeling", "DCNN based human activity recognition framework with depth vision guiding.pdf", "\u5f3a\u5316\u5b66\u4e60", "DCNN based human activity recognition framework with depth vision guiding.pdf", "k-means", "DCNN based human activity recognition framework with depth vision guiding.pdf", "\u81ea\u52a8\u5316\u90e8\u7f72", "DCNN based human activity recognition framework with depth vision guiding.pdf", "machine learning", "DCNN based human activity recognition framework with depth vision guiding.pdf", "serial number", "DCNN based human activity recognition framework with depth vision guiding.pdf", "\u7279\u5f81\u62bd\u53d6", "DCNN based human activity recognition framework with depth vision guiding.pdf", "\u7279\u5f81\u63d0\u53d6", "DCNN based human activity recognition framework with depth vision guiding.pdf", "speed", "DCNN based human activity recognition framework with depth vision guiding.pdf", "computer interface", "DCNN based human activity recognition framework with depth vision guiding.pdf", "BIDI-rectional LSTM", "DCNN based human activity recognition framework with depth vision guiding.pdf", "Kinect", "DCNN based human activity recognition framework with depth vision guiding.pdf", "activities", "DCNN based human activity recognition framework with depth vision guiding.pdf", "\u4fe1\u53f7\u5904\u7406\u7b97\u6cd5", "DCNN based human activity recognition framework with depth vision guiding.pdf", "Robustness", "DCNN based human activity recognition framework with depth vision guiding.pdf", "swarm\u51b3\u7b56\u8868", "DCNN based human activity recognition framework with depth vision guiding.pdf", "Kinect devices", "DCNN based human activity recognition framework with depth vision guiding.pdf", "joints", "DCNN based human activity recognition framework with depth vision guiding.pdf", "HCI", "DCNN based human activity recognition framework with depth vision guiding.pdf", "Kinect\u8bbe\u5907", "DCNN based human activity recognition framework with depth vision guiding.pdf", "Mechatronics", "DCNN based human activity recognition framework with depth vision guiding.pdf", "\u53cc\u91cd\u8fdc\u7a0b\u64cd\u4f5c", "DCNN based human activity recognition framework with depth vision guiding.pdf", "data processing units", "DCNN based human activity recognition framework with depth vision guiding.pdf", "earable \u4f20\u611f\u5668", "DCNN based human activity recognition framework with depth vision guiding.pdf", "Complexity", "DCNN based human activity recognition framework with depth vision guiding.pdf", "drifting\u566a\u58f0", "DCNN based human activity recognition framework with depth vision guiding.pdf", "signal sequences", "DCNN based human activity recognition framework with depth vision guiding.pdf", "Hk-medoids model", "DCNN based human activity recognition framework with depth vision guiding.pdf", "\u6df1\u5ea6\u6570\u636e guild.framework", "DCNN based human activity recognition framework with depth vision guiding.pdf", "\u4e24\u5411\u8fdc\u7a0b\u64cd\u4f5c", "DCNN based human activity recognition framework with depth vision guiding.pdf", "Neuro\u8ba1\u7b97\u673a", "Deep learning for sensor-based human activity recognition Overview, challenges, and opportunities.pdf", "summarization", "Deep learning for sensor-based human activity recognition Overview, challenges, and opportunities.pdf", "\u4eba\u5de5\u667a\u80fd", "Deep learning for sensor-based human activity recognition Overview, challenges, and opportunities.pdf", "\u53cd\u590d\u795e\u7ecf\u7f51\u7edc", "Deep learning for sensor-based human activity recognition Overview, challenges, and opportunities.pdf", "\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc", "Deep learning for sensor-based human activity recognition Overview, challenges, and opportunities.pdf", "Fully convolutional networks", "Deep learning for sensor-based human activity recognition Overview, challenges, and opportunities.pdf", "pooling", "Deep learning for sensor-based human activity recognition Overview, challenges, and opportunities.pdf", "fine-tuning", "Deep learning for sensor-based human activity recognition Overview, challenges, and opportunities.pdf", "LSTM", "Deep learning for sensor-based human activity recognition Overview, challenges, and opportunities.pdf", "LSTM\u7f51\u7edc", "Deep learning for sensor-based human activity recognition Overview, challenges, and opportunities.pdf", "data augmentation", "Deep learning for sensor-based human activity recognition Overview, challenges, and opportunities.pdf", "convolutional neural networks", "Deep learning for sensor-based human activity recognition Overview, challenges, and opportunities.pdf", "CNNs", "Deep learning for sensor-based human activity recognition Overview, challenges, and opportunities.pdf", "action recognition", "Deep learning for sensor-based human activity recognition Overview, challenges, and opportunities.pdf", "neural network", "Deep learning for sensor-based human activity recognition Overview, challenges, and opportunities.pdf", "CNN", "Deep learning for sensor-based human activity recognition Overview, challenges, and opportunities.pdf", "semantic segmentation", "Deep learning for sensor-based human activity recognition Overview, challenges, and opportunities.pdf", "LSTMs", "Deep learning for sensor-based human activity recognition Overview, challenges, and opportunities.pdf", "\u795e\u7ecf\u7f51\u7edc", "Deep learning for sensor-based human activity recognition Overview, challenges, and opportunities.pdf", "\u65e0\u76d1\u7763\u5b66\u4e60", "Deep learning for sensor-based human activity recognition Overview, challenges, and opportunities.pdf", "RNNs", "Deep learning for sensor-based human activity recognition Overview, challenges, and opportunities.pdf", "\u6570\u636e\u589e\u5f3a", "Deep learning for sensor-based human activity recognition Overview, challenges, and opportunities.pdf", "AlexNet", "Deep learning for sensor-based human activity recognition Overview, challenges, and opportunities.pdf", "\u4eba\u673a\u4ea4\u4e92", "Deep learning for sensor-based human activity recognition Overview, challenges, and opportunities.pdf", "autoencoder", "Deep learning for sensor-based human activity recognition Overview, challenges, and opportunities.pdf", "\u6df1\u5ea6\u5b66\u4e60", "Deep learning for sensor-based human activity recognition Overview, challenges, and opportunities.pdf", "attention mechanism", "Deep learning for sensor-based human activity recognition Overview, challenges, and opportunities.pdf", "\u6ce8\u610f\u529b\u673a\u5236", "Deep learning for sensor-based human activity recognition Overview, challenges, and opportunities.pdf", "Distribution Shift", "Deep learning for sensor-based human activity recognition Overview, challenges, and opportunities.pdf", "network", "Deep learning for sensor-based human activity recognition Overview, challenges, and opportunities.pdf", "ArtificialIntelligence", "Deep learning for sensor-based human activity recognition Overview, challenges, and opportunities.pdf", "\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b", "Deep learning for sensor-based human activity recognition Overview, challenges, and opportunities.pdf", "software", "Deep learning for sensor-based human activity recognition Overview, challenges, and opportunities.pdf", "\u673a\u5668\u5b66\u4e60", "Deep learning for sensor-based human activity recognition Overview, challenges, and opportunities.pdf", "users", "Deep learning for sensor-based human activity recognition Overview, challenges, and opportunities.pdf", "\u5927\u6570\u636e", "Deep learning for sensor-based human activity recognition Overview, challenges, and opportunities.pdf", "S3\u5b58\u50a8\u670d\u52a1", "Deep learning for sensor-based human activity recognition Overview, challenges, and opportunities.pdf", "\u68af\u5ea6\u6d88\u5931", "Deep learning for sensor-based human activity recognition Overview, challenges, and opportunities.pdf", "concept drift", "Deep learning for sensor-based human activity recognition Overview, challenges, and opportunities.pdf", "GPU", "Deep learning for sensor-based human activity recognition Overview, challenges, and opportunities.pdf", "DNN", "Deep learning for sensor-based human activity recognition Overview, challenges, and opportunities.pdf", "\u6df1\u5b66\u4e60", "Deep learning for sensor-based human activity recognition Overview, challenges, and opportunities.pdf", "depth camera", "Deep learning for sensor-based human activity recognition Overview, challenges, and opportunities.pdf", "Network", "Deep learning for sensor-based human activity recognition Overview, challenges, and opportunities.pdf", "Convolutional Neural Networks", "Deep learning for sensor-based human activity recognition Overview, challenges, and opportunities.pdf", "\u5bb9\u5668\u7f16\u6392", "Deep learning for sensor-based human activity recognition Overview, challenges, and opportunities.pdf", "natural language processing", "Deep learning for sensor-based human activity recognition Overview, challenges, and opportunities.pdf", "LSTM networks", "Deep learning for sensor-based human activity recognition Overview, challenges, and opportunities.pdf", "\u6807\u51c6\u5316", "Deep learning for sensor-based human activity recognition Overview, challenges, and opportunities.pdf", "Channel-based late fusion", "Deep learning for sensor-based human activity recognition Overview, challenges, and opportunities.pdf", "Convolutional Neural Network", "1-s2", "Kubernetes", "1-s2", "network", "1-s2", "graphics", "1-s2", "cloud computing platform", "1-s2", "global", "1-s2", "Python", "1-s2", "model", "1-s2", "PoseNet", "1-s2", "\u4eba\u4f53\u59ff\u52bf\u4f30\u8ba1", "1-s2", "Android", "1-s2", "DNN", "1-s2", "classification", "1-s2", "mapping", "1-s2", "Docker\u5bb9\u5668", "1-s2", "planning", "1-s2", "reliability", "1-s2", "\u81ea\u52a8\u5316\u90e8\u7f72", "1-s2", "cluster", "1-s2", "speed", "1-s2", "parallel", "1-s2", "features", "1-s2", "classi\ufb01cation experiments", "1-s2", "human motion", "1-s2", "robustness", "1-s2", "eigenvector", "1-s2", "distance measurement", "1-s2", "motion\u7279\u5f81", "1-s2", "Distance Measurement", "1-s2", "limbs", "1-s2", "self-similarity plot", "1-s2", "regions", "1-s2", "Central Nervous System", "1-s2", "matrix", "1-s2", "aerobics", "1-s2", "gradient", "1-s2", "freno-pa\u4eba\u5de5\u667a\u80fd", "1-s2", "filtering", "1-s2", "Visual motion perception", "1-s2", "data selection", "1-s2", "experiments", "1-s2", "\u4eba\u4f53\u8fd0\u52a8\u8bc6\u522b\uff0c\u964d\u7ef4\u7a7a\u95f4", "1-s2", "non-linear", "1-s2", "D.L. Swetscontrast", "1-s2", "Human Motion Model", "1-s2", "3D model-basedtracking", "1-s2", "bio\u52a8\u753b\u7684\u89c6\u89c9\u611f\u77e5\u548c\u5176\u5206\u6790\u6a21\u578bysis", "1-s2", "spread", "1-s2", "eigenvalue", "1-s2", "\u751f\u7269\u4f53\u8fd0\u52a8\u611f\u77e5", "1-s2", "\u51b2usions plots", "1-s2", "Kubernetes", "1-s2", "network", "1-s2", "graphics", "1-s2", "cloud computing platform", "1-s2", "global", "1-s2", "Python", "1-s2", "model", "1-s2", "PoseNet", "1-s2", "\u4eba\u4f53\u59ff\u52bf\u4f30\u8ba1", "1-s2", "Android", "1-s2", "DNN", "1-s2", "classification", "1-s2", "mapping", "1-s2", "Docker\u5bb9\u5668", "1-s2", "planning", "1-s2", "reliability", "1-s2", "\u81ea\u52a8\u5316\u90e8\u7f72", "1-s2", "cluster", "1-s2", "speed", "1-s2", "features", "1-s2", "robustness", "1-s2", "gradient", "1-s2", "measurement", "1-s2", "action classes", "1-s2", "Temporal segmentation", "1-s2", "Motion analysis", "1-s2", "GestureRecognition", "1-s2", "HMMs", "1-s2", "dimensions", "1-s2", "manifold", "1-s2", "silhouettes", "1-s2", "dynamic time warping", "1-s2", "human movement", "1-s2", "Pattern Recognition", "1-s2", "PCA", "1-s2", "action performance", "1-s2", "key pose matching", "1-s2", "Actions as space-time shapes", "1-s2", "sequences", "1-s2", "RANSAC", "1-s2", "split-based representation", "1-s2", "stability analysis", "1-s2", "trackingearning appearance", "1-s2", "European Conference on Computer Vision", "1-s2", "Image Segmentation by Region-based Affinity Fields", "1-s2", "HOF descriptors", "1-s2", "periodicity", "1-s2", "Isomap", "1-s2", "flexibility", "1-s2", "evaluation practice", "1-s2", "Kubernetes", "1-s2", "network", "1-s2", "graphics", "1-s2", "cloud computing platform", "1-s2", "Python", "1-s2", "model", "1-s2", "PoseNet", "1-s2", "\u4eba\u4f53\u59ff\u52bf\u4f30\u8ba1", "1-s2", "Android", "1-s2", "DNN", "1-s2", "classification", "1-s2", "planning", "1-s2", "reliability", "1-s2", "\u81ea\u52a8\u5316\u90e8\u7f72", "1-s2", "speed", "1-s2", "features", "1-s2", "robustness", "1-s2", "measurement", "1-s2", "dimensions", "1-s2", "dynamic time warping", "1-s2", "human movement", "1-s2", "tracking", "1-s2", "background", "1-s2", "correlation", "1-s2", "pose estimation", "1-s2", "movement", "1-s2", "value of feedback in physical education", "1-s2", "overall performance", "1-s2", "\u52a8\u6001\u65f6\u95f4\u53d8\u6362", "1-s2", "\u591a\u79cd\u7c7b\u578b\u7684\u953b\u70bc", "1-s2", "Teleccommunications Research Institute", "1-s2", "correctionsmotor variability", "1-s2", "Camera-based(web camera)", "1-s2", "Mediapipe", "1-s2", "usability issues", "1-s2", "comparisoGradient Boosting\u667a\u80fd yoga\u8bad\u7ec3\u7cfb\u7edf", "1-s2", "reviewed applications of pose estimation in motionhit distance", "1-s2", "alignment2D pose estimation", "1-s2", "CrossFit", "1-s2", "\u89d2\u5ea6", "1-s2", "iPad Pro", "1-s2", "Poseestimation", "1-s2", "convolutional layers", "1-s2", "audio-verbal", "1-s2", "augmented feedback", "1-s2", "\u89c4\u5212\u9002\u5e94\uff0cIntelliigent data analysis methods", "1-s2", "motion evaluation", "1-s2", "Relationship Encoding", "1-s2", "patient Performance", "1-s2", "ACM International Conference Proceeding Series", "2312", "optimization", "2312", "network", "2312", "\u56fe\u50cf\u9884\u5904\u7406", "2312", "TensorFlow", "2312", "model", "2312", "Recognition", "2312", "Pattern Recognition", "2312", "European Conference on Computer Vision", "2312", "motion prediction", "2312", "multiple instance learning", "2312", "motions", "2312", "dense human-carrier representation", "2312", "deep featur", "2312", "Forecasting", "2312", "global frameionship", "2312", "Spatio-temporal Transformer", "2312", "4D\u8fd0\u52a8\u53d8\u6362", "2312", "Advn ces in neural informa", "2312", "Desire", "2312", "\u7ebf\u6027\u7f16\u7801", "2312", "Learned Local Frame", "2312", "Graph\u795e\u7ecf\u7f51\u7edc", "2312", "CANonicalization", "2312", "Method FID", "2312", "Classification Accuracy", "2312", "encoderan-machine interaction", "2312", "Geometric Vector Perceptrons", "2312", "6D_transform", "2312", "EquivLayer", "2312", "Human-Whole-Body-Motion-Reaction", "2312", "canonical", "2312", "Handshake", "2312", "Motion Analysis", "2312", "Social affordance forecasting scheme", "2312", "Transformer", "2312", "human actor's motion coding", "2312", "Motion", "2312", "Action-conditioned", "2312", "HUMAN MOTION", "2312", "human actor motionsdataset", "2312", "4D backbone", "2312", "InterFormer", "2312", "Temporal attention", "2312", "Conditioned gen", "2312", "agents", "2312", "D-grasp", "2312", "User Preferencence", "2312", "humanoid reactor", "2312", "whole-body motion capture", "2312", "Ai choreographer", "2411", "operator", "2411", "optimization", "2411", "\u673a\u5668\u5b66\u4e60\u7b97\u6cd5", "2411", "model", "2411", "kernel", "2411", "modules", "2411", "human motion", "2411", "centroid", "2411", "robotics", "2411", "information", "2411", "Fourier\u53d8\u6362", "2411", "movements", "2411", "joint locations", "2411", "Computer Vis", "2411", "Machine Learning", "2411", "video analysis", "2411", "2D keypoints", "2411", "Euclidean distance", "2411", "evaluation", "2411", "Transformer", "2411", "forecasting", "2411", "MSE", "2411", "transformer", "2411", "singles tennis games", "2411", "recognizing", "2411", "Mean Euclidean Distance Error", "2411", "Bahdanau", "2411", "IceCV", "2411", "\u5e8f\u5217\u5bf9\u5e8f\u5217\u95ee\u9898\uff0ccentroid", "2411", "Body Pose", "2411", "time vec", "2411", "orientation", "2411", "Trajectory", "2411", "Tennis Player Trajectory", "2411", "2D\u56fe\u50cf\u5904\u7406", "2411", "normalization layer", "2411", "GUI\u811a\u672c\u56fe\u50cf\u6807\u8bb0", "2411", "Generative Pre-Training", "2411", "\u70ed\u56fe\uff0cBERT\uff0c\u5f02\u5e38\u4eba\u7fa4\u884c\u4e3a\u68c0\u6d4b\u963f\u59c6\u65af\u7279\u4e39\uff0c\u6bcf\u79d2\u6846\u67b6\u6570\uff0c\u73a9\u5bb6\u51e0\u4f55\u5f62\u72b6\uff0c\u5e8f\u5217\u9884\u6d4b\uff0c\u6a21\u578b\u9884\u6d4b\uff0c\u4f24\u5bb3\u9632\u6cbb\uff0c\u6ce8\u610f\u673a\u5236", "2411", "sensor information", "2411", "deep transformer", "2411", "Springer handbook of robotics", "2411", "body joint data model", "2411", "analysisgan", "2411", "Learning", "2411", "TrackNet\u6a21\u578b", "2411", "NBA", "2411", "broadcasting", "2411", "ball detection", "2411", "Deep learningassociation metric", "3D Ball Localization From A Single Calibrated Image_zh", "TensorFlow", "3D Ball Localization From A Single Calibrated Image_zh", "spatiotemporal approach", "3D Ball Localization From A Single Calibrated Image_zh", "survey", "3D Ball Localization From A Single Calibrated Image_zh", "Artificial Intelligence", "3D Ball Localization From A Single Calibrated Image_zh", "\u9ad8\u8d28\u91cf\u7403\u4f53\u7ef4\u5b9a\u4f4d", "3D Ball Localization From A Single Calibrated Image_zh", "\u6807\u51c6\u504f\u5dee", "3D Ball Localization From A Single Calibrated Image_zh", "calibrated\u6444\u50cf\u5934\uff0cProjection\u65b9\u6cd5\uff0c\u03b1\uff08\u6743\u503c\uff09\uff0c\u4e09\u7ef4\u5b9a", "3D Ball Localization From A Single Calibrated Image_zh", "\u970d\u592b\u5706\u53d8\u6362", "3D Ball Localization From A Single Calibrated Image_zh", "BallSeg-top1", "3D Ball Localization From A Single Calibrated Image_zh", "3D trajectory", "3D Ball Localization From A Single Calibrated Image_zh", "\u8bc6\u522b\u5f39\u9053\u8f68\u8ff9", "3D Ball Localization From A Single Calibrated Image_zh", "\u76f8\u673a\u77e9\u9635K", "3D Ball Localization From A Single Calibrated Image_zh", "DeepSport testset", "3D Ball Localization From A Single Calibrated Image_zh", "Hohl\u5706\u53d8\u6362\uff0cICNet\uff0c\u56fe\u50cf\u68af\u5ea6\uff0c\u5706\u5f62\u6ee4\u6ce2\u5668\uff0c\u81ea\u9002\u5e94\u9608\u503c\u6cd5\uff0c\u5377\u79ef\u795e\u7ecf\u7f51\u7edc", "3D Ball Localization From A Single Calibrated Image_zh", "Virtual replay", "3D Ball Localization From A Single Calibrated Image_zh", "LectureNotesinComputerScience", "3D Ball Localization From A Single Calibrated Image_zh", "Hoffmann\u5706\u53d8\u6362", "3D Ball Localization From A Single Calibrated Image_zh", "\u5355\u76f8\u673a\u8ffd\u8e2a", "3D Ball Localization From A Single Calibrated Image_zh", "DIP", "3D Ball Localization From A Single Calibrated Image_zh", "BallSeg", "3D Ball Localization From A Single Calibrated Image_zh", "Ball tracking", "3D Ball Localization From A Single Calibrated Image_zh", "Diederik P.Kingma", "3D Ball Localization From A Single Calibrated Image_zh", "\u7403\u4f53\u5b58\u50a8CNN\u65b9\u6cd5", "3D Ball Localization From A Single Calibrated Image_zh", "\u76d1\u89c6\u5b66\u4e60", "3D Ball Localization From A Single Calibrated Image_zh", "Fonds de la Recherche Scientifique - FNRS", "3D Ball Localization From A Single Calibrated Image_zh", "Gradient-based learning\u68c0\u6d4b", "3D Ball Localization From A Single Calibrated Image_zh", "\u7cbe\u5ea6\u8bc4\u4f30\u96c6", "3D Ball Localization From A Single Calibrated Image_zh", "Basket-APIDIS", "3D Ball Localization From A Single Calibrated Image_zh", "\u6e05\u6670\u53ef\u89c1\u6027", "3D Ball Localization From A Single Calibrated Image_zh", "\u5143\u53c2\u6570\uff08\u03b4\uff09y\u4f30\u8ba1", "3D Ball Localization From A Single Calibrated Image_zh", "annotation", "3D Ball Localization From A Single Calibrated Image_zh", "\u8bef\u62a5\u7387", "3D Ball Localization From A Single Calibrated Image_zh", "\u7ec6\u80de\u5206\u5272", "3D Ball Localization From A Single Calibrated Image_zh", "Dock\u5f39\u9053\u8f68\u8ff9", "3D Ball Localization From A Single Calibrated Image_zh", "PAMI-8(6)", "3D Ball Localization From A Single Calibrated Image_zh", "physically constrained interaction", "3D Ball Localization From A Single Calibrated Image_zh", "Glorot initializer", "3D Ball Localization From A Single Calibrated Image_zh", "Dis-tributed video acquisition", "3D Ball Localization From A Single Calibrated Image_zh", "Graph-based filtering of ballistictrajectory", "3D Ball Localization From A Single Calibrated Image_zh", "\u89c6\u9891\u6280\u672f", "3D Ball Localization From A Single Calibrated Image_zh", "APIDIS\u6570\u636e\u96c6", "3D Ball Localization From A Single Calibrated Image_zh", "\u7403\u8f68\u8ff9\u4f30\u8ba1", "3D Ball Localization From A Single Calibrated Image_zh", "3D\u7403\u4f53\u4f4d\u7f6e\u6807\u6ce8", "3D Ball Localization From A Single Calibrated Image_zh", "Huber\u635f\u5931", "3D Ball Localization From A Single Calibrated Image_zh", "\u5206\u6790\u4f53\u80b2", "3D Ball Localization From A Single Calibrated Image_zh", "ball trajectory tracking", "3D Ball Localization From A Single Calibrated Image_zh", "Andrew Zisserman", "3D Ball Localization From A Single Calibrated Image_zh", "LdJournal of Real-Time Image Processing", "3D Ball Localization From A Single Calibrated Image_zh", "\u4e2d\u5fc3+\u6295\u5f71\u65b9\u6cd5", "3D Ball Localization From A Single Calibrated Image_zh", "ICNet", "3D_Convolutional_Neural_Networks_for_Human_Action_Recognition", "classifier", "3D_Convolutional_Neural_Networks_for_Human_Action_Recognition", "DNN", "3D_Convolutional_Neural_Networks_for_Human_Action_Recognition", "kernel", "3D_Convolutional_Neural_Networks_for_Human_Action_Recognition", "Kernel", "3D_Convolutional_Neural_Networks_for_Human_Action_Recognition", "gradient", "3D_Convolutional_Neural_Networks_for_Human_Action_Recognition", "human action recognition", "3D_Convolutional_Neural_Networks_for_Human_Action_Recognition", "concatenation", "3D_Convolutional_Neural_Networks_for_Human_Action_Recognition", "motion information", "3D_Convolutional_Neural_Networks_for_Human_Action_Recognition", "unsupervised learning", "3D_Convolutional_Neural_Networks_for_Human_Action_Recognition", "tracking", "3D_Convolutional_Neural_Networks_for_Human_Action_Recognition", "PAMI", "3D_Convolutional_Neural_Networks_for_Human_Action_Recognition", "human action categories", "3D_Convolutional_Neural_Networks_for_Human_Action_Recognition", "Gabor filters", "3D_Convolutional_Neural_Networks_for_Human_Action_Recognition", "detector", "3D_Convolutional_Neural_Networks_for_Human_Action_Recognition", "scheme", "3D_Convolutional_Neural_Networks_for_Human_Action_Recognition", "bounding box", "3D_Convolutional_Neural_Networks_for_Human_Action_Recognition", "predictor", "3D_Convolutional_Neural_Networks_for_Human_Action_Recognition", "Evaluation", "3D_Convolutional_Neural_Networks_for_Human_Action_Recognition", "multimodalp", "3D_Convolutional_Neural_Networks_for_Human_Action_Recognition", "Brain-Computer Interfaces", "3D_Convolutional_Neural_Networks_for_Human_Action_Recognition", "Sparse Features with Limited Receptive Fields", "3D_Convolutional_Neural_Networks_for_Human_Action_Recognition", "L. Bottou", "3D_Convolutional_Neural_Networks_for_Human_Action_Recognition", "CNN for action recognition", "3D_Convolutional_Neural_Networks_for_Human_Action_Recognition", "video\u901a\u4fe1", "3D_Convolutional_Neural_Networks_for_Human_Action_Recognition", "Spatial dimensionson", "3D_Convolutional_Neural_Networks_for_Human_Action_Recognition", "IEEE ConfComputer Vision", "3D_Convolutional_Neural_Networks_for_Human_Action_Recognition", "Action Recognitionting invariance", "3D_Convolutional_Neural_Networks_for_Human_Action_Recognition", "Unsupervised Learning", "3D_Convolutional_Neural_Networks_for_Human_Action_Recognition", "\u667a\u80fd\u591a\u5a92\u4f53\u5185\u5bb9\u5206\u6790", "3D_Convolutional_Neural_Networks_for_Human_Action_Recognition", "Carnegie Mellon University (CMU)", "3D_Convolutional_Neural_Networks_for_Human_Action_Recognition", "NEC\u7684\u4eba\u884c\u4e3a\u8bc6\u522b\u7cfb\u7edf", "3D_Convolutional_Neural_Networks_for_Human_Action_Recognition", "ME degree", "3D_Convolutional_Neural_Networks_for_Human_Action_Recognition", "bioinformatics", "3D_Convolutional_Neural_Networks_for_Human_Action_Recognition", "CellToEar", "3D_Convolutional_Neural_Networks_for_Human_Action_Recognition", "\u9ad8\u7ea7\u8fd0\u52a8\u7279\u5f81", "3D_Convolutional_Neural_Networks_for_Human_Action_Recognition", "A Fast Learning Algorithm for Deep Belief Nets", "3D_Convolutional_Neural_Networks_for_Human_Action_Recognition", "unsupervised learning of human action", "3D_Convolutional_Neural_Networks_for_Human_Action_Recognition", "3D CNN architectures", "3D_Convolutional_Neural_Networks_for_Human_Action_Recognition", "spatiotemporal feature", "3D_Convolutional_Neural_Networks_for_Human_Action_Recognition", "proposal-based 3D\u5377\u79ef", "3D_Convolutional_Neural_Networks_for_Human_Action_Recognition", "unsupervisedfeaturelearning", "3D_Convolutional_Neural_Networks_for_Human_Action_Recognition", "recall", "3D_Convolutional_Neural_Networks_for_Human_Action_Recognition", "\u8f85\u52a9\u5355\u5143Local Spatio-Temporal Features", "3D_Convolutional_Neural_Networks_for_Human_Action_Recognition", "Samples Action", "3D_Convolutional_Neural_Networks_for_Human_Action_Recognition", "Learning Hierarchical Invariant Spatio-Temporal Feature3D\u5377\u79ef", "3D_Convolutional_Neural_Networks_for_Human_Action_Recognition", "hyperbolic tasigmoid\u51fd\u6570", "3D_Convolutional_Neural_Networks_for_Human_Action_Recognition", "visual object recognition", "3D_Convolutional_Neural_Networks_for_Human_Action_Recognition", "CNN model", "3D_Convolutional_Neural_Networks_for_Human_Action_Recognition", "Outstaconvolutions", "3D_Convolutional_Neural_Networks_for_Human_Action_Recognition", "\u591a\u91cd\u7279\u5f81\u62bd\u53d6", "923-Article Text-1720-2-10-20220519", "motion recognition", "923-Article Text-1720-2-10-20220519", "flexibility", "923-Article Text-1720-2-10-20220519", "feature extraction", "923-Article Text-1720-2-10-20220519", "movements", "923-Article Text-1720-2-10-20220519", "pose estimation", "923-Article Text-1720-2-10-20220519", "Mobilenetv2", "923-Article Text-1720-2-10-20220519", "\u4eba\u4f53\u59ff\u52bf\u4f30\u7b97", "923-Article Text-1720-2-10-20220519", "Human Pose Estimation", "923-Article Text-1720-2-10-20220519", "human-computer interaction", "923-Article Text-1720-2-10-20220519", "estimation", "923-Article Text-1720-2-10-20220519", "pose\u4f30\u8ba1", "923-Article Text-1720-2-10-20220519", "motion capture", "923-Article Text-1720-2-10-20220519", "Object Recognition", "923-Article Text-1720-2-10-20220519", "channels", "923-Article Text-1720-2-10-20220519", "nodal point attribution", "923-Article Text-1720-2-10-20220519", "reasonnable way", "923-Article Text-1720-2-10-20220519", "perceptual field", "923-Article Text-1720-2-10-20220519", "\u7ec6\u80de\u751f\u7269\u529b\u5b66", "923-Article Text-1720-2-10-20220519", "Paf heat map", "923-Article Text-1720-2-10-20220519", "enthusiasts", "923-Article Text-1720-2-10-20220519", "Network learning", "923-Article Text-1720-2-10-20220519", "bottom-up detection", "923-Article Text-1720-2-10-20220519", "PointwiseConvolution", "923-Article Text-1720-2-10-20220519", "Network Optimizing", "923-Article Text-1720-2-10-20220519", "human pose estimationion", "923-Article Text-1720-2-10-20220519", "Keypoint Confidence Mapints", "923-Article Text-1720-2-10-20220519", "joint embedding", "923-Article Text-1720-2-10-20220519", "heat map", "923-Article Text-1720-2-10-20220519", "badminton", "923-Article Text-1720-2-10-20220519", "figure", "923-Article Text-1720-2-10-20220519", "C-feature maps", "923-Article Text-1720-2-10-20220519", "Python 3.8", "923-Article Text-1720-2-10-20220519", "part affinity fields", "923-Article Text-1720-2-10-20220519", "Depthwise Separable Convolution", "923-Article Text-1720-2-10-20220519", "XC(3)", "923-Article Text-1720-2-10-20220519", "multiscale feature fusion", "923-Article Text-1720-2-10-20220519", "Polarized Self-Attention", "923-Article Text-1720-2-10-20220519", "OpenPose\u6a21\u578b", "923-Article Text-1720-2-10-20220519", "Mobilenets", "923-Article Text-1720-2-10-20220519", "Polarized Self-Attention Module", "923-Article Text-1720-2-10-20220519", "convolutional kernel", "923-Article Text-1720-2-10-20220519", "regular convolution", "923-Article Text-1720-2-10-20220519", "Conv DW", "923-Article Text-1720-2-10-20220519", "VConvolution", "923-Article Text-1720-2-10-20220519", "channel-by-channel convolution", "923-Article Text-1720-2-10-20220519", "Detectionman pose estimation", "923-Article Text-1720-2-10-20220519", "\u6570\u636ePose Estimationmotion", "923-Article Text-1720-2-10-20220519", "\u4eba\u4f53\u5173\u952e\u70b9\u68c0\u6d4b", "923-Article Text-1720-2-10-20220519", "\u5e8f\u5217\u578b\u591a\u5c3a\u5ea6\u7279\u5f81\u878d\u5408", "923-Article Text-1720-2-10-20220519", "image screening", "A survey on deep learning-based real-time crowd anomaly detection", "\u673a\u5668\u5b66\u4e60\u7b97\u6cd5", "A survey on deep learning-based real-time crowd anomaly detection", "application", "A survey on deep learning-based real-time crowd anomaly detection", "\u7269\u8054\u7f51", "A survey on deep learning-based real-time crowd anomaly detection", "IoT", "A survey on deep learning-based real-time crowd anomaly detection", "DNN", "A survey on deep learning-based real-time crowd anomaly detection", "classification", "A survey on deep learning-based real-time crowd anomaly detection", "cluster", "A survey on deep learning-based real-time crowd anomaly detection", "SVC", "A survey on deep learning-based real-time crowd anomaly detection", "features", "A survey on deep learning-based real-time crowd anomaly detection", "human motion", "A survey on deep learning-based real-time crowd anomaly detection", "dimensions", "A survey on deep learning-based real-time crowd anomaly detection", "motion detection", "A survey on deep learning-based real-time crowd anomaly detection", "surveillance", "A survey on deep learning-based real-time crowd anomaly detection", "local descriptor", "A survey on deep learning-based real-time crowd anomaly detection", "optical\u6d41", "A survey on deep learning-based real-time crowd anomaly detection", "datasets", "A survey on deep learning-based real-time crowd anomaly detection", "video analysis", "A survey on deep learning-based real-time crowd anomaly detection", "networks", "A survey on deep learning-based real-time crowd anomaly detection", "visual analytics", "A survey on deep learning-based real-time crowd anomaly detection", "video\u5e8f\u5217", "A survey on deep learning-based real-time crowd anomaly detection", "uncertainty", "A survey on deep learning-based real-time crowd anomaly detection", "deep learning", "A survey on deep learning-based real-time crowd anomaly detection", "Kalman filter", "A survey on deep learning-based real-time crowd anomaly detection", "\u56fe\u50cf\u5206\u6790", "A survey on deep learning-based real-time crowd anomaly detection", "convolutional neural network", "A survey on deep learning-based real-time crowd anomaly detection", "hybrid model", "A survey on deep learning-based real-time crowd anomaly detection", "\u533a\u57df\u6df1\u5ea6\u5377\u79ef\u795e\u7ecf\u7f51\u7edc", "A survey on deep learning-based real-time crowd anomaly detection", "uncertainty analysis", "A survey on deep learning-based real-time crowd anomaly detection", "Pedestrian behavior understanding", "A survey on deep learning-based real-time crowd anomaly detection", "fuzzy cognitive deep learning framework", "A survey on deep learning-based real-time crowd anomaly detection", "visual feature extraction", "A survey on deep learning-based real-time crowd anomaly detection", "\u4eba\u7c7b\u8fd0\u52a8\u68c0\u6d4b", "A survey on deep learning-based real-time crowd anomaly detection", "mixed\u51b3\u7b56\u7cfb\u7edf", "A survey on deep learning-based real-time crowd anomaly detection", "optimal responses", "A survey on deep learning-based real-time crowd anomaly detection", "adjusted procedures", "A survey on deep learning-based real-time crowd anomaly detection", "\u96c6\u4f53", "A survey on deep learning-based real-time crowd anomaly detection", "swarm intelligence", "A survey on deep learning-based real-time crowd anomaly detection", "\u7a7a\u95f4\u65f6\u95f4\u7279\u5f81", "A survey on deep learning-based real-time crowd anomaly detection", "\u89c6\u9891\u4fe1\u606f\u5904\u7406", "A survey on deep learning-based real-time crowd anomaly detection", "\u81ea\u884c\u8f66", "A survey on deep learning-based real-time crowd anomaly detection", "EM\u7b97\u6cd5", "A survey on deep learning-based real-time crowd anomaly detection", "hollystic", "A survey on deep learning-based real-time crowd anomaly detection", "distance-based margin", "A survey on deep learning-based real-time crowd anomaly detection", "regular convolutional layers", "A survey on deep learning-based real-time crowd anomaly detection", "human error", "A survey on deep learning-based real-time crowd anomaly detection", "\u73af\u5883\u76d1\u63a7", "A survey on deep learning-based real-time crowd anomaly detection", "Gaussian\u6df7\u5408\u6a21\u578b", "A survey on deep learning-based real-time crowd anomaly detection", "K-means++", "A survey on deep learning-based real-time crowd anomaly detection", "behavioral patternern detection", "A survey on deep learning-based real-time crowd anomaly detection", "attribute-based approach", "Deep learning in computer vision principles and applications (Mahmoud Hassaballah, Ali Ismail Awad) (Z-Library).pdf", "automated mapping", "Deep learning in computer vision principles and applications (Mahmoud Hassaballah, Ali Ismail Awad) (Z-Library).pdf", "empirical study", "Deep learning in computer vision principles and applications (Mahmoud Hassaballah, Ali Ismail Awad) (Z-Library).pdf", "summarization", "Deep learning in computer vision principles and applications (Mahmoud Hassaballah, Ali Ismail Awad) (Z-Library).pdf", "\u4eba\u5de5\u667a\u80fd", "Deep learning in computer vision principles and applications (Mahmoud Hassaballah, Ali Ismail Awad) (Z-Library).pdf", "\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc", "Deep learning in computer vision principles and applications (Mahmoud Hassaballah, Ali Ismail Awad) (Z-Library).pdf", "single-shot refinement object detection", "Deep learning in computer vision principles and applications (Mahmoud Hassaballah, Ali Ismail Awad) (Z-Library).pdf", "learning", "Deep learning in computer vision principles and applications (Mahmoud Hassaballah, Ali Ismail Awad) (Z-Library).pdf", "cvpr", "Deep learning in computer vision principles and applications (Mahmoud Hassaballah, Ali Ismail Awad) (Z-Library).pdf", "image features", "Deep learning in computer vision principles and applications (Mahmoud Hassaballah, Ali Ismail Awad) (Z-Library).pdf", "LSTM", "Deep learning in computer vision principles and applications (Mahmoud Hassaballah, Ali Ismail Awad) (Z-Library).pdf", "\u6df1\u5ea6\u5377\u79ef\u7f51\u7edc", "Deep learning in computer vision principles and applications (Mahmoud Hassaballah, Ali Ismail Awad) (Z-Library).pdf", "\u4eba\u8138\u8bc6\u522b", "Deep learning in computer vision principles and applications (Mahmoud Hassaballah, Ali Ismail Awad) (Z-Library).pdf", "data augmentation", "Deep learning in computer vision principles and applications (Mahmoud Hassaballah, Ali Ismail Awad) (Z-Library).pdf", "neural networks", "Deep learning in computer vision principles and applications (Mahmoud Hassaballah, Ali Ismail Awad) (Z-Library).pdf", "segmentation", "Deep learning in computer vision principles and applications (Mahmoud Hassaballah, Ali Ismail Awad) (Z-Library).pdf", "convolutional neural networks", "Deep learning in computer vision principles and applications (Mahmoud Hassaballah, Ali Ismail Awad) (Z-Library).pdf", "CNNs", "Deep learning in computer vision principles and applications (Mahmoud Hassaballah, Ali Ismail Awad) (Z-Library).pdf", "\u6df1\u5ea6\u5377\u79ef\u795e\u7ecf\u7f51\u7edc", "Deep learning in computer vision principles and applications (Mahmoud Hassaballah, Ali Ismail Awad) (Z-Library).pdf", "action recognition", "Deep learning in computer vision principles and applications (Mahmoud Hassaballah, Ali Ismail Awad) (Z-Library).pdf", "neural network", "Deep learning in computer vision principles and applications (Mahmoud Hassaballah, Ali Ismail Awad) (Z-Library).pdf", "CNN", "Deep learning in computer vision principles and applications (Mahmoud Hassaballah, Ali Ismail Awad) (Z-Library).pdf", "semantic segmentation", "Deep learning in computer vision principles and applications (Mahmoud Hassaballah, Ali Ismail Awad) (Z-Library).pdf", "Malignant Melanomas", "Deep learning in computer vision principles and applications (Mahmoud Hassaballah, Ali Ismail Awad) (Z-Library).pdf", "SVM", "Deep learning in computer vision principles and applications (Mahmoud Hassaballah, Ali Ismail Awad) (Z-Library).pdf", "\u795e\u7ecf\u7f51\u7edc", "Deep learning in computer vision principles and applications (Mahmoud Hassaballah, Ali Ismail Awad) (Z-Library).pdf", "geometry", "Deep learning in computer vision principles and applications (Mahmoud Hassaballah, Ali Ismail Awad) (Z-Library).pdf", "VGGnet", "Deep learning in computer vision principles and applications (Mahmoud Hassaballah, Ali Ismail Awad) (Z-Library).pdf", "AlexNet", "Deep learning in computer vision principles and applications (Mahmoud Hassaballah, Ali Ismail Awad) (Z-Library).pdf", "NIPS", "Deep learning in computer vision principles and applications (Mahmoud Hassaballah, Ali Ismail Awad) (Z-Library).pdf", "Unsupervised learning", "Deep learning in computer vision principles and applications (Mahmoud Hassaballah, Ali Ismail Awad) (Z-Library).pdf", "\u6df1\u5ea6\u5b66\u4e60", "Deep learning in computer vision principles and applications (Mahmoud Hassaballah, Ali Ismail Awad) (Z-Library).pdf", "ICML", "Deep learning in computer vision principles and applications (Mahmoud Hassaballah, Ali Ismail Awad) (Z-Library).pdf", "multimedia big data", "Deep learning in computer vision principles and applications (Mahmoud Hassaballah, Ali Ismail Awad) (Z-Library).pdf", "FPGAeleration", "Deep learning in computer vision principles and applications (Mahmoud Hassaballah, Ali Ismail Awad) (Z-Library).pdf", "AlexNet\u7ea7\u522b\u7684\u51c6\u786e\u7387", "Deep learning in computer vision principles and applications (Mahmoud Hassaballah, Ali Ismail Awad) (Z-Library).pdf", "Tensor", "Deep learning in computer vision principles and applications (Mahmoud Hassaballah, Ali Ismail Awad) (Z-Library).pdf", "Softmax\u51fd\u6570", "Deep learning in computer vision principles and applications (Mahmoud Hassaballah, Ali Ismail Awad) (Z-Library).pdf", "multi-layer perceptron", "Deep learning in computer vision principles and applications (Mahmoud Hassaballah, Ali Ismail Awad) (Z-Library).pdf", "ISCA\u7ed3\u6784\u7ea6\u675f", "Deep learning in computer vision principles and applications (Mahmoud Hassaballah, Ali Ismail Awad) (Z-Library).pdf", "Backpropagation", "Deep learning in computer vision principles and applications (Mahmoud Hassaballah, Ali Ismail Awad) (Z-Library).pdf", "Subcategory-aware convolutional neural networks", "Deep learning in computer vision principles and applications (Mahmoud Hassaballah, Ali Ismail Awad) (Z-Library).pdf", "Dynamic F\u00d7P", "Deep learning in computer vision principles and applications (Mahmoud Hassaballah, Ali Ismail Awad) (Z-Library).pdf", "KD-tree", "Deep learning in computer vision principles and applications (Mahmoud Hassaballah, Ali Ismail Awad) (Z-Library).pdf", "\u6743\u5229\u4fdd\u62a4", "Deep learning in computer vision principles and applications (Mahmoud Hassaballah, Ali Ismail Awad) (Z-Library).pdf", "openblas", "Deep learning in computer vision principles and applications (Mahmoud Hassaballah, Ali Ismail Awad) (Z-Library).pdf", "Fixed-Point Arithmetic", "Deep learning in computer vision principles and applications (Mahmoud Hassaballah, Ali Ismail Awad) (Z-Library).pdf", "self-driving car", "Deep learning in computer vision principles and applications (Mahmoud Hassaballah, Ali Ismail Awad) (Z-Library).pdf", "Entry Network", "Deep learning in computer vision principles and applications (Mahmoud Hassaballah, Ali Ismail Awad) (Z-Library).pdf", "fused-layer-accelerator", "Deep learning in computer vision principles and applications (Mahmoud Hassaballah, Ali Ismail Awad) (Z-Library).pdf", "\u56fe\u50cf\u8bc6\u522b", "Action recognition using optimized deep autoencoder and CNN for", "classifier", "Action recognition using optimized deep autoencoder and CNN for", "activation", "Action recognition using optimized deep autoencoder and CNN for", "classification", "Action recognition using optimized deep autoencoder and CNN for", "actionrecognition", "Action recognition using optimized deep autoencoder and CNN for", "motion information", "Action recognition using optimized deep autoencoder and CNN for", "duration", "Action recognition using optimized deep autoencoder and CNN for", "Recognition", "Action recognition using optimized deep autoencoder and CNN for", "surveillance", "Action recognition using optimized deep autoencoder and CNN for", "occlusion", "Action recognition using optimized deep autoencoder and CNN for", "\u5206\u7c7b\u7b97\u6cd5", "Action recognition using optimized deep autoencoder and CNN for", "optical flow", "Action recognition using optimized deep autoencoder and CNN for", "movement", "Action recognition using optimized deep autoencoder and CNN for", "deeplearning", "Action recognition using optimized deep autoencoder and CNN for", "MATLAB", "Action recognition using optimized deep autoencoder and CNN for", "Diversity", "Action recognition using optimized deep autoencoder and CNN for", "MSE", "Action recognition using optimized deep autoencoder and CNN for", "orientation", "Action recognition using optimized deep autoencoder and CNN for", "deep learning", "Action recognition using optimized deep autoencoder and CNN for", "recall", "Action recognition using optimized deep autoencoder and CNN for", "CNNarchitecture", "Action recognition using optimized deep autoencoder and CNN for", "3D CNN", "Action recognition using optimized deep autoencoder and CNN for", "CNN models", "Action recognition using optimized deep autoencoder and CNN for", "precision", "Action recognition using optimized deep autoencoder and CNN for", "Detection", "Action recognition using optimized deep autoencoder and CNN for", "ConvNets", "Action recognition using optimized deep autoencoder and CNN for", "VGG-16", "Action recognition using optimized deep autoencoder and CNN for", "backpropagation", "Action recognition using optimized deep autoencoder and CNN for", "VGG", "Action recognition using optimized deep autoencoder and CNN for", "Adeeplearningtoolbox", "Action recognition using optimized deep autoencoder and CNN for", "onlinevideo-stream", "Action recognition using optimized deep autoencoder and CNN for", "one-vs-all", "Action recognition using optimized deep autoencoder and CNN for", "Dense Autoencoder", "Action recognition using optimized deep autoencoder and CNN for", "Adjacent Predictions", "Action recognition using optimized deep autoencoder and CNN for", "Conv4b", "Action recognition using optimized deep autoencoder and CNN for", "deepcnns", "Action recognition using optimized deep autoencoder and CNN for", "Modelbehavior", "Action recognition using optimized deep autoencoder and CNN for", "texture", "Action recognition using optimized deep autoencoder and CNN for", "inPatternRecognition(ICPR)", "Action recognition using optimized deep autoencoder and CNN for", "Sensor-based activity recognition", "Action recognition using optimized deep autoencoder and CNN for", "SCIfusion", "Action recognition using optimized deep autoencoder and CNN for", "IterativeModel", "Action recognition using optimized deep autoencoder and CNN for", "VGG-16CNNmodel", "Action recognition using optimized deep autoencoder and CNN for", "horseracing", "Action recognition using optimized deep autoencoder and CNN for", "opticalflow", "Action recognition using optimized deep autoencoder and CNN for", "integralvideorepresentation", "Action recognition using optimized deep autoencoder and CNN for", "Actionrecognitionbydensetrajectories", "Action recognition using optimized deep autoencoder and CNN for", "humanmotionrecognitio", "Action recognition using optimized deep autoencoder and CNN for", "optimizationproblemitymodel", "Action recognition using optimized deep autoencoder and CNN for", "online datasream mining", "Action recognition using optimized deep autoencoder and CNN for", "datastreamconfidencescores", "Ball tracking and trajectory prediction system for tennis robots", "model", "Ball tracking and trajectory prediction system for tennis robots", "measurement", "Ball tracking and trajectory prediction system for tennis robots", "robotics", "Ball tracking and trajectory prediction system for tennis robots", "camera setup", "Ball tracking and trajectory prediction system for tennis robots", "noise reduction", "Ball tracking and trajectory prediction system for tennis robots", "background subtraction", "Ball tracking and trajectory prediction system for tennis robots", "movement", "Ball tracking and trajectory prediction system for tennis robots", "ball detection", "Ball tracking and trajectory prediction system for tennis robots", "resolution", "Ball tracking and trajectory prediction system for tennis robots", "image classification", "Ball tracking and trajectory prediction system for tennis robots", "\u8fd0\u52a8\u68c0\u6d4b", "Ball tracking and trajectory prediction system for tennis robots", "confusion matrix", "Ball tracking and trajectory prediction system for tennis robots", "robot vision", "Ball tracking and trajectory prediction system for tennis robots", "euclidean\u8ddd\u79bb", "Ball tracking and trajectory prediction system for tennis robots", "Hawk-eye", "Ball tracking and trajectory prediction system for tennis robots", "Real-time tracking", "Ball tracking and trajectory prediction system for tennis robots", "Tennis ball tracking", "Ball tracking and trajectory prediction system for tennis robots", "Reithler Ltime point", "Ball tracking and trajectory prediction system for tennis robots", "Creative Commons", "Ball tracking and trajectory prediction system for tennis robots", "\u5149\u5ea6\u5b66", "Ball tracking and trajectory prediction system for tennis robots", "vision system", "Ball tracking and trajectory prediction system for tennis robots", "error bound positiona", "Ball tracking and trajectory prediction system for tennis robots", "L \u2212 n X c", "Ball tracking and trajectory prediction system for tennis robots", "Pattern Analysis and Applications", "Ball tracking and trajectory prediction system for tennis robots", "connected component labelling", "Ball tracking and trajectory prediction system for tennis robots", "feature point matching", "Ball tracking and trajectory prediction system for tennis robots", "\u7403\u4f53\u4f4d\u7f6e\u8f6c\u6362", "Ball tracking and trajectory prediction system for tennis robots", "\u6df1\u5ea6\u56fe\u50cf\u5904\u7406", "Ball tracking and trajectory prediction system for tennis robots", "Two-pass connected analysis", "Ball tracking and trajectory prediction system for tennis robots", "neural\u7f51\u7edc\u7f16\u7801\u5668", "Ball tracking and trajectory prediction system for tennis robots", "z-axis", "Ball tracking and trajectory prediction system for tennis robots", "Ball Motion", "Ball tracking and trajectory prediction system for tennis robots", "A co s(45\u25e6\u2213co s-1A)", "Ball tracking and trajectory prediction system for tennis robots", "ference on Computer Vision", "Ball tracking and trajectory prediction system for tennis robots", "Prediction Model", "Ball tracking and trajectory prediction system for tennis robots", "vision\u7cfb\u7edf", "Ball tracking and trajectory prediction system for tennis robots", "Binarized deconvolution engine", "Ball tracking and trajectory prediction system for tennis robots", "Creative Commons Attribution-NonCommercial License", "Ball tracking and trajectory prediction system for tennis robots", "neural net-work", "Ball tracking and trajectory prediction system for tennis robots", "y ball trajectory prediction", "Ball tracking and trajectory prediction system for tennis robots", "MOG2 background subtract", "Ball tracking and trajectory prediction system for tennis robots", "real-world data", "Ball tracking and trajectory prediction system for tennis robots", "commercial reuse", "Ball tracking and trajectory prediction system for tennis robots", "dr a g\u7cfb\u6570", "Ball tracking and trajectory prediction system for tennis robots", "broadcast view", "Ball tracking and trajectory prediction system for tennis robots", "SPIE", "Ball tracking and trajectory prediction system for tennis robots", "upsampling layer", "Ball tracking and trajectory prediction system for tennis robots", "Tennis Robot", "Ball tracking and trajectory prediction system for tennis robots", "Owens Ngineering", "Ball tracking and trajectory prediction system for tennis robots", "tan \u22121", "Bilen_Dynamic_Image_Networks_CVPR_2016_paper", "operator", "Bilen_Dynamic_Image_Networks_CVPR_2016_paper", "optimization", "Bilen_Dynamic_Image_Networks_CVPR_2016_paper", "network", "Bilen_Dynamic_Image_Networks_CVPR_2016_paper", "DNN", "Bilen_Dynamic_Image_Networks_CVPR_2016_paper", "gradient", "Bilen_Dynamic_Image_Networks_CVPR_2016_paper", "video sequence", "Bilen_Dynamic_Image_Networks_CVPR_2016_paper", "video features", "Bilen_Dynamic_Image_Networks_CVPR_2016_paper", "datasets", "Bilen_Dynamic_Image_Networks_CVPR_2016_paper", "video", "Bilen_Dynamic_Image_Networks_CVPR_2016_paper", "max pooling", "Bilen_Dynamic_Image_Networks_CVPR_2016_paper", "3D convolution", "Bilen_Dynamic_Image_Networks_CVPR_2016_paper", "convolutional layer", "Bilen_Dynamic_Image_Networks_CVPR_2016_paper", "state-of-the-art", "Bilen_Dynamic_Image_Networks_CVPR_2016_paper", "backpropagation", "Bilen_Dynamic_Image_Networks_CVPR_2016_paper", "deep learning\u65b9\u6cd5", "Bilen_Dynamic_Image_Networks_CVPR_2016_paper", "_gradients", "Bilen_Dynamic_Image_Networks_CVPR_2016_paper", "input RGB video frames", "Bilen_Dynamic_Image_Networks_CVPR_2016_paper", "SVMs", "Bilen_Dynamic_Image_Networks_CVPR_2016_paper", "\u652f\u6301\u5411\u91cf regressi\u00f3n", "Bilen_Dynamic_Image_Networks_CVPR_2016_paper", "UCF101 dataset", "Bilen_Dynamic_Image_Networks_CVPR_2016_paper", "recurrent architectures", "Bilen_Dynamic_Image_Networks_CVPR_2016_paper", "time-averaged feature frames \u03c8t", "Bilen_Dynamic_Image_Networks_CVPR_2016_paper", "3D\u6df1\u5ea6\u5377\u79ef\u795e\u7ecf\u7f51\u7edc", "Bilen_Dynamic_Image_Networks_CVPR_2016_paper", "\u52a8\u6001\u6620\u5c04", "Bilen_Dynamic_Image_Networks_CVPR_2016_paper", "metricsoptical flow", "Bilen_Dynamic_Image_Networks_CVPR_2016_paper", "\u7ebf\u6027\u64cd\u4f5c", "Bilen_Dynamic_Image_Networks_CVPR_2016_paper", "d\u2217\u52a8\u529b\u56fe\uff0c\u6700\u5927\u503c\u51fd\u6570", "Bilen_Dynamic_Image_Networks_CVPR_2016_paper", "Soccer Juggling", "Bilen_Dynamic_Image_Networks_CVPR_2016_paper", "local features", "Bilen_Dynamic_Image_Networks_CVPR_2016_paper", "hand-crafted features", "Bilen_Dynamic_Image_Networks_CVPR_2016_paper", "\u5355\u52a8\u6001\u56fe\u50cf (SDI)", "Bilen_Dynamic_Image_Networks_CVPR_2016_paper", "im-age features", "Bilen_Dynamic_Image_Networks_CVPR_2016_paper", "Dynamics at Image Pixel Level", "Bilen_Dynamic_Image_Networks_CVPR_2016_paper", "longtermrecurrerecognitionconvolutional layers", "Bilen_Dynamic_Image_Networks_CVPR_2016_paper", "actionrecognition datasets", "Bilen_Dynamic_Image_Networks_CVPR_2016_paper", "RGB framenetworks", "Bilen_Dynamic_Image_Networks_CVPR_2016_paper", "approximate rank pooling", "Bilen_Dynamic_Image_Networks_CVPR_2016_paper", "hinge\u635f\u5931", "Bilen_Dynamic_Image_Networks_CVPR_2016_paper", "RankSVM", "Bilen_Dynamic_Image_Networks_CVPR_2016_paper", "\u94a2\u7434\u6f14\u594f", "Bilen_Dynamic_Image_Networks_CVPR_2016_paper", "rank pool-ing weighti", "Bilen_Dynamic_Image_Networks_CVPR_2016_paper", "Dual Representational learning", "Bilen_Dynamic_Image_Networks_CVPR_2016_paper", "\u68af\u5ea6\u53cd\u5411\u4f20\u64ad", "Bilen_Dynamic_Image_Networks_CVPR_2016_paper", "BVLC reference CaffeNet model", "Bilen_Dynamic_Image_Networks_CVPR_2016_paper", "motion\u56fe\u50cf", "Bilen_Dynamic_Image_Networks_CVPR_2016_paper", "net-works", "Bilen_Dynamic_Image_Networks_CVPR_2016_paper", "\u89c6\u9891\u957f\u671f\u52a8\u529b\u5b66", "Bilen_Dynamic_Image_Networks_CVPR_2016_paper", "reconstruction", "Bilen_Dynamic_Image_Networks_CVPR_2016_paper", "pixel intensities", "Bilen_Dynamic_Image_Networks_CVPR_2016_paper", "\u72b6\u6001-of-the-artCNN\u67b6\u6784", "Estimation of Camera Pose, Nonlinear.pdf", "quaternions", "Estimation of Camera Pose, Nonlinear.pdf", "image plane", "Estimation of Camera Pose, Nonlinear.pdf", "camera", "Estimation of Camera Pose, Nonlinear.pdf", "estimation of normalized camera projection matrix", "Estimation of Camera Pose, Nonlinear.pdf", "linear estimation for initial estimate", "Estimation of Camera Pose, Nonlinear.pdf", "camera projection matrix", "Estimation of Camera Pose, Nonlinear.pdf", "iterative estimation", "Estimation of Camera Pose, Nonlinear.pdf", "CALIBRATION", "Estimation of Camera Pose, Nonlinear.pdf", "Rotation matrix", "Estimation of Camera Pose, Nonlinear.pdf", "axis representation", "Estimation of Camera Pose, Nonlinear.pdf", "\u6b63\u5e38\u5316\u5750\u6807", "Estimation of Camera Pose, Nonlinear.pdf", "SO(3)", "Estimation of Camera Pose, Nonlinear.pdf", "Stereo \u89c6\u89c9", "Estimation of Camera Pose, Nonlinear.pdf", "Levenberg-Marquardt algorithm", "Estimation of Camera Pose, Nonlinear.pdf", "minimal parameterization", "Estimation of Camera Pose, Nonlinear.pdf", "\u76f8\u673a\u6a21\u578b", "Estimation of Camera Pose, Nonlinear.pdf", "Euclidean transformation", "Estimation of Camera Pose, Nonlinear.pdf", "covariance propagation", "Estimation of Camera Pose, Nonlinear.pdf", "cam\u0435\u0440aprojection", "Estimation of Camera Pose, Nonlinear.pdf", "Nonlinear estimation", "Estimation of Camera Pose, Nonlinear.pdf", "\u6b27\u62c9\u65cb\u8f6c\u5b9a\u7406", "Estimation of Camera Pose, Nonlinear.pdf", "Euler axis and angle", "Estimation of Camera Pose, Nonlinear.pdf", "\u89d2\u8f74\u8868\u793a", "Estimation of Camera Pose, Nonlinear.pdf", "Spherical linear interpolation (Slerp)", "Estimation of Camera Pose, Nonlinear.pdf", "camera translation vector", "Estimation of Camera Pose, Nonlinear.pdf", "CSE 252B", "Estimation of Camera Pose, Nonlinear.pdf", "normalized camera projectionection matrix", "Estimation of Camera Pose, Nonlinear.pdf", "\u50cf\u7d20\u77e9\u9635", "Estimation of Camera Pose, Nonlinear.pdf", "\u65cb\u8f6c\u89d2\u5ea6\u5173\u4e8e\u8f74\u7684\u5b9a\u4f4dterpol", "Estimation of Camera Pose, Nonlinear.pdf", "rotation matrix", "Estimation of Camera Pose, Nonlinear.pdf", "\u89d2\u8f74\u8868\u793a\u6cd5", "Estimation of Camera Pose, Nonlinear.pdf", "Computervision II", "Estimation of Camera Pose, Nonlinear.pdf", "Scheduling", "Estimation of Camera Pose, Nonlinear.pdf", "3D\u70b9\u5750\u6807\u7cfb", "Estimation of Camera Pose, Nonlinear.pdf", "\u4e09\u70b9\u76f8\u673a\u89c6\u89c9", "Estimation of Camera Pose, Nonlinear.pdf", "normalizedprojectionmatrixcross-correlation", "Estimation of Camera Pose, Nonlinear.pdf", "\u5355\u89c6\u89c9\u51e0\u4f55", "Estimation of Camera Pose, Nonlinear.pdf", "calibrated camera", "Estimation of Camera Pose, Nonlinear.pdf", "adjustment", "Estimation of Camera Pose, Nonlinear.pdf", "Levenberg-Marquardt\u7b97\u6cd5", "Estimation of Camera Pose, Nonlinear.pdf", "angle-axis", "Estimation of Camera Pose, Nonlinear.pdf", "Camera Projection\u77e9\u9635", "Estimation of Camera Pose, Nonlinear.pdf", "3D \u65cb\u8f6c", "Estimation of Camera Pose, Nonlinear.pdf", "Quaternion", "Estimation of Camera Pose, Nonlinear.pdf", "Linear estimation of normal", "Estimation of Camera Pose, Nonlinear.pdf", "Euler\u89d2\u5ea6", "Estimation of Camera Pose, Nonlinear.pdf", "3D\u91cd\u5efa", "Estimation of Camera Pose, Nonlinear.pdf", "\u6b27\u62c9\u8f6c\u6362\u5b9a\u7406", "Estimation of Camera Pose, Nonlinear.pdf", "Camera projection matrix", "Estimation of Camera Pose, Nonlinear.pdf", "3D\u65cb\u8f6c", "Fast R-CNN.pdf", "max-pooling", "Fast R-CNN.pdf", "pooling", "Fast R-CNN.pdf", "fine-tuning", "Fast R-CNN.pdf", "ImageNet", "Fast R-CNN.pdf", "data augmentation", "Fast R-CNN.pdf", "neural networks", "Fast R-CNN.pdf", "segmentation", "Fast R-CNN.pdf", "\u6df1\u5ea6\u5377\u79ef\u795e\u7ecf\u7f51\u7edc", "Fast R-CNN.pdf", "CaffeNet", "Fast R-CNN.pdf", "CNN", "Fast R-CNN.pdf", "SVM", "Fast R-CNN.pdf", "\u795e\u7ecf\u7f51\u7edc", "Fast R-CNN.pdf", "AlexNet", "Fast R-CNN.pdf", "\u6df1\u5ea6\u5b66\u4e60", "Fast R-CNN.pdf", "\u5377\u79ef\u5c42", "Fast R-CNN.pdf", "\u6df1\u5ea6\u7f51\u7edc", "Fast R-CNN.pdf", "softmax", "Fast R-CNN.pdf", "IoU", "Fast R-CNN.pdf", "Python", "Fast R-CNN.pdf", "Dense", "Fast R-CNN.pdf", "SGD", "Fast R-CNN.pdf", "loss function", "Fast R-CNN.pdf", "VGG16", "Fast R-CNN.pdf", "accuracy", "Fast R-CNN.pdf", "object detection", "Fast R-CNN.pdf", "R-CNN", "Fast R-CNN.pdf", "Detection object", "Fast R-CNN.pdf", "Convolutions", "Fast R-CNN.pdf", "bird", "Fast R-CNN.pdf", "classi\ufb01cation", "Fast R-CNN.pdf", "computer vision", "Fast R-CNN.pdf", "fully connected layers", "Fast R-CNN.pdf", "multi-task learning", "Fast R-CNN.pdf", "training data", "Fast R-CNN.pdf", "projection", "Fast R-CNN.pdf", "heuristic", "Fast R-CNN.pdf", "C++", "Fast R-CNN.pdf", "max pooling", "Fast R-CNN.pdf", "Convolutional Networks", "Fast R-CNN.pdf", "ConvNets", "Fast R-CNN.pdf", "localization", "Fast R-CNN.pdf", "selective search", "Fast R-CNN.pdf", "SVMs", "Fast R-CNN.pdf", "back-propagation", "Fast R-CNN.pdf", "fast R-CNN", "Fast R-CNN.pdf", "Caffe", "Fast R-CNN.pdf", "Object detection", "Fast R-CNN.pdf", "SVD", "Fast R-CNN.pdf", "bounding-box regression", "Fast R-CNN.pdf", "proposalfeature extraction", "Faster R-CNN.pdf", "\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc", "Faster R-CNN.pdf", "ImageNet", "Faster R-CNN.pdf", "neural networks", "Faster R-CNN.pdf", "segmentation", "Faster R-CNN.pdf", "CNNs", "Faster R-CNN.pdf", "CNN", "Faster R-CNN.pdf", "semantic segmentation", "Faster R-CNN.pdf", "SVM", "Faster R-CNN.pdf", "NIPS", "Faster R-CNN.pdf", "ReLU\u6fc0\u6d3b\u51fd\u6570", "Faster R-CNN.pdf", "\u53cd\u5411\u4f20\u64ad", "Faster R-CNN.pdf", "attention mechanism", "Faster R-CNN.pdf", "CPU", "Faster R-CNN.pdf", "feature map", "Faster R-CNN.pdf", "Kubernetes\u7ba1\u7406\u7cfb\u7edf", "Faster R-CNN.pdf", "\u6df1\u5ea6\u7f51\u7edc", "Faster R-CNN.pdf", "softmax", "Faster R-CNN.pdf", "S3\u5b58\u50a8\u670d\u52a1", "Faster R-CNN.pdf", "anchors", "Faster R-CNN.pdf", "momentum", "Faster R-CNN.pdf", "ReLU", "Faster R-CNN.pdf", "IoU", "Faster R-CNN.pdf", "classifier", "Faster R-CNN.pdf", "SGD", "Faster R-CNN.pdf", "Gaussian\u5206\u5e03", "Faster R-CNN.pdf", "GPU\u52a0\u901f", "Faster R-CNN.pdf", "GPU", "Faster R-CNN.pdf", "DNN", "Faster R-CNN.pdf", "layer", "Faster R-CNN.pdf", "models", "Faster R-CNN.pdf", "Convolutional Neural Networks", "Faster R-CNN.pdf", "classification", "Faster R-CNN.pdf", "cloud platform", "Faster R-CNN.pdf", "feature maps", "Faster R-CNN.pdf", "Convolutional Neural Network", "Faster R-CNN.pdf", "Docker\u5bb9\u5668", "Faster R-CNN.pdf", "Neural Information Processing Systems", "Faster R-CNN.pdf", "\u5377\u79ef\u795e\u7ecf\u7f51\u7edc", "Faster R-CNN.pdf", "region proposal network", "Faster R-CNN.pdf", "accuracy", "Faster R-CNN.pdf", "object detection", "Faster R-CNN.pdf", "\u5168\u8fde\u63a5\u5c42", "Faster R-CNN.pdf", "R-CNN", "Faster R-CNN.pdf", "\u81ea\u52a8\u5316\u90e8\u7f72", "Faster R-CNN.pdf", "arXiv", "Faster R-CNN.pdf", "AWS", "Faster R-CNN.pdf", "mouse", "Faster R-CNN.pdf", "bird", "Faster R-CNN.pdf", "sliding window", "Faster R-CNN.pdf", "\u5fae\u8c03\u5b66\u4e60\u7387", "Human segmentation in surveillance video with deep learning.pdf", "\u4eba\u5de5\u667a\u80fd", "Human segmentation in surveillance video with deep learning.pdf", "\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc", "Human segmentation in surveillance video with deep learning.pdf", "max-pooling", "Human segmentation in surveillance video with deep learning.pdf", "ImageNet", "Human segmentation in surveillance video with deep learning.pdf", "data augmentation", "Human segmentation in surveillance video with deep learning.pdf", "segmentation", "Human segmentation in surveillance video with deep learning.pdf", "motion blur", "Human segmentation in surveillance video with deep learning.pdf", "\u6df1\u5ea6\u5377\u79ef\u795e\u7ecf\u7f51\u7edc", "Human segmentation in surveillance video with deep learning.pdf", "neural network", "Human segmentation in surveillance video with deep learning.pdf", "RGB image", "Human segmentation in surveillance video with deep learning.pdf", "semantic segmentation", "Human segmentation in surveillance video with deep learning.pdf", "\u795e\u7ecf\u7f51\u7edc", "Human segmentation in surveillance video with deep learning.pdf", "\u4eba\u673a\u4ea4\u4e92", "Human segmentation in surveillance video with deep learning.pdf", "NIPS", "Human segmentation in surveillance video with deep learning.pdf", "\u6df1\u5ea6\u5b66\u4e60", "Human segmentation in surveillance video with deep learning.pdf", "network", "Human segmentation in surveillance video with deep learning.pdf", "\u56fe\u50cf\u8bc6\u522b", "Human segmentation in surveillance video with deep learning.pdf", "\u56fe\u50cf\u5904\u7406", "Human segmentation in surveillance video with deep learning.pdf", "uniform", "Human segmentation in surveillance video with deep learning.pdf", "\u7f16\u7801\u5668", "Human segmentation in surveillance video with deep learning.pdf", "NVIDIA", "Human segmentation in surveillance video with deep learning.pdf", "Class", "Human segmentation in surveillance video with deep learning.pdf", "Accuracy", "Human segmentation in surveillance video with deep learning.pdf", "\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b", "Human segmentation in surveillance video with deep learning.pdf", "video processing", "Human segmentation in surveillance video with deep learning.pdf", "\u673a\u5668\u5b66\u4e60", "Human segmentation in surveillance video with deep learning.pdf", "convolution", "Human segmentation in surveillance video with deep learning.pdf", "ReLU", "Human segmentation in surveillance video with deep learning.pdf", "SegNet", "Human segmentation in surveillance video with deep learning.pdf", "IoU", "Human segmentation in surveillance video with deep learning.pdf", "\u56fe\u50cf\u5206\u7c7b", "Human segmentation in surveillance video with deep learning.pdf", "DNN", "Human segmentation in surveillance video with deep learning.pdf", "kernel", "Human segmentation in surveillance video with deep learning.pdf", "Deep learning", "Human segmentation in surveillance video with deep learning.pdf", "loss function", "Human segmentation in surveillance video with deep learning.pdf", "epoch", "Human segmentation in surveillance video with deep learning.pdf", "Convolutional Neural Networks", "Human segmentation in surveillance video with deep learning.pdf", "\u5377\u79ef\u795e\u7ecf\u7f51\u7edc", "Human segmentation in surveillance video with deep learning.pdf", "\u6fc0\u6d3b\u51fd\u6570", "Human segmentation in surveillance video with deep learning.pdf", "semantic image segmentation", "Human segmentation in surveillance video with deep learning.pdf", "\u8ba1\u7b97\u673a\u89c6\u89c9", "Human segmentation in surveillance video with deep learning.pdf", "accuracy", "Human segmentation in surveillance video with deep learning.pdf", "object detection", "Human segmentation in surveillance video with deep learning.pdf", "\u5168\u8fde\u63a5\u5c42", "Human segmentation in surveillance video with deep learning.pdf", "\u673a\u5668\u89c6\u89c9", "Human segmentation in surveillance video with deep learning.pdf", "encoder", "Human segmentation in surveillance video with deep learning.pdf", "Adam\u7b97\u6cd5", "Human segmentation in surveillance video with deep learning.pdf", "dataset", "Human segmentation in surveillance video with deep learning.pdf", "\u56fe\u50cf\u5206\u5272", "Human segmentation in surveillance video with deep learning.pdf", "Semantic Segmentation", "Human_Action_Recognition_From_Various_Data_Modalities_A_Review.pdf", "motion patterns", "Human_Action_Recognition_From_Various_Data_Modalities_A_Review.pdf", "\u4eba\u5de5\u667a\u80fd", "Human_Action_Recognition_From_Various_Data_Modalities_A_Review.pdf", "3D filters", "Human_Action_Recognition_From_Various_Data_Modalities_A_Review.pdf", "\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc", "Human_Action_Recognition_From_Various_Data_Modalities_A_Review.pdf", "LSTM", "Human_Action_Recognition_From_Various_Data_Modalities_A_Review.pdf", "LSTM\u7f51\u7edc", "Human_Action_Recognition_From_Various_Data_Modalities_A_Review.pdf", "data augmentation", "Human_Action_Recognition_From_Various_Data_Modalities_A_Review.pdf", "Human Action Recognition", "Human_Action_Recognition_From_Various_Data_Modalities_A_Review.pdf", "convolutional neural networks", "Human_Action_Recognition_From_Various_Data_Modalities_A_Review.pdf", "CNNs", "Human_Action_Recognition_From_Various_Data_Modalities_A_Review.pdf", "action recognition", "Human_Action_Recognition_From_Various_Data_Modalities_A_Review.pdf", "neural network", "Human_Action_Recognition_From_Various_Data_Modalities_A_Review.pdf", "feature", "Human_Action_Recognition_From_Various_Data_Modalities_A_Review.pdf", "CNN", "Human_Action_Recognition_From_Various_Data_Modalities_A_Review.pdf", "\u795e\u7ecf\u7f51\u7edc", "Human_Action_Recognition_From_Various_Data_Modalities_A_Review.pdf", "RNNs", "Human_Action_Recognition_From_Various_Data_Modalities_A_Review.pdf", "\u4eba\u673a\u4ea4\u4e92", "Human_Action_Recognition_From_Various_Data_Modalities_A_Review.pdf", "autoencoder", "Human_Action_Recognition_From_Various_Data_Modalities_A_Review.pdf", "\u6df1\u5ea6\u5b66\u4e60", "Human_Action_Recognition_From_Various_Data_Modalities_A_Review.pdf", "rank pooling", "Human_Action_Recognition_From_Various_Data_Modalities_A_Review.pdf", "NLP", "Human_Action_Recognition_From_Various_Data_Modalities_A_Review.pdf", "multi-layer perceptron", "Human_Action_Recognition_From_Various_Data_Modalities_A_Review.pdf", "network", "Human_Action_Recognition_From_Various_Data_Modalities_A_Review.pdf", "CPU", "Human_Action_Recognition_From_Various_Data_Modalities_A_Review.pdf", "semi-supervised learning", "Human_Action_Recognition_From_Various_Data_Modalities_A_Review.pdf", "\u56fe\u50cf\u5904\u7406", "Human_Action_Recognition_From_Various_Data_Modalities_A_Review.pdf", "Computer Vision", "Human_Action_Recognition_From_Various_Data_Modalities_A_Review.pdf", "\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b", "Human_Action_Recognition_From_Various_Data_Modalities_A_Review.pdf", "video processing", "Human_Action_Recognition_From_Various_Data_Modalities_A_Review.pdf", "sparse representation", "Human_Action_Recognition_From_Various_Data_Modalities_A_Review.pdf", "convolution", "Human_Action_Recognition_From_Various_Data_Modalities_A_Review.pdf", "S3\u5b58\u50a8\u670d\u52a1", "Human_Action_Recognition_From_Various_Data_Modalities_A_Review.pdf", "DeepLearning", "Human_Action_Recognition_From_Various_Data_Modalities_A_Review.pdf", "Deep LSTM", "Human_Action_Recognition_From_Various_Data_Modalities_A_Review.pdf", "performance", "Human_Action_Recognition_From_Various_Data_Modalities_A_Review.pdf", "classifier", "Human_Action_Recognition_From_Various_Data_Modalities_A_Review.pdf", "GPU", "Human_Action_Recognition_From_Various_Data_Modalities_A_Review.pdf", "DNN", "Human_Action_Recognition_From_Various_Data_Modalities_A_Review.pdf", "\u534f\u540c\u5b66\u4e60", "Human_Action_Recognition_From_Various_Data_Modalities_A_Review.pdf", "VLSI", "Human_Action_Recognition_From_Various_Data_Modalities_A_Review.pdf", "depth camera", "Human_Action_Recognition_From_Various_Data_Modalities_A_Review.pdf", "Convolutional Neural Networks", "Human_Action_Recognition_From_Various_Data_Modalities_A_Review.pdf", "LSTM networks", "Human_Action_Recognition_From_Various_Data_Modalities_A_Review.pdf", "feature maps", "Human_Action_Recognition_From_Various_Data_Modalities_A_Review.pdf", "Docker\u5bb9\u5668", "Human_Action_Recognition_From_Various_Data_Modalities_A_Review.pdf", "\u5377\u79ef\u795e\u7ecf\u7f51\u7edc", "Human_Action_Recognition_From_Various_Data_Modalities_A_Review.pdf", "attention", "Human_Action_Recognition_From_Various_Data_Modalities_A_Review.pdf", "\u8ba1\u7b97\u673a\u89c6\u89c9", "Human_Action_Recognition_From_Various_Data_Modalities_A_Review.pdf", "Neural Network", "Human_Action_Recognition_From_Various_Data_Modalities_A_Review.pdf", "GRU", "IJCS_48_4_02.pdf", "\u4eba\u5de5\u667a\u80fd", "IJCS_48_4_02.pdf", "action recognition", "IJCS_48_4_02.pdf", "SVM\u5206\u7c7b\u5668", "IJCS_48_4_02.pdf", "CNN", "IJCS_48_4_02.pdf", "\u795e\u7ecf\u7f51\u7edc", "IJCS_48_4_02.pdf", "\u4eba\u673a\u4ea4\u4e92", "IJCS_48_4_02.pdf", "\u6df1\u5ea6\u5b66\u4e60", "IJCS_48_4_02.pdf", "knn", "IJCS_48_4_02.pdf", "PyTorch", "IJCS_48_4_02.pdf", "NVIDIA", "IJCS_48_4_02.pdf", "\u673a\u5668\u5b66\u4e60", "IJCS_48_4_02.pdf", "TensorFlow", "IJCS_48_4_02.pdf", "TensorFlow Lite", "IJCS_48_4_02.pdf", "epochs", "IJCS_48_4_02.pdf", "Keras", "IJCS_48_4_02.pdf", "\u4eba\u4f53\u59ff\u52bf\u4f30\u8ba1", "IJCS_48_4_02.pdf", "OpenCV", "IJCS_48_4_02.pdf", "VGG16", "IJCS_48_4_02.pdf", "Convolutional Neural Network", "IJCS_48_4_02.pdf", "\u591a\u6837\u6027", "IJCS_48_4_02.pdf", "dropout", "IJCS_48_4_02.pdf", "\u8ba1\u7b97\u673a\u89c6\u89c9", "IJCS_48_4_02.pdf", "accuracy", "IJCS_48_4_02.pdf", "Neural Network", "IJCS_48_4_02.pdf", "dataset", "IJCS_48_4_02.pdf", "\u4eba\u884c\u4e3a\u8bc6\u522b", "IJCS_48_4_02.pdf", "Sensors", "IJCS_48_4_02.pdf", "human activity recognition", "IJCS_48_4_02.pdf", "\u4eba\u5de5\u795e\u7ecf\u7f51\u7edc", "IJCS_48_4_02.pdf", "\u4eba\u673a\u8bc6\u522b", "IJCS_48_4_02.pdf", "CNN\u7ed3\u6784", "IJCS_48_4_02.pdf", "Kernel", "IJCS_48_4_02.pdf", "network depth", "IJCS_48_4_02.pdf", "Pattern Recognition", "IJCS_48_4_02.pdf", "Machine Learning", "IJCS_48_4_02.pdf", "Pose estimation", "IJCS_48_4_02.pdf", "Dataset", "IJCS_48_4_02.pdf", "COCOdataset", "IJCS_48_4_02.pdf", "image resolution", "IJCS_48_4_02.pdf", "recall", "IJCS_48_4_02.pdf", "\u4eba\u4f53\u52a8\u4f5c\u8bc6\u522b", "IJCS_48_4_02.pdf", "precision", "IJCS_48_4_02.pdf", "Part Affinity Fields", "IJCS_48_4_02.pdf", "OpenPose", "IJCS_48_4_02.pdf", "confidence", "IJCS_48_4_02.pdf", "EfficientNet", "IJCS_48_4_02.pdf", "Caffe", "IJCS_48_4_02.pdf", "GPU memory", "IJCS_48_4_02.pdf", "Object Detection", "IJCS_48_4_02.pdf", "Fusion", "Intelligent Video Analytics for Human Action Recognition The State of Knowledge.pdf", "\u4eba\u5de5\u667a\u80fd", "Intelligent Video Analytics for Human Action Recognition The State of Knowledge.pdf", "\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc", "Intelligent Video Analytics for Human Action Recognition The State of Knowledge.pdf", "LSTM", "Intelligent Video Analytics for Human Action Recognition The State of Knowledge.pdf", "\u4eba\u8138\u8bc6\u522b", "Intelligent Video Analytics for Human Action Recognition The State of Knowledge.pdf", "ImageNet", "Intelligent Video Analytics for Human Action Recognition The State of Knowledge.pdf", "Human Action Recognition", "Intelligent Video Analytics for Human Action Recognition The State of Knowledge.pdf", "segmentation", "Intelligent Video Analytics for Human Action Recognition The State of Knowledge.pdf", "CNNs", "Intelligent Video Analytics for Human Action Recognition The State of Knowledge.pdf", "action recognition", "Intelligent Video Analytics for Human Action Recognition The State of Knowledge.pdf", "UCF101", "Intelligent Video Analytics for Human Action Recognition The State of Knowledge.pdf", "RGB image", "Intelligent Video Analytics for Human Action Recognition The State of Knowledge.pdf", "CNN", "Intelligent Video Analytics for Human Action Recognition The State of Knowledge.pdf", "semantic segmentation", "Intelligent Video Analytics for Human Action Recognition The State of Knowledge.pdf", "SVM", "Intelligent Video Analytics for Human Action Recognition The State of Knowledge.pdf", "\u795e\u7ecf\u7f51\u7edc", "Intelligent Video Analytics for Human Action Recognition The State of Knowledge.pdf", "3D\u5377\u79ef\u795e\u7ecf\u7f51\u7edc", "Intelligent Video Analytics for Human Action Recognition The State of Knowledge.pdf", "RNNs", "Intelligent Video Analytics for Human Action Recognition The State of Knowledge.pdf", "AlexNet", "Intelligent Video Analytics for Human Action Recognition The State of Knowledge.pdf", "motion boundary description", "Intelligent Video Analytics for Human Action Recognition The State of Knowledge.pdf", "\u6df1\u5ea6\u5b66\u4e60", "Intelligent Video Analytics for Human Action Recognition The State of Knowledge.pdf", "\u52a8\u6001\u56fe\u50cf\u7f51\u7edc", "Intelligent Video Analytics for Human Action Recognition The State of Knowledge.pdf", "\u53cd\u5411\u4f20\u64ad", "Intelligent Video Analytics for Human Action Recognition The State of Knowledge.pdf", "CNN\u67b6\u6784", "Intelligent Video Analytics for Human Action Recognition The State of Knowledge.pdf", "Bert", "Intelligent Video Analytics for Human Action Recognition The State of Knowledge.pdf", "Optimization", "Intelligent Video Analytics for Human Action Recognition The State of Knowledge.pdf", "\u56fe\u50cf\u8bc6\u522b", "Intelligent Video Analytics for Human Action Recognition The State of Knowledge.pdf", "\u6b63\u5219\u5316", "Intelligent Video Analytics for Human Action Recognition The State of Knowledge.pdf", "\u56fe\u50cf\u5904\u7406", "Intelligent Video Analytics for Human Action Recognition The State of Knowledge.pdf", "Computer Vision", "Intelligent Video Analytics for Human Action Recognition The State of Knowledge.pdf", "storage", "Intelligent Video Analytics for Human Action Recognition The State of Knowledge.pdf", "Dense", "Intelligent Video Analytics for Human Action Recognition The State of Knowledge.pdf", "TensorFlow", "Intelligent Video Analytics for Human Action Recognition The State of Knowledge.pdf", "IoT", "Intelligent Video Analytics for Human Action Recognition The State of Knowledge.pdf", "\u4eba\u4f53\u59ff\u52bf\u4f30\u8ba1", "Intelligent Video Analytics for Human Action Recognition The State of Knowledge.pdf", "DNN", "Intelligent Video Analytics for Human Action Recognition The State of Knowledge.pdf", "surveillance videos", "Intelligent Video Analytics for Human Action Recognition The State of Knowledge.pdf", "cloud computing", "Intelligent Video Analytics for Human Action Recognition The State of Knowledge.pdf", "\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5", "Intelligent Video Analytics for Human Action Recognition The State of Knowledge.pdf", "Network", "Intelligent Video Analytics for Human Action Recognition The State of Knowledge.pdf", "Deep Learning", "Intelligent Video Analytics for Human Action Recognition The State of Knowledge.pdf", "LSTM networks", "Intelligent Video Analytics for Human Action Recognition The State of Knowledge.pdf", "object tracking", "Intelligent Video Analytics for Human Action Recognition The State of Knowledge.pdf", "Hessian", "Intelligent Video Analytics for Human Action Recognition The State of Knowledge.pdf", "\u7b97\u6cd5", "Intelligent Video Analytics for Human Action Recognition The State of Knowledge.pdf", "attention", "Intelligent Video Analytics for Human Action Recognition The State of Knowledge.pdf", "\u8ba1\u7b97\u673a\u89c6\u89c9", "Intelligent Video Analytics for Human Action Recognition The State of Knowledge.pdf", "Neural Network", "Intelligent Video Analytics for Human Action Recognition The State of Knowledge.pdf", "object detection", "Intelligent Video Analytics for Human Action Recognition The State of Knowledge.pdf", "Intel", "Intelligent Video Analytics for Human Action Recognition The State of Knowledge.pdf", "ResNet", "International Journal of Intelligent Systems - 2024 - Dastbaravardeh - Channel Attention\u2010Based Approach with Autoencoder.pdf", "\u4eba\u5de5\u667a\u80fd", "International Journal of Intelligent Systems - 2024 - Dastbaravardeh - Channel Attention\u2010Based Approach with Autoencoder.pdf", "\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc", "International Journal of Intelligent Systems - 2024 - Dastbaravardeh - Channel Attention\u2010Based Approach with Autoencoder.pdf", "learning", "International Journal of Intelligent Systems - 2024 - Dastbaravardeh - Channel Attention\u2010Based Approach with Autoencoder.pdf", "pooling", "International Journal of Intelligent Systems - 2024 - Dastbaravardeh - Channel Attention\u2010Based Approach with Autoencoder.pdf", "fine-tuning", "International Journal of Intelligent Systems - 2024 - Dastbaravardeh - Channel Attention\u2010Based Approach with Autoencoder.pdf", "LSTM", "International Journal of Intelligent Systems - 2024 - Dastbaravardeh - Channel Attention\u2010Based Approach with Autoencoder.pdf", "neural networks", "International Journal of Intelligent Systems - 2024 - Dastbaravardeh - Channel Attention\u2010Based Approach with Autoencoder.pdf", "CNNs", "International Journal of Intelligent Systems - 2024 - Dastbaravardeh - Channel Attention\u2010Based Approach with Autoencoder.pdf", "action recognition", "International Journal of Intelligent Systems - 2024 - Dastbaravardeh - Channel Attention\u2010Based Approach with Autoencoder.pdf", "UCF101", "International Journal of Intelligent Systems - 2024 - Dastbaravardeh - Channel Attention\u2010Based Approach with Autoencoder.pdf", "CNN", "International Journal of Intelligent Systems - 2024 - Dastbaravardeh - Channel Attention\u2010Based Approach with Autoencoder.pdf", "\u795e\u7ecf\u7f51\u7edc", "International Journal of Intelligent Systems - 2024 - Dastbaravardeh - Channel Attention\u2010Based Approach with Autoencoder.pdf", "videoframes", "International Journal of Intelligent Systems - 2024 - Dastbaravardeh - Channel Attention\u2010Based Approach with Autoencoder.pdf", "video frames", "International Journal of Intelligent Systems - 2024 - Dastbaravardeh - Channel Attention\u2010Based Approach with Autoencoder.pdf", "3D\u5377\u79ef", "International Journal of Intelligent Systems - 2024 - Dastbaravardeh - Channel Attention\u2010Based Approach with Autoencoder.pdf", "\u6df1\u5ea6\u5b66\u4e60", "International Journal of Intelligent Systems - 2024 - Dastbaravardeh - Channel Attention\u2010Based Approach with Autoencoder.pdf", "CNN\u67b6\u6784", "International Journal of Intelligent Systems - 2024 - Dastbaravardeh - Channel Attention\u2010Based Approach with Autoencoder.pdf", "flatten", "International Journal of Intelligent Systems - 2024 - Dastbaravardeh - Channel Attention\u2010Based Approach with Autoencoder.pdf", "\u56fe\u50cf\u5904\u7406", "International Journal of Intelligent Systems - 2024 - Dastbaravardeh - Channel Attention\u2010Based Approach with Autoencoder.pdf", "image recognition", "International Journal of Intelligent Systems - 2024 - Dastbaravardeh - Channel Attention\u2010Based Approach with Autoencoder.pdf", "Accuracy", "International Journal of Intelligent Systems - 2024 - Dastbaravardeh - Channel Attention\u2010Based Approach with Autoencoder.pdf", "Kubernetes\u7ba1\u7406\u7cfb\u7edf", "International Journal of Intelligent Systems - 2024 - Dastbaravardeh - Channel Attention\u2010Based Approach with Autoencoder.pdf", "video processing", "International Journal of Intelligent Systems - 2024 - Dastbaravardeh - Channel Attention\u2010Based Approach with Autoencoder.pdf", "\u673a\u5668\u5b66\u4e60", "International Journal of Intelligent Systems - 2024 - Dastbaravardeh - Channel Attention\u2010Based Approach with Autoencoder.pdf", "convolution", "International Journal of Intelligent Systems - 2024 - Dastbaravardeh - Channel Attention\u2010Based Approach with Autoencoder.pdf", "S3\u5b58\u50a8\u670d\u52a1", "International Journal of Intelligent Systems - 2024 - Dastbaravardeh - Channel Attention\u2010Based Approach with Autoencoder.pdf", "DeepLearning", "International Journal of Intelligent Systems - 2024 - Dastbaravardeh - Channel Attention\u2010Based Approach with Autoencoder.pdf", "ReLU", "International Journal of Intelligent Systems - 2024 - Dastbaravardeh - Channel Attention\u2010Based Approach with Autoencoder.pdf", "Training", "International Journal of Intelligent Systems - 2024 - Dastbaravardeh - Channel Attention\u2010Based Approach with Autoencoder.pdf", "SGD", "International Journal of Intelligent Systems - 2024 - Dastbaravardeh - Channel Attention\u2010Based Approach with Autoencoder.pdf", "IoT", "International Journal of Intelligent Systems - 2024 - Dastbaravardeh - Channel Attention\u2010Based Approach with Autoencoder.pdf", "Deep learning", "International Journal of Intelligent Systems - 2024 - Dastbaravardeh - Channel Attention\u2010Based Approach with Autoencoder.pdf", "transfer", "International Journal of Intelligent Systems - 2024 - Dastbaravardeh - Channel Attention\u2010Based Approach with Autoencoder.pdf", "Convolutional Neural Networks", "International Journal of Intelligent Systems - 2024 - Dastbaravardeh - Channel Attention\u2010Based Approach with Autoencoder.pdf", "license", "International Journal of Intelligent Systems - 2024 - Dastbaravardeh - Channel Attention\u2010Based Approach with Autoencoder.pdf", "feature maps", "International Journal of Intelligent Systems - 2024 - Dastbaravardeh - Channel Attention\u2010Based Approach with Autoencoder.pdf", "\u5377\u79ef\u795e\u7ecf\u7f51\u7edc", "International Journal of Intelligent Systems - 2024 - Dastbaravardeh - Channel Attention\u2010Based Approach with Autoencoder.pdf", "\u6fc0\u6d3b\u51fd\u6570", "International Journal of Intelligent Systems - 2024 - Dastbaravardeh - Channel Attention\u2010Based Approach with Autoencoder.pdf", "training", "International Journal of Intelligent Systems - 2024 - Dastbaravardeh - Channel Attention\u2010Based Approach with Autoencoder.pdf", "inference", "International Journal of Intelligent Systems - 2024 - Dastbaravardeh - Channel Attention\u2010Based Approach with Autoencoder.pdf", "accuracy", "International Journal of Intelligent Systems - 2024 - Dastbaravardeh - Channel Attention\u2010Based Approach with Autoencoder.pdf", "ReLU\u51fd\u6570", "International Journal of Intelligent Systems - 2024 - Dastbaravardeh - Channel Attention\u2010Based Approach with Autoencoder.pdf", "ResNet", "International Journal of Intelligent Systems - 2024 - Dastbaravardeh - Channel Attention\u2010Based Approach with Autoencoder.pdf", "\u635f\u5931\u51fd\u6570", "International Journal of Intelligent Systems - 2024 - Dastbaravardeh - Channel Attention\u2010Based Approach with Autoencoder.pdf", "signal processing", "International Journal of Intelligent Systems - 2024 - Dastbaravardeh - Channel Attention\u2010Based Approach with Autoencoder.pdf", "\u8d85\u5206\u8fa8\u7387", "International Journal of Intelligent Systems - 2024 - Dastbaravardeh - Channel Attention\u2010Based Approach with Autoencoder.pdf", "maxpooling", "International Journal of Intelligent Systems - 2024 - Dastbaravardeh - Channel Attention\u2010Based Approach with Autoencoder.pdf", "sampling", "International Journal of Intelligent Systems - 2024 - Dastbaravardeh - Channel Attention\u2010Based Approach with Autoencoder.pdf", "\u7279\u5f81\u63d0\u53d6", "International Journal of Intelligent Systems - 2024 - Dastbaravardeh - Channel Attention\u2010Based Approach with Autoencoder.pdf", "RNN", "LLM-v1.0.0.pdf", "bash", "LLM-v1.0.0.pdf", "\u4eba\u5de5\u667a\u80fd", "LLM-v1.0.0.pdf", "segmentation", "LLM-v1.0.0.pdf", "SVM", "LLM-v1.0.0.pdf", "\u65e0\u76d1\u7763\u5b66\u4e60", "LLM-v1.0.0.pdf", "\u6570\u636e\u589e\u5f3a", "LLM-v1.0.0.pdf", "\u6df1\u5ea6\u5b66\u4e60", "LLM-v1.0.0.pdf", "Kubernetes", "LLM-v1.0.0.pdf", "NLP", "LLM-v1.0.0.pdf", "embeddings", "LLM-v1.0.0.pdf", "Mysql", "LLM-v1.0.0.pdf", "Axes", "LLM-v1.0.0.pdf", "\u56fe\u50cf\u5904\u7406", "LLM-v1.0.0.pdf", "PyTorch", "LLM-v1.0.0.pdf", "tokenization", "LLM-v1.0.0.pdf", "Kubernetes\u7ba1\u7406\u7cfb\u7edf", "LLM-v1.0.0.pdf", "temperature", "LLM-v1.0.0.pdf", "\u4e91\u8ba1\u7b97\u5e73\u53f0", "LLM-v1.0.0.pdf", "\u673a\u5668\u5b66\u4e60", "LLM-v1.0.0.pdf", "S3\u5b58\u50a8\u670d\u52a1", "LLM-v1.0.0.pdf", "Python", "LLM-v1.0.0.pdf", "github", "LLM-v1.0.0.pdf", "Docker", "LLM-v1.0.0.pdf", "Android", "LLM-v1.0.0.pdf", "\u538b\u7f29\u6280\u672f", "LLM-v1.0.0.pdf", "cloud\u8ba1\u7b97\u5e73\u53f0", "LLM-v1.0.0.pdf", "cloud computing", "LLM-v1.0.0.pdf", "\u5bb9\u5668\u7f16\u6392", "LLM-v1.0.0.pdf", "\u5b66\u4e60\u7b97\u6cd5", "LLM-v1.0.0.pdf", "natural language processing", "LLM-v1.0.0.pdf", "\u81ea\u7136\u8bed\u8a00\u5904\u7406", "LLM-v1.0.0.pdf", "Docker\u5bb9\u5668", "LLM-v1.0.0.pdf", "service", "LLM-v1.0.0.pdf", "Button", "LLM-v1.0.0.pdf", "\u7ec6\u80de\u7ed3\u6784", "LLM-v1.0.0.pdf", "primary", "LLM-v1.0.0.pdf", "cross-platform", "LLM-v1.0.0.pdf", "\u7b97\u6cd5", "LLM-v1.0.0.pdf", "pandas", "LLM-v1.0.0.pdf", "numpy", "LLM-v1.0.0.pdf", "tokenizer", "LLM-v1.0.0.pdf", "\u667a\u80fd\u624b\u673a", "LLM-v1.0.0.pdf", "NumPy", "LLM-v1.0.0.pdf", "\u81ea\u52a8\u5316\u90e8\u7f72", "LLM-v1.0.0.pdf", "machine learning", "LLM-v1.0.0.pdf", "similarity", "LLM-v1.0.0.pdf", "axes", "LLM-v1.0.0.pdf", "Natural Language Processing", "LLM-v1.0.0.pdf", "smartphone", "LLM-v1.0.0.pdf", "density", "Mask R-CNN.pdf", "\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc", "Mask R-CNN.pdf", "segmentation", "Mask R-CNN.pdf", "convolutional neural networks", "Mask R-CNN.pdf", "CNN", "Mask R-CNN.pdf", "semantic segmentation", "Mask R-CNN.pdf", "\u6df1\u5ea6\u5b66\u4e60", "Mask R-CNN.pdf", "Kubernetes", "Mask R-CNN.pdf", "CPU", "Mask R-CNN.pdf", "APM", "Mask R-CNN.pdf", "class", "Mask R-CNN.pdf", "softmax", "Mask R-CNN.pdf", "S3\u5b58\u50a8\u670d\u52a1", "Mask R-CNN.pdf", "anchors", "Mask R-CNN.pdf", "momentum", "Mask R-CNN.pdf", "ReLU", "Mask R-CNN.pdf", "IoU", "Mask R-CNN.pdf", "Docker", "Mask R-CNN.pdf", "GPU", "Mask R-CNN.pdf", "inception-resnet", "Mask R-CNN.pdf", "Convolutional Neural Networks", "Mask R-CNN.pdf", "classification", "Mask R-CNN.pdf", "\u5bb9\u5668\u7f16\u6392", "Mask R-CNN.pdf", "Docker\u5bb9\u5668", "Mask R-CNN.pdf", "training", "Mask R-CNN.pdf", "sigmoid", "Mask R-CNN.pdf", "branch", "Mask R-CNN.pdf", "fork", "Mask R-CNN.pdf", "cross-entropy\u635f\u5931", "Mask R-CNN.pdf", "accuracy", "Mask R-CNN.pdf", "object detection", "Mask R-CNN.pdf", "ResNet", "Mask R-CNN.pdf", "R-CNN", "Mask R-CNN.pdf", "learning rate", "Mask R-CNN.pdf", "AWS", "Mask R-CNN.pdf", "baseline", "Mask R-CNN.pdf", "\u8d1f\u8f7d\u5747\u8861\u5668", "Mask R-CNN.pdf", "classi\ufb01cation", "Mask R-CNN.pdf", "Deep residual learning", "Mask R-CNN.pdf", "presentation", "Mask R-CNN.pdf", "training data", "Mask R-CNN.pdf", "classifiers", "Mask R-CNN.pdf", "robustness", "Mask R-CNN.pdf", "Restricted Boltzmann Machines", "Mask R-CNN.pdf", "FCN", "Mask R-CNN.pdf", "unsupervised learning", "Mask R-CNN.pdf", "feature extraction", "Mask R-CNN.pdf", "FCNs", "Mask R-CNN.pdf", "convolutions", "Mask R-CNN.pdf", "pipeline", "Mask R-CNN.pdf", "Human Pose Estimation", "OpenPose Realtime Multi-Person 2D PoseEstimation using Part Affinity Fields.pdf", "\u4eba\u8138\u8bc6\u522b", "OpenPose Realtime Multi-Person 2D PoseEstimation using Part Affinity Fields.pdf", "CNNs", "OpenPose Realtime Multi-Person 2D PoseEstimation using Part Affinity Fields.pdf", "CNN", "OpenPose Realtime Multi-Person 2D PoseEstimation using Part Affinity Fields.pdf", "DenseNet", "OpenPose Realtime Multi-Person 2D PoseEstimation using Part Affinity Fields.pdf", "NIPS", "OpenPose Realtime Multi-Person 2D PoseEstimation using Part Affinity Fields.pdf", "\u6df1\u5ea6\u5b66\u4e60", "OpenPose Realtime Multi-Person 2D PoseEstimation using Part Affinity Fields.pdf", "\u56fe\u50cf\u68c0\u6d4b", "OpenPose Realtime Multi-Person 2D PoseEstimation using Part Affinity Fields.pdf", "CPU", "OpenPose Realtime Multi-Person 2D PoseEstimation using Part Affinity Fields.pdf", "APM", "OpenPose Realtime Multi-Person 2D PoseEstimation using Part Affinity Fields.pdf", "\u56fe\u50cf\u5904\u7406", "OpenPose Realtime Multi-Person 2D PoseEstimation using Part Affinity Fields.pdf", "\u7f51\u7edc\u67b6\u6784", "OpenPose Realtime Multi-Person 2D PoseEstimation using Part Affinity Fields.pdf", "image recognition", "OpenPose Realtime Multi-Person 2D PoseEstimation using Part Affinity Fields.pdf", "\u4e91\u8ba1\u7b97\u5e73\u53f0", "OpenPose Realtime Multi-Person 2D PoseEstimation using Part Affinity Fields.pdf", "\u673a\u5668\u5b66\u4e60", "OpenPose Realtime Multi-Person 2D PoseEstimation using Part Affinity Fields.pdf", "S3\u5b58\u50a8\u670d\u52a1", "OpenPose Realtime Multi-Person 2D PoseEstimation using Part Affinity Fields.pdf", "IoU", "OpenPose Realtime Multi-Person 2D PoseEstimation using Part Affinity Fields.pdf", "GPU", "OpenPose Realtime Multi-Person 2D PoseEstimation using Part Affinity Fields.pdf", "\u4eba\u4f53\u59ff\u52bf\u4f30\u8ba1", "OpenPose Realtime Multi-Person 2D PoseEstimation using Part Affinity Fields.pdf", "DNN", "OpenPose Realtime Multi-Person 2D PoseEstimation using Part Affinity Fields.pdf", "\u975e\u6781\u5927\u503c\u6291\u5236", "OpenPose Realtime Multi-Person 2D PoseEstimation using Part Affinity Fields.pdf", "\u5bb9\u5668\u7f16\u6392", "OpenPose Realtime Multi-Person 2D PoseEstimation using Part Affinity Fields.pdf", "\u5377\u79ef\u795e\u7ecf\u7f51\u7edc", "OpenPose Realtime Multi-Person 2D PoseEstimation using Part Affinity Fields.pdf", "\u8ba1\u7b97\u673a\u89c6\u89c9", "OpenPose Realtime Multi-Person 2D PoseEstimation using Part Affinity Fields.pdf", "ResNet", "OpenPose Realtime Multi-Person 2D PoseEstimation using Part Affinity Fields.pdf", "DARPA", "OpenPose Realtime Multi-Person 2D PoseEstimation using Part Affinity Fields.pdf", "\u635f\u5931\u51fd\u6570", "OpenPose Realtime Multi-Person 2D PoseEstimation using Part Affinity Fields.pdf", "\u903b\u8f91\u56de\u5f52", "OpenPose Realtime Multi-Person 2D PoseEstimation using Part Affinity Fields.pdf", "\u68af\u5ea6\u6d88\u5931\u95ee\u9898", "OpenPose Realtime Multi-Person 2D PoseEstimation using Part Affinity Fields.pdf", "AWS", "OpenPose Realtime Multi-Person 2D PoseEstimation using Part Affinity Fields.pdf", "\u56fe\u6a21\u578b", "OpenPose Realtime Multi-Person 2D PoseEstimation using Part Affinity Fields.pdf", "self-supervised learning", "OpenPose Realtime Multi-Person 2D PoseEstimation using Part Affinity Fields.pdf", "IROS", "OpenPose Realtime Multi-Person 2D PoseEstimation using Part Affinity Fields.pdf", "\u4eba\u5de5\u795e\u7ecf\u7f51\u7edc", "OpenPose Realtime Multi-Person 2D PoseEstimation using Part Affinity Fields.pdf", "pose estimation", "OpenPose Realtime Multi-Person 2D PoseEstimation using Part Affinity Fields.pdf", "Human pose estimation", "OpenPose Realtime Multi-Person 2D PoseEstimation using Part Affinity Fields.pdf", "Human Pose Estimation", "OpenPose Realtime Multi-Person 2D PoseEstimation using Part Affinity Fields.pdf", "Dataset", "OpenPose Realtime Multi-Person 2D PoseEstimation using Part Affinity Fields.pdf", "networks", "OpenPose Realtime Multi-Person 2D PoseEstimation using Part Affinity Fields.pdf", "Faster R-CNN", "OpenPose Realtime Multi-Person 2D PoseEstimation using Part Affinity Fields.pdf", "Ssd", "OpenPose Realtime Multi-Person 2D PoseEstimation using Part Affinity Fields.pdf", "\u56fe\u50cf\u5206\u6790", "OpenPose Realtime Multi-Person 2D PoseEstimation using Part Affinity Fields.pdf", "part affinity fields", "OpenPose Realtime Multi-Person 2D PoseEstimation using Part Affinity Fields.pdf", "\u4eba\u4f53\u5173\u952e\u70b9\u68c0\u6d4b", "OpenPose Realtime Multi-Person 2D PoseEstimation using Part Affinity Fields.pdf", "Part Affinity Fields", "OpenPose Realtime Multi-Person 2D PoseEstimation using Part Affinity Fields.pdf", "keypoint detection", "OpenPose Realtime Multi-Person 2D PoseEstimation using Part Affinity Fields.pdf", "OpenPose", "OpenPose Realtime Multi-Person 2D PoseEstimation using Part Affinity Fields.pdf", "VGG-19", "OpenPose Realtime Multi-Person 2D PoseEstimation using Part Affinity Fields.pdf", "OpenCL", "OpenPose Realtime Multi-Person 2D PoseEstimation using Part Affinity Fields.pdf", "\u5355\u4f4d\u5411\u91cf", "OpenPose Realtime Multi-Person 2D PoseEstimation using Part Affinity Fields.pdf", "L2\u635f\u5931", "Pedestrian attribute recognition A survey.pdf", "\u4eba\u5de5\u667a\u80fd", "Pedestrian attribute recognition A survey.pdf", "learning", "Pedestrian attribute recognition A survey.pdf", "LSTM\u7f51\u7edc", "Pedestrian attribute recognition A survey.pdf", "\u4eba\u8138\u8bc6\u522b", "Pedestrian attribute recognition A survey.pdf", "data augmentation", "Pedestrian attribute recognition A survey.pdf", "neural networks", "Pedestrian attribute recognition A survey.pdf", "motion blur", "Pedestrian attribute recognition A survey.pdf", "SVM\u5206\u7c7b\u5668", "Pedestrian attribute recognition A survey.pdf", "CNN", "Pedestrian attribute recognition A survey.pdf", "SVM", "Pedestrian attribute recognition A survey.pdf", "\u795e\u7ecf\u7f51\u7edc", "Pedestrian attribute recognition A survey.pdf", "\u6570\u636e\u589e\u5f3a", "Pedestrian attribute recognition A survey.pdf", "AlexNet", "Pedestrian attribute recognition A survey.pdf", "NIPS", "Pedestrian attribute recognition A survey.pdf", "\u6df1\u5ea6\u5b66\u4e60", "Pedestrian attribute recognition A survey.pdf", "\u8d1f\u8f7d\u5747\u8861", "Pedestrian attribute recognition A survey.pdf", "feature map", "Pedestrian attribute recognition A survey.pdf", "\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b", "Pedestrian attribute recognition A survey.pdf", "\u673a\u5668\u5b66\u4e60", "Pedestrian attribute recognition A survey.pdf", "S3\u5b58\u50a8\u670d\u52a1", "Pedestrian attribute recognition A survey.pdf", "logistic\u56de\u5f52", "Pedestrian attribute recognition A survey.pdf", "DNN", "Pedestrian attribute recognition A survey.pdf", "loss function", "Pedestrian attribute recognition A survey.pdf", "\u591a\u4efb\u52a1\u5b66\u4e60", "Pedestrian attribute recognition A survey.pdf", "\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5", "Pedestrian attribute recognition A survey.pdf", "\u5b66\u4e60\u7b97\u6cd5", "Pedestrian attribute recognition A survey.pdf", "\u81ea\u7136\u8bed\u8a00\u5904\u7406", "Pedestrian attribute recognition A survey.pdf", "Deep Learning", "Pedestrian attribute recognition A survey.pdf", "feature maps", "Pedestrian attribute recognition A survey.pdf", "Docker\u5bb9\u5668", "Pedestrian attribute recognition A survey.pdf", "\u5377\u79ef\u795e\u7ecf\u7f51\u7edc", "Pedestrian attribute recognition A survey.pdf", "SIFT", "Pedestrian attribute recognition A survey.pdf", "\u7b97\u6cd5", "Pedestrian attribute recognition A survey.pdf", "\u4ea4\u53c9\u71b5\u635f\u5931", "Pedestrian attribute recognition A survey.pdf", "attention", "Pedestrian attribute recognition A survey.pdf", "\u7aef\u5230\u7aef\u5b66\u4e60", "Pedestrian attribute recognition A survey.pdf", "\u8ba1\u7b97\u673a\u89c6\u89c9", "Pedestrian attribute recognition A survey.pdf", "CNN-based", "Pedestrian attribute recognition A survey.pdf", "object detection", "Pedestrian attribute recognition A survey.pdf", "\u6c60\u5316\u5c42", "Pedestrian attribute recognition A survey.pdf", "Natural Language Processing", "Pedestrian attribute recognition A survey.pdf", "AWS", "Pedestrian attribute recognition A survey.pdf", "\u7279\u5f81\u63d0\u53d6", "Pedestrian attribute recognition A survey.pdf", "RNN", "Pedestrian attribute recognition A survey.pdf", "pattern recognition", "Pedestrian attribute recognition A survey.pdf", "modules", "Pedestrian attribute recognition A survey.pdf", "self-supervised learning", "Pedestrian attribute recognition A survey.pdf", "Robustness", "Pedestrian attribute recognition A survey.pdf", "incremental learning", "Pedestrian attribute recognition A survey.pdf", "computer vision", "Pose2Trajectory \u4f7f\u7528 Transformers \u57fa\u4e8e\u8eab\u4f53\u59ff\u52bf\u9884\u6d4b\u7f51\u7403\u8fd0\u52a8\u5458\u7684\u8f68\u8ff9.pdf", "\u4eba\u5de5\u667a\u80fd", "Pose2Trajectory \u4f7f\u7528 Transformers \u57fa\u4e8e\u8eab\u4f53\u59ff\u52bf\u9884\u6d4b\u7f51\u7403\u8fd0\u52a8\u5458\u7684\u8f68\u8ff9.pdf", "LSTM", "Pose2Trajectory \u4f7f\u7528 Transformers \u57fa\u4e8e\u8eab\u4f53\u59ff\u52bf\u9884\u6d4b\u7f51\u7403\u8fd0\u52a8\u5458\u7684\u8f68\u8ff9.pdf", "neural network", "Pose2Trajectory \u4f7f\u7528 Transformers \u57fa\u4e8e\u8eab\u4f53\u59ff\u52bf\u9884\u6d4b\u7f51\u7403\u8fd0\u52a8\u5458\u7684\u8f68\u8ff9.pdf", "CNN", "Pose2Trajectory \u4f7f\u7528 Transformers \u57fa\u4e8e\u8eab\u4f53\u59ff\u52bf\u9884\u6d4b\u7f51\u7403\u8fd0\u52a8\u5458\u7684\u8f68\u8ff9.pdf", "Kubernetes", "Pose2Trajectory \u4f7f\u7528 Transformers \u57fa\u4e8e\u8eab\u4f53\u59ff\u52bf\u9884\u6d4b\u7f51\u7403\u8fd0\u52a8\u5458\u7684\u8f68\u8ff9.pdf", "Computer Vision", "Pose2Trajectory \u4f7f\u7528 Transformers \u57fa\u4e8e\u8eab\u4f53\u59ff\u52bf\u9884\u6d4b\u7f51\u7403\u8fd0\u52a8\u5458\u7684\u8f68\u8ff9.pdf", "\u673a\u5668\u5b66\u4e60", "Pose2Trajectory \u4f7f\u7528 Transformers \u57fa\u4e8e\u8eab\u4f53\u59ff\u52bf\u9884\u6d4b\u7f51\u7403\u8fd0\u52a8\u5458\u7684\u8f68\u8ff9.pdf", "Signal Processing", "Pose2Trajectory \u4f7f\u7528 Transformers \u57fa\u4e8e\u8eab\u4f53\u59ff\u52bf\u9884\u6d4b\u7f51\u7403\u8fd0\u52a8\u5458\u7684\u8f68\u8ff9.pdf", "Docker", "Pose2Trajectory \u4f7f\u7528 Transformers \u57fa\u4e8e\u8eab\u4f53\u59ff\u52bf\u9884\u6d4b\u7f51\u7403\u8fd0\u52a8\u5458\u7684\u8f68\u8ff9.pdf", "\u5bb9\u5668\u7f16\u6392", "Pose2Trajectory \u4f7f\u7528 Transformers \u57fa\u4e8e\u8eab\u4f53\u59ff\u52bf\u9884\u6d4b\u7f51\u7403\u8fd0\u52a8\u5458\u7684\u8f68\u8ff9.pdf", "Deep Learning", "Pose2Trajectory \u4f7f\u7528 Transformers \u57fa\u4e8e\u8eab\u4f53\u59ff\u52bf\u9884\u6d4b\u7f51\u7403\u8fd0\u52a8\u5458\u7684\u8f68\u8ff9.pdf", "dropout", "Pose2Trajectory \u4f7f\u7528 Transformers \u57fa\u4e8e\u8eab\u4f53\u59ff\u52bf\u9884\u6d4b\u7f51\u7403\u8fd0\u52a8\u5458\u7684\u8f68\u8ff9.pdf", "object detection", "Pose2Trajectory \u4f7f\u7528 Transformers \u57fa\u4e8e\u8eab\u4f53\u59ff\u52bf\u9884\u6d4b\u7f51\u7403\u8fd0\u52a8\u5458\u7684\u8f68\u8ff9.pdf", "R-CNN", "Pose2Trajectory \u4f7f\u7528 Transformers \u57fa\u4e8e\u8eab\u4f53\u59ff\u52bf\u9884\u6d4b\u7f51\u7403\u8fd0\u52a8\u5458\u7684\u8f68\u8ff9.pdf", "\u81ea\u52a8\u5316\u90e8\u7f72", "Pose2Trajectory \u4f7f\u7528 Transformers \u57fa\u4e8e\u8eab\u4f53\u59ff\u52bf\u9884\u6d4b\u7f51\u7403\u8fd0\u52a8\u5458\u7684\u8f68\u8ff9.pdf", "machine learning", "Pose2Trajectory \u4f7f\u7528 Transformers \u57fa\u4e8e\u8eab\u4f53\u59ff\u52bf\u9884\u6d4b\u7f51\u7403\u8fd0\u52a8\u5458\u7684\u8f68\u8ff9.pdf", "BERT", "Pose2Trajectory \u4f7f\u7528 Transformers \u57fa\u4e8e\u8eab\u4f53\u59ff\u52bf\u9884\u6d4b\u7f51\u7403\u8fd0\u52a8\u5458\u7684\u8f68\u8ff9.pdf", "\u7279\u5f81\u63d0\u53d6", "Pose2Trajectory \u4f7f\u7528 Transformers \u57fa\u4e8e\u8eab\u4f53\u59ff\u52bf\u9884\u6d4b\u7f51\u7403\u8fd0\u52a8\u5458\u7684\u8f68\u8ff9.pdf", "pattern recognition", "Pose2Trajectory \u4f7f\u7528 Transformers \u57fa\u4e8e\u8eab\u4f53\u59ff\u52bf\u9884\u6d4b\u7f51\u7403\u8fd0\u52a8\u5458\u7684\u8f68\u8ff9.pdf", "computer vision", "Pose2Trajectory \u4f7f\u7528 Transformers \u57fa\u4e8e\u8eab\u4f53\u59ff\u52bf\u9884\u6d4b\u7f51\u7403\u8fd0\u52a8\u5458\u7684\u8f68\u8ff9.pdf", "motion perception", "Pose2Trajectory \u4f7f\u7528 Transformers \u57fa\u4e8e\u8eab\u4f53\u59ff\u52bf\u9884\u6d4b\u7f51\u7403\u8fd0\u52a8\u5458\u7684\u8f68\u8ff9.pdf", "Image Processing", "Pose2Trajectory \u4f7f\u7528 Transformers \u57fa\u4e8e\u8eab\u4f53\u59ff\u52bf\u9884\u6d4b\u7f51\u7403\u8fd0\u52a8\u5458\u7684\u8f68\u8ff9.pdf", "recurrent neural networks", "Pose2Trajectory \u4f7f\u7528 Transformers \u57fa\u4e8e\u8eab\u4f53\u59ff\u52bf\u9884\u6d4b\u7f51\u7403\u8fd0\u52a8\u5458\u7684\u8f68\u8ff9.pdf", "GAN", "Pose2Trajectory \u4f7f\u7528 Transformers \u57fa\u4e8e\u8eab\u4f53\u59ff\u52bf\u9884\u6d4b\u7f51\u7403\u8fd0\u52a8\u5458\u7684\u8f68\u8ff9.pdf", "Pose Estimation", "Pose2Trajectory \u4f7f\u7528 Transformers \u57fa\u4e8e\u8eab\u4f53\u59ff\u52bf\u9884\u6d4b\u7f51\u7403\u8fd0\u52a8\u5458\u7684\u8f68\u8ff9.pdf", "human pose estimation", "Pose2Trajectory \u4f7f\u7528 Transformers \u57fa\u4e8e\u8eab\u4f53\u59ff\u52bf\u9884\u6d4b\u7f51\u7403\u8fd0\u52a8\u5458\u7684\u8f68\u8ff9.pdf", "\u4eba\u7c7b\u884c\u4e3a\u5206\u6790", "Pose2Trajectory \u4f7f\u7528 Transformers \u57fa\u4e8e\u8eab\u4f53\u59ff\u52bf\u9884\u6d4b\u7f51\u7403\u8fd0\u52a8\u5458\u7684\u8f68\u8ff9.pdf", "Transformer", "Pose2Trajectory \u4f7f\u7528 Transformers \u57fa\u4e8e\u8eab\u4f53\u59ff\u52bf\u9884\u6d4b\u7f51\u7403\u8fd0\u52a8\u5458\u7684\u8f68\u8ff9.pdf", "forecasting", "Pose2Trajectory \u4f7f\u7528 Transformers \u57fa\u4e8e\u8eab\u4f53\u59ff\u52bf\u9884\u6d4b\u7f51\u7403\u8fd0\u52a8\u5458\u7684\u8f68\u8ff9.pdf", "MSE", "Pose2Trajectory \u4f7f\u7528 Transformers \u57fa\u4e8e\u8eab\u4f53\u59ff\u52bf\u9884\u6d4b\u7f51\u7403\u8fd0\u52a8\u5458\u7684\u8f68\u8ff9.pdf", "transformer", "Pose2Trajectory \u4f7f\u7528 Transformers \u57fa\u4e8e\u8eab\u4f53\u59ff\u52bf\u9884\u6d4b\u7f51\u7403\u8fd0\u52a8\u5458\u7684\u8f68\u8ff9.pdf", "Springer handbook of robotics", "Pose2Trajectory \u4f7f\u7528 Transformers \u57fa\u4e8e\u8eab\u4f53\u59ff\u52bf\u9884\u6d4b\u7f51\u7403\u8fd0\u52a8\u5458\u7684\u8f68\u8ff9.pdf", "Graph Attention Networks", "Pose2Trajectory \u4f7f\u7528 Transformers \u57fa\u4e8e\u8eab\u4f53\u59ff\u52bf\u9884\u6d4b\u7f51\u7403\u8fd0\u52a8\u5458\u7684\u8f68\u8ff9.pdf", "Pose2Trajectory", "Pose2Trajectory \u4f7f\u7528 Transformers \u57fa\u4e8e\u8eab\u4f53\u59ff\u52bf\u9884\u6d4b\u7f51\u7403\u8fd0\u52a8\u5458\u7684\u8f68\u8ff9.pdf", "generative pre-training", "Pose2Trajectory \u4f7f\u7528 Transformers \u57fa\u4e8e\u8eab\u4f53\u59ff\u52bf\u9884\u6d4b\u7f51\u7403\u8fd0\u52a8\u5458\u7684\u8f68\u8ff9.pdf", "Time2vec", "Pose2Trajectory \u4f7f\u7528 Transformers \u57fa\u4e8e\u8eab\u4f53\u59ff\u52bf\u9884\u6d4b\u7f51\u7403\u8fd0\u52a8\u5458\u7684\u8f68\u8ff9.pdf", "ByteTrack", "Pose2Trajectory \u4f7f\u7528 Transformers \u57fa\u4e8e\u8eab\u4f53\u59ff\u52bf\u9884\u6d4b\u7f51\u7403\u8fd0\u52a8\u5458\u7684\u8f68\u8ff9.pdf", "ViTPose", "Pose2Trajectory \u4f7f\u7528 Transformers \u57fa\u4e8e\u8eab\u4f53\u59ff\u52bf\u9884\u6d4b\u7f51\u7403\u8fd0\u52a8\u5458\u7684\u8f68\u8ff9.pdf", "Time2Vector", "Pose2Trajectory \u4f7f\u7528 Transformers \u57fa\u4e8e\u8eab\u4f53\u59ff\u52bf\u9884\u6d4b\u7f51\u7403\u8fd0\u52a8\u5458\u7684\u8f68\u8ff9.pdf", "Bicycle-GAN", "Pose2Trajectory \u4f7f\u7528 Transformers \u57fa\u4e8e\u8eab\u4f53\u59ff\u52bf\u9884\u6d4b\u7f51\u7403\u8fd0\u52a8\u5458\u7684\u8f68\u8ff9.pdf", "Kalman filter", "Pose2Trajectory \u4f7f\u7528 Transformers \u57fa\u4e8e\u8eab\u4f53\u59ff\u52bf\u9884\u6d4b\u7f51\u7403\u8fd0\u52a8\u5458\u7684\u8f68\u8ff9.pdf", "Detection", "Pose2Trajectory \u4f7f\u7528 Transformers \u57fa\u4e8e\u8eab\u4f53\u59ff\u52bf\u9884\u6d4b\u7f51\u7403\u8fd0\u52a8\u5458\u7684\u8f68\u8ff9.pdf", "motion estimation", "Pose2Trajectory \u4f7f\u7528 Transformers \u57fa\u4e8e\u8eab\u4f53\u59ff\u52bf\u9884\u6d4b\u7f51\u7403\u8fd0\u52a8\u5458\u7684\u8f68\u8ff9.pdf", "Hawk-eye", "Pose2Trajectory \u4f7f\u7528 Transformers \u57fa\u4e8e\u8eab\u4f53\u59ff\u52bf\u9884\u6d4b\u7f51\u7403\u8fd0\u52a8\u5458\u7684\u8f68\u8ff9.pdf", "Tennis", "Pose2Trajectory \u4f7f\u7528 Transformers \u57fa\u4e8e\u8eab\u4f53\u59ff\u52bf\u9884\u6d4b\u7f51\u7403\u8fd0\u52a8\u5458\u7684\u8f68\u8ff9.pdf", "current neural networks", "Pose2Trajectory \u4f7f\u7528 Transformers \u57fa\u4e8e\u8eab\u4f53\u59ff\u52bf\u9884\u6d4b\u7f51\u7403\u8fd0\u52a8\u5458\u7684\u8f68\u8ff9.pdf", "PMLR", "Pose2Trajectory \u4f7f\u7528 Transformers \u57fa\u4e8e\u8eab\u4f53\u59ff\u52bf\u9884\u6d4b\u7f51\u7403\u8fd0\u52a8\u5458\u7684\u8f68\u8ff9.pdf", "fast r-cnn", "Pose2Trajectory \u4f7f\u7528 Transformers \u57fa\u4e8e\u8eab\u4f53\u59ff\u52bf\u9884\u6d4b\u7f51\u7403\u8fd0\u52a8\u5458\u7684\u8f68\u8ff9.pdf", "focal loss", "Pose2Trajectory \u4f7f\u7528 Transformers \u57fa\u4e8e\u8eab\u4f53\u59ff\u52bf\u9884\u6d4b\u7f51\u7403\u8fd0\u52a8\u5458\u7684\u8f68\u8ff9.pdf", "video surveillance system", "R-CNN.pdf", "\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc", "R-CNN.pdf", "fine-tuning", "R-CNN.pdf", "ImageNet", "R-CNN.pdf", "SVR", "R-CNN.pdf", "convolutional neural networks", "R-CNN.pdf", "CNNs", "R-CNN.pdf", "feature", "R-CNN.pdf", "CNN", "R-CNN.pdf", "SVM", "R-CNN.pdf", "CNN\u67b6\u6784", "R-CNN.pdf", "ruler", "R-CNN.pdf", "class", "R-CNN.pdf", "Kubernetes\u7ba1\u7406\u7cfb\u7edf", "R-CNN.pdf", "\u4e91\u8ba1\u7b97\u5e73\u53f0", "R-CNN.pdf", "\u673a\u5668\u5b66\u4e60", "R-CNN.pdf", "softmax", "R-CNN.pdf", "S3\u5b58\u50a8\u670d\u52a1", "R-CNN.pdf", "Dropout", "R-CNN.pdf", "square", "R-CNN.pdf", "Krizhevsky", "R-CNN.pdf", "IoU", "R-CNN.pdf", "classifier", "R-CNN.pdf", "Docker", "R-CNN.pdf", "SGD", "R-CNN.pdf", "GPU", "R-CNN.pdf", "activation", "R-CNN.pdf", "IIS", "R-CNN.pdf", "layer", "R-CNN.pdf", "Docker\u5bb9\u5668", "R-CNN.pdf", "\u5377\u79ef\u795e\u7ecf\u7f51\u7edc", "R-CNN.pdf", "training", "R-CNN.pdf", "SIFT", "R-CNN.pdf", "\u8ba1\u7b97\u673a\u89c6\u89c9", "R-CNN.pdf", "object detection", "R-CNN.pdf", "R-CNN", "R-CNN.pdf", "learning rate", "R-CNN.pdf", "\u81ea\u52a8\u5316\u90e8\u7f72", "R-CNN.pdf", "strides", "R-CNN.pdf", "scene classification", "R-CNN.pdf", "\u8d1f\u8f7d\u5747\u8861\u5668", "R-CNN.pdf", "supervised learning", "R-CNN.pdf", "pattern recognition", "R-CNN.pdf", "Semantic Segmentation", "R-CNN.pdf", "dimensionality reduction", "R-CNN.pdf", "features", "R-CNN.pdf", "classi\ufb01cation", "R-CNN.pdf", "object", "R-CNN.pdf", "clustering", "R-CNN.pdf", "fully connected layers", "R-CNN.pdf", "feature learning", "RetinaNet.pdf", "CNN", "RetinaNet.pdf", "\u53cd\u5411\u4f20\u64ad", "RetinaNet.pdf", "APM", "RetinaNet.pdf", "Accuracy", "RetinaNet.pdf", "anchors", "RetinaNet.pdf", "momentum", "RetinaNet.pdf", "ReLU", "RetinaNet.pdf", "model", "RetinaNet.pdf", "loss function", "RetinaNet.pdf", "Convolutional Neural Networks", "RetinaNet.pdf", "Focal loss", "RetinaNet.pdf", "gamma", "RetinaNet.pdf", "accuracy", "RetinaNet.pdf", "object detection", "RetinaNet.pdf", "ResNet", "RetinaNet.pdf", "R-CNN", "RetinaNet.pdf", "learning rate", "RetinaNet.pdf", "anchor", "RetinaNet.pdf", "batch", "RetinaNet.pdf", "robustness", "RetinaNet.pdf", "regions", "RetinaNet.pdf", "gradient", "RetinaNet.pdf", "spatial positions", "RetinaNet.pdf", "FCN", "RetinaNet.pdf", "human detection", "RetinaNet.pdf", "sparse set", "RetinaNet.pdf", "recurrent neural networks", "RetinaNet.pdf", "scales", "RetinaNet.pdf", "networks", "RetinaNet.pdf", "Faster R-CNN", "RetinaNet.pdf", "anchor box", "RetinaNet.pdf", "image resolution", "RetinaNet.pdf", "foreground", "RetinaNet.pdf", "outliers", "RetinaNet.pdf", "convolutional network", "RetinaNet.pdf", "convolutional neural network", "RetinaNet.pdf", "batch size", "RetinaNet.pdf", "class imbalance", "RetinaNet.pdf", "state-of-the-art", "RetinaNet.pdf", "R-FCN", "RetinaNet.pdf", "convolutional", "RetinaNet.pdf", "deep neural networks", "RetinaNet.pdf", "deep residual network", "RetinaNet.pdf", "Object detection", "RetinaNet.pdf", "conv layers", "RetinaNet.pdf", "ResNet-50", "RetinaNet.pdf", "object proposal", "RetinaNet.pdf", "mini-batch", "RetinaNet.pdf", "hard negative mining", "RetinaNet.pdf", "object\u68c0\u6d4b", "s11263-022-01594-9.pdf", "\u4eba\u5de5\u667a\u80fd", "s11263-022-01594-9.pdf", "\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc", "s11263-022-01594-9.pdf", "max-pooling", "s11263-022-01594-9.pdf", "pooling", "s11263-022-01594-9.pdf", "LSTM", "s11263-022-01594-9.pdf", "segmentation", "s11263-022-01594-9.pdf", "CNNs", "s11263-022-01594-9.pdf", "\u6df1\u5ea6\u5377\u79ef\u795e\u7ecf\u7f51\u7edc", "s11263-022-01594-9.pdf", "action recognition", "s11263-022-01594-9.pdf", "UCF101", "s11263-022-01594-9.pdf", "CNN", "s11263-022-01594-9.pdf", "LSTMs", "s11263-022-01594-9.pdf", "SVM", "s11263-022-01594-9.pdf", "3D\u5377\u79ef\u795e\u7ecf\u7f51\u7edc", "s11263-022-01594-9.pdf", "\u65e0\u76d1\u7763\u5b66\u4e60", "s11263-022-01594-9.pdf", "\u652f\u6301\u5411\u91cf\u673a", "s11263-022-01594-9.pdf", "Hmdb", "s11263-022-01594-9.pdf", "\u4eba\u673a\u4ea4\u4e92", "s11263-022-01594-9.pdf", "\u52a8\u6001\u56fe\u50cf\u5904\u7406", "s11263-022-01594-9.pdf", "\u6df1\u5ea6\u5b66\u4e60", "s11263-022-01594-9.pdf", "video representations", "s11263-022-01594-9.pdf", "ICML", "s11263-022-01594-9.pdf", "\u6df1\u5ea6\u76f8\u673a", "s11263-022-01594-9.pdf", "\u6df1\u5ea6\u7f51\u7edc", "s11263-022-01594-9.pdf", "\u6700\u5927\u6c60\u5316", "s11263-022-01594-9.pdf", "\u673a\u5668\u5b66\u4e60", "s11263-022-01594-9.pdf", "LSTM\u6a21\u578b", "s11263-022-01594-9.pdf", "\u6982\u7387\u5206\u5e03", "s11263-022-01594-9.pdf", "performance", "s11263-022-01594-9.pdf", "IoU", "s11263-022-01594-9.pdf", "model", "s11263-022-01594-9.pdf", "DNN", "s11263-022-01594-9.pdf", "Representation", "s11263-022-01594-9.pdf", "\u591a\u4efb\u52a1\u5b66\u4e60", "s11263-022-01594-9.pdf", "Recurrent neural networks", "s11263-022-01594-9.pdf", "\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5", "s11263-022-01594-9.pdf", "depth camera", "s11263-022-01594-9.pdf", "\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60", "s11263-022-01594-9.pdf", "reinforcement learning", "s11263-022-01594-9.pdf", "MLP", "s11263-022-01594-9.pdf", "\u5377\u79ef\u795e\u7ecf\u7f51\u7edc", "s11263-022-01594-9.pdf", "training", "s11263-022-01594-9.pdf", "SIFT", "s11263-022-01594-9.pdf", "\u7b97\u6cd5", "s11263-022-01594-9.pdf", "\u8ba1\u7b97\u673a\u89c6\u89c9", "s11263-022-01594-9.pdf", "inference", "s11263-022-01594-9.pdf", "ICCV", "s11263-022-01594-9.pdf", "R-CNN", "s11263-022-01594-9.pdf", "softmax\u51fd\u6570", "s11263-022-01594-9.pdf", "arXiv", "sensors-19-01005.pdf", "\u4eba\u5de5\u667a\u80fd", "sensors-19-01005.pdf", "\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc", "sensors-19-01005.pdf", "LSTM", "sensors-19-01005.pdf", "\u4eba\u8138\u8bc6\u522b", "sensors-19-01005.pdf", "video representation", "sensors-19-01005.pdf", "convolutional neural networks", "sensors-19-01005.pdf", "CNNs", "sensors-19-01005.pdf", "action recognition", "sensors-19-01005.pdf", "CNN", "sensors-19-01005.pdf", "DenseNet", "sensors-19-01005.pdf", "\u4eba\u673a\u4ea4\u4e92", "sensors-19-01005.pdf", "\u6df1\u5ea6\u5b66\u4e60", "sensors-19-01005.pdf", "RGB\u56fe\u50cf", "sensors-19-01005.pdf", "attention mechanism", "sensors-19-01005.pdf", "\u6df1\u5ea6\u76f8\u673a", "sensors-19-01005.pdf", "\u56fe\u50cf\u8bc6\u522b", "sensors-19-01005.pdf", "Tornado", "sensors-19-01005.pdf", "sparse representation", "sensors-19-01005.pdf", "\u673a\u5668\u5b66\u4e60", "sensors-19-01005.pdf", "\u56fe\u50cf\u5206\u7c7b", "sensors-19-01005.pdf", "\u4eba\u4f53\u59ff\u52bf\u4f30\u8ba1", "sensors-19-01005.pdf", "Deep learning", "sensors-19-01005.pdf", "cloud computing", "sensors-19-01005.pdf", "\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5", "sensors-19-01005.pdf", "classification", "sensors-19-01005.pdf", "Convolutional Neural Network", "sensors-19-01005.pdf", "\u8ba1\u7b97\u673a\u89c6\u89c9", "sensors-19-01005.pdf", "accuracy", "sensors-19-01005.pdf", "\u673a\u5668\u89c6\u89c9", "sensors-19-01005.pdf", "RNN", "sensors-19-01005.pdf", "dataset", "sensors-19-01005.pdf", "sliding window", "sensors-19-01005.pdf", "ComputerVision", "sensors-19-01005.pdf", "Robustness", "sensors-19-01005.pdf", "activity recognition", "sensors-19-01005.pdf", "\u6df1\u5ea6\u611f\u77e5", "sensors-19-01005.pdf", "skeleton", "sensors-19-01005.pdf", "\u591a\u6a21\u6001\u6570\u636e\u878d\u5408", "sensors-19-01005.pdf", "\u4eba\u4f53\u6d3b\u52a8\u68c0\u6d4b", "sensors-19-01005.pdf", "spatiotemporal features", "sensors-19-01005.pdf", "Kinect sensor", "sensors-19-01005.pdf", "object", "sensors-19-01005.pdf", "\u4eba\u673a\u8bc6\u522b", "sensors-19-01005.pdf", "gesture recognition", "sensors-19-01005.pdf", "Sliding Window", "sensors-19-01005.pdf", "human motion", "sensors-19-01005.pdf", "human action recognition", "sensors-19-01005.pdf", "\u4eba\u7c7b\u52a8\u4f5c\u8bc6\u522b", "sensors-19-01005.pdf", "human detection", "sensors-19-01005.pdf", "histograms of oriented gradients", "SkateFormer Skeletal-Temporal Transformer for Human Action Recognition.pdf", "learning", "SkateFormer Skeletal-Temporal Transformer for Human Action Recognition.pdf", "data augmentation", "SkateFormer Skeletal-Temporal Transformer for Human Action Recognition.pdf", "CNNs", "SkateFormer Skeletal-Temporal Transformer for Human Action Recognition.pdf", "action recognition", "SkateFormer Skeletal-Temporal Transformer for Human Action Recognition.pdf", "CNN", "SkateFormer Skeletal-Temporal Transformer for Human Action Recognition.pdf", "\u6570\u636e\u589e\u5f3a", "SkateFormer Skeletal-Temporal Transformer for Human Action Recognition.pdf", "\u4eba\u673a\u4ea4\u4e92", "SkateFormer Skeletal-Temporal Transformer for Human Action Recognition.pdf", "\u6df1\u5ea6\u5b66\u4e60", "SkateFormer Skeletal-Temporal Transformer for Human Action Recognition.pdf", "\u7279\u5f81\u6620\u5c04", "SkateFormer Skeletal-Temporal Transformer for Human Action Recognition.pdf", "PyTorch", "SkateFormer Skeletal-Temporal Transformer for Human Action Recognition.pdf", "tokenization", "SkateFormer Skeletal-Temporal Transformer for Human Action Recognition.pdf", "global", "SkateFormer Skeletal-Temporal Transformer for Human Action Recognition.pdf", "Linear", "SkateFormer Skeletal-Temporal Transformer for Human Action Recognition.pdf", "\u673a\u5668\u5b66\u4e60", "SkateFormer Skeletal-Temporal Transformer for Human Action Recognition.pdf", "performance", "SkateFormer Skeletal-Temporal Transformer for Human Action Recognition.pdf", "model", "SkateFormer Skeletal-Temporal Transformer for Human Action Recognition.pdf", "downsampling", "SkateFormer Skeletal-Temporal Transformer for Human Action Recognition.pdf", "\u6df1\u5b66\u4e60", "SkateFormer Skeletal-Temporal Transformer for Human Action Recognition.pdf", "natural language processing", "SkateFormer Skeletal-Temporal Transformer for Human Action Recognition.pdf", "feature maps", "SkateFormer Skeletal-Temporal Transformer for Human Action Recognition.pdf", "Turing", "SkateFormer Skeletal-Temporal Transformer for Human Action Recognition.pdf", "attention", "SkateFormer Skeletal-Temporal Transformer for Human Action Recognition.pdf", "\u8ba1\u7b97\u673a\u89c6\u89c9", "SkateFormer Skeletal-Temporal Transformer for Human Action Recognition.pdf", "CNN-based", "SkateFormer Skeletal-Temporal Transformer for Human Action Recognition.pdf", "GRU", "SkateFormer Skeletal-Temporal Transformer for Human Action Recognition.pdf", "\u77e9\u9635\u4e58\u6cd5", "SkateFormer Skeletal-Temporal Transformer for Human Action Recognition.pdf", "\u635f\u5931\u51fd\u6570", "SkateFormer Skeletal-Temporal Transformer for Human Action Recognition.pdf", "Hinton", "SkateFormer Skeletal-Temporal Transformer for Human Action Recognition.pdf", "\u81ea\u52a8\u5fae\u5206", "SkateFormer Skeletal-Temporal Transformer for Human Action Recognition.pdf", "axes", "SkateFormer Skeletal-Temporal Transformer for Human Action Recognition.pdf", "Transform", "SkateFormer Skeletal-Temporal Transformer for Human Action Recognition.pdf", "baseline", "SkateFormer Skeletal-Temporal Transformer for Human Action Recognition.pdf", "\u7279\u5f81\u62bd\u53d6", "SkateFormer Skeletal-Temporal Transformer for Human Action Recognition.pdf", "pattern recognition", "SkateFormer Skeletal-Temporal Transformer for Human Action Recognition.pdf", "Kinect", "SkateFormer Skeletal-Temporal Transformer for Human Action Recognition.pdf", "joints", "SkateFormer Skeletal-Temporal Transformer for Human Action Recognition.pdf", "skeleton", "SkateFormer Skeletal-Temporal Transformer for Human Action Recognition.pdf", "artificial intelligence", "SkateFormer Skeletal-Temporal Transformer for Human Action Recognition.pdf", "computer vision", "SkateFormer Skeletal-Temporal Transformer for Human Action Recognition.pdf", "sensors", "SkateFormer Skeletal-Temporal Transformer for Human Action Recognition.pdf", "attributes", "SkateFormer Skeletal-Temporal Transformer for Human Action Recognition.pdf", "Batch Normalization", "SkateFormer Skeletal-Temporal Transformer for Human Action Recognition.pdf", "complexity", "SkateFormer Skeletal-Temporal Transformer for Human Action Recognition.pdf", "Neural Networks", "SkateFormer Skeletal-Temporal Transformer for Human Action Recognition.pdf", "sequences", "SkateFormer Skeletal-Temporal Transformer for Human Action Recognition.pdf", "recognition", "SkateFormer Skeletal-Temporal Transformer for Human Action Recognition.pdf", "generative models", "SkateFormer Skeletal-Temporal Transformer for Human Action Recognition.pdf", "ensemble", "SkateFormer Skeletal-Temporal Transformer for Human Action Recognition.pdf", "transformer-based models", "SkateFormer Skeletal-Temporal Transformer for Human Action Recognition.pdf", "multi-modal fusion", "SlowFast Networks for Video Recognition.pdf", "\u6df1\u5ea6\u5377\u79ef\u795e\u7ecf\u7f51\u7edc", "SlowFast Networks for Video Recognition.pdf", "optimization", "SlowFast Networks for Video Recognition.pdf", "action recognition", "SlowFast Networks for Video Recognition.pdf", "\u795e\u7ecf\u7f51\u7edc", "SlowFast Networks for Video Recognition.pdf", "Accuracy", "SlowFast Networks for Video Recognition.pdf", "momentum", "SlowFast Networks for Video Recognition.pdf", "distributed training", "SlowFast Networks for Video Recognition.pdf", "model", "SlowFast Networks for Video Recognition.pdf", "training", "SlowFast Networks for Video Recognition.pdf", "\u5e73\u5747\u6c60\u5316", "SlowFast Networks for Video Recognition.pdf", "design", "SlowFast Networks for Video Recognition.pdf", "ResNet", "SlowFast Networks for Video Recognition.pdf", "R-CNN", "SlowFast Networks for Video Recognition.pdf", "learning rate", "SlowFast Networks for Video Recognition.pdf", "strides", "SlowFast Networks for Video Recognition.pdf", "sampling", "SlowFast Networks for Video Recognition.pdf", "human action recognition", "SlowFast Networks for Video Recognition.pdf", "concatenation", "SlowFast Networks for Video Recognition.pdf", "feature detection", "SlowFast Networks for Video Recognition.pdf", "dense sampling", "SlowFast Networks for Video Recognition.pdf", "correlation", "SlowFast Networks for Video Recognition.pdf", "histogram of oriented flow", "SlowFast Networks for Video Recognition.pdf", "movement", "SlowFast Networks for Video Recognition.pdf", "ensemble", "SlowFast Networks for Video Recognition.pdf", "GAN", "SlowFast Networks for Video Recognition.pdf", "spatiotemporal", "SlowFast Networks for Video Recognition.pdf", "multi-modal fusion", "SlowFast Networks for Video Recognition.pdf", "video recognition", "SlowFast Networks for Video Recognition.pdf", "networks", "SlowFast Networks for Video Recognition.pdf", "Faster R-CNN", "SlowFast Networks for Video Recognition.pdf", "resolution", "SlowFast Networks for Video Recognition.pdf", "input frames", "SlowFast Networks for Video Recognition.pdf", "3D convolution", "SlowFast Networks for Video Recognition.pdf", "precision", "SlowFast Networks for Video Recognition.pdf", "convolutional network", "SlowFast Networks for Video Recognition.pdf", "Detection", "SlowFast Networks for Video Recognition.pdf", "\u7edf\u8ba1\u5b66", "SlowFast Networks for Video Recognition.pdf", "spatio-temporal features", "SlowFast Networks for Video Recognition.pdf", "confidence", "SlowFast Networks for Video Recognition.pdf", "colors", "SlowFast Networks for Video Recognition.pdf", "receptive fields", "SlowFast Networks for Video Recognition.pdf", "DNN training", "SlowFast Networks for Video Recognition.pdf", "ResNet-50", "SlowFast Networks for Video Recognition.pdf", "pre-training", "SlowFast Networks for Video Recognition.pdf", "Normalization", "SlowFast Networks for Video Recognition.pdf", "train", "SlowFast Networks for Video Recognition.pdf", "Fast R-CNN", "SlowFast Networks for Video Recognition.pdf", "ImageNet\u5206\u7c7b", "SlowFast Networks for Video Recognition.pdf", "region proposals", "SlowFast Networks for Video Recognition.pdf", "hyper-parameters", "SSD.pdf", "data augmentation", "SSD.pdf", "convolutional neural networks", "SSD.pdf", "CNN", "SSD.pdf", "image classi\ufb01cation", "SSD.pdf", "\u795e\u7ecf\u7f51\u7edc", "SSD.pdf", "video object detection", "SSD.pdf", "\u6df1\u5ea6\u5b66\u4e60", "SSD.pdf", "feature map", "SSD.pdf", "Kubernetes\u7ba1\u7406\u7cfb\u7edf", "SSD.pdf", "Softmax", "SSD.pdf", "loss function", "SSD.pdf", "models", "SSD.pdf", "classification", "SSD.pdf", "VGG16", "SSD.pdf", "feature maps", "SSD.pdf", "accuracy", "SSD.pdf", "object detection", "SSD.pdf", "learning rate", "SSD.pdf", "\u81ea\u52a8\u5316\u90e8\u7f72", "SSD.pdf", "AWS", "SSD.pdf", "\u8d1f\u8f7d\u5747\u8861\u5668", "SSD.pdf", "sampling", "SSD.pdf", "dataset", "SSD.pdf", "Fully Connected", "SSD.pdf", "bird", "SSD.pdf", "classi\ufb01cation", "SSD.pdf", "layers", "SSD.pdf", "\u6df1\u5b66\u4e60\u6a21\u578b", "SSD.pdf", "recurrent neural networks", "SSD.pdf", "convolutional layers", "SSD.pdf", "networks", "SSD.pdf", "Faster R-CNN", "SSD.pdf", "deep learning", "SSD.pdf", "recall", "SSD.pdf", "subsampling", "SSD.pdf", "convolutional network", "SSD.pdf", "kernels", "SSD.pdf", "Detection", "SSD.pdf", "state-of-the-art", "SSD.pdf", "VGG-16", "SSD.pdf", "backpropagation", "SSD.pdf", "horse", "SSD.pdf", "fast R-CNN", "SSD.pdf", "feedforward neural networks", "SSD.pdf", "chair", "SSD.pdf", "multi-scale", "SSD.pdf", "bike", "SSD.pdf", "object\u68c0\u6d4b", "SSD.pdf", "Rich feature hierarchies", "SSD.pdf", "Fast R-CNN", "STNet\u7fbd\u6bdb\u7403\u8fd0\u52a8\u5c0f\u76ee\u6807\u5b9a\u4f4d\u8ddf\u8e2a\u7f51\u7edc.pdf", "learning", "STNet\u7fbd\u6bdb\u7403\u8fd0\u52a8\u5c0f\u76ee\u6807\u5b9a\u4f4d\u8ddf\u8e2a\u7f51\u7edc.pdf", "segmentation", "STNet\u7fbd\u6bdb\u7403\u8fd0\u52a8\u5c0f\u76ee\u6807\u5b9a\u4f4d\u8ddf\u8e2a\u7f51\u7edc.pdf", "CNN", "STNet\u7fbd\u6bdb\u7403\u8fd0\u52a8\u5c0f\u76ee\u6807\u5b9a\u4f4d\u8ddf\u8e2a\u7f51\u7edc.pdf", "\u795e\u7ecf\u7f51\u7edc", "STNet\u7fbd\u6bdb\u7403\u8fd0\u52a8\u5c0f\u76ee\u6807\u5b9a\u4f4d\u8ddf\u8e2a\u7f51\u7edc.pdf", "video frames", "STNet\u7fbd\u6bdb\u7403\u8fd0\u52a8\u5c0f\u76ee\u6807\u5b9a\u4f4d\u8ddf\u8e2a\u7f51\u7edc.pdf", "\u6df1\u5ea6\u5b66\u4e60", "STNet\u7fbd\u6bdb\u7403\u8fd0\u52a8\u5c0f\u76ee\u6807\u5b9a\u4f4d\u8ddf\u8e2a\u7f51\u7edc.pdf", "\u5377\u79ef\u5c42", "STNet\u7fbd\u6bdb\u7403\u8fd0\u52a8\u5c0f\u76ee\u6807\u5b9a\u4f4d\u8ddf\u8e2a\u7f51\u7edc.pdf", "\u56fe\u50cf\u8bc6\u522b", "STNet\u7fbd\u6bdb\u7403\u8fd0\u52a8\u5c0f\u76ee\u6807\u5b9a\u4f4d\u8ddf\u8e2a\u7f51\u7edc.pdf", "\u56fe\u50cf\u5904\u7406", "STNet\u7fbd\u6bdb\u7403\u8fd0\u52a8\u5c0f\u76ee\u6807\u5b9a\u4f4d\u8ddf\u8e2a\u7f51\u7edc.pdf", "Computer Vision", "STNet\u7fbd\u6bdb\u7403\u8fd0\u52a8\u5c0f\u76ee\u6807\u5b9a\u4f4d\u8ddf\u8e2a\u7f51\u7edc.pdf", "\u8ba1\u7b97\u673a\u89c6\u89c9", "STNet\u7fbd\u6bdb\u7403\u8fd0\u52a8\u5c0f\u76ee\u6807\u5b9a\u4f4d\u8ddf\u8e2a\u7f51\u7edc.pdf", "ICCV", "STNet\u7fbd\u6bdb\u7403\u8fd0\u52a8\u5c0f\u76ee\u6807\u5b9a\u4f4d\u8ddf\u8e2a\u7f51\u7edc.pdf", "\u5e73\u5747\u6c60\u5316", "STNet\u7fbd\u6bdb\u7403\u8fd0\u52a8\u5c0f\u76ee\u6807\u5b9a\u4f4d\u8ddf\u8e2a\u7f51\u7edc.pdf", "\u524d\u5411\u63a8\u7406", "STNet\u7fbd\u6bdb\u7403\u8fd0\u52a8\u5c0f\u76ee\u6807\u5b9a\u4f4d\u8ddf\u8e2a\u7f51\u7edc.pdf", "\u7279\u5f81\u63d0\u53d6", "STNet\u7fbd\u6bdb\u7403\u8fd0\u52a8\u5c0f\u76ee\u6807\u5b9a\u4f4d\u8ddf\u8e2a\u7f51\u7edc.pdf", "\u5377\u79ef\u6838", "STNet\u7fbd\u6bdb\u7403\u8fd0\u52a8\u5c0f\u76ee\u6807\u5b9a\u4f4d\u8ddf\u8e2a\u7f51\u7edc.pdf", "\u6b8b\u5dee\u8fde\u63a5", "STNet\u7fbd\u6bdb\u7403\u8fd0\u52a8\u5c0f\u76ee\u6807\u5b9a\u4f4d\u8ddf\u8e2a\u7f51\u7edc.pdf", "artificial intelligence", "STNet\u7fbd\u6bdb\u7403\u8fd0\u52a8\u5c0f\u76ee\u6807\u5b9a\u4f4d\u8ddf\u8e2a\u7f51\u7edc.pdf", "Recognition", "STNet\u7fbd\u6bdb\u7403\u8fd0\u52a8\u5c0f\u76ee\u6807\u5b9a\u4f4d\u8ddf\u8e2a\u7f51\u7edc.pdf", "tracking", "STNet\u7fbd\u6bdb\u7403\u8fd0\u52a8\u5c0f\u76ee\u6807\u5b9a\u4f4d\u8ddf\u8e2a\u7f51\u7edc.pdf", "temporal_features", "STNet\u7fbd\u6bdb\u7403\u8fd0\u52a8\u5c0f\u76ee\u6807\u5b9a\u4f4d\u8ddf\u8e2a\u7f51\u7edc.pdf", "TrackNet", "STNet\u7fbd\u6bdb\u7403\u8fd0\u52a8\u5c0f\u76ee\u6807\u5b9a\u4f4d\u8ddf\u8e2a\u7f51\u7edc.pdf", "Faster R-CNN", "STNet\u7fbd\u6bdb\u7403\u8fd0\u52a8\u5c0f\u76ee\u6807\u5b9a\u4f4d\u8ddf\u8e2a\u7f51\u7edc.pdf", "localization", "STNet\u7fbd\u6bdb\u7403\u8fd0\u52a8\u5c0f\u76ee\u6807\u5b9a\u4f4d\u8ddf\u8e2a\u7f51\u7edc.pdf", "machinelearning", "STNet\u7fbd\u6bdb\u7403\u8fd0\u52a8\u5c0f\u76ee\u6807\u5b9a\u4f4d\u8ddf\u8e2a\u7f51\u7edc.pdf", "Neurocomputing", "STNet\u7fbd\u6bdb\u7403\u8fd0\u52a8\u5c0f\u76ee\u6807\u5b9a\u4f4d\u8ddf\u8e2a\u7f51\u7edc.pdf", "TCN", "STNet\u7fbd\u6bdb\u7403\u8fd0\u52a8\u5c0f\u76ee\u6807\u5b9a\u4f4d\u8ddf\u8e2a\u7f51\u7edc.pdf", "channel attention", "STNet\u7fbd\u6bdb\u7403\u8fd0\u52a8\u5c0f\u76ee\u6807\u5b9a\u4f4d\u8ddf\u8e2a\u7f51\u7edc.pdf", "\u53ec\u56de\u7387", "STNet\u7fbd\u6bdb\u7403\u8fd0\u52a8\u5c0f\u76ee\u6807\u5b9a\u4f4d\u8ddf\u8e2a\u7f51\u7edc.pdf", "\u89c6\u89c9\u8ffd\u8e2a", "STNet\u7fbd\u6bdb\u7403\u8fd0\u52a8\u5c0f\u76ee\u6807\u5b9a\u4f4d\u8ddf\u8e2a\u7f51\u7edc.pdf", "region proposal networks", "STNet\u7fbd\u6bdb\u7403\u8fd0\u52a8\u5c0f\u76ee\u6807\u5b9a\u4f4d\u8ddf\u8e2a\u7f51\u7edc.pdf", "feature learning-based methods", "STNet\u7fbd\u6bdb\u7403\u8fd0\u52a8\u5c0f\u76ee\u6807\u5b9a\u4f4d\u8ddf\u8e2a\u7f51\u7edc.pdf", "efficient shuttlecock tracking network", "STNet\u7fbd\u6bdb\u7403\u8fd0\u52a8\u5c0f\u76ee\u6807\u5b9a\u4f4d\u8ddf\u8e2a\u7f51\u7edc.pdf", "\u591a\u5143\u8868\u793a\u5b66\u4e60", "STNet\u7fbd\u6bdb\u7403\u8fd0\u52a8\u5c0f\u76ee\u6807\u5b9a\u4f4d\u8ddf\u8e2a\u7f51\u7edc.pdf", "\u591a\u5c3a\u5ea6\u4fe1\u606f\u4ea4\u6362", "STNet\u7fbd\u6bdb\u7403\u8fd0\u52a8\u5c0f\u76ee\u6807\u5b9a\u4f4d\u8ddf\u8e2a\u7f51\u7edc.pdf", "\u7f51\u7edc\u8d85\u53c2\u6570\u8bbe\u7f6e", "STNet\u7fbd\u6bdb\u7403\u8fd0\u52a8\u5c0f\u76ee\u6807\u5b9a\u4f4d\u8ddf\u8e2a\u7f51\u7edc.pdf", "video-based person re-identification", "STNet\u7fbd\u6bdb\u7403\u8fd0\u52a8\u5c0f\u76ee\u6807\u5b9a\u4f4d\u8ddf\u8e2a\u7f51\u7edc.pdf", "automation", "STNet\u7fbd\u6bdb\u7403\u8fd0\u52a8\u5c0f\u76ee\u6807\u5b9a\u4f4d\u8ddf\u8e2a\u7f51\u7edc.pdf", "\u6df1\u5ea6\u5b66\u4e60\u7f51\u7edcter\u5de5\u7a0b", "STNet\u7fbd\u6bdb\u7403\u8fd0\u52a8\u5c0f\u76ee\u6807\u5b9a\u4f4d\u8ddf\u8e2a\u7f51\u7edc.pdf", "\u4f2a\u8272\u5f69\u8f6c\u6362", "STNet\u7fbd\u6bdb\u7403\u8fd0\u52a8\u5c0f\u76ee\u6807\u5b9a\u4f4d\u8ddf\u8e2a\u7f51\u7edc.pdf", "\u70ed\u529b\u56fe", "STNet\u7fbd\u6bdb\u7403\u8fd0\u52a8\u5c0f\u76ee\u6807\u5b9a\u4f4d\u8ddf\u8e2a\u7f51\u7edc.pdf", "heat map\u6062\u590d", "STNet\u7fbd\u6bdb\u7403\u8fd0\u52a8\u5c0f\u76ee\u6807\u5b9a\u4f4d\u8ddf\u8e2a\u7f51\u7edc.pdf", "\u57fa\u51c6\u7f51\u7edc", "STNet\u7fbd\u6bdb\u7403\u8fd0\u52a8\u5c0f\u76ee\u6807\u5b9a\u4f4d\u8ddf\u8e2a\u7f51\u7edc.pdf", "SECAR \u7279\u5f81\u63d0\u53d6\u6a21\u5757", "STNet\u7fbd\u6bdb\u7403\u8fd0\u52a8\u5c0f\u76ee\u6807\u5b9a\u4f4d\u8ddf\u8e2a\u7f51\u7edc.pdf", "\u4e09\u7ef4\u8f68\u8ff9\u91cd\u5efa", "STNet\u7fbd\u6bdb\u7403\u8fd0\u52a8\u5c0f\u76ee\u6807\u5b9a\u4f4d\u8ddf\u8e2a\u7f51\u7edc.pdf", "Yolov3", "STNet\u7fbd\u6bdb\u7403\u8fd0\u52a8\u5c0f\u76ee\u6807\u5b9a\u4f4d\u8ddf\u8e2a\u7f51\u7edc.pdf", "Hypercolumn \u7ed3\u6784", "STNet\u7fbd\u6bdb\u7403\u8fd0\u52a8\u5c0f\u76ee\u6807\u5b9a\u4f4d\u8ddf\u8e2a\u7f51\u7edc.pdf", "\u9ad8\u5206\u8fa8\u7387\u6a21\u5757", "STNet\u7fbd\u6bdb\u7403\u8fd0\u52a8\u5c0f\u76ee\u6807\u5b9a\u4f4d\u8ddf\u8e2a\u7f51\u7edc.pdf", "Tiny YOLOv2", "STNet\u7fbd\u6bdb\u7403\u8fd0\u52a8\u5c0f\u76ee\u6807\u5b9a\u4f4d\u8ddf\u8e2a\u7f51\u7edc.pdf", "\u65f6\u57df\u7279\u5f81", "Toward human activity recognition a survey.pdf", "Dense trajectories", "Toward human activity recognition a survey.pdf", "\u4eba\u5de5\u667a\u80fd", "Toward human activity recognition a survey.pdf", "\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc", "Toward human activity recognition a survey.pdf", "learning", "Toward human activity recognition a survey.pdf", "LSTM", "Toward human activity recognition a survey.pdf", "data augmentation", "Toward human activity recognition a survey.pdf", "Human Action Recognition", "Toward human activity recognition a survey.pdf", "convolutional neural networks", "Toward human activity recognition a survey.pdf", "action recognition", "Toward human activity recognition a survey.pdf", "neural network", "Toward human activity recognition a survey.pdf", "video data", "Toward human activity recognition a survey.pdf", "CNN", "Toward human activity recognition a survey.pdf", "\u795e\u7ecf\u7f51\u7edc", "Toward human activity recognition a survey.pdf", "3D\u5377\u79ef\u795e\u7ecf\u7f51\u7edc", "Toward human activity recognition a survey.pdf", "3D\u5377\u79ef", "Toward human activity recognition a survey.pdf", "\u4eba\u673a\u4ea4\u4e92", "Toward human activity recognition a survey.pdf", "\u52a8\u6001\u56fe\u50cf\u5904\u7406", "Toward human activity recognition a survey.pdf", "\u6df1\u5ea6\u5b66\u4e60", "Toward human activity recognition a survey.pdf", "rank pooling", "Toward human activity recognition a survey.pdf", "attention mechanism", "Toward human activity recognition a survey.pdf", "network", "Toward human activity recognition a survey.pdf", "devices", "Toward human activity recognition a survey.pdf", "\u5927\u89c4\u6a21\u6570\u636e\u96c6", "Toward human activity recognition a survey.pdf", "\u56fe\u50cf\u5904\u7406", "Toward human activity recognition a survey.pdf", "image recognition", "Toward human activity recognition a survey.pdf", "\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b", "Toward human activity recognition a survey.pdf", "\u6df1\u5ea6\u7f51\u7edc", "Toward human activity recognition a survey.pdf", "\u673a\u5668\u5b66\u4e60", "Toward human activity recognition a survey.pdf", "\u5927\u6570\u636e", "Toward human activity recognition a survey.pdf", "\u7279\u5f81\u5de5\u7a0b", "Toward human activity recognition a survey.pdf", "Docker", "Toward human activity recognition a survey.pdf", "model", "Toward human activity recognition a survey.pdf", "\u56fe\u50cf\u5206\u7c7b", "Toward human activity recognition a survey.pdf", "surveillance data streams", "Toward human activity recognition a survey.pdf", "\u591a\u4efb\u52a1\u5b66\u4e60", "Toward human activity recognition a survey.pdf", "Recurrent neural networks", "Toward human activity recognition a survey.pdf", "\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5", "Toward human activity recognition a survey.pdf", "classification", "Toward human activity recognition a survey.pdf", "natural language processing", "Toward human activity recognition a survey.pdf", "reinforcement learning", "Toward human activity recognition a survey.pdf", "\u5377\u79ef\u795e\u7ecf\u7f51\u7edc", "Toward human activity recognition a survey.pdf", "security", "Toward human activity recognition a survey.pdf", "SIFT", "Toward human activity recognition a survey.pdf", "Markov\u94fe", "Toward human activity recognition a survey.pdf", "\u8ba1\u7b97\u673a\u89c6\u89c9", "Toward human activity recognition a survey.pdf", "object detection", "Toward human activity recognition a survey.pdf", "Group", "Toward human activity recognition a survey.pdf", "\u5f3a\u5316\u5b66\u4e60", "Toward human activity recognition a survey.pdf", "Convolutional neural networks", "Toward human activity recognition a survey.pdf", "\u795e\u7ecf\u8ba1\u7b97", "TrackNet A Deep Learning Network for TrackingHigh-speed and Tiny Objects in Sports Applications.pdf", "\u4eba\u5de5\u667a\u80fd", "TrackNet A Deep Learning Network for TrackingHigh-speed and Tiny Objects in Sports Applications.pdf", "\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc", "TrackNet A Deep Learning Network for TrackingHigh-speed and Tiny Objects in Sports Applications.pdf", "Fully convolutional networks", "TrackNet A Deep Learning Network for TrackingHigh-speed and Tiny Objects in Sports Applications.pdf", "learning", "TrackNet A Deep Learning Network for TrackingHigh-speed and Tiny Objects in Sports Applications.pdf", "pooling", "TrackNet A Deep Learning Network for TrackingHigh-speed and Tiny Objects in Sports Applications.pdf", "neural networks", "TrackNet A Deep Learning Network for TrackingHigh-speed and Tiny Objects in Sports Applications.pdf", "CNNs", "TrackNet A Deep Learning Network for TrackingHigh-speed and Tiny Objects in Sports Applications.pdf", "neural network", "TrackNet A Deep Learning Network for TrackingHigh-speed and Tiny Objects in Sports Applications.pdf", "CNN", "TrackNet A Deep Learning Network for TrackingHigh-speed and Tiny Objects in Sports Applications.pdf", "semantic segmentation", "TrackNet A Deep Learning Network for TrackingHigh-speed and Tiny Objects in Sports Applications.pdf", "\u795e\u7ecf\u7f51\u7edc", "TrackNet A Deep Learning Network for TrackingHigh-speed and Tiny Objects in Sports Applications.pdf", "\u6df1\u5ea6\u5b66\u4e60", "TrackNet A Deep Learning Network for TrackingHigh-speed and Tiny Objects in Sports Applications.pdf", "Frame", "TrackNet A Deep Learning Network for TrackingHigh-speed and Tiny Objects in Sports Applications.pdf", "\u5377\u79ef\u5c42", "TrackNet A Deep Learning Network for TrackingHigh-speed and Tiny Objects in Sports Applications.pdf", "\u56fe\u50cf\u5904\u7406", "TrackNet A Deep Learning Network for TrackingHigh-speed and Tiny Objects in Sports Applications.pdf", "Overfitting", "TrackNet A Deep Learning Network for TrackingHigh-speed and Tiny Objects in Sports Applications.pdf", "\u6700\u5927\u6c60\u5316", "TrackNet A Deep Learning Network for TrackingHigh-speed and Tiny Objects in Sports Applications.pdf", "batch normalization", "TrackNet A Deep Learning Network for TrackingHigh-speed and Tiny Objects in Sports Applications.pdf", "Softmax", "TrackNet A Deep Learning Network for TrackingHigh-speed and Tiny Objects in Sports Applications.pdf", "\u8d85\u53c2\u6570\u8c03\u4f18", "TrackNet A Deep Learning Network for TrackingHigh-speed and Tiny Objects in Sports Applications.pdf", "ReLU", "TrackNet A Deep Learning Network for TrackingHigh-speed and Tiny Objects in Sports Applications.pdf", "\u7279\u5f81\u5b66\u4e60", "TrackNet A Deep Learning Network for TrackingHigh-speed and Tiny Objects in Sports Applications.pdf", "Gaussian\u5206\u5e03", "TrackNet A Deep Learning Network for TrackingHigh-speed and Tiny Objects in Sports Applications.pdf", "\u56fe\u50cf\u5206\u7c7b", "TrackNet A Deep Learning Network for TrackingHigh-speed and Tiny Objects in Sports Applications.pdf", "kernel", "TrackNet A Deep Learning Network for TrackingHigh-speed and Tiny Objects in Sports Applications.pdf", "loss function", "TrackNet A Deep Learning Network for TrackingHigh-speed and Tiny Objects in Sports Applications.pdf", "epoch", "TrackNet A Deep Learning Network for TrackingHigh-speed and Tiny Objects in Sports Applications.pdf", "Convolutional Neural Networks", "TrackNet A Deep Learning Network for TrackingHigh-speed and Tiny Objects in Sports Applications.pdf", "\u5377\u79ef\u795e\u7ecf\u7f51\u7edc", "TrackNet A Deep Learning Network for TrackingHigh-speed and Tiny Objects in Sports Applications.pdf", "\u6fc0\u6d3b\u51fd\u6570", "TrackNet A Deep Learning Network for TrackingHigh-speed and Tiny Objects in Sports Applications.pdf", "pooling layer", "TrackNet A Deep Learning Network for TrackingHigh-speed and Tiny Objects in Sports Applications.pdf", "SIFT", "TrackNet A Deep Learning Network for TrackingHigh-speed and Tiny Objects in Sports Applications.pdf", "object detection", "TrackNet A Deep Learning Network for TrackingHigh-speed and Tiny Objects in Sports Applications.pdf", "R-CNN", "TrackNet A Deep Learning Network for TrackingHigh-speed and Tiny Objects in Sports Applications.pdf", "learning rate", "TrackNet A Deep Learning Network for TrackingHigh-speed and Tiny Objects in Sports Applications.pdf", "\u673a\u5668\u89c6\u89c9", "TrackNet A Deep Learning Network for TrackingHigh-speed and Tiny Objects in Sports Applications.pdf", "softmax\u51fd\u6570", "TrackNet A Deep Learning Network for TrackingHigh-speed and Tiny Objects in Sports Applications.pdf", "\u7ef4\u5ea6", "TrackNet A Deep Learning Network for TrackingHigh-speed and Tiny Objects in Sports Applications.pdf", "dataset", "TrackNet A Deep Learning Network for TrackingHigh-speed and Tiny Objects in Sports Applications.pdf", "\u6df1\u5ea6\u5b66\u4e60\u7f51\u7edc", "TrackNet A Deep Learning Network for TrackingHigh-speed and Tiny Objects in Sports Applications.pdf", "smartphones", "TrackNet A Deep Learning Network for TrackingHigh-speed and Tiny Objects in Sports Applications.pdf", "\u4eba\u4f53\u6d3b\u52a8\u8bc6\u522b", "TrackNet A Deep Learning Network for TrackingHigh-speed and Tiny Objects in Sports Applications.pdf", "Batch Normalization", "TrackNet A Deep Learning Network for TrackingHigh-speed and Tiny Objects in Sports Applications.pdf", "occlusion", "TrackNet A Deep Learning Network for TrackingHigh-speed and Tiny Objects in Sports Applications.pdf", "video analysis", "TrackNet A Deep Learning Network for TrackingHigh-speed and Tiny Objects in Sports Applications.pdf", "Euclidean\u8ddd\u79bb", "TrackNet A Deep Learning Network for TrackingHigh-speed and Tiny Objects in Sports Applications.pdf", "\u7edf\u8ba1\u7279\u5f81", "TrackNet A Deep Learning Network for TrackingHigh-speed and Tiny Objects in Sports Applications.pdf", "angles", "TrackNet A Deep Learning Network for TrackingHigh-speed and Tiny Objects in Sports Applications.pdf", "ground truth", "TrackNet A Deep Learning Network for TrackingHigh-speed and Tiny Objects in Sports Applications.pdf", "Trajectory", "TrackNetV2 Efficient Shuttlecock TrackingNetwork.pdf", "\u4eba\u5de5\u667a\u80fd", "TrackNetV2 Efficient Shuttlecock TrackingNetwork.pdf", "DenseNet", "TrackNetV2 Efficient Shuttlecock TrackingNetwork.pdf", "\u6df1\u5ea6\u5b66\u4e60", "TrackNetV2 Efficient Shuttlecock TrackingNetwork.pdf", "\u5377\u79ef\u5c42", "TrackNetV2 Efficient Shuttlecock TrackingNetwork.pdf", "network", "TrackNetV2 Efficient Shuttlecock TrackingNetwork.pdf", "relu", "TrackNetV2 Efficient Shuttlecock TrackingNetwork.pdf", "softmax", "TrackNetV2 Efficient Shuttlecock TrackingNetwork.pdf", "S3\u5b58\u50a8\u670d\u52a1", "TrackNetV2 Efficient Shuttlecock TrackingNetwork.pdf", "loss function", "TrackNetV2 Efficient Shuttlecock TrackingNetwork.pdf", "\u7f51\u7edc\u7ed3\u6784", "TrackNetV2 Efficient Shuttlecock TrackingNetwork.pdf", "VGG16", "TrackNetV2 Efficient Shuttlecock TrackingNetwork.pdf", "concatenate", "TrackNetV2 Efficient Shuttlecock TrackingNetwork.pdf", "Docker\u5bb9\u5668", "TrackNetV2 Efficient Shuttlecock TrackingNetwork.pdf", "\u8ba1\u7b97\u673a\u89c6\u89c9", "TrackNetV2 Efficient Shuttlecock TrackingNetwork.pdf", "accuracy", "TrackNetV2 Efficient Shuttlecock TrackingNetwork.pdf", "object detection", "TrackNetV2 Efficient Shuttlecock TrackingNetwork.pdf", "U-Net", "TrackNetV2 Efficient Shuttlecock TrackingNetwork.pdf", "\u81ea\u52a8\u5316\u90e8\u7f72", "TrackNetV2 Efficient Shuttlecock TrackingNetwork.pdf", "machine learning", "TrackNetV2 Efficient Shuttlecock TrackingNetwork.pdf", "AWS", "TrackNetV2 Efficient Shuttlecock TrackingNetwork.pdf", "Adadelta", "TrackNetV2 Efficient Shuttlecock TrackingNetwork.pdf", "\u7279\u5f81\u62bd\u53d6", "TrackNetV2 Efficient Shuttlecock TrackingNetwork.pdf", "\u6df1\u5ea6\u5b66\u4e60\u7f51\u7edc", "TrackNetV2 Efficient Shuttlecock TrackingNetwork.pdf", "computer vision", "TrackNetV2 Efficient Shuttlecock TrackingNetwork.pdf", "acoustic data", "TrackNetV2 Efficient Shuttlecock TrackingNetwork.pdf", "softmax layer", "TrackNetV2 Efficient Shuttlecock TrackingNetwork.pdf", "FCN", "TrackNetV2 Efficient Shuttlecock TrackingNetwork.pdf", "golf swing", "TrackNetV2 Efficient Shuttlecock TrackingNetwork.pdf", "pose estimation", "TrackNetV2 Efficient Shuttlecock TrackingNetwork.pdf", "deeplearning", "TrackNetV2 Efficient Shuttlecock TrackingNetwork.pdf", "Euclideandean\u8ddd\u79bb", "TrackNetV2 Efficient Shuttlecock TrackingNetwork.pdf", "deep learning", "TrackNetV2 Efficient Shuttlecock TrackingNetwork.pdf", "ball tracking", "TrackNetV2 Efficient Shuttlecock TrackingNetwork.pdf", "max pooling", "TrackNetV2 Efficient Shuttlecock TrackingNetwork.pdf", "precision", "TrackNetV2 Efficient Shuttlecock TrackingNetwork.pdf", "F1-measure", "TrackNetV2 Efficient Shuttlecock TrackingNetwork.pdf", "Kernelsize", "TrackNetV2 Efficient Shuttlecock TrackingNetwork.pdf", "batch norm", "TrackNetV2 Efficient Shuttlecock TrackingNetwork.pdf", "GPU memory", "TrackNetV2 Efficient Shuttlecock TrackingNetwork.pdf", "broad", "TrackNetV2 Efficient Shuttlecock TrackingNetwork.pdf", "L1 loss", "TrackNetV2 Efficient Shuttlecock TrackingNetwork.pdf", "Gaussian distribution", "TrackNetV2 Efficient Shuttlecock TrackingNetwork.pdf", "cross-entropy", "TrackNetV2 Efficient Shuttlecock TrackingNetwork.pdf", "overfitting", "TrackNetV2 Efficient Shuttlecock TrackingNetwork.pdf", "backgrounds", "TrackNetV2 Efficient Shuttlecock TrackingNetwork.pdf", "multi-task deep learning", "TrackNetV2 Efficient Shuttlecock TrackingNetwork.pdf", "weighted cross-entropy", "TrackNetV2 Efficient Shuttlecock TrackingNetwork.pdf", "high-speed object", "TrackNetV2 Efficient Shuttlecock TrackingNetwork.pdf", "KDNN", "TrackNetV2 Efficient Shuttlecock TrackingNetwork.pdf", "heatmap", "TrackNetV3.pdf", "data augmentation", "TrackNetV3.pdf", "\u52a8\u529b\u5b66", "TrackNetV3.pdf", "motion blur", "TrackNetV3.pdf", "video frames", "TrackNetV3.pdf", "AlexNet", "TrackNetV3.pdf", "\u6df1\u5ea6\u5b66\u4e60", "TrackNetV3.pdf", "\u5377\u79ef\u5c42", "TrackNetV3.pdf", "Computer Vision", "TrackNetV3.pdf", "Accuracy", "TrackNetV3.pdf", "\u673a\u5668\u5b66\u4e60", "TrackNetV3.pdf", "IoU", "TrackNetV3.pdf", "epochs", "TrackNetV3.pdf", "downsampling", "TrackNetV3.pdf", "training", "TrackNetV3.pdf", "U-Net", "TrackNetV3.pdf", "R-CNN", "TrackNetV3.pdf", "baseline", "TrackNetV3.pdf", "\u4e8c\u8fdb\u5236\u4ea4\u53c9\u71b5", "TrackNetV3.pdf", "pattern recognition", "TrackNetV3.pdf", "fully convolutional networks", "TrackNetV3.pdf", "Robustness", "TrackNetV3.pdf", "strategy", "TrackNetV3.pdf", "robustness", "TrackNetV3.pdf", "regions", "TrackNetV3.pdf", "IEEE Conference on Computer Vision and Pattern Recognition", "TrackNetV3.pdf", "Sigmoid", "TrackNetV3.pdf", "information", "TrackNetV3.pdf", "cross-correlation", "TrackNetV3.pdf", "tracking", "TrackNetV3.pdf", "background", "TrackNetV3.pdf", "formula", "TrackNetV3.pdf", "Yolov4", "TrackNetV3.pdf", "Dataset", "TrackNetV3.pdf", "TrackNet", "TrackNetV3.pdf", "Faster R-CNN", "TrackNetV3.pdf", "dense object detection", "TrackNetV3.pdf", "bounding box", "TrackNetV3.pdf", "Tracknet", "TrackNetV3.pdf", "Prediction", "TrackNetV3.pdf", "sports analytics", "TrackNetV3.pdf", "recall", "TrackNetV3.pdf", "Frames", "TrackNetV3.pdf", "baseline methods", "TrackNetV3.pdf", "precision", "TrackNetV3.pdf", "Convolutional Networks", "TrackNetV3.pdf", "heat map", "TrackNetV3.pdf", "Gaussian kernel", "TrackNetV3.pdf", "batch size", "TrackNetV3.pdf", "Precision", "TrackNetV3.pdf", "Recall", "TrackNetV4 Enhancing Fast Sports Object.pdf", "max-pooling", "TrackNetV4 Enhancing Fast Sports Object.pdf", "fine-tuning", "TrackNetV4 Enhancing Fast Sports Object.pdf", "neural networks", "TrackNetV4 Enhancing Fast Sports Object.pdf", "motion blur", "TrackNetV4 Enhancing Fast Sports Object.pdf", "\u6df1\u5ea6\u5b66\u4e60", "TrackNetV4 Enhancing Fast Sports Object.pdf", "pixel intensity", "TrackNetV4 Enhancing Fast Sports Object.pdf", "Performance", "TrackNetV4 Enhancing Fast Sports Object.pdf", "Frame", "TrackNetV4 Enhancing Fast Sports Object.pdf", "\u5377\u79ef\u5c42", "TrackNetV4 Enhancing Fast Sports Object.pdf", "DNS", "TrackNetV4 Enhancing Fast Sports Object.pdf", "\u8ba1\u7b97\u673a\u79d1\u5b66", "TrackNetV4 Enhancing Fast Sports Object.pdf", "DenseLayer", "TrackNetV4 Enhancing Fast Sports Object.pdf", "Kubernetes\u7ba1\u7406\u7cfb\u7edf", "TrackNetV4 Enhancing Fast Sports Object.pdf", "Convolutional\u5757", "TrackNetV4 Enhancing Fast Sports Object.pdf", "video processing", "TrackNetV4 Enhancing Fast Sports Object.pdf", "Softmax", "TrackNetV4 Enhancing Fast Sports Object.pdf", "S3\u5b58\u50a8\u670d\u52a1", "TrackNetV4 Enhancing Fast Sports Object.pdf", "Dense", "TrackNetV4 Enhancing Fast Sports Object.pdf", "activation", "TrackNetV4 Enhancing Fast Sports Object.pdf", "keras", "TrackNetV4 Enhancing Fast Sports Object.pdf", "\u03c3(\u00b7)", "TrackNetV4 Enhancing Fast Sports Object.pdf", "Sigmoid function", "TrackNetV4 Enhancing Fast Sports Object.pdf", "conv2D", "TrackNetV4 Enhancing Fast Sports Object.pdf", "Computer Science", "TrackNetV4 Enhancing Fast Sports Object.pdf", "linear", "TrackNetV4 Enhancing Fast Sports Object.pdf", "feature maps", "TrackNetV4 Enhancing Fast Sports Object.pdf", "batch_norm", "TrackNetV4 Enhancing Fast Sports Object.pdf", "Docker\u5bb9\u5668", "TrackNetV4 Enhancing Fast Sports Object.pdf", "Acoustics", "TrackNetV4 Enhancing Fast Sports Object.pdf", "sigmoid", "TrackNetV4 Enhancing Fast Sports Object.pdf", "\u8ba1\u7b97\u673a\u89c6\u89c9", "TrackNetV4 Enhancing Fast Sports Object.pdf", "accuracy", "TrackNetV4 Enhancing Fast Sports Object.pdf", "object detection", "TrackNetV4 Enhancing Fast Sports Object.pdf", "tensor", "TrackNetV4 Enhancing Fast Sports Object.pdf", "learning rate", "TrackNetV4 Enhancing Fast Sports Object.pdf", "input_shape", "TrackNetV4 Enhancing Fast Sports Object.pdf", "machine learning", "TrackNetV4 Enhancing Fast Sports Object.pdf", "dataset", "TrackNetV4 Enhancing Fast Sports Object.pdf", "2D\u5377\u79ef\u5c42", "TrackNetV4 Enhancing Fast Sports Object.pdf", "computer vision", "TrackNetV4 Enhancing Fast Sports Object.pdf", "robustness", "TrackNetV4 Enhancing Fast Sports Object.pdf", "Sigmoid", "TrackNetV4 Enhancing Fast Sports Object.pdf", "concatenation", "TrackNetV4 Enhancing Fast Sports Object.pdf", "tracking", "TrackNetV4 Enhancing Fast Sports Object.pdf", "occlusion", "TrackNetV4 Enhancing Fast Sports Object.pdf", "\u8fd0\u52a8\u8bc6\u522b", "TrackNetV4 Enhancing Fast Sports Object.pdf", "Machine Learning", "TrackNetV4 Enhancing Fast Sports Object.pdf", "Human pose estimation", "TrackNetV4 Enhancing Fast Sports Object.pdf", "Motion", "TrackNetV4 Enhancing Fast Sports Object.pdf", "ACM MM", "YO-CSA-T A Real-time Badminton Tracking System Utilizing YOLOBased on Contextual and Spatial Attention.pdf", "ImageNet", "YO-CSA-T A Real-time Badminton Tracking System Utilizing YOLOBased on Contextual and Spatial Attention.pdf", "data augmentation", "YO-CSA-T A Real-time Badminton Tracking System Utilizing YOLOBased on Contextual and Spatial Attention.pdf", "neural networks", "YO-CSA-T A Real-time Badminton Tracking System Utilizing YOLOBased on Contextual and Spatial Attention.pdf", "convolutional neural networks", "YO-CSA-T A Real-time Badminton Tracking System Utilizing YOLOBased on Contextual and Spatial Attention.pdf", "\u6df1\u5ea6\u5b66\u4e60", "YO-CSA-T A Real-time Badminton Tracking System Utilizing YOLOBased on Contextual and Spatial Attention.pdf", "\u5377\u79ef\u5c42", "YO-CSA-T A Real-time Badminton Tracking System Utilizing YOLOBased on Contextual and Spatial Attention.pdf", "image recognition", "YO-CSA-T A Real-time Badminton Tracking System Utilizing YOLOBased on Contextual and Spatial Attention.pdf", "convolution", "YO-CSA-T A Real-time Badminton Tracking System Utilizing YOLOBased on Contextual and Spatial Attention.pdf", "distribution", "YO-CSA-T A Real-time Badminton Tracking System Utilizing YOLOBased on Contextual and Spatial Attention.pdf", "saturation", "YO-CSA-T A Real-time Badminton Tracking System Utilizing YOLOBased on Contextual and Spatial Attention.pdf", "imagenet", "YO-CSA-T A Real-time Badminton Tracking System Utilizing YOLOBased on Contextual and Spatial Attention.pdf", "downsampling", "YO-CSA-T A Real-time Badminton Tracking System Utilizing YOLOBased on Contextual and Spatial Attention.pdf", "classification", "YO-CSA-T A Real-time Badminton Tracking System Utilizing YOLOBased on Contextual and Spatial Attention.pdf", "Bottleneck", "YO-CSA-T A Real-time Badminton Tracking System Utilizing YOLOBased on Contextual and Spatial Attention.pdf", "attention", "YO-CSA-T A Real-time Badminton Tracking System Utilizing YOLOBased on Contextual and Spatial Attention.pdf", "\u8ba1\u7b97\u673a\u89c6\u89c9", "YO-CSA-T A Real-time Badminton Tracking System Utilizing YOLOBased on Contextual and Spatial Attention.pdf", "U-Net", "YO-CSA-T A Real-time Badminton Tracking System Utilizing YOLOBased on Contextual and Spatial Attention.pdf", "ResNet", "YO-CSA-T A Real-time Badminton Tracking System Utilizing YOLOBased on Contextual and Spatial Attention.pdf", "R-CNN", "YO-CSA-T A Real-time Badminton Tracking System Utilizing YOLOBased on Contextual and Spatial Attention.pdf", "Convolutions", "YO-CSA-T A Real-time Badminton Tracking System Utilizing YOLOBased on Contextual and Spatial Attention.pdf", "dataset", "YO-CSA-T A Real-time Badminton Tracking System Utilizing YOLOBased on Contextual and Spatial Attention.pdf", "Robotics", "YO-CSA-T A Real-time Badminton Tracking System Utilizing YOLOBased on Contextual and Spatial Attention.pdf", "layers", "YO-CSA-T A Real-time Badminton Tracking System Utilizing YOLOBased on Contextual and Spatial Attention.pdf", "UAV", "YO-CSA-T A Real-time Badminton Tracking System Utilizing YOLOBased on Contextual and Spatial Attention.pdf", "robotics", "YO-CSA-T A Real-time Badminton Tracking System Utilizing YOLOBased on Contextual and Spatial Attention.pdf", "tracking", "YO-CSA-T A Real-time Badminton Tracking System Utilizing YOLOBased on Contextual and Spatial Attention.pdf", "feature extraction", "YO-CSA-T A Real-time Badminton Tracking System Utilizing YOLOBased on Contextual and Spatial Attention.pdf", "pipeline", "YO-CSA-T A Real-time Badminton Tracking System Utilizing YOLOBased on Contextual and Spatial Attention.pdf", "Transformer", "YO-CSA-T A Real-time Badminton Tracking System Utilizing YOLOBased on Contextual and Spatial Attention.pdf", "transformer", "YO-CSA-T A Real-time Badminton Tracking System Utilizing YOLOBased on Contextual and Spatial Attention.pdf", "encoder-decoder architecture", "YO-CSA-T A Real-time Badminton Tracking System Utilizing YOLOBased on Contextual and Spatial Attention.pdf", "3D trajectory", "YO-CSA-T A Real-time Badminton Tracking System Utilizing YOLOBased on Contextual and Spatial Attention.pdf", "self-attention", "YO-CSA-T A Real-time Badminton Tracking System Utilizing YOLOBased on Contextual and Spatial Attention.pdf", "spatial attention", "YO-CSA-T A Real-time Badminton Tracking System Utilizing YOLOBased on Contextual and Spatial Attention.pdf", "Detection", "YO-CSA-T A Real-time Badminton Tracking System Utilizing YOLOBased on Contextual and Spatial Attention.pdf", "Computer vision", "YO-CSA-T A Real-time Badminton Tracking System Utilizing YOLOBased on Contextual and Spatial Attention.pdf", "localization", "YO-CSA-T A Real-time Badminton Tracking System Utilizing YOLOBased on Contextual and Spatial Attention.pdf", "stereo vision", "YO-CSA-T A Real-time Badminton Tracking System Utilizing YOLOBased on Contextual and Spatial Attention.pdf", "YOLOv5", "YO-CSA-T A Real-time Badminton Tracking System Utilizing YOLOBased on Contextual and Spatial Attention.pdf", "architecture", "YO-CSA-T A Real-time Badminton Tracking System Utilizing YOLOBased on Contextual and Spatial Attention.pdf", "medical image segmentation", "YO-CSA-T A Real-time Badminton Tracking System Utilizing YOLOBased on Contextual and Spatial Attention.pdf", "detection network", "YO-CSA-T A Real-time Badminton Tracking System Utilizing YOLOBased on Contextual and Spatial Attention.pdf", "stereo cameras", "YO-CSA-T A Real-time Badminton Tracking System Utilizing YOLOBased on Contextual and Spatial Attention.pdf", "\u7a7a\u95f4\u6ce8\u610f\u529b", "YO-CSA-T A Real-time Badminton Tracking System Utilizing YOLOBased on Contextual and Spatial Attention.pdf", "HRNet", "YO-CSA-T A Real-time Badminton Tracking System Utilizing YOLOBased on Contextual and Spatial Attention.pdf", "\u6df1\u5ea6\u6b8b\u5dee\u5b66\u4e60", "YO-CSA-T A Real-time Badminton Tracking System Utilizing YOLOBased on Contextual and Spatial Attention.pdf", "ViT", "YO-CSA-T A Real-time Badminton Tracking System Utilizing YOLOBased on Contextual and Spatial Attention.pdf", "RetinaNet", "YO-CSA-T A Real-time Badminton Tracking System Utilizing YOLOBased on Contextual and Spatial Attention.pdf", "long-range dependencies", "YO-CSA-T A Real-time Badminton Tracking System Utilizing YOLOBased on Contextual and Spatial Attention.pdf", "lighting", "YOLOv1.pdf", "\u4eba\u5de5\u667a\u80fd", "YOLOv1.pdf", "\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc", "YOLOv1.pdf", "data augmentation", "YOLOv1.pdf", "neural networks", "YOLOv1.pdf", "neural network", "YOLOv1.pdf", "CNN", "YOLOv1.pdf", "SVM", "YOLOv1.pdf", "convolutional.layers", "YOLOv1.pdf", "\u5377\u79ef\u5c42", "YOLOv1.pdf", "YOLO\u6a21\u578b", "YOLOv1.pdf", "momentum", "YOLOv1.pdf", "saturation", "YOLOv1.pdf", "image segmentation", "YOLOv1.pdf", "Image Classification", "YOLOv1.pdf", "Convolutional Neural Network", "YOLOv1.pdf", "SIFT", "YOLOv1.pdf", "\u8ba1\u7b97\u673a\u89c6\u89c9", "YOLOv1.pdf", "inference", "YOLOv1.pdf", "R-CNN", "YOLOv1.pdf", "learning rate", "YOLOv1.pdf", "learning rate schedule", "YOLOv1.pdf", "arXiv", "YOLOv1.pdf", "sliding window", "YOLOv1.pdf", "human", "YOLOv1.pdf", "fully connected layers", "YOLOv1.pdf", "extraction", "YOLOv1.pdf", "\u5b9e\u65f6\u7cfb\u7edf", "YOLOv1.pdf", "regression problem", "YOLOv1.pdf", "feature extraction", "YOLOv1.pdf", "detectors", "YOLOv1.pdf", "detector", "YOLOv1.pdf", "convolutional layers", "YOLOv1.pdf", "deeplearning", "YOLOv1.pdf", "convolutions", "YOLOv1.pdf", "pipeline", "YOLOv1.pdf", "ground truth", "YOLOv1.pdf", "Faster R-CNN", "YOLOv1.pdf", "bounding box", "YOLOv1.pdf", "predictor", "YOLOv1.pdf", "bounding boxes", "YOLOv1.pdf", "recall", "YOLOv1.pdf", "resolution", "YOLOv1.pdf", "convolutional layer", "YOLOv1.pdf", "RCNN", "YOLOv1.pdf", "convolutional neural network", "YOLOv1.pdf", "Detection", "YOLOv1.pdf", "VGG-16", "YOLOv1.pdf", "FAST", "YOLOv1.pdf", "VGG", "YOLOv1.pdf", "localization", "YOLOv2.pdf", "\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc", "YOLOv2.pdf", "ImageNet", "YOLOv2.pdf", "neural networks", "YOLOv2.pdf", "convolutional neural networks", "YOLOv2.pdf", "\u795e\u7ecf\u7f51\u7edc", "YOLOv2.pdf", "AlexNet", "YOLOv2.pdf", "\u5377\u79ef\u5c42", "YOLOv2.pdf", "feature map", "YOLOv2.pdf", "batch normalization", "YOLOv2.pdf", "momentum", "YOLOv2.pdf", "\u5b66\u4e60\u7387\u8c03\u8282", "YOLOv2.pdf", "Sutskever", "YOLOv2.pdf", "Krizhevsky", "YOLOv2.pdf", "saturation", "YOLOv2.pdf", "layer", "YOLOv2.pdf", "inception-resnet", "YOLOv2.pdf", "Node", "YOLOv2.pdf", "pooling layer", "YOLOv2.pdf", "dropout", "YOLOv2.pdf", "\u8ba1\u7b97\u673a\u89c6\u89c9", "YOLOv2.pdf", "ResNet", "YOLOv2.pdf", "k-means", "YOLOv2.pdf", "softmax\u51fd\u6570", "YOLOv2.pdf", "Hinton", "YOLOv2.pdf", "inception-v4", "YOLOv2.pdf", "1\u00d71\u5377\u79ef\u5c42", "YOLOv2.pdf", "cluster", "YOLOv2.pdf", "classi\ufb01cation", "YOLOv2.pdf", "object", "YOLOv2.pdf", "height", "YOLOv2.pdf", "clustering", "YOLOv2.pdf", "Deep residual learning", "YOLOv2.pdf", "frequency", "YOLOv2.pdf", "robustness", "YOLOv2.pdf", "centroid", "YOLOv2.pdf", "Euclidean\u8ddd\u79bb", "YOLOv2.pdf", "ground truth", "YOLOv2.pdf", "Faster R-CNN", "YOLOv2.pdf", "anchor box", "YOLOv2.pdf", "bounding box", "YOLOv2.pdf", "real-time object detection", "YOLOv2.pdf", "bounding boxes", "YOLOv2.pdf", "Image recognition", "YOLOv2.pdf", "oversampling", "YOLOv2.pdf", "resolution", "YOLOv2.pdf", "convolutional layer", "YOLOv2.pdf", "image classification", "YOLOv2.pdf", "VGG", "YOLOv2.pdf", "batch norm", "YOLOv2.pdf", "top-5 accuracy", "YOLOv3.pdf", "\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc", "YOLOv3.pdf", "ImageNet", "YOLOv3.pdf", "feature map", "YOLOv3.pdf", "Accuracy", "YOLOv3.pdf", "\u673a\u5668\u5b66\u4e60", "YOLOv3.pdf", "Softmax", "YOLOv3.pdf", "softmax", "YOLOv3.pdf", "GPU", "YOLOv3.pdf", "Residual", "YOLOv3.pdf", "\u7aef\u5230\u7aef\u5b66\u4e60", "YOLOv3.pdf", "accuracy", "YOLOv3.pdf", "object detection", "YOLOv3.pdf", "ICCV", "YOLOv3.pdf", "tensor", "YOLOv3.pdf", "dataset", "YOLOv3.pdf", "computer vision", "YOLOv3.pdf", "clustering", "YOLOv3.pdf", "ResNet-152", "YOLOv3.pdf", "detectors", "YOLOv3.pdf", "semantic information", "YOLOv3.pdf", "scales", "YOLOv3.pdf", "convolutional layers", "YOLOv3.pdf", "GAN", "YOLOv3.pdf", "residual network", "YOLOv3.pdf", "Faster R-CNN", "YOLOv3.pdf", "Ssd", "YOLOv3.pdf", "bounding box", "YOLOv3.pdf", "deep learning", "YOLOv3.pdf", "R-FCN", "YOLOv3.pdf", "floating point operations", "YOLOv3.pdf", "focal loss", "YOLOv3.pdf", "anchor boxes", "YOLOv3.pdf", "ResNet-101", "YOLOv3.pdf", "ObjectDetection", "YOLOv3.pdf", "vision", "YOLOv3.pdf", "Inception-ResNet-v2", "YOLOv3.pdf", "top-down modulation", "YOLOv3.pdf", "RetinaNet", "YOLOv3.pdf", "region proposal networks", "YOLOv3.pdf", "single shot multibox detector", "YOLOv3.pdf", "ResNet-101-FPN", "YOLOv3.pdf", "ResNets", "YOLOv3.pdf", "bounding box detection", "YOLOv3.pdf", "ResNeXt-101-FPN", "YOLOv3.pdf", "Titan X", "YOLOv3.pdf", "Person", "YOLOv3.pdf", "feature extractor", "YOLOv3.pdf", "Upsample", "YOLOv3.pdf", "Bounding boxes", "YOLOv3.pdf", "Avgpool", "YOLOv4.pdf", "max-pooling", "YOLOv4.pdf", "cvpr", "YOLOv4.pdf", "ImageNet", "YOLOv4.pdf", "data augmentation", "YOLOv4.pdf", "neural networks", "YOLOv4.pdf", "neural network", "YOLOv4.pdf", "CNN", "YOLOv4.pdf", "\u795e\u7ecf\u7f51\u7edc", "YOLOv4.pdf", "DenseNet", "YOLOv4.pdf", "NIPS", "YOLOv4.pdf", "\u6df1\u5ea6\u5b66\u4e60", "YOLOv4.pdf", "Kubernetes", "YOLOv4.pdf", "tanh", "YOLOv4.pdf", "attention mechanism", "YOLOv4.pdf", "Computer Vision", "YOLOv4.pdf", "batch normalization", "YOLOv4.pdf", "softmax", "YOLOv4.pdf", "momentum", "YOLOv4.pdf", "ReLU", "YOLOv4.pdf", "IoU", "YOLOv4.pdf", "GPU", "YOLOv4.pdf", "Convolutional Neural Network", "YOLOv4.pdf", "Docker\u5bb9\u5668", "YOLOv4.pdf", "training", "YOLOv4.pdf", "sigmoid", "YOLOv4.pdf", "semantic image segmentation", "YOLOv4.pdf", "dropout", "YOLOv4.pdf", "Cross Entropy", "YOLOv4.pdf", "object detection", "YOLOv4.pdf", "ICCV", "YOLOv4.pdf", "ResNet", "YOLOv4.pdf", "R-CNN", "YOLOv4.pdf", "Label", "YOLOv4.pdf", "AWS", "YOLOv4.pdf", "normalization", "YOLOv4.pdf", "pattern recognition", "YOLOv4.pdf", "\u68af\u5ea6\u4e0b\u964d", "YOLOv4.pdf", "features", "YOLOv4.pdf", "artificial intelligence", "YOLOv4.pdf", "computer vision", "YOLOv4.pdf", "Batch Normalization", "YOLOv4.pdf", "recognition", "YOLOv4.pdf", "feature extraction", "YOLOv4.pdf", "CRFs", "YOLOv4.pdf", "detector", "YOLOv4.pdf", "Machine Learning", "YOLOv4.pdf", "Fully Convolutional Network", "YOLOv4.pdf", "MSE", "YOLOv4.pdf", "networks", "YOLOv4.pdf", "ground truth", "YOLOv5.pdf", "ReLU\u5c42", "YOLOv5.pdf", "neural networks", "YOLOv5.pdf", "segmentation", "YOLOv5.pdf", "convolutional neural networks", "YOLOv5.pdf", "feature", "YOLOv5.pdf", "CNN", "YOLOv5.pdf", "\u6df1\u5ea6\u5b66\u4e60", "YOLOv5.pdf", "attention mechanism", "YOLOv5.pdf", "\u56fe\u50cf\u5904\u7406", "YOLOv5.pdf", "Convolution", "YOLOv5.pdf", "Deep learning", "YOLOv5.pdf", "feature maps", "YOLOv5.pdf", "Neural Information Processing Systems", "YOLOv5.pdf", "object detection", "YOLOv5.pdf", "R-CNN", "YOLOv5.pdf", "arXiv", "YOLOv5.pdf", "AWS", "YOLOv5.pdf", "\u52a0\u6743\u548c", "YOLOv5.pdf", "Deeplab", "YOLOv5.pdf", "computer vision", "YOLOv5.pdf", "Sigmoid", "YOLOv5.pdf", "Recognition", "YOLOv5.pdf", "Pattern Recognition", "YOLOv5.pdf", "translation", "YOLOv5.pdf", "multiple instance learning", "YOLOv5.pdf", "bounding box", "YOLOv5.pdf", "convolutional layer", "YOLOv5.pdf", "convolutional network", "YOLOv5.pdf", "Detection", "YOLOv5.pdf", "convolutional", "YOLOv5.pdf", "fast R-CNN", "YOLOv5.pdf", "Atrous Convolution", "YOLOv5.pdf", "ResNet-50", "YOLOv5.pdf", "Object Detection", "YOLOv5.pdf", "instance segmentation", "YOLOv5.pdf", "focal loss", "YOLOv5.pdf", "global context", "YOLOv5.pdf", "Fusion", "YOLOv5.pdf", "Detectron", "YOLOv5.pdf", "vision", "YOLOv5.pdf", "Conv", "YOLOv5.pdf", "backbone", "YOLOv5.pdf", "\u89c6\u89c9\u6ce8\u610f\u529b", "YOLOv5.pdf", "Mask R-CNN", "YOLOv5.pdf", "image super-resolution", "YOLOv5.pdf", "ResNeXt-101", "YOLOv5.pdf", "multi-scale testing", "YOLOv5.pdf", "ResNeXt", "YOLOv5.pdf", "APL", "YOLOv5.pdf", "Instance Segmentation", "YOLOv5s-Megvii.pdf", "ImageNet", "YOLOv5s-Megvii.pdf", "data augmentation", "YOLOv5s-Megvii.pdf", "CNN", "YOLOv5s-Megvii.pdf", "NIPS", "YOLOv5s-Megvii.pdf", "\u56fe\u50cf\u8bc6\u522b", "YOLOv5s-Megvii.pdf", "Computer Vision", "YOLOv5s-Megvii.pdf", "feature map", "YOLOv5s-Megvii.pdf", "convolution", "YOLOv5s-Megvii.pdf", "batch normalization", "YOLOv5s-Megvii.pdf", "anchors", "YOLOv5s-Megvii.pdf", "ReLU", "YOLOv5s-Megvii.pdf", "IoU", "YOLOv5s-Megvii.pdf", "SGD", "YOLOv5s-Megvii.pdf", "model", "YOLOv5s-Megvii.pdf", "epochs", "YOLOv5s-Megvii.pdf", "Deep learning", "YOLOv5s-Megvii.pdf", "split", "YOLOv5s-Megvii.pdf", "training", "YOLOv5s-Megvii.pdf", "region proposal network", "YOLOv5s-Megvii.pdf", "inference", "YOLOv5s-Megvii.pdf", "object detection", "YOLOv5s-Megvii.pdf", "blocks", "YOLOv5s-Megvii.pdf", "ResNet", "YOLOv5s-Megvii.pdf", "Memory", "YOLOv5s-Megvii.pdf", "learning rate", "YOLOv5s-Megvii.pdf", "residual blocks", "YOLOv5s-Megvii.pdf", "arXiv", "YOLOv5s-Megvii.pdf", "anchor", "YOLOv5s-Megvii.pdf", "encoder", "YOLOv5s-Megvii.pdf", "pattern recognition", "YOLOv5s-Megvii.pdf", "Model", "YOLOv5s-Megvii.pdf", "Blocks", "YOLOv5s-Megvii.pdf", "computer vision", "YOLOv5s-Megvii.pdf", "strategy", "YOLOv5s-Megvii.pdf", "dilated convolution", "YOLOv5s-Megvii.pdf", "matching", "YOLOv5s-Megvii.pdf", "feature detection", "YOLOv5s-Megvii.pdf", "detector", "YOLOv5s-Megvii.pdf", "scales", "YOLOv5s-Megvii.pdf", "GAN", "YOLOv5s-Megvii.pdf", "transformer", "YOLOv5s-Megvii.pdf", "Ssd", "YOLOv5s-Megvii.pdf", "dense object detection", "YOLOv5s-Megvii.pdf", "convolution layers", "YOLOv5s-Megvii.pdf", "figure", "YOLOv5s-Megvii.pdf", "feature fusion", "YOLOv5s-Megvii.pdf", "batch size", "YOLOv5s-Megvii.pdf", "R-FCN", "YOLOv5s-Megvii.pdf", "receptive fields", "YOLOv5s-Megvii.pdf", "UNet", "YOLOv6.pdf", "Tensor", "YOLOv6.pdf", "momentum", "YOLOv6.pdf", "ReLU", "YOLOv6.pdf", "\u6982\u7387\u5206\u5e03", "YOLOv6.pdf", "IoU", "YOLOv6.pdf", "Dense", "YOLOv6.pdf", "SGD", "YOLOv6.pdf", "epochs", "YOLOv6.pdf", "\u5377\u79ef", "YOLOv6.pdf", "Quantization-aware training", "YOLOv6.pdf", "DNN", "YOLOv6.pdf", "loss\u51fd\u6570", "YOLOv6.pdf", "Distribution", "YOLOv6.pdf", "loss function", "YOLOv6.pdf", "Network", "YOLOv6.pdf", "training", "YOLOv6.pdf", "accuracy", "YOLOv6.pdf", "object detection", "YOLOv6.pdf", "arXiv", "YOLOv6.pdf", "pattern recognition", "YOLOv6.pdf", "Model", "YOLOv6.pdf", "Densely connected convolutional networks", "YOLOv6.pdf", "\u6df1\u795e\u7ecf\u7f51\u7edc", "YOLOv6.pdf", "training process", "YOLOv6.pdf", "convolutional layers", "YOLOv6.pdf", "Yolov4", "YOLOv6.pdf", "MSE", "YOLOv6.pdf", "uncertainty", "YOLOv6.pdf", "deep learning", "YOLOv6.pdf", "bounding boxes", "YOLOv6.pdf", "VGG", "YOLOv6.pdf", "quantization scheme", "YOLOv6.pdf", "YOLOv5", "YOLOv6.pdf", "Quantization", "YOLOv6.pdf", "stochastic gradient descent", "YOLOv6.pdf", "L1 loss", "YOLOv6.pdf", "focal loss", "YOLOv6.pdf", "Yolov7", "YOLOv6.pdf", "soft labels", "YOLOv6.pdf", "vision", "YOLOv6.pdf", "\u6df1\u5ea6\u6b8b\u5dee\u7f51\u7edc", "YOLOv6.pdf", "Conv", "YOLOv6.pdf", "FLOPs", "YOLOv6.pdf", "Latency", "YOLOv6.pdf", "quantization", "YOLOv6.pdf", "CSP", "YOLOv6.pdf", "boundaries", "YOLOv6.pdf", "keypoints", "YOLOv6.pdf", "image resizing", "YOLOv6.pdf", "Cross-entropy Loss", "YOLOv7.pdf", "LSTM", "YOLOv7.pdf", "convolutional neural networks", "YOLOv7.pdf", "CNNs", "YOLOv7.pdf", "optimization", "YOLOv7.pdf", "CNN", "YOLOv7.pdf", "DenseNet", "YOLOv7.pdf", "\u5377\u79ef\u5c42", "YOLOv7.pdf", "NIS", "YOLOv7.pdf", "\u7279\u5f81\u6620\u5c04", "YOLOv7.pdf", "Computer Vision", "YOLOv7.pdf", "feature map", "YOLOv7.pdf", "S3\u5b58\u50a8\u670d\u52a1", "YOLOv7.pdf", "IoU", "YOLOv7.pdf", "MobileNetV2", "YOLOv7.pdf", "MobileNet", "YOLOv7.pdf", "IoT", "YOLOv7.pdf", "3\u00d73\u5377\u79ef\u5c42", "YOLOv7.pdf", "\u591a\u4efb\u52a1\u5b66\u4e60", "YOLOv7.pdf", "feature maps", "YOLOv7.pdf", "\u5377\u79ef\u795e\u7ecf\u7f51\u7edc", "YOLOv7.pdf", "\u8ba1\u7b97\u673a\u89c6\u89c9", "YOLOv7.pdf", "Batch normalization", "YOLOv7.pdf", "ResNet", "YOLOv7.pdf", "AWS", "YOLOv7.pdf", "\u6df1\u5ea6\u5b66\u4e60\u7f51\u7edc", "YOLOv7.pdf", "1\u00d71\u5377\u79ef\u5c42", "YOLOv7.pdf", "transition layer", "YOLOv7.pdf", "Model", "YOLOv7.pdf", "self-supervised learning", "YOLOv7.pdf", "batch normalization layer", "YOLOv7.pdf", "DNNs", "YOLOv7.pdf", "robotics", "YOLOv7.pdf", "grid", "YOLOv7.pdf", "feature extraction", "YOLOv7.pdf", "pose estimation", "YOLOv7.pdf", "Dataset", "YOLOv7.pdf", "objects", "YOLOv7.pdf", "3D vision", "YOLOv7.pdf", "computing", "YOLOv7.pdf", "Very deep convolution", "YOLOv7.pdf", "recall", "YOLOv7.pdf", "kernels", "YOLOv7.pdf", "convolutional neural network", "YOLOv7.pdf", "mobile\u8bbe\u5907", "YOLOv7.pdf", "EfficientNet", "YOLOv7.pdf", "YOLOv5", "YOLOv7.pdf", "UNet", "YOLOv7.pdf", "fully convolutional network", "YOLOv7.pdf", "pyramid", "YOLOv7.pdf", "frame rate", "\u4e2d\u56fd\u8ba1\u7b97\u673a\u5b66\u4f1a\u63a8\u8350\u56fd\u9645\u5b66\u672f\u4f1a\u8bae\u548c\u671f\u520a\u76ee\u5f55-2022.pdf", "\u4eba\u5de5\u667a\u80fd", "\u4e2d\u56fd\u8ba1\u7b97\u673a\u5b66\u4f1a\u63a8\u8350\u56fd\u9645\u5b66\u672f\u4f1a\u8bae\u548c\u671f\u520a\u76ee\u5f55-2022.pdf", "NLP", "\u4e2d\u56fd\u8ba1\u7b97\u673a\u5b66\u4f1a\u63a8\u8350\u56fd\u9645\u5b66\u672f\u4f1a\u8bae\u548c\u671f\u520a\u76ee\u5f55-2022.pdf", "Optimization", "\u4e2d\u56fd\u8ba1\u7b97\u673a\u5b66\u4f1a\u63a8\u8350\u56fd\u9645\u5b66\u672f\u4f1a\u8bae\u548c\u671f\u520a\u76ee\u5f55-2022.pdf", "\u4f18\u5316\u7b97\u6cd5", "\u4e2d\u56fd\u8ba1\u7b97\u673a\u5b66\u4f1a\u63a8\u8350\u56fd\u9645\u5b66\u672f\u4f1a\u8bae\u548c\u671f\u520a\u76ee\u5f55-2022.pdf", "\u8ba1\u7b97\u673a\u79d1\u5b66", "\u4e2d\u56fd\u8ba1\u7b97\u673a\u5b66\u4f1a\u63a8\u8350\u56fd\u9645\u5b66\u672f\u4f1a\u8bae\u548c\u671f\u520a\u76ee\u5f55-2022.pdf", "\u56fe\u50cf\u5904\u7406", "\u4e2d\u56fd\u8ba1\u7b97\u673a\u5b66\u4f1a\u63a8\u8350\u56fd\u9645\u5b66\u672f\u4f1a\u8bae\u548c\u671f\u520a\u76ee\u5f55-2022.pdf", "Computer Vision", "\u4e2d\u56fd\u8ba1\u7b97\u673a\u5b66\u4f1a\u63a8\u8350\u56fd\u9645\u5b66\u672f\u4f1a\u8bae\u548c\u671f\u520a\u76ee\u5f55-2022.pdf", "B Class", "\u4e2d\u56fd\u8ba1\u7b97\u673a\u5b66\u4f1a\u63a8\u8350\u56fd\u9645\u5b66\u672f\u4f1a\u8bae\u548c\u671f\u520a\u76ee\u5f55-2022.pdf", "Computer Science", "\u4e2d\u56fd\u8ba1\u7b97\u673a\u5b66\u4f1a\u63a8\u8350\u56fd\u9645\u5b66\u672f\u4f1a\u8bae\u548c\u671f\u520a\u76ee\u5f55-2022.pdf", "VLSI", "\u4e2d\u56fd\u8ba1\u7b97\u673a\u5b66\u4f1a\u63a8\u8350\u56fd\u9645\u5b66\u672f\u4f1a\u8bae\u548c\u671f\u520a\u76ee\u5f55-2022.pdf", "\u81ea\u7136\u8bed\u8a00\u5904\u7406", "\u4e2d\u56fd\u8ba1\u7b97\u673a\u5b66\u4f1a\u63a8\u8350\u56fd\u9645\u5b66\u672f\u4f1a\u8bae\u548c\u671f\u520a\u76ee\u5f55-2022.pdf", "Software", "\u4e2d\u56fd\u8ba1\u7b97\u673a\u5b66\u4f1a\u63a8\u8350\u56fd\u9645\u5b66\u672f\u4f1a\u8bae\u548c\u671f\u520a\u76ee\u5f55-2022.pdf", "\u6027\u80fd\u5206\u6790", "\u4e2d\u56fd\u8ba1\u7b97\u673a\u5b66\u4f1a\u63a8\u8350\u56fd\u9645\u5b66\u672f\u4f1a\u8bae\u548c\u671f\u520a\u76ee\u5f55-2022.pdf", "databases", "\u4e2d\u56fd\u8ba1\u7b97\u673a\u5b66\u4f1a\u63a8\u8350\u56fd\u9645\u5b66\u672f\u4f1a\u8bae\u548c\u671f\u520a\u76ee\u5f55-2022.pdf", "\u4fe1\u606f\u7ba1\u7406", "\u4e2d\u56fd\u8ba1\u7b97\u673a\u5b66\u4f1a\u63a8\u8350\u56fd\u9645\u5b66\u672f\u4f1a\u8bae\u548c\u671f\u520a\u76ee\u5f55-2022.pdf", "ICASSP", "\u4e2d\u56fd\u8ba1\u7b97\u673a\u5b66\u4f1a\u63a8\u8350\u56fd\u9645\u5b66\u672f\u4f1a\u8bae\u548c\u671f\u520a\u76ee\u5f55-2022.pdf", "Git", "\u4e2d\u56fd\u8ba1\u7b97\u673a\u5b66\u4f1a\u63a8\u8350\u56fd\u9645\u5b66\u672f\u4f1a\u8bae\u548c\u671f\u520a\u76ee\u5f55-2022.pdf", "Neural Network", "\u4e2d\u56fd\u8ba1\u7b97\u673a\u5b66\u4f1a\u63a8\u8350\u56fd\u9645\u5b66\u672f\u4f1a\u8bae\u548c\u671f\u520a\u76ee\u5f55-2022.pdf", "ICCV", "\u4e2d\u56fd\u8ba1\u7b97\u673a\u5b66\u4f1a\u63a8\u8350\u56fd\u9645\u5b66\u672f\u4f1a\u8bae\u548c\u671f\u520a\u76ee\u5f55-2022.pdf", "ACL", "\u4e2d\u56fd\u8ba1\u7b97\u673a\u5b66\u4f1a\u63a8\u8350\u56fd\u9645\u5b66\u672f\u4f1a\u8bae\u548c\u671f\u520a\u76ee\u5f55-2022.pdf", "HCI", "\u4e2d\u56fd\u8ba1\u7b97\u673a\u5b66\u4f1a\u63a8\u8350\u56fd\u9645\u5b66\u672f\u4f1a\u8bae\u548c\u671f\u520a\u76ee\u5f55-2022.pdf", "\u52a0\u5bc6\u6280\u672f", "\u4e2d\u56fd\u8ba1\u7b97\u673a\u5b66\u4f1a\u63a8\u8350\u56fd\u9645\u5b66\u672f\u4f1a\u8bae\u548c\u671f\u520a\u76ee\u5f55-2022.pdf", "computer vision", "\u4e2d\u56fd\u8ba1\u7b97\u673a\u5b66\u4f1a\u63a8\u8350\u56fd\u9645\u5b66\u672f\u4f1a\u8bae\u548c\u671f\u520a\u76ee\u5f55-2022.pdf", "GROUP", "\u4e2d\u56fd\u8ba1\u7b97\u673a\u5b66\u4f1a\u63a8\u8350\u56fd\u9645\u5b66\u672f\u4f1a\u8bae\u548c\u671f\u520a\u76ee\u5f55-2022.pdf", "Biology", "\u4e2d\u56fd\u8ba1\u7b97\u673a\u5b66\u4f1a\u63a8\u8350\u56fd\u9645\u5b66\u672f\u4f1a\u8bae\u548c\u671f\u520a\u76ee\u5f55-2022.pdf", "CPP", "\u4e2d\u56fd\u8ba1\u7b97\u673a\u5b66\u4f1a\u63a8\u8350\u56fd\u9645\u5b66\u672f\u4f1a\u8bae\u548c\u671f\u520a\u76ee\u5f55-2022.pdf", "Neural Networks", "\u4e2d\u56fd\u8ba1\u7b97\u673a\u5b66\u4f1a\u63a8\u8350\u56fd\u9645\u5b66\u672f\u4f1a\u8bae\u548c\u671f\u520a\u76ee\u5f55-2022.pdf", "ACM", "\u4e2d\u56fd\u8ba1\u7b97\u673a\u5b66\u4f1a\u63a8\u8350\u56fd\u9645\u5b66\u672f\u4f1a\u8bae\u548c\u671f\u520a\u76ee\u5f55-2022.pdf", "Pattern Recognition", "\u4e2d\u56fd\u8ba1\u7b97\u673a\u5b66\u4f1a\u63a8\u8350\u56fd\u9645\u5b66\u672f\u4f1a\u8bae\u548c\u671f\u520a\u76ee\u5f55-2022.pdf", "Image Processing", "\u4e2d\u56fd\u8ba1\u7b97\u673a\u5b66\u4f1a\u63a8\u8350\u56fd\u9645\u5b66\u672f\u4f1a\u8bae\u548c\u671f\u520a\u76ee\u5f55-2022.pdf", "Machine Learning", "\u4e2d\u56fd\u8ba1\u7b97\u673a\u5b66\u4f1a\u63a8\u8350\u56fd\u9645\u5b66\u672f\u4f1a\u8bae\u548c\u671f\u520a\u76ee\u5f55-2022.pdf", "Artificial Intelligence", "\u4e2d\u56fd\u8ba1\u7b97\u673a\u5b66\u4f1a\u63a8\u8350\u56fd\u9645\u5b66\u672f\u4f1a\u8bae\u548c\u671f\u520a\u76ee\u5f55-2022.pdf", "Internet of Things", "\u4e2d\u56fd\u8ba1\u7b97\u673a\u5b66\u4f1a\u63a8\u8350\u56fd\u9645\u5b66\u672f\u4f1a\u8bae\u548c\u671f\u520a\u76ee\u5f55-2022.pdf", "ACM MM", "\u4e2d\u56fd\u8ba1\u7b97\u673a\u5b66\u4f1a\u63a8\u8350\u56fd\u9645\u5b66\u672f\u4f1a\u8bae\u548c\u671f\u520a\u76ee\u5f55-2022.pdf", "Springer", "\u4e2d\u56fd\u8ba1\u7b97\u673a\u5b66\u4f1a\u63a8\u8350\u56fd\u9645\u5b66\u672f\u4f1a\u8bae\u548c\u671f\u520a\u76ee\u5f55-2022.pdf", "C++", "\u4e2d\u56fd\u8ba1\u7b97\u673a\u5b66\u4f1a\u63a8\u8350\u56fd\u9645\u5b66\u672f\u4f1a\u8bae\u548c\u671f\u520a\u76ee\u5f55-2022.pdf", "University", "\u4e2d\u56fd\u8ba1\u7b97\u673a\u5b66\u4f1a\u63a8\u8350\u56fd\u9645\u5b66\u672f\u4f1a\u8bae\u548c\u671f\u520a\u76ee\u5f55-2022.pdf", "Neural Computation", "\u4e2d\u56fd\u8ba1\u7b97\u673a\u5b66\u4f1a\u63a8\u8350\u56fd\u9645\u5b66\u672f\u4f1a\u8bae\u548c\u671f\u520a\u76ee\u5f55-2022.pdf", "Distributed systems", "\u4e2d\u56fd\u8ba1\u7b97\u673a\u5b66\u4f1a\u63a8\u8350\u56fd\u9645\u5b66\u672f\u4f1a\u8bae\u548c\u671f\u520a\u76ee\u5f55-2022.pdf", "IETF", "\u4e2d\u56fd\u8ba1\u7b97\u673a\u5b66\u4f1a\u63a8\u8350\u56fd\u9645\u5b66\u672f\u4f1a\u8bae\u548c\u671f\u520a\u76ee\u5f55-2022.pdf", "Cybernetics", "\u4e2d\u56fd\u8ba1\u7b97\u673a\u5b66\u4f1a\u63a8\u8350\u56fd\u9645\u5b66\u672f\u4f1a\u8bae\u548c\u671f\u520a\u76ee\u5f55-2022.pdf", "Journal", "\u4e2d\u56fd\u8ba1\u7b97\u673a\u5b66\u4f1a\u63a8\u8350\u56fd\u9645\u5b66\u672f\u4f1a\u8bae\u548c\u671f\u520a\u76ee\u5f55-2022.pdf", "multimedia", "\u4e2d\u56fd\u8ba1\u7b97\u673a\u5b66\u4f1a\u63a8\u8350\u56fd\u9645\u5b66\u672f\u4f1a\u8bae\u548c\u671f\u520a\u76ee\u5f55-2022.pdf", "assessment", "\u4e2d\u56fd\u8ba1\u7b97\u673a\u5b66\u4f1a\u63a8\u8350\u56fd\u9645\u5b66\u672f\u4f1a\u8bae\u548c\u671f\u520a\u76ee\u5f55-2022.pdf", "Vision", "\u4e2d\u56fd\u8ba1\u7b97\u673a\u5b66\u4f1a\u63a8\u8350\u56fd\u9645\u5b66\u672f\u4f1a\u8bae\u548c\u671f\u520a\u76ee\u5f55-2022.pdf", "medical image computing", "\u4e2d\u56fd\u8ba1\u7b97\u673a\u5b66\u4f1a\u63a8\u8350\u56fd\u9645\u5b66\u672f\u4f1a\u8bae\u548c\u671f\u520a\u76ee\u5f55-2022.pdf", "Mobile Computing", "\u4e2d\u56fd\u8ba1\u7b97\u673a\u5b66\u4f1a\u63a8\u8350\u56fd\u9645\u5b66\u672f\u4f1a\u8bae\u548c\u671f\u520a\u76ee\u5f55-2022.pdf", "stems", "\u4e2d\u56fd\u8ba1\u7b97\u673a\u5b66\u4f1a\u63a8\u8350\u56fd\u9645\u5b66\u672f\u4f1a\u8bae\u548c\u671f\u520a\u76ee\u5f55-2022.pdf", "\u591a\u5a92\u4f53\u5de5\u5177\u548c\u5e94\u7528", "\u4e2d\u56fd\u8ba1\u7b97\u673a\u5b66\u4f1a\u63a8\u8350\u56fd\u9645\u5b66\u672f\u4f1a\u8bae\u548c\u671f\u520a\u76ee\u5f55-2022.pdf", "HPC", "\u5468\u5fd7\u534e-\u673a\u5668\u5b66\u4e60.pdf", "learning", "\u5468\u5fd7\u534e-\u673a\u5668\u5b66\u4e60.pdf", "\u4eba\u8138\u8bc6\u522b", "\u5468\u5fd7\u534e-\u673a\u5668\u5b66\u4e60.pdf", "ImageNet", "\u5468\u5fd7\u534e-\u673a\u5668\u5b66\u4e60.pdf", "SVR", "\u5468\u5fd7\u534e-\u673a\u5668\u5b66\u4e60.pdf", "optimization", "\u5468\u5fd7\u534e-\u673a\u5668\u5b66\u4e60.pdf", "neural network", "\u5468\u5fd7\u534e-\u673a\u5668\u5b66\u4e60.pdf", "\u51b3\u7b56\u6811", "\u5468\u5fd7\u534e-\u673a\u5668\u5b66\u4e60.pdf", "CNN", "\u5468\u5fd7\u534e-\u673a\u5668\u5b66\u4e60.pdf", "SVM", "\u5468\u5fd7\u534e-\u673a\u5668\u5b66\u4e60.pdf", "\u795e\u7ecf\u7f51\u7edc", "\u5468\u5fd7\u534e-\u673a\u5668\u5b66\u4e60.pdf", "\u68af\u5ea6", "\u5468\u5fd7\u534e-\u673a\u5668\u5b66\u4e60.pdf", "\u652f\u6301\u5411\u91cf\u673a", "\u5468\u5fd7\u534e-\u673a\u5668\u5b66\u4e60.pdf", "NIPS", "\u5468\u5fd7\u534e-\u673a\u5668\u5b66\u4e60.pdf", "\u6df1\u5ea6\u5b66\u4e60", "\u5468\u5fd7\u534e-\u673a\u5668\u5b66\u4e60.pdf", "\u72ec\u70ed\u7f16\u7801", "\u5468\u5fd7\u534e-\u673a\u5668\u5b66\u4e60.pdf", "\u53cd\u5411\u4f20\u64ad", "\u5468\u5fd7\u534e-\u673a\u5668\u5b66\u4e60.pdf", "tanh", "\u5468\u5fd7\u534e-\u673a\u5668\u5b66\u4e60.pdf", "\u5377\u79ef\u5c42", "\u5468\u5fd7\u534e-\u673a\u5668\u5b66\u4e60.pdf", "LeCun", "\u5468\u5fd7\u534e-\u673a\u5668\u5b66\u4e60.pdf", "network", "\u5468\u5fd7\u534e-\u673a\u5668\u5b66\u4e60.pdf", "\u6837\u672c\u5747\u503c", "\u5468\u5fd7\u534e-\u673a\u5668\u5b66\u4e60.pdf", "\u4e3b\u6210\u5206\u5206\u6790", "\u5468\u5fd7\u534e-\u673a\u5668\u5b66\u4e60.pdf", "\u8bcd\u888b\u6a21\u578b", "\u5468\u5fd7\u534e-\u673a\u5668\u5b66\u4e60.pdf", "L1\u6b63\u5219\u5316", "\u5468\u5fd7\u534e-\u673a\u5668\u5b66\u4e60.pdf", "\u7ebf\u6027\u51fd\u6570", "\u5468\u5fd7\u534e-\u673a\u5668\u5b66\u4e60.pdf", "\u4f3c\u7136\u51fd\u6570", "\u5468\u5fd7\u534e-\u673a\u5668\u5b66\u4e60.pdf", "\u8ba1\u7b97\u673a\u79d1\u5b66", "\u5468\u5fd7\u534e-\u673a\u5668\u5b66\u4e60.pdf", "\u8d2a\u5fc3\u641c\u7d22", "\u5468\u5fd7\u534e-\u673a\u5668\u5b66\u4e60.pdf", "\u6b63\u5219\u5316", "\u5468\u5fd7\u534e-\u673a\u5668\u5b66\u4e60.pdf", "\u6982\u7387\u56fe\u6a21\u578b", "\u5468\u5fd7\u534e-\u673a\u5668\u5b66\u4e60.pdf", "Overfitting", "\u5468\u5fd7\u534e-\u673a\u5668\u5b66\u4e60.pdf", "\u6837\u672c\u7a7a\u95f4", "\u5468\u5fd7\u534e-\u673a\u5668\u5b66\u4e60.pdf", "\u5b9a\u7406", "\u5468\u5fd7\u534e-\u673a\u5668\u5b66\u4e60.pdf", "\u673a\u5668\u5b66\u4e60\u7b97\u6cd5", "\u5468\u5fd7\u534e-\u673a\u5668\u5b66\u4e60.pdf", "\u89c4\u5219\u5b66\u4e60", "\u5468\u5fd7\u534e-\u673a\u5668\u5b66\u4e60.pdf", "sparse representation", "\u5468\u5fd7\u534e-\u673a\u5668\u5b66\u4e60.pdf", "\u673a\u5668\u5b66\u4e60", "\u5468\u5fd7\u534e-\u673a\u5668\u5b66\u4e60.pdf", "softmax", "\u5468\u5fd7\u534e-\u673a\u5668\u5b66\u4e60.pdf", "\u6781\u5927\u4f3c\u7136\u4f30\u8ba1", "\u5468\u5fd7\u534e-\u673a\u5668\u5b66\u4e60.pdf", "\u5927\u6570\u636e", "\u5468\u5fd7\u534e-\u673a\u5668\u5b66\u4e60.pdf", "S3\u5b58\u50a8\u670d\u52a1", "\u5468\u5fd7\u534e-\u673a\u5668\u5b66\u4e60.pdf", "\u9a6c\u5c14\u53ef\u592b\u94fe", "\u5468\u5fd7\u534e-\u673a\u5668\u5b66\u4e60.pdf", "Frobenius\u8303\u6570", "\u5468\u5fd7\u534e-\u673a\u5668\u5b66\u4e60.pdf", "\u6b27\u51e0\u91cc\u5f97\u8ddd\u79bb", "\u5468\u5fd7\u534e-\u673a\u5668\u5b66\u4e60.pdf", "ReLU", "\u5468\u5fd7\u534e-\u673a\u5668\u5b66\u4e60.pdf", "\u7279\u5f81\u5b66\u4e60", "\u5468\u5fd7\u534e-\u673a\u5668\u5b66\u4e60.pdf", "bias", "\u5468\u5fd7\u534e-\u673a\u5668\u5b66\u4e60.pdf", "\u5747\u65b9\u8bef\u5dee", "\u5468\u5fd7\u534e-\u673a\u5668\u5b66\u4e60.pdf", "LDA", "\u5468\u5fd7\u534e-\u673a\u5668\u5b66\u4e60.pdf", "\u6807\u51c6\u5dee", "additional-responses.md", "HTTPvalidationError", "additional-responses.md", "OpenAPI", "additional-status-codes.md", "OpenAPI", "additional-status-codes.md", "FastAPI", "advanced-dependencies.md", "__call__", "async.md", "\u673a\u5668\u5b66\u4e60", "async.md", "Python", "async.md", "\u591a\u7ebf\u7a0b", "async.md", "\u591a\u4efb\u52a1\u5904\u7406", "async.md", "\u5e76\u884c\u8ba1\u7b97", "async.md", "Go", "async.md", "AnyIO", "async.md", "\u5f02\u6b65\u673a\u5236", "async.md", "CPU\u5bc6\u96c6\u578b", "async.md", "async/await", "async.md", "\u97f3\u9891\u5904\u7406", "async.md", "NodeJS", "async.md", "\u5e76\u884c\u6027", "async.md", "\u5f02\u6b65\u6027", "async.md", "Web", "async.md", "CPU \u5bc6\u96c6\u578b \u5de5\u4f5c\u7a0b\u5e8f", "async.md", "Web API", "async.md", "Goroutinees", "async.md", "\u73b0\u4ee3\u7248\u672c", "async.md", "\u7ebf\u7a0b\u6c60", "async.md", "Async", "async.md", "\u5f02\u6b65IO", "async.md", "\u6570\u5b57\u5316\u5de5\u4f5c\u8005", "async.md", "burgers", "async.md", "\u534f\u7a0b", "async.md", "Starlette", "async.md", "Await", "background-tasks.md", "\u5f02\u6b65IO", "background-tasks.md", "fastapi", "background-tasks.md", "Annotated", "background-tasks.md", "Redis", "background-tasks.md", "Python 3.10", "background-tasks.md", "starlette.backgroundpass\uff0c\u6d88\u606f\u961f\u5217\uff0c\u7535\u5b50\u90ae\u4ef6\uff0cRabbitMQ\uff0casync def", "behind-a-proxy.md", "FastAPI", "behind-a-proxy.md", "OpenAPI \u6982\u56fe", "behind-a-proxy.md", "Traefik", "behind-a-proxy.md", "Uvicorn", "bigger-applications.md", "users", "bigger-applications.md", "Python", "bigger-applications.md", "admin", "bigger-applications.md", "routers", "bigger-applications.md", "\u81ea\u52a8\u5316\u90e8\u7f72", "bigger-applications.md", "prefix", "bigger-applications.md", "OpenAPI", "bigger-applications.md", "FastAPI", "bigger-applications.md", "uvicorn", "bigger-applications.md", "Python\u5f00\u53d1", "bigger-applications.md", "\u5e94\u7528\u7a0b\u5e8f\u8bbe\u8ba1", "bigger-applications.md", "OpenAPI\u6a21\u5f0f", "bigger-applications.md", "\u6784\u9020\u5668", "bigger-applications.md", "Security \u4f9d\u8d56\u9879", "bigger-applications.md", "key wordsDjango", "bigger-applications.md", "Python app", "bigger-applications.md", "internal\u5b50\u5305", "bigger-applications.md", "Python\u5b50\u5305dmin", "bigger-applications.md", "\u6587\u4ef6\u7ed3\u6784\u8a2d\u8a08", "bigger-applications.md", "DDPContextManager", "bigger-applications.md", "Python \u5305", "bigger-applications.md", "APIRouter", "bigger-applications.md", "admin\u6a21\u5757", "bigger-applications.md", "\u4f9d\u8d56\u7ba1\u7406", "bigger-applications.md", "_init__.py\u6587\u4ef6", "bigger-applications.md", "\u5355\u70b9\u5bfc\u5165 ers.router", "bigger-applications.md", "itemsrouter", "bigger-applications.md", "Python\u6a21\u5757", "bigger-applications.md", "X-Token\u8bf7\u6c42\u9996\u90e8\u6a21\u5757\u5316\u5f00\u53d1", "bigger-applications.md", "\u95e8\u67b6\u5f0f\u5f00\u53d1", "bigger-applications.md", "router", "body-fields.md", "Field", "body-fields.md", "Pydantic", "cloud.md", "FastAPI", "cloud.md", "\u4e91\u670d\u52a1\u5546", "cloud.md", "\u4e91\u90e8\u7f72", "cloud.md", "porter", "cloud.md", "\u5e73\u53f0\u67b6\u6784", "concepts.md", "Kubernetes", "concepts.md", "\u72ec\u7acb\u7a0b\u5e8f", "concepts.md", "Traefik", "concepts.md", "Uvicorn", "concepts.md", "\u7cfb\u7edf\u8d44\u6e90\u5229\u7528\u7387", "concepts.md", "TLS \u8bc1\u4e66", "concepts.md", "\u7cfb\u7edf\u76d1\u89c6\u5668", "concepts.md", "\u81ea\u52a8\u5316\u8bc1\u4e66\u66f4\u65b0", "concepts.md", "\u670d\u52a1\u5668\u5185\u5b58", "concepts.md", "\u5bb9\u5668\u6620\u50cf", "concepts.md", "Supervisor", "concepts.md", "\u4e91\u670d\u52a1", "concepts.md", "docker-compose", "concepts.md", "TLS", "concepts.md", "HAPROXY", "concepts.md", "Certbot", "concepts.md", "\u5bb9\u5668", "concepts.md", "\u4e3b\u9898\u7ba1\u7406", "concepts.md", "cert-manager", "concepts.md", "Systemd", "concepts.md", "Gunicorn", "concepts.md", "Ingress Controller", "concepts.md", "\u8fc7\u7a0b\u7ba1\u7406", "concepts.md", "Docker in Swarm Mode", "concepts.md", "cpu\u5229\u7528\u7387", "cors.md", "expose_headers", "cors.md", "CORSMiddleware", "cors.md", "cross-originBearer\u4ee4\u724c", "cors.md", "allow_headers", "custom-response.md", "fastapi", "custom-response.md", "Pydantic", "custom-response.md", "StreamingResponse", "custom-response.md", "JsonOpenAPI", "docker.md", "Kubernetes", "docker.md", "\u5e76\u884c\u5316", "docker.md", "S3\u5b58\u50a8\u670d\u52a1", "docker.md", "Python", "docker.md", "Docker", "docker.md", "\u81ea\u52a8\u5316\u90e8\u7f72", "docker.md", "docker", "docker.md", "AWS", "docker.md", "\u8d1f\u8f7d\u5747\u8861\u5668", "docker.md", "Linux", "docker.md", "\u7f51\u7edc\u901a\u4fe1", "docker.md", "stage", "docker.md", "Distributed Systems", "docker.md", "FastAPI", "docker.md", "Redis", "docker.md", "Gunicorn", "docker.md", "\u8fdb\u7a0b\u7ba1\u7406\u5668", "docker.md", "MongoDB", "docker.md", "COPY --from(requirements-stage)", "docker.md", "incremental", "docker.md", "Prometheus", "docker.md", "ReDoc", "docker.md", "\u5206\u5e03\u5f0f\u5bb9\u5668", "docker.md", "docker \u955c\u50cf", "docker.md", "\u591a\u8fdb\u7a0b\u5bb9\u5668", "docker.md", "Docker\u955c\u50cf", "docker.md", "Init Container", "docker.md", "\u81ea\u52a8CPU\u6838\u5fc3\u5206\u914dUvicorn", "docker.md", "PostgreSQL", "docker.md", "Docker Swarm", "docker.md", "Traefik\u8d1f\u8f7d\u5747\u8861", "docker.md", "\u96c6\u7fa4\u7ea7\u522b", "docker.md", "Swagger UI", "docker.md", "Kubernetesbernetes\u7ba1\u7406\u7cfb\u7edf", "docker.md", "FASTAPI", "docker.md", "HTTPS TLS \u7ec8\u6b62\u4ee3\u7406", "docker.md", "docker \u5bb9\u5668", "docker.md", "\u670d\u52a1\u5668\u5de5\u4f5c\u7ebf\u7a0b", "docker.md", "--upg\u5bb9\u5668", "docker.md", "HTTPS certificates", "docker.md", "\u5bb9\u5668\u7ba1\u7406\u7cfb\u7edf", "docker.md", "\u5185\u90e8\u7f51\u7edc\u673a\u5236", "docker.md", "cker\u955c\u50cf\u5143\u6570\u636e", "docker.md", "\u4f9d\u8d56\u9879\u7ba1\u7406", "docker.md", "cpu\u6838\u6570", "docker.md", "Docker\u5bb9\u5668\u955c\u50cf", "docker.md", "Docker \u955c\u50cf", "docker.md", "\u96c6\u7fa4", "docker.md", "Poetry", "docker.md", "Dockerfiles", "encoder.md", "JSON", "encoder.md", "dict", "encoder.md", "fastapi", "encoder.md", "JSON \u5154\u5b50\u5bf9\u8c61", "encoder.md", "jsonable_encoder", "encoder.md", "Pydantic \u6a21\u578b", "encoder.md", "datetime", "environment-variables.md", "Python\u73af\u5883\u53d8\u91cf", "environment-variables.md", "Windows PowerShell", "events.md", "Python", "events.md", "yield", "events.md", "FastAPI", "events.md", "\u6570\u636e\u5e93\u8fde\u63a5\u6c60", "events.md", "lifespan", "events.md", "\u4e8b\u4ef6\u5904\u7406\u5668", "events.md", "\u865a\u62df\u7684\u6a21\u578b\u51fd\u6570", "events.md", "startup \u4e8b\u4ef6", "events.md", "\u5f02\u6b65\u4e0a\u4e0b\u6587\u7ba1\u7406\u5668", "events.md", "event", "events.md", "ASGI", "events.md", "\u751f\u547d\u5468\u671f\u4e8b\u4ef6", "events.md", "\u5f02\u5f02\u6b65\u51fd\u6570", "extra-models.md", "email", "extra-models.md", "\u6570\u636e\u6a21\u578b", "extra-models.md", "Pydantic\u5bf9\u8c61", "extra-models.md", "u FastAPI", "extra-models.md", "typing.Dict", "fastapi-cli.md", "FastAPI", "fastapi-cli.md", "Uvicorn", "fastapi-cli.md", "Server processes", "fastapi-cli.md", "ASGI\u670d\u52a1\u5668", "fastapi-cli.md", "import string", "features.md", "OpenAPI", "features.md", "FastAPI", "features.md", "Pydantic", "features.md", "ReDoc", "features.md", "linting", "features.md", "\u81ea\u52a8\u6587\u6863\u751f\u6210", "features.md", "JSON Schema", "features.md", "HTTP \u57fa\u672c\u8ba4\u8bc1", "features.md", "editor support", "features.md", "Swagger UG", "features.md", "API\u5b9a\u4e49", "features.md", "python_types", "features.md", "mypy", "first-steps.md", "FastAPI", "first-steps.md", "OpenAPI\u6a21\u5f0f", "first-steps.md", "ReDoc", "first-steps.md", "JSON Schema", "first-steps.md", "API \u6a21\u5f0f", "first-steps.md", "FastAPI\u6784\u5efa\u5e94\u7528\u7a0b\u5e8f", "first-steps.md", "async\u51fd\u6570", "general.md", "OpenAPI", "general.md", "JSON\u517c\u5bb9\u7f16\u7801\u5668", "generate-clients.md", "FastAPI", "generate-clients.md", "OpenAPI\u6a21\u5f0f", "generate-clients.md", "Swagger UI", "generate-clients.md", "SDKs", "generate-clients.md", "Item\u6a21\u578b", "generate-clients.md", "openapi-ts", "generate-clients.md", "TypeScript \u5ba2\u6237\u7aef", "generate-clients.md", "ItemsService.createItem", "generate-clients.md", "NPM generadote-client", "generate-clients.md", "ItemsService", "handling-errors.md", "FastAPI", "handling-errors.md", "Pydantic", "handling-errors.md", "Starlette HTTPException", "handling-errors.md", "HTTPException", "handling-errors.md", "UnicornException", "handling-errors.md", "Python \u5f02\u5e38Validation", "handling-errors.md", "FastAPI \u5168\u7403\u5f02\u5e38\u5904\u7406", "handling-errors.md", "fastapi.exception_handlers", "header-param-models.md", "FastAPI", "header-param-models.md", "fastapi", "header-param-models.md", "Pydantic", "header-param-models.md", "Pydantic\u6a21\u578b", "header-param-models.md", "headers", "header-param-models.md", "Header\u53c2\u6570\u6a21\u578b", "http-basic-auth.md", "compare_digest", "http-basic-auth.md", "HTTP \u57fa\u7840\u6388\u6743", "http-basic-auth.md", "\u65f6\u5dee\u653b\u51fb", "http-basic-auth.md", "secrets", "http-basic-auth.md", "bytes", "http-basic-auth.md", "secrets.compare_digest()", "http-basic-auth.md", "compare_digest()", "http-basic-auth.md", "credentials", "http-basic-auth.md", "authenticate", "https.md", "DNS\u670d\u52a1\u5668", "https.md", "Traefik", "https.md", "\u4e91\u670d\u52a1\u5546", "https.md", "TLS \u8bc1\u4e66", "https.md", "TLS\u7ec8\u6b62\u4ee3\u7406", "https.md", "certificate", "https.md", "SSL/TCP", "https.md", "\u8bc1\u4e66", "https.md", "HAProxy", "https.md", "TCP\u5c42", "https.md", "\u5b89\u5168\u52a0\u5bc6", "https.md", "TLS \u534f\u8bae", "https.md", "HTTPS\u5de5\u4f5c\u539f\u7406", "https.md", "HTTPS\u57fa\u7840\u77e5\u8bc6", "metadata.md", "\u81ea\u52a8\u5316\u90e8\u7f72", "metadata.md", "OpenAPI\u6a21\u5f0f", "metadata.md", "ReDoc", "metadata.md", "Swagger UI", "metadata.md", "OpenAPI\u89c4\u8303", "metadata.md", "terms_of_service", "metadata.md", "openapi_tags", "metadata.md", "redoc", "metadata.md", "\u5f00\u6e90\u8bb8\u53ef\u8bc1", "oauth2-scopes.md", "FastAPI", "oauth2-scopes.md", "Pydantic", "oauth2-scopes.md", "HTTPException", "oauth2-scopes.md", "security_scopes", "oauth2-scopes.md", "oauth2\u4f5c\u7528\u57df", "oauth2-scopes.md", "\u7b2c\u4e09\u65b9\u8eab\u4efd\u9a8c\u8bc1", "oauth2-scopes.md", "scopes", "oauth2-scopes.md", "API\u81ea\u52a8\u6587\u6863", "oauth2-scopes.md", "psychological_domain", "oauth2-scopes.md", "Security\u7cfb\u7edf", "openapi-callbacks.md", "Uvicorn", "openapi-callbacks.md", "Pydantic", "openapi-callbacks.md", "invoices_callback_routers", "openapi-callbacks.md", "invoices", "openapi-callbacks.md", "\u56de\u8c03\u6d41\u7a0b", "openapi-callbacks.md", "Pydantic URL\u7c7b\u578b", "openapi-callbacks.md", "APIDocumentation", "openapi-callbacks.md", "callbacks", "openapi-callbacks.md", "FastAPI\u5e94\u7528", "path-params.md", "OpenAPI", "path-params.md", "FastAPI", "path-params.md", "Pydantic", "path-params.md", "ReDoc", "path-params.md", "Swagger UI", "path-params.md", "Enum\u7c7b", "path-params.md", "Python \u679a\u4e3e\u7c7b\u578b", "path-params.md", "Python \u5b57\u7b26\u4e32\u683c\u5f0f\u5316\u7c7b\u578b\u6ce8\u89e3", "path-params.md", "API\u6ce8\u89e3", "Python\u4fee\u70bc\u4e4b\u9053.pdf", "bash", "Python\u4fee\u70bc\u4e4b\u9053.pdf", "\u4eba\u5de5\u667a\u80fd", "Python\u4fee\u70bc\u4e4b\u9053.pdf", "Kubernetes", "Python\u4fee\u70bc\u4e4b\u9053.pdf", "\u56fe\u50cf\u5904\u7406", "Python\u4fee\u70bc\u4e4b\u9053.pdf", "Float", "Python\u4fee\u70bc\u4e4b\u9053.pdf", "class", "Python\u4fee\u70bc\u4e4b\u9053.pdf", "random", "Python\u4fee\u70bc\u4e4b\u9053.pdf", "tuple", "Python\u4fee\u70bc\u4e4b\u9053.pdf", "sys", "Python\u4fee\u70bc\u4e4b\u9053.pdf", "Kubernetes\u7ba1\u7406\u7cfb\u7edf", "Python\u4fee\u70bc\u4e4b\u9053.pdf", "email", "Python\u4fee\u70bc\u4e4b\u9053.pdf", "\u5185\u5b58\u5206\u914d", "Python\u4fee\u70bc\u4e4b\u9053.pdf", "\u673a\u5668\u5b66\u4e60", "Python\u4fee\u70bc\u4e4b\u9053.pdf", "\u5927\u6570\u636e", "Python\u4fee\u70bc\u4e4b\u9053.pdf", "S3\u5b58\u50a8\u670d\u52a1", "Python\u4fee\u70bc\u4e4b\u9053.pdf", "\u52a0\u5bc6\u7b97\u6cd5", "Python\u4fee\u70bc\u4e4b\u9053.pdf", "\u8fed\u4ee3\u5668", "Python\u4fee\u70bc\u4e4b\u9053.pdf", "IDE", "Python\u4fee\u70bc\u4e4b\u9053.pdf", "Python", "Python\u4fee\u70bc\u4e4b\u9053.pdf", "Java", "Python\u4fee\u70bc\u4e4b\u9053.pdf", "Docker", "Python\u4fee\u70bc\u4e4b\u9053.pdf", "mysql", "Python\u4fee\u70bc\u4e4b\u9053.pdf", "Node", "Python\u4fee\u70bc\u4e4b\u9053.pdf", "cloud\u8ba1\u7b97\u5e73\u53f0", "Python\u4fee\u70bc\u4e4b\u9053.pdf", "C\u8bed\u8a00", "Python\u4fee\u70bc\u4e4b\u9053.pdf", "\u5bb9\u5668\u7f16\u6392", "Python\u4fee\u70bc\u4e4b\u9053.pdf", "AES", "Python\u4fee\u70bc\u4e4b\u9053.pdf", "\u591a\u7ebf\u7a0b", "Python\u4fee\u70bc\u4e4b\u9053.pdf", "Docker\u5bb9\u5668", "Python\u4fee\u70bc\u4e4b\u9053.pdf", "split", "Python\u4fee\u70bc\u4e4b\u9053.pdf", "SHELL", "Python\u4fee\u70bc\u4e4b\u9053.pdf", "\u7b97\u6cd5", "Python\u4fee\u70bc\u4e4b\u9053.pdf", "encoding", "Python\u4fee\u70bc\u4e4b\u9053.pdf", "numpy", "Python\u4fee\u70bc\u4e4b\u9053.pdf", "lambda", "Python\u4fee\u70bc\u4e4b\u9053.pdf", "\u81ea\u52a8\u5316\u90e8\u7f72", "Python\u4fee\u70bc\u4e4b\u9053.pdf", "charset", "Python\u4fee\u70bc\u4e4b\u9053.pdf", "AWS", "Python\u4fee\u70bc\u4e4b\u9053.pdf", "\u8d1f\u8f7d\u5747\u8861\u5668", "Python\u4fee\u70bc\u4e4b\u9053.pdf", "\u7a0b\u5e8f\u8bbe\u8ba1", "Python\u4fee\u70bc\u4e4b\u9053.pdf", "variable", "Python\u4fee\u70bc\u4e4b\u9053.pdf", "\u903b\u8f91\u5224\u65ad", "Python\u4fee\u70bc\u4e4b\u9053.pdf", "filesystem", "Python\u4fee\u70bc\u4e4b\u9053.pdf", "jar", "Python\u4fee\u70bc\u4e4b\u9053.pdf", "attribute", "Python\u4fee\u70bc\u4e4b\u9053.pdf", "object", "Python\u4fee\u70bc\u4e4b\u9053.pdf", "height", "Python\u4fee\u70bc\u4e4b\u9053.pdf", "attributes", "Python\u4fee\u70bc\u4e4b\u9053.pdf", "c++", "Python\u4fee\u70bc\u4e4b\u9053.pdf", "ACM", "query-params-str-validations.md", "S3\u5b58\u50a8\u670d\u52a1", "query-params-str-validations.md", "AWS", "query-params-str-validations.md", "List[str] ", "query-params-str-validations.md", "OpenAPI \u6a21\u5f0f", "query-params-str-validations.md", "Union[str", "query-params-str-validations.md", "regular exppression", "query-params-str-validations.md", "\u6709\u6548\u53d8\u91cf\u540d Query(default=None)", "request-files.md", "python-multipart", "request-files.md", "file-like \u5bf9\u8c61", "request-files.md", "async\u65b9\u6cd5", "request-forms-and-files.md", "JSON", "request-forms-and-files.md", "python-multipart", "response-change-status-code.md", "cookies", "response-model.md", "path_operation\u88c5\u9970\u5668", "response-model.md", "Union[str\uff0c\u4ea4\u4e92\u5f0fAPI\uff0c\u6a21\u578b\u878d\u5408\uff0cresponse_model_exclude_unset\uff0cvisible_data\uff0cPydantic\uff0cJSONSchema\uff0cexclude_unset\uff0cdefault_values\uff0cList[str]response_model_include", "schema-extra-example.md", "OpenAPI", "schema-extra-example.md", "Field", "schema-extra-example.md", "Pydantic", "schema-extra-example.md", "JSON Schema", "schema-extra-example.md", "swagger-ui", "schema-extra-example.md", "swagger", "settings.md", "Docker", "settings.md", "uvicorn", "settings.md", "Pydantic", "settings.md", "say_hi", "settings.md", "functors\u73af\u5883\u53d8\u91cf\u8bbe\u7f6e", "settings.md", "Pydantic:Settings\u73af\u5883\u53d8\u91cf creation", "settings.md", "rect", "settings.md", "\u9a8c\u8bc1\u529f\u80fdpython-dotenv", "settings.md", "\u5bc6\u94a5", "settings.md", "Twelve-Factor App", "settings.md", "sensitive data\u914d\u7f6e\u6587\u4ef6\u914d\u7f6e\u5bf9\u8c61", "settings.md", "Settings\u7c7b", "settings.md", "D\u4f9d\u8d56\u9879\u8986\u76d6", "settings.md", "os.getenv()", "settings.md", "lru_cache", "settings.md", "@lru_cache", "sql-databases.md", "MySQL", "sql-databases.md", "yield", "sql-databases.md", "FastAPI", "sql-databases.md", "fastapi", "sql-databases.md", "Uvicorn", "sql-databases.md", "Pydantic \u6a21\u578b", "sql-databases.md", "\u6570\u636e\u6a21\u578b", "sql-databases.md", "\u865a\u62df\u73af\u5883", "sql-databases.md", "HeroCreate", "sql-databases.md", "Oracle", "sql-databases.md", "SQLite", "sql-databases.md", "SQLAlchemy", "sql-databases.md", "HeroCre\u4f9d\u8d56\u9879", "sql-databases.md", "checksamethread", "sql-databases.md", "FieldPydantic\u6a21\u578b", "sql-databases.md", "hero\u6a21\u578b", "sql-databases.md", "Hero", "sql-databases.md", "HeroPublic\u6570\u636e\u6a21\u578b", "sql-databases.md", "SQLAlchemy engine", "sql-databases.md", "SQLModel", "sql-databases.md", "Postgresqlql_model", "sql-databases.md", "Alembic", "sql-databases.md", "engine", "sql-databases.md", "SQLModel.engine", "sql-databases.md", "SessionDep", "sql-databases.md", "HeroBase\uff0cHero", "sql-databases.md", "HeroBase", "sql-databases.md", "SQL\u6570\u636e\u5e93", "sql-databases.md", "Hero\u8868\u6a21\u578b", "sql-databases.md", "HeroPublic", "sql-databases.md", "data model", "static-files.md", "FastAPI", "static-files.md", "Starlette", "static-files.md", "StaticFiles", "static-files.md", "\u9759\u6001\u6587\u4ef6\u670d\u52a1", "testing-events.md", "TestClient", "testing-events.md", "with", "testing-websockets.md", "TestClient", "testing-websockets.md", "WebSocket", "testing-websockets.md", "with\u8bed\u53e5", "testing-websockets.md", "TestWebSockets", "testing.md", "Python 3.8", "testing.md", "JSON", "testing.md", "FastAPI", "testing.md", "Annotated", "testing.md", "Python 3.10", "testing.md", "async\u51fd\u6570", "testing.md", "TestMain\uff0ccookie", "testing.md", "pytest", "testing.md", "starlette.testclient", "testing.md", "HTTPXydantic\u6a21\u578b", "testing.md", "\u975e\u6ce8\u89e3\u5316\u7684Python", "using-request-directly.md", "OpenAPI \u6ce8\u91ca", "virtual-environments.md", "\u81ea\u52a8\u5316\u90e8\u7f72", "virtual-environments.md", "AWS", "virtual-environments.md", "Linux", "virtual-environments.md", "fastapi", "virtual-environments.md", "virtualenv", "virtual-environments.md", "software package managemen", "virtual-environments.md", "python \u865a\u62df\u73af\u5883", "virtual-environments.md", "Python\u5de5\u7a0b", "virtual-environments.md", "S3 \u5b58\u50a8\u670d\u52a1", "virtual-environments.md", "Python package", "virtual-environments.md", "\u5168\u5c40\u8f6f\u4ef6\u5305\u4f9d\u8d56\u7ba1\u7406venv", "virtual-environments.md", "\u68c0\u67e5\u865a\u62df\u73af\u5883", "virtual-environments.md", "Philosophers-StoneFastAPI", "virtual-environments.md", "PYthon", "virtual-environments.md", "sirius", "virtual-environments.md", "awesome-project", "virtual-environments.md", "global environment", "virtual-environments.md", "Docker \u5bb9\u5668", "virtual-environments.md", "software package", "websockets.md", "FastAPI", "websockets.md", "Redis", "websockets.md", "Uvicorn", "websockets.md", "HTTPException", "websockets.md", "WebSocket", "websockets.md", "uunicorn(main.py)unicorn", "websockets.md", "WebSockets", "wsgi.md", "Django", "wsgi.md", "JSON", "wsgi.md", "FastAPI", "wsgi.md", "Flask", "wsgi.md", "WSGIMiddleware", "wsgi.md", "WSGI", "MySQL-\u57fa\u7840\u7bc7.pdf", "major", "MySQL-\u57fa\u7840\u7bc7.pdf", "Kubernetes", "MySQL-\u57fa\u7840\u7bc7.pdf", "account", "MySQL-\u57fa\u7840\u7bc7.pdf", "Docker", "MySQL-\u57fa\u7840\u7bc7.pdf", "mysql", "MySQL-\u57fa\u7840\u7bc7.pdf", "cloud computing", "MySQL-\u57fa\u7840\u7bc7.pdf", "AWS", "MySQL-\u57fa\u7840\u7bc7.pdf", ".net", "MySQL-\u57fa\u7840\u7bc7.pdf", "MySQL", "MySQL-\u57fa\u7840\u7bc7.pdf", "phone", "MySQL-\u57fa\u7840\u7bc7.pdf", "PostgreSQL", "MySQL-\u57fa\u7840\u7bc7.pdf", "datetime", "MySQL-\u57fa\u7840\u7bc7.pdf", "\u6570\u636e\u6a21\u578b", "MySQL-\u57fa\u7840\u7bc7.pdf", "\u5173\u7cfb\u578b\u6570\u636e\u5e93", "MySQL-\u57fa\u7840\u7bc7.pdf", "\u6570\u636e\u5e93\u7ba1\u7406", "MySQL-\u57fa\u7840\u7bc7.pdf", "Oracle", "MySQL-\u57fa\u7840\u7bc7.pdf", "SQLite", "MySQL-\u57fa\u7840\u7bc7.pdf", "MySQL Community Server", "MySQL-\u57fa\u7840\u7bc7.pdf", "\u6301\u4e45\u6027", "MySQL-\u57fa\u7840\u7bc7.pdf", "ACID", "MySQL-\u57fa\u7840\u7bc7.pdf", "\u5916\u8fde\u63a5", "MySQL-\u57fa\u7840\u7bc7.pdf", "\u96c6\u5408\u548c\u96c6", "MySQL-\u57fa\u7840\u7bc7.pdf", "Datenbank", "MySQL-\u57fa\u7840\u7bc7.pdf", "mysql\u670d\u52a1", "MySQL-\u57fa\u7840\u7bc7.pdf", "Mathematical", "MySQL-\u57fa\u7840\u7bc7.pdf", "CASE WHEN THEN ELSE END", "MySQL-\u57fa\u7840\u7bc7.pdf", "agebetween15and20", "MySQL-\u57fa\u7840\u7bc7.pdf", "FOREIGN KEY", "MySQL-\u57fa\u7840\u7bc7.pdf", "Read committed", "MySQL-\u57fa\u7840\u7bc7.pdf", "union all", "MySQL-\u57fa\u7840\u7bc7.pdf", "degree", "MySQL-\u57fa\u7840\u7bc7.pdf", "varchar", "MySQL-\u57fa\u7840\u7bc7.pdf", "CASE WHEN", "MySQL-\u57fa\u7840\u7bc7.pdf", "UNIQUE", "MySQL-\u57fa\u7840\u7bc7.pdf", "left join", "MySQL-\u57fa\u7840\u7bc7.pdf", "DML", "MySQL-\u57fa\u7840\u7bc7.pdf", "TINYBLOB", "MySQL-\u57fa\u7840\u7bc7.pdf", "\u6570\u636e\u5e93\u8bbe\u8ba1", "MySQL-\u57fa\u7840\u7bc7.pdf", "DECIMAL", "MySQL-\u57fa\u7840\u7bc7.pdf", "dept.name", "MySQL-\u57fa\u7840\u7bc7.pdf", "ON DELETE CASCADE", "MySQL-\u57fa\u7840\u7bc7.pdf", "data definition language", "MySQL-\u57fa\u7840\u7bc7.pdf", "Repeatable Read", "MySQL-\u57fa\u7840\u7bc7.pdf", "\u8d27\u5e01", "MySQL-\u57fa\u7840\u7bc7.pdf", "Serializable", "MySQL-\u57fa\u7840\u7bc7.pdf", "double", "MySQL-\u57fa\u7840\u7bc7.pdf", "SELECT\u8bed\u53e5", "MySQL-\u57fa\u7840\u7bc7.pdf", "\u5b58\u50a8\u5f15\u64ce", "MySQL-\u57fa\u7840\u7bc7.pdf", "RESTRICT", "MySQL-\u57fa\u7840\u7bc7.pdf", "BMS", "MySQL-\u8fd0\u7ef4\u7bc7.pdf", "mysqld", "MySQL-\u8fd0\u7ef4\u7bc7.pdf", "Kubernetes", "MySQL-\u8fd0\u7ef4\u7bc7.pdf", "global", "MySQL-\u8fd0\u7ef4\u7bc7.pdf", "hash", "MySQL-\u8fd0\u7ef4\u7bc7.pdf", "ssl", "MySQL-\u8fd0\u7ef4\u7bc7.pdf", "Docker\u5bb9\u5668", "MySQL-\u8fd0\u7ef4\u7bc7.pdf", "processors", "MySQL-\u8fd0\u7ef4\u7bc7.pdf", "\u7b97\u6cd5", "MySQL-\u8fd0\u7ef4\u7bc7.pdf", "MySQL\u6570\u636e\u5e93", "MySQL-\u8fd0\u7ef4\u7bc7.pdf", "charset", "MySQL-\u8fd0\u7ef4\u7bc7.pdf", "master", "MySQL-\u8fd0\u7ef4\u7bc7.pdf", "MySQL", "MySQL-\u8fd0\u7ef4\u7bc7.pdf", "columns", "MySQL-\u8fd0\u7ef4\u7bc7.pdf", "\u6570\u636e\u5206\u533a", "MySQL-\u8fd0\u7ef4\u7bc7.pdf", "schema", "MySQL-\u8fd0\u7ef4\u7bc7.pdf", "replication", "MySQL-\u8fd0\u7ef4\u7bc7.pdf", "Function", "MySQL-\u8fd0\u7ef4\u7bc7.pdf", "\u6570\u636e\u5e93\u7ba1\u7406", "MySQL-\u8fd0\u7ef4\u7bc7.pdf", "varchar", "MySQL-\u8fd0\u7ef4\u7bc7.pdf", "DML", "MySQL-\u8fd0\u7ef4\u7bc7.pdf", "MyCat\u63a7\u5236\u540e\u53f0\u6570\u636e\u5e93\u7684\u8bfb\u5199\u5206\u79bb\u548c\u8d1f\u8f7d\u5747\u8861", "MySQL-\u8fd0\u7ef4\u7bc7.pdf", "\u6570\u636e\u5e93\u670d\u52a1\u5668\u89c4\u5212", "MySQL-\u8fd0\u7ef4\u7bc7.pdf", "dataHost", "MySQL-\u8fd0\u7ef4\u7bc7.pdf", "CHANGE REPLICATION SOURCE TO", "MySQL-\u8fd0\u7ef4\u7bc7.pdf", "\u4ece\u5e93\u5173\u8054\u4e3b\u5e93", "MySQL-\u8fd0\u7ef4\u7bc7.pdf", "BINLOG", "MySQL-\u8fd0\u7ef4\u7bc7.pdf", "binlog_do_db", "MySQL-\u8fd0\u7ef4\u7bc7.pdf", "truesharding-by-intfile-enumstatus", "MySQL-\u8fd0\u7ef4\u7bc7.pdf", "\u4ee5\u5bf9\u5e94\u4e0d\u540c\u7684\u6570\u636e\u5e93\u670d\u52a1\u5668", "MySQL-\u8fd0\u7ef4\u7bc7.pdf", "\u6570\u636e_nodeMyCat\u7ba1\u7406", "MySQL-\u8fd0\u7ef4\u7bc7.pdf", "GRANT REPLITCAST_RW2", "MySQL-\u8fd0\u7ef4\u7bc7.pdf", "binlogmurmurHash", "MySQL-\u8fd0\u7ef4\u7bc7.pdf", "\u78c1\u76d8IO\u624b\u672f\uff0cSQL\u5206\u6790\uff0c\u62c6\u5206", "MySQL-\u8fd0\u7ef4\u7bc7.pdf", "DML\u5c5e\u6027", "MySQL-\u8fd0\u7ef4\u7bc7.pdf", "eHost", "MySQL-\u8fd0\u7ef4\u7bc7.pdf", "PRIMARY KEY", "MySQL-\u8fd0\u7ef4\u7bc7.pdf", "enum", "MySQL-\u8fd0\u7ef4\u7bc7.pdf", "faultPartition", "MySQL-\u8fd0\u7ef4\u7bc7.pdf", "AOP", "MySQL-\u8fd0\u7ef4\u7bc7.pdf", "log_bin_basename", "MySQL-\u8fd0\u7ef4\u7bc7.pdf", "dataDateformat", "MySQL-\u8fd0\u7ef4\u7bc7.pdf", "return_classschema.xml\u4e2d\u7684\u6570\u636e\u8282\u70b9\u914d\u7f6e", "MySQL-\u8fd0\u7ef4\u7bc7.pdf", "purgemon", "MySQL-\u8fd0\u7ef4\u7bc7.pdf", "AutoPartitionByLong", "MySQL-\u8fd0\u7ef4\u7bc7.pdf", "SERIALIZABLE", "MySQL-\u8fd0\u7ef4\u7bc7.pdf", "\u5bb9\u91cf\u74f6\u9888", "MySQL-\u8fd0\u7ef4\u7bc7.pdf", "zookeeper", "MySQL-\u8fd0\u7ef4\u7bc7.pdf", "mycatseq", "MySQL-\u8fd0\u7ef4\u7bc7.pdf", "schemasJava", "MySQL-\u8fd0\u7ef4\u7bc7.pdf", "testDataImport", "MySQL-\u8fdb\u9636\u7bc7.pdf", "Kubernetes", "MySQL-\u8fdb\u9636\u7bc7.pdf", "sys", "MySQL-\u8fdb\u9636\u7bc7.pdf", "global", "MySQL-\u8fdb\u9636\u7bc7.pdf", "Kubernetes\u7ba1\u7406\u7cfb\u7edf", "MySQL-\u8fdb\u9636\u7bc7.pdf", "email", "MySQL-\u8fdb\u9636\u7bc7.pdf", "S3\u5b58\u50a8\u670d\u52a1", "MySQL-\u8fdb\u9636\u7bc7.pdf", "mysql", "MySQL-\u8fdb\u9636\u7bc7.pdf", "cloud\u8ba1\u7b97\u5e73\u53f0", "MySQL-\u8fdb\u9636\u7bc7.pdf", "Memory", "MySQL-\u8fdb\u9636\u7bc7.pdf", "\u81ea\u52a8\u5316\u90e8\u7f72", "MySQL-\u8fdb\u9636\u7bc7.pdf", "docker", "MySQL-\u8fdb\u9636\u7bc7.pdf", "VARIABLES", "MySQL-\u8fdb\u9636\u7bc7.pdf", "\u670d\u52a1\u5c42", "MySQL-\u8fdb\u9636\u7bc7.pdf", "MySQL", "MySQL-\u8fdb\u9636\u7bc7.pdf", "phone", "MySQL-\u8fdb\u9636\u7bc7.pdf", "\u5185\u5b58\u7f13\u51b2\u533a", "MySQL-\u8fdb\u9636\u7bc7.pdf", "IOT", "MySQL-\u8fdb\u9636\u7bc7.pdf", "\u8f6f\u4ef6\u5de5\u7a0b", "MySQL-\u8fdb\u9636\u7bc7.pdf", "Redis", "MySQL-\u8fdb\u9636\u7bc7.pdf", "if\u8bed\u53e5", "MySQL-\u8fdb\u9636\u7bc7.pdf", "sql", "MySQL-\u8fdb\u9636\u7bc7.pdf", "NoSQL", "MySQL-\u8fdb\u9636\u7bc7.pdf", "\u6301\u4e45\u6027", "MySQL-\u8fdb\u9636\u7bc7.pdf", "CASE WHEN", "MySQL-\u8fdb\u9636\u7bc7.pdf", "DML", "MySQL-\u8fdb\u9636\u7bc7.pdf", "\u5b58\u50a8\u5f15\u64ce", "MySQL-\u8fdb\u9636\u7bc7.pdf", "\u4e8b\u52a1\u63a7\u5236", "MySQL-\u8fdb\u9636\u7bc7.pdf", "AUTO_INCREMENT", "MySQL-\u8fdb\u9636\u7bc7.pdf", "GROUP BY", "MySQL-\u8fdb\u9636\u7bc7.pdf", "\u539f\u5b50\u6027", "MySQL-\u8fdb\u9636\u7bc7.pdf", "BIGINT", "MySQL-\u8fdb\u9636\u7bc7.pdf", "DISTINCT", "MySQL-\u8fdb\u9636\u7bc7.pdf", "DQL", "MySQL-\u8fdb\u9636\u7bc7.pdf", "slow_query_log", "MySQL-\u8fdb\u9636\u7bc7.pdf", "Buffer Pool", "MySQL-\u8fdb\u9636\u7bc7.pdf", "S\u6392\u4ed6\u9501", "MySQL-\u8fdb\u9636\u7bc7.pdf", "lock in share mode", "MySQL-\u8fdb\u9636\u7bc7.pdf", "andler", "MySQL-\u8fdb\u9636\u7bc7.pdf", "innodb_file_per_table", "MySQL-\u8fdb\u9636\u7bc7.pdf", "\u6392\u4ed6\u9501", "MySQL-\u8fdb\u9636\u7bc7.pdf", "t\u8868\u9501\u5171\u4eab\u9501(read)", "MySQL-\u8fdb\u9636\u7bc7.pdf", "\u67e5\u8be2\u89c6\u56fe", "MySQL-\u8fdb\u9636\u7bc7.pdf", "UNION\u6216\u8005UNION ALL", "MySQL-\u8fdb\u9636\u7bc7.pdf", "\u8868\u7ed3\u6784\u8bbe\u8ba1", "MySQL-\u8fdb\u9636\u7bc7.pdf", "score grade", "MySQL-\u8fdb\u9636\u7bc7.pdf", "Backward index scan", "MySQL-\u8fdb\u9636\u7bc7.pdf", "InnoDB\u5b58\u50a8\u5f15\u64ce", "MySQL-\u8fdb\u9636\u7bc7.pdf", "dirty page", "MySQL-\u8fdb\u9636\u7bc7.pdf", "\u6307\u5411\u6027\u6570\u636e\u7ed3\u6784", "MySQL-\u8fdb\u9636\u7bc7.pdf", "InnoDB\u5f15\u64ce", "MySQL\u5fc5\u77e5\u5fc5\u4f1a.pdf", "\u6570\u636e\u5e93\u5f15\u64ce", "MySQL\u5fc5\u77e5\u5fc5\u4f1a.pdf", "\u5185\u5b58\u5206\u914d", "MySQL\u5fc5\u77e5\u5fc5\u4f1a.pdf", "software", "MySQL\u5fc5\u77e5\u5fc5\u4f1a.pdf", "\u4e91\u8ba1\u7b97\u5e73\u53f0", "MySQL\u5fc5\u77e5\u5fc5\u4f1a.pdf", "anchors", "MySQL\u5fc5\u77e5\u5fc5\u4f1a.pdf", "\u670d\u52a1\u5668\u8f6f\u4ef6", "MySQL\u5fc5\u77e5\u5fc5\u4f1a.pdf", "\u4f59\u5f26\u51fd\u6570", "MySQL\u5fc5\u77e5\u5fc5\u4f1a.pdf", "mysql", "MySQL\u5fc5\u77e5\u5fc5\u4f1a.pdf", "DBMS", "MySQL\u5fc5\u77e5\u5fc5\u4f1a.pdf", "queries", "MySQL\u5fc5\u77e5\u5fc5\u4f1a.pdf", "\u6570\u636e\u5b89\u5168", "MySQL\u5fc5\u77e5\u5fc5\u4f1a.pdf", "Docker\u5bb9\u5668", "MySQL\u5fc5\u77e5\u5fc5\u4f1a.pdf", "databases", "MySQL\u5fc5\u77e5\u5fc5\u4f1a.pdf", "encoding", "MySQL\u5fc5\u77e5\u5fc5\u4f1a.pdf", "\u53ef\u79fb\u690d\u6027", "MySQL\u5fc5\u77e5\u5fc5\u4f1a.pdf", "wildcard", "MySQL\u5fc5\u77e5\u5fc5\u4f1a.pdf", "Linux", "MySQL\u5fc5\u77e5\u5fc5\u4f1a.pdf", "MySQL", "MySQL\u5fc5\u77e5\u5fc5\u4f1a.pdf", "mysql\u6570\u636e\u5e93", "MySQL\u5fc5\u77e5\u5fc5\u4f1a.pdf", "vendor", "MySQL\u5fc5\u77e5\u5fc5\u4f1a.pdf", "Ordering", "MySQL\u5fc5\u77e5\u5fc5\u4f1a.pdf", "price", "MySQL\u5fc5\u77e5\u5fc5\u4f1a.pdf", "schema", "MySQL\u5fc5\u77e5\u5fc5\u4f1a.pdf", "ranking", "MySQL\u5fc5\u77e5\u5fc5\u4f1a.pdf", "\u7406", "MySQL\u5fc5\u77e5\u5fc5\u4f1a.pdf", "\u4e13\u5bb6\u7cfb\u7edf", "MySQL\u5fc5\u77e5\u5fc5\u4f1a.pdf", "datetime", "MySQL\u5fc5\u77e5\u5fc5\u4f1a.pdf", "cursors", "MySQL\u5fc5\u77e5\u5fc5\u4f1a.pdf", "COMMIT", "MySQL\u5fc5\u77e5\u5fc5\u4f1a.pdf", "CASE WHEN", "MySQL\u5fc5\u77e5\u5fc5\u4f1a.pdf", "TINYBLOB", "MySQL\u5fc5\u77e5\u5fc5\u4f1a.pdf", "DECIMAL", "MySQL\u5fc5\u77e5\u5fc5\u4f1a.pdf", "AUTO_INCREMENT", "MySQL\u5fc5\u77e5\u5fc5\u4f1a.pdf", "GROUP BY", "MySQL\u5fc5\u77e5\u5fc5\u4f1a.pdf", "TINYINT", "MySQL\u5fc5\u77e5\u5fc5\u4f1a.pdf", "BLOB", "MySQL\u5fc5\u77e5\u5fc5\u4f1a.pdf", "ORDER BY", "MySQL\u5fc5\u77e5\u5fc5\u4f1a.pdf", "BIGINT", "MySQL\u5fc5\u77e5\u5fc5\u4f1a.pdf", "UNION", "MySQL\u5fc5\u77e5\u5fc5\u4f1a.pdf", "DISTINCT", "MySQL\u5fc5\u77e5\u5fc5\u4f1a.pdf", "INNER JOIN", "MySQL\u5fc5\u77e5\u5fc5\u4f1a.pdf", "MySQL\u670d\u52a1\u5668", "MySQL\u5fc5\u77e5\u5fc5\u4f1a.pdf", "InnoDB", "MySQL\u5fc5\u77e5\u5fc5\u4f1a.pdf", "InnoDB\u5f15\u64ce", "MySQL\u5fc5\u77e5\u5fc5\u4f1a.pdf", "MyISAM\u5f15\u64ce", "MySQL\u5fc5\u77e5\u5fc5\u4f1a.pdf", "MEMORY", "MySQL\u5fc5\u77e5\u5fc5\u4f1a.pdf", "mysql_performance", "MySQL\u5fc5\u77e5\u5fc5\u4f1a.pdf", "SAVEPOINT", "MySQL\u5fc5\u77e5\u5fc5\u4f1a.pdf", "AUTO_INCREMENT\u5217", "MySQL\u5fc5\u77e5\u5fc5\u4f1a.pdf", "data formatting"], "edges": [{"source": "Bilen_Dynamic_Image_Networks_CVPR_2016_paper.pdf", "target": "\u5e73\u5747\u56fe\u6a21\u578b", "value": "\u77e5\u8bc6"}, {"source": "Bilen_Dynamic_Image_Networks_CVPR_2016_paper.pdf", "target": "video descriptor", "value": "\u77e5\u8bc6"}, {"source": "Bilen_Dynamic_Image_Networks_CVPR_2016_paper.pdf", "target": "Hu-\u52a8\u4f5c\u8bc6\u522b", "value": "\u77e5\u8bc6"}, {"source": "Bilen_Dynamic_Image_Networks_CVPR_2016_paper.pdf", "target": "Dynamick Image Networks", "value": "\u77e5\u8bc6"}, {"source": "Bilen_Dynamic_Image_Networks_CVPR_2016_paper.pdf", "target": "\u975e\u7ebf\u6027(I)operator", "value": "\u77e5\u8bc6"}, {"source": "Bilen_Dynamic_Image_Networks_CVPR_2016_paper.pdf", "target": "Simonyan et al. ", "value": "\u77e5\u8bc6"}, {"source": "Bilen_Dynamic_Image_Networks_CVPR_2016_paper.pdf", "target": "motion patterns", "value": "\u77e5\u8bc6"}, {"source": "Bilen_Dynamic_Image_Networks_CVPR_2016_paper.pdf", "target": "\u6df1\u5ea6\u5b66\u4e60 CNN", "value": "\u77e5\u8bc6"}, {"source": "Bilen_Dynamic_Image_Networks_CVPR_2016_paper.pdf", "target": "Dense trajectories", "value": "\u77e5\u8bc6"}, {"source": "Bilen_Dynamic_Image_Networks_CVPR_2016_paper.pdf", "target": "RankPool", "value": "\u77e5\u8bc6"}, {"source": "Bilen_Dynamic_Image_Networks_CVPR_2016_paper.pdf", "target": "\u6700\u5927 epochranking scores", "value": "\u77e5\u8bc6"}, {"source": "Bilen_Dynamic_Image_Networks_CVPR_2016_paper.pdf", "target": "summarization", "value": "\u77e5\u8bc6"}, {"source": "Bilen_Dynamic_Image_Networks_CVPR_2016_paper.pdf", "target": "tensorflow", "value": "\u77e5\u8bc6"}, {"source": "Bilen_Dynamic_Image_Networks_CVPR_2016_paper.pdf", "target": "human actionsdentyity function", "value": "\u77e5\u8bc6"}, {"source": "Bilen_Dynamic_Image_Networks_CVPR_2016_paper.pdf", "target": "temporal pooling", "value": "\u77e5\u8bc6"}, {"source": "Bilen_Dynamic_Image_Networks_CVPR_2016_paper.pdf", "target": "CNNvideo data", "value": "\u77e5\u8bc6"}, {"source": "Bilen_Dynamic_Image_Networks_CVPR_2016_paper.pdf", "target": "SoccererJuggling", "value": "\u77e5\u8bc6"}, {"source": "Bilen_Dynamic_Image_Networks_CVPR_2016_paper.pdf", "target": "Ranked-Classifier", "value": "\u77e5\u8bc6"}, {"source": "Bilen_Dynamic_Image_Networks_CVPR_2016_paper.pdf", "target": "\u4eba\u5de5\u667a\u80fd", "value": "\u77e5\u8bc6"}, {"source": "Bilen_Dynamic_Image_Networks_CVPR_2016_paper.pdf", "target": "\u6df1\u5ea6 CNN \u6a21\u578bclassification", "value": "\u77e5\u8bc6"}, {"source": "Bilen_Dynamic_Image_Networks_CVPR_2016_paper.pdf", "target": "\u52a8\u6001\u5efa\u6a21", "value": "\u77e5\u8bc6"}, {"source": "Bilen_Dynamic_Image_Networks_CVPR_2016_paper.pdf", "target": "ReLU\u5c42", "value": "\u77e5\u8bc6"}, {"source": "Bilen_Dynamic_Image_Networks_CVPR_2016_paper.pdf", "target": "3D filters", "value": "\u77e5\u8bc6"}, {"source": "Bilen_Dynamic_Image_Networks_CVPR_2016_paper.pdf", "target": "Hellingerkernel", "value": "\u77e5\u8bc6"}, {"source": "Bilen_Dynamic_Image_Networks_CVPR_2016_paper.pdf", "target": "L1\u957f\u77ed\u8bb0\u5fc6face identi\ufb01cat", "value": "\u77e5\u8bc6"}, {"source": "Bilen_Dynamic_Image_Networks_CVPR_2016_paper.pdf", "target": "multi-stream architecture", "value": "\u77e5\u8bc6"}, {"source": "Bilen_Dynamic_Image_Networks_CVPR_2016_paper.pdf", "target": "\u957f\u671f\u91cd\u590d\u5377\u79ef\u795e\u7ecf\u7f51\u7edc", "value": "\u77e5\u8bc6"}, {"source": "Bilen_Dynamic_Image_Networks_CVPR_2016_paper.pdf", "target": "\u56db\u6b21\u65b9\u6b63\u5219\u5316", "value": "\u77e5\u8bc6"}, {"source": "Bilen_Dynamic_Image_Networks_CVPR_2016_paper.pdf", "target": "end-to-end\u8bad\u7ec3", "value": "\u77e5\u8bc6"}, {"source": "Bilen_Dynamic_Image_Networks_CVPR_2016_paper.pdf", "target": "\u53cd\u590d\u795e\u7ecf\u7f51\u7edc", "value": "\u77e5\u8bc6"}, {"source": "Bilen_Dynamic_Image_Networks_CVPR_2016_paper.pdf", "target": "neural network encoder", "value": "\u77e5\u8bc6"}, {"source": "Bilen_Dynamic_Image_Networks_CVPR_2016_paper.pdf", "target": "\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc", "value": "\u77e5\u8bc6"}, {"source": "Bilen_Dynamic_Image_Networks_CVPR_2016_paper.pdf", "target": "_signal\u4e2d\u95f4\u7f51\u7edc\u5c42", "value": "\u77e5\u8bc6"}, {"source": "Bilen_Dynamic_Image_Networks_CVPR_2016_paper.pdf", "target": "video\u7406\u89e3", "value": "\u77e5\u8bc6"}, {"source": "Bilen_Dynamic_Image_Networks_CVPR_2016_paper.pdf", "target": "Fully convolutional networks", "value": "\u77e5\u8bc6"}, {"source": "Bilen_Dynamic_Image_Networks_CVPR_2016_paper.pdf", "target": "human action categorization", "value": "\u77e5\u8bc6"}, {"source": "Bilen_Dynamic_Image_Networks_CVPR_2016_paper.pdf", "target": "dense labeling", "value": "\u77e5\u8bc6"}, {"source": "Bilen_Dynamic_Image_Networks_CVPR_2016_paper.pdf", "target": "max-pooling", "value": "\u77e5\u8bc6"}, {"source": "Bilen_Dynamic_Image_Networks_CVPR_2016_paper.pdf", "target": "cvpr", "value": "\u77e5\u8bc6"}, {"source": "Bilen_Dynamic_Image_Networks_CVPR_2016_paper.pdf", "target": "pooling", "value": "\u77e5\u8bc6"}, {"source": "Bilen_Dynamic_Image_Networks_CVPR_2016_paper.pdf", "target": "CNN Architectures", "value": "\u77e5\u8bc6"}, {"source": "Bilen_Dynamic_Image_Networks_CVPR_2016_paper.pdf", "target": "image features", "value": "\u77e5\u8bc6"}, {"source": "Bilen_Dynamic_Image_Networks_CVPR_2016_paper.pdf", "target": "Optimally Represented ImageNet", "value": "\u77e5\u8bc6"}, {"source": "Bilen_Dynamic_Image_Networks_CVPR_2016_paper.pdf", "target": "\u53ef\u79fb\u690d\u7684\u5377\u79ef\u5c42", "value": "\u77e5\u8bc6"}, {"source": "Bilen_Dynamic_Image_Networks_CVPR_2016_paper.pdf", "target": "fine-tuning", "value": "\u77e5\u8bc6"}, {"source": "Bilen_Dynamic_Image_Networks_CVPR_2016_paper.pdf", "target": "Score distribution", "value": "\u77e5\u8bc6"}, {"source": "Bilen_Dynamic_Image_Networks_CVPR_2016_paper.pdf", "target": "vector", "value": "\u77e5\u8bc6"}, {"source": "Bilen_Dynamic_Image_Networks_CVPR_2016_paper.pdf", "target": "LSTM", "value": "\u77e5\u8bc6"}, {"source": "Bilen_Dynamic_Image_Networks_CVPR_2016_paper.pdf", "target": "\u6df1\u5ea6\u5377\u79ef\u7f51\u7edc", "value": "\u77e5\u8bc6"}, {"source": "Bilen_Dynamic_Image_Networks_CVPR_2016_paper.pdf", "target": "\u9759\u6001\u795e\u7ecf\u7f51\u7edc\u67b6\u6784\uff0c\u8c10\u6570", "value": "\u77e5\u8bc6"}, {"source": "d2l-zh-pytorch.pdf", "target": "torch.ones", "value": "\u77e5\u8bc6"}, {"source": "d2l-zh-pytorch.pdf", "target": "\u968f\u673a\u68af\u5ea6\u4e0b\u964d\u6cd5", "value": "\u77e5\u8bc6"}, {"source": "d2l-zh-pytorch.pdf", "target": "tensorflow", "value": "\u77e5\u8bc6"}, {"source": "d2l-zh-pytorch.pdf", "target": "\u4eba\u5de5\u667a\u80fd", "value": "\u77e5\u8bc6"}, {"source": "d2l-zh-pytorch.pdf", "target": "\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc", "value": "\u77e5\u8bc6"}, {"source": "d2l-zh-pytorch.pdf", "target": "pooling", "value": "\u77e5\u8bc6"}, {"source": "d2l-zh-pytorch.pdf", "target": "fine-tuning", "value": "\u77e5\u8bc6"}, {"source": "d2l-zh-pytorch.pdf", "target": "LSTM", "value": "\u77e5\u8bc6"}, {"source": "d2l-zh-pytorch.pdf", "target": "\u8fb9\u7f18\u68c0\u6d4b", "value": "\u77e5\u8bc6"}, {"source": "d2l-zh-pytorch.pdf", "target": "LSTM\u7f51\u7edc", "value": "\u77e5\u8bc6"}, {"source": "d2l-zh-pytorch.pdf", "target": "\u4eba\u8138\u8bc6\u522b", "value": "\u77e5\u8bc6"}, {"source": "d2l-zh-pytorch.pdf", "target": "NVMe SSD", "value": "\u77e5\u8bc6"}, {"source": "d2l-zh-pytorch.pdf", "target": "\u6df1\u5ea6\u5377\u79ef\u795e\u7ecf\u7f51\u7edc", "value": "\u77e5\u8bc6"}, {"source": "d2l-zh-pytorch.pdf", "target": "Fashion\u2010MNIST", "value": "\u77e5\u8bc6"}, {"source": "d2l-zh-pytorch.pdf", "target": "\u51b3\u7b56\u6811", "value": "\u77e5\u8bc6"}, {"source": "d2l-zh-pytorch.pdf", "target": "CNN", "value": "\u77e5\u8bc6"}, {"source": "d2l-zh-pytorch.pdf", "target": "semantic segmentation", "value": "\u77e5\u8bc6"}, {"source": "d2l-zh-pytorch.pdf", "target": "IntelOptane", "value": "\u77e5\u8bc6"}, {"source": "d2l-zh-pytorch.pdf", "target": "\u795e\u7ecf\u7f51\u7edc", "value": "\u77e5\u8bc6"}, {"source": "d2l-zh-pytorch.pdf", "target": "\u68af\u5ea6", "value": "\u77e5\u8bc6"}, {"source": "d2l-zh-pytorch.pdf", "target": "train_func", "value": "\u77e5\u8bc6"}, {"source": "d2l-zh-pytorch.pdf", "target": "DenseNet", "value": "\u77e5\u8bc6"}, {"source": "d2l-zh-pytorch.pdf", "target": "\u652f\u6301\u5411\u91cf\u673a", "value": "\u77e5\u8bc6"}, {"source": "d2l-zh-pytorch.pdf", "target": "\u591a\u7a0b\u5e8f\u6267\u884c", "value": "\u77e5\u8bc6"}, {"source": "d2l-zh-pytorch.pdf", "target": "\u521d\u59cb\u5316\u53c2\u6570\u7ba1\u7406", "value": "\u77e5\u8bc6"}, {"source": "d2l-zh-pytorch.pdf", "target": "SGD\u4f18\u5316\u5668", "value": "\u77e5\u8bc6"}, {"source": "d2l-zh-pytorch.pdf", "target": "\u6570\u636e\u589e\u5f3a", "value": "\u77e5\u8bc6"}, {"source": "d2l-zh-pytorch.pdf", "target": "AlexNet", "value": "\u77e5\u8bc6"}, {"source": "d2l-zh-pytorch.pdf", "target": "random_gradient_descent", "value": "\u77e5\u8bc6"}, {"source": "d2l-zh-pytorch.pdf", "target": "\u6df1\u5ea6\u5b66\u4e60", "value": "\u77e5\u8bc6"}, {"source": "d2l-zh-pytorch.pdf", "target": "\u2202J/\u2202z", "value": "\u77e5\u8bc6"}, {"source": "d2l-zh-pytorch.pdf", "target": "ReLU\u6fc0\u6d3b\u51fd\u6570", "value": "\u77e5\u8bc6"}, {"source": "d2l-zh-pytorch.pdf", "target": "\u72ec\u70ed\u7f16\u7801", "value": "\u77e5\u8bc6"}, {"source": "d2l-zh-pytorch.pdf", "target": "\u53cd\u5411\u4f20\u64ad", "value": "\u77e5\u8bc6"}, {"source": "d2l-zh-pytorch.pdf", "target": "Dualog\u66f2\u6b63\u5207", "value": "\u77e5\u8bc6"}, {"source": "d2l-zh-pytorch.pdf", "target": "\u663e\u5b58\u6269\u5c55", "value": "\u77e5\u8bc6"}, {"source": "d2l-zh-pytorch.pdf", "target": "\u8d1f\u8f7d\u5747\u8861", "value": "\u77e5\u8bc6"}, {"source": "d2l-zh-pytorch.pdf", "target": "Kubernetes", "value": "\u77e5\u8bc6"}, {"source": "d2l-zh-pytorch.pdf", "target": "Performance", "value": "\u77e5\u8bc6"}, {"source": "d2l-zh-pytorch.pdf", "target": "NLP", "value": "\u77e5\u8bc6"}, {"source": "d2l-zh-pytorch.pdf", "target": "ultivariateNormal", "value": "\u77e5\u8bc6"}, {"source": "d2l-zh-pytorch.pdf", "target": "embeddings", "value": "\u77e5\u8bc6"}, {"source": "d2l-zh-pytorch.pdf", "target": "\u4e8c\u5143\u51fd\u6570", "value": "\u77e5\u8bc6"}, {"source": "d2l-zh-pytorch.pdf", "target": "CBOW\u6a21\u578b", "value": "\u77e5\u8bc6"}, {"source": "d2l-zh-pytorch.pdf", "target": "git", "value": "\u77e5\u8bc6"}, {"source": "d2l-zh-pytorch.pdf", "target": "\u67b6\u6784\u5b58\u50a8", "value": "\u77e5\u8bc6"}, {"source": "d2l-zh-pytorch.pdf", "target": "tanh", "value": "\u77e5\u8bc6"}, {"source": "d2l-zh-pytorch.pdf", "target": "\u5bc6\u5ea6\u4f30\u8ba1", "value": "\u77e5\u8bc6"}, {"source": "d2l-zh-pytorch.pdf", "target": "kaggle_house_pred_train", "value": "\u77e5\u8bc6"}, {"source": "d2l-zh-pytorch.pdf", "target": "Tensor Processing Unit", "value": "\u77e5\u8bc6"}, {"source": "cp08-\u6837\u7ae0\u793a\u4f8b-TensorFlow Lite", "target": "TFLite\u6a21\u578b", "value": "\u77e5\u8bc6"}, {"source": "cp08-\u6837\u7ae0\u793a\u4f8b-TensorFlow Lite", "target": "Python", "value": "\u77e5\u8bc6"}, {"source": "cp08-\u6837\u7ae0\u793a\u4f8b-TensorFlow Lite", "target": "hardware accelerator delegate", "value": "\u77e5\u8bc6"}, {"source": "cp08-\u6837\u7ae0\u793a\u4f8b-TensorFlow Lite", "target": "Dense", "value": "\u77e5\u8bc6"}, {"source": "cp08-\u6837\u7ae0\u793a\u4f8b-TensorFlow Lite", "target": "Flow.js", "value": "\u77e5\u8bc6"}, {"source": "cp08-\u6837\u7ae0\u793a\u4f8b-TensorFlow Lite", "target": "Keras H5", "value": "\u77e5\u8bc6"}, {"source": "cp08-\u6837\u7ae0\u793a\u4f8b-TensorFlow Lite", "target": "global_average_pooling2d (GlobalAveragePooling2D)", "value": "\u77e5\u8bc6"}, {"source": "cp08-\u6837\u7ae0\u793a\u4f8b-TensorFlow Lite", "target": "SavedModelTensorFlow Lite", "value": "\u77e5\u8bc6"}, {"source": "cp08-\u6837\u7ae0\u793a\u4f8b-TensorFlow Lite", "target": "tf_*_API", "value": "\u77e5\u8bc6"}, {"source": "cp08-\u6837\u7ae0\u793a\u4f8b-TensorFlow Lite", "target": "Arm64", "value": "\u77e5\u8bc6"}, {"source": "cp08-\u6837\u7ae0\u793a\u4f8b-TensorFlow Lite", "target": "github", "value": "\u77e5\u8bc6"}, {"source": "cp08-\u6837\u7ae0\u793a\u4f8b-TensorFlow Lite", "target": "inceptionv3", "value": "\u77e5\u8bc6"}, {"source": "cp08-\u6837\u7ae0\u793a\u4f8b-TensorFlow Lite", "target": "train_generator", "value": "\u77e5\u8bc6"}, {"source": "cp08-\u6837\u7ae0\u793a\u4f8b-TensorFlow Lite", "target": "repositories", "value": "\u77e5\u8bc6"}, {"source": "cp08-\u6837\u7ae0\u793a\u4f8b-TensorFlow Lite", "target": "\u7f16\u8bd1\u4f18\u5316", "value": "\u77e5\u8bc6"}, {"source": "cp08-\u6837\u7ae0\u793a\u4f8b-TensorFlow Lite", "target": "mean_squared_error", "value": "\u77e5\u8bc6"}, {"source": "cp08-\u6837\u7ae0\u793a\u4f8b-TensorFlow Lite", "target": "prediction process(tf.keras model)", "value": "\u77e5\u8bc6"}, {"source": "cp08-\u6837\u7ae0\u793a\u4f8b-TensorFlow Lite", "target": "MobileNetV2", "value": "\u77e5\u8bc6"}, {"source": "cp08-\u6837\u7ae0\u793a\u4f8b-TensorFlow Lite", "target": "\u7269\u8054\u7f51", "value": "\u77e5\u8bc6"}, {"source": "cp08-\u6837\u7ae0\u793a\u4f8b-TensorFlow Lite", "target": "buildscript", "value": "\u77e5\u8bc6"}, {"source": "cp08-\u6837\u7ae0\u793a\u4f8b-TensorFlow Lite", "target": "recognizeImage", "value": "\u77e5\u8bc6"}, {"source": "cp08-\u6837\u7ae0\u793a\u4f8b-TensorFlow Lite", "target": "\u5168\u8fde\u63a5\u5206\u7c7b\u5668", "value": "\u77e5\u8bc6"}, {"source": "cp08-\u6837\u7ae0\u793a\u4f8b-TensorFlow Lite", "target": "GpuDelegate", "value": "\u77e5\u8bc6"}, {"source": "cp08-\u6837\u7ae0\u793a\u4f8b-TensorFlow Lite", "target": "ImageProcessor", "value": "\u77e5\u8bc6"}, {"source": "cp08-\u6837\u7ae0\u793a\u4f8b-TensorFlow Lite", "target": "MobileNet V2\u57fa\u7840\u6a21\u578b", "value": "\u77e5\u8bc6"}, {"source": "cp08-\u6837\u7ae0\u793a\u4f8b-TensorFlow Lite", "target": "Java", "value": "\u77e5\u8bc6"}, {"source": "cp08-\u6837\u7ae0\u793a\u4f8b-TensorFlow Lite", "target": "tflite_convert", "value": "\u77e5\u8bc6"}, {"source": "cp08-\u6837\u7ae0\u793a\u4f8b-TensorFlow Lite", "target": "Tf.keras model", "value": "\u77e5\u8bc6"}, {"source": "cp08-\u6837\u7ae0\u793a\u4f8b-TensorFlow Lite", "target": "\u8ba1\u7b97\u673a\u6444\u50cf\u5934", "value": "\u77e5\u8bc6"}, {"source": "cp08-\u6837\u7ae0\u793a\u4f8b-TensorFlow Lite", "target": "tf.lite.Optimize.OPTIMIZE_FOR_SIZE", "value": "\u77e5\u8bc6"}, {"source": "cp08-\u6837\u7ae0\u793a\u4f8b-TensorFlow Lite", "target": "\u5d4c\u5165\u5f0f\u8bbe\u5907", "value": "\u77e5\u8bc6"}, {"source": "cp08-\u6837\u7ae0\u793a\u4f8b-TensorFlow Lite", "target": "device deployment", "value": "\u77e5\u8bc6"}, {"source": "cp08-\u6837\u7ae0\u793a\u4f8b-TensorFlow Lite", "target": "TensorFlow Serving", "value": "\u77e5\u8bc6"}, {"source": "cp08-\u6837\u7ae0\u793a\u4f8b-TensorFlow Lite", "target": "Interpreter", "value": "\u77e5\u8bc6"}, {"source": "cp08-\u6837\u7ae0\u793a\u4f8b-TensorFlow Lite", "target": "maven", "value": "\u77e5\u8bc6"}, {"source": "cp08-\u6837\u7ae0\u793a\u4f8b-TensorFlow Lite", "target": "datagen.flow_from_directory", "value": "\u77e5\u8bc6"}, {"source": "cp08-\u6837\u7ae0\u793a\u4f8b-TensorFlow Lite", "target": "migration learning", "value": "\u77e5\u8bc6"}, {"source": "cp08-\u6837\u7ae0\u793a\u4f8b-TensorFlow Lite", "target": "Android StudioAndroid Studio Project", "value": "\u77e5\u8bc6"}, {"source": "cp08-\u6837\u7ae0\u793a\u4f8b-TensorFlow Lite", "target": "global_average_pooling2d", "value": "\u77e5\u8bc6"}, {"source": "cp08-\u6837\u7ae0\u793a\u4f8b-TensorFlow Lite", "target": "Live Caption", "value": "\u77e5\u8bc6"}, {"source": "cp08-\u6837\u7ae0\u793a\u4f8b-TensorFlow Lite", "target": "model.save", "value": "\u77e5\u8bc6"}, {"source": "cp08-\u6837\u7ae0\u793a\u4f8b-TensorFlow Lite", "target": "\u50cf\u7d20\u7f29\u653e", "value": "\u77e5\u8bc6"}, {"source": "cp08-\u6837\u7ae0\u793a\u4f8b-TensorFlow Lite", "target": "noCcompress\"TFLite\"", "value": "\u77e5\u8bc6"}, {"source": "cp08-\u6837\u7ae0\u793a\u4f8b-TensorFlow Lite", "target": "\u7c7b\u522b\u4ea4\u53c9\u71b5", "value": "\u77e5\u8bc6"}, {"source": "cp08-\u6837\u7ae0\u793a\u4f8b-TensorFlow Lite", "target": "\u62df\u8bbe\u5907\u7ba1\u7406\u5668", "value": "\u77e5\u8bc6"}, {"source": "cp08-\u6837\u7ae0\u793a\u4f8b-TensorFlow Lite", "target": "Training", "value": "\u77e5\u8bc6"}, {"source": "cp08-\u6837\u7ae0\u793a\u4f8b-TensorFlow Lite", "target": "pooling\u5c42", "value": "\u77e5\u8bc6"}, {"source": "cp08-\u6837\u7ae0\u793a\u4f8b-TensorFlow Lite", "target": "TensorFlow \u6a21\u578b", "value": "\u77e5\u8bc6"}, {"source": "cp08-\u6837\u7ae0\u793a\u4f8b-TensorFlow Lite", "target": "TFLiteConverter", "value": "\u77e5\u8bc6"}, {"source": "cp08-\u6837\u7ae0\u793a\u4f8b-TensorFlow Lite", "target": "tf.lite", "value": "\u77e5\u8bc6"}, {"source": "\u300a\u9e1f\u54e5\u7684Linux\u79c1\u623f\u83dc\u300b", "target": "RAID-0", "value": "\u77e5\u8bc6"}, {"source": "\u300a\u9e1f\u54e5\u7684Linux\u79c1\u623f\u83dc\u300b", "target": "startup_scripts", "value": "\u77e5\u8bc6"}, {"source": "\u300a\u9e1f\u54e5\u7684Linux\u79c1\u623f\u83dc\u300b", "target": "Realtek\u7f51\u5361", "value": "\u77e5\u8bc6"}, {"source": "\u300a\u9e1f\u54e5\u7684Linux\u79c1\u623f\u83dc\u300b", "target": "dhcp-client", "value": "\u77e5\u8bc6"}, {"source": "\u300a\u9e1f\u54e5\u7684Linux\u79c1\u623f\u83dc\u300b", "target": "Matrox g200/g400", "value": "\u77e5\u8bc6"}, {"source": "\u300a\u9e1f\u54e5\u7684Linux\u79c1\u623f\u83dc\u300b", "target": "I/AGP\u603b\u7ebf", "value": "\u77e5\u8bc6"}, {"source": "\u300a\u9e1f\u54e5\u7684Linux\u79c1\u623f\u83dc\u300b", "target": "DNS\u7ba1\u7406", "value": "\u77e5\u8bc6"}, {"source": "\u300a\u9e1f\u54e5\u7684Linux\u79c1\u623f\u83dc\u300b", "target": "suite", "value": "\u77e5\u8bc6"}, {"source": "\u300a\u9e1f\u54e5\u7684Linux\u79c1\u623f\u83dc\u300b", "target": "\u7a0b\u5e8f\u5f00\u53d1\u5e73\u53f0", "value": "\u77e5\u8bc6"}, {"source": "\u300a\u9e1f\u54e5\u7684Linux\u79c1\u623f\u83dc\u300b", "target": "NIS-server\uff0cNIS\u5ba2\u6237", "value": "\u77e5\u8bc6"}, {"source": "\u300a\u9e1f\u54e5\u7684Linux\u79c1\u623f\u83dc\u300b", "target": "bash shell sccript", "value": "\u77e5\u8bc6"}, {"source": "\u300a\u9e1f\u54e5\u7684Linux\u79c1\u623f\u83dc\u300b", "target": "internet_interfaces", "value": "\u77e5\u8bc6"}, {"source": "\u300a\u9e1f\u54e5\u7684Linux\u79c1\u623f\u83dc\u300b", "target": "Userspace Events", "value": "\u77e5\u8bc6"}, {"source": "\u300a\u9e1f\u54e5\u7684Linux\u79c1\u623f\u83dc\u300b", "target": "Email\u4fe1\u7bb1", "value": "\u77e5\u8bc6"}, {"source": "\u300a\u9e1f\u54e5\u7684Linux\u79c1\u623f\u83dc\u300b", "target": "bash", "value": "\u77e5\u8bc6"}, {"source": "\u300a\u9e1f\u54e5\u7684Linux\u79c1\u623f\u83dc\u300b", "target": "2.6_linux_kernel", "value": "\u77e5\u8bc6"}, {"source": "\u300a\u9e1f\u54e5\u7684Linux\u79c1\u623f\u83dc\u300b", "target": "\u660e\u7801\u4f20\u8f93\u7f51\u7edc\u8054\u673a\u6570\u636e\u5b89\u5168\u98ce\u9669", "value": "\u77e5\u8bc6"}, {"source": "\u300a\u9e1f\u54e5\u7684Linux\u79c1\u623f\u83dc\u300b", "target": "equal cost multipath", "value": "\u77e5\u8bc6"}, {"source": "\u300a\u9e1f\u54e5\u7684Linux\u79c1\u623f\u83dc\u300b", "target": "allow-transfer", "value": "\u77e5\u8bc6"}, {"source": "\u300a\u9e1f\u54e5\u7684Linux\u79c1\u623f\u83dc\u300b", "target": "RPM\u5305\u7ba1\u7406", "value": "\u77e5\u8bc6"}, {"source": "\u300a\u9e1f\u54e5\u7684Linux\u79c1\u623f\u83dc\u300b", "target": "Bcast", "value": "\u77e5\u8bc6"}, {"source": "\u300a\u9e1f\u54e5\u7684Linux\u79c1\u623f\u83dc\u300b", "target": "Secure Socket Layer", "value": "\u77e5\u8bc6"}, {"source": "\u300a\u9e1f\u54e5\u7684Linux\u79c1\u623f\u83dc\u300b", "target": "Linux \u78c1\u76d8\u9635\u5217", "value": "\u77e5\u8bc6"}, {"source": "\u300a\u9e1f\u54e5\u7684Linux\u79c1\u623f\u83dc\u300b", "target": "learning", "value": "\u77e5\u8bc6"}, {"source": "\u300a\u9e1f\u54e5\u7684Linux\u79c1\u623f\u83dc\u300b", "target": "major", "value": "\u77e5\u8bc6"}, {"source": "\u300a\u9e1f\u54e5\u7684Linux\u79c1\u623f\u83dc\u300b", "target": "tethereal", "value": "\u77e5\u8bc6"}, {"source": "\u300a\u9e1f\u54e5\u7684Linux\u79c1\u623f\u83dc\u300b", "target": "SMBus", "value": "\u77e5\u8bc6"}, {"source": "\u300a\u9e1f\u54e5\u7684Linux\u79c1\u623f\u83dc\u300b", "target": "PCI\u9002\u914d\u5361", "value": "\u77e5\u8bc6"}, {"source": "\u300a\u9e1f\u54e5\u7684Linux\u79c1\u623f\u83dc\u300b", "target": "pam_listfile.so", "value": "\u77e5\u8bc6"}, {"source": "\u300a\u9e1f\u54e5\u7684Linux\u79c1\u623f\u83dc\u300b", "target": "NFS server over TCP\u652f\u6301", "value": "\u77e5\u8bc6"}, {"source": "\u300a\u9e1f\u54e5\u7684Linux\u79c1\u623f\u83dc\u300b", "target": "Info reader", "value": "\u77e5\u8bc6"}, {"source": "\u300a\u9e1f\u54e5\u7684Linux\u79c1\u623f\u83dc\u300b", "target": "SATA \u63d2\u69fd", "value": "\u77e5\u8bc6"}, {"source": "\u300a\u9e1f\u54e5\u7684Linux\u79c1\u623f\u83dc\u300b", "target": "CIFS/remote\u8ba1\u7b97\u673a\u767b\u5f55\u4fe1\u606f\u8bb0\u5f55", "value": "\u77e5\u8bc6"}, {"source": "\u300a\u9e1f\u54e5\u7684Linux\u79c1\u623f\u83dc\u300b", "target": "proftpd", "value": "\u77e5\u8bc6"}, {"source": "\u300a\u9e1f\u54e5\u7684Linux\u79c1\u623f\u83dc\u300b", "target": "NS\u670d\u52a1", "value": "\u77e5\u8bc6"}, {"source": "\u300a\u9e1f\u54e5\u7684Linux\u79c1\u623f\u83dc\u300b", "target": "operator", "value": "\u77e5\u8bc6"}, {"source": "\u300a\u9e1f\u54e5\u7684Linux\u79c1\u623f\u83dc\u300b", "target": "smtpd_sasl_application_name", "value": "\u77e5\u8bc6"}, {"source": "\u300a\u9e1f\u54e5\u7684Linux\u79c1\u623f\u83dc\u300b", "target": "Docker\u7f51\u7edc\u5361", "value": "\u77e5\u8bc6"}, {"source": "\u300a\u9e1f\u54e5\u7684Linux\u79c1\u623f\u83dc\u300b", "target": "Start of Authority", "value": "\u77e5\u8bc6"}, {"source": "\u300a\u9e1f\u54e5\u7684Linux\u79c1\u623f\u83dc\u300b", "target": "pwcheck_meth", "value": "\u77e5\u8bc6"}, {"source": "\u300a\u9e1f\u54e5\u7684Linux\u79c1\u623f\u83dc\u300b", "target": "Screentheme", "value": "\u77e5\u8bc6"}, {"source": "\u300a\u9e1f\u54e5\u7684Linux\u79c1\u623f\u83dc\u300b", "target": "boot/initrd-2.6.11-1.1", "value": "\u77e5\u8bc6"}, {"source": "\u300a\u9e1f\u54e5\u7684Linux\u79c1\u623f\u83dc\u300b", "target": "dns resolver", "value": "\u77e5\u8bc6"}, {"source": "\u300a\u9e1f\u54e5\u7684Linux\u79c1\u623f\u83dc\u300b", "target": "noip-2.1.3.http\u73af\u5883\u8bbe\u5b9a", "value": "\u77e5\u8bc6"}, {"source": "\u300a\u9e1f\u54e5\u7684Linux\u79c1\u623f\u83dc\u300b", "target": "stage1", "value": "\u77e5\u8bc6"}, {"source": "\u300a\u9e1f\u54e5\u7684Linux\u79c1\u623f\u83dc\u300b", "target": "\u7535\u529b\u8282\u7ea6", "value": "\u77e5\u8bc6"}, {"source": "\u300a\u9e1f\u54e5\u7684Linux\u79c1\u623f\u83dc\u300b", "target": "Primary IDE\u63a5\u53e3", "value": "\u77e5\u8bc6"}, {"source": "\u300a\u9e1f\u54e5\u7684Linux\u79c1\u623f\u83dc\u300b", "target": "Postfix Mail \u670d\u52a1\u5668ific", "value": "\u77e5\u8bc6"}, {"source": "\u300a\u9e1f\u54e5\u7684Linux\u79c1\u623f\u83dc\u300b", "target": "optimization", "value": "\u77e5\u8bc6"}, {"source": "\u300a\u9e1f\u54e5\u7684Linux\u79c1\u623f\u83dc\u300b", "target": "BIOS Time", "value": "\u77e5\u8bc6"}, {"source": "DCNN based human activity recognition framework with depth vision guiding.pdf", "target": "\u4eba\u5de5\u667a\u80fd", "value": "\u77e5\u8bc6"}, {"source": "DCNN based human activity recognition framework with depth vision guiding.pdf", "target": "ReLU\u5c42", "value": "\u77e5\u8bc6"}, {"source": "DCNN based human activity recognition framework with depth vision guiding.pdf", "target": "\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc", "value": "\u77e5\u8bc6"}, {"source": "DCNN based human activity recognition framework with depth vision guiding.pdf", "target": "LSTM", "value": "\u77e5\u8bc6"}, {"source": "DCNN based human activity recognition framework with depth vision guiding.pdf", "target": "segmentation", "value": "\u77e5\u8bc6"}, {"source": "DCNN based human activity recognition framework with depth vision guiding.pdf", "target": "action recognition", "value": "\u77e5\u8bc6"}, {"source": "DCNN based human activity recognition framework with depth vision guiding.pdf", "target": "CNN", "value": "\u77e5\u8bc6"}, {"source": "DCNN based human activity recognition framework with depth vision guiding.pdf", "target": "SVM", "value": "\u77e5\u8bc6"}, {"source": "DCNN based human activity recognition framework with depth vision guiding.pdf", "target": "\u795e\u7ecf\u7f51\u7edc", "value": "\u77e5\u8bc6"}, {"source": "DCNN based human activity recognition framework with depth vision guiding.pdf", "target": "\u652f\u6301\u5411\u91cf\u673a", "value": "\u77e5\u8bc6"}, {"source": "DCNN based human activity recognition framework with depth vision guiding.pdf", "target": "\u4eba\u673a\u4ea4\u4e92", "value": "\u77e5\u8bc6"}, {"source": "DCNN based human activity recognition framework with depth vision guiding.pdf", "target": "\u6df1\u5ea6\u5b66\u4e60", "value": "\u77e5\u8bc6"}, {"source": "DCNN based human activity recognition framework with depth vision guiding.pdf", "target": "\u673a\u5668\u5b66\u4e60", "value": "\u77e5\u8bc6"}, {"source": "DCNN based human activity recognition framework with depth vision guiding.pdf", "target": "batch normalization", "value": "\u77e5\u8bc6"}, {"source": "DCNN based human activity recognition framework with depth vision guiding.pdf", "target": "ReLU", "value": "\u77e5\u8bc6"}, {"source": "DCNN based human activity recognition framework with depth vision guiding.pdf", "target": "classifier", "value": "\u77e5\u8bc6"}, {"source": "DCNN based human activity recognition framework with depth vision guiding.pdf", "target": "IoT", "value": "\u77e5\u8bc6"}, {"source": "DCNN based human activity recognition framework with depth vision guiding.pdf", "target": "DNN", "value": "\u77e5\u8bc6"}, {"source": "DCNN based human activity recognition framework with depth vision guiding.pdf", "target": "\u6807\u51c6\u5dee", "value": "\u77e5\u8bc6"}, {"source": "DCNN based human activity recognition framework with depth vision guiding.pdf", "target": "predictive modeling", "value": "\u77e5\u8bc6"}, {"source": "DCNN based human activity recognition framework with depth vision guiding.pdf", "target": "\u5f3a\u5316\u5b66\u4e60", "value": "\u77e5\u8bc6"}, {"source": "DCNN based human activity recognition framework with depth vision guiding.pdf", "target": "k-means", "value": "\u77e5\u8bc6"}, {"source": "DCNN based human activity recognition framework with depth vision guiding.pdf", "target": "\u81ea\u52a8\u5316\u90e8\u7f72", "value": "\u77e5\u8bc6"}, {"source": "DCNN based human activity recognition framework with depth vision guiding.pdf", "target": "machine learning", "value": "\u77e5\u8bc6"}, {"source": "DCNN based human activity recognition framework with depth vision guiding.pdf", "target": "serial number", "value": "\u77e5\u8bc6"}, {"source": "DCNN based human activity recognition framework with depth vision guiding.pdf", "target": "\u7279\u5f81\u62bd\u53d6", "value": "\u77e5\u8bc6"}, {"source": "DCNN based human activity recognition framework with depth vision guiding.pdf", "target": "\u7279\u5f81\u63d0\u53d6", "value": "\u77e5\u8bc6"}, {"source": "DCNN based human activity recognition framework with depth vision guiding.pdf", "target": "speed", "value": "\u77e5\u8bc6"}, {"source": "DCNN based human activity recognition framework with depth vision guiding.pdf", "target": "computer interface", "value": "\u77e5\u8bc6"}, {"source": "DCNN based human activity recognition framework with depth vision guiding.pdf", "target": "BIDI-rectional LSTM", "value": "\u77e5\u8bc6"}, {"source": "DCNN based human activity recognition framework with depth vision guiding.pdf", "target": "Kinect", "value": "\u77e5\u8bc6"}, {"source": "DCNN based human activity recognition framework with depth vision guiding.pdf", "target": "activities", "value": "\u77e5\u8bc6"}, {"source": "DCNN based human activity recognition framework with depth vision guiding.pdf", "target": "\u4fe1\u53f7\u5904\u7406\u7b97\u6cd5", "value": "\u77e5\u8bc6"}, {"source": "DCNN based human activity recognition framework with depth vision guiding.pdf", "target": "Robustness", "value": "\u77e5\u8bc6"}, {"source": "DCNN based human activity recognition framework with depth vision guiding.pdf", "target": "swarm\u51b3\u7b56\u8868", "value": "\u77e5\u8bc6"}, {"source": "DCNN based human activity recognition framework with depth vision guiding.pdf", "target": "Kinect devices", "value": "\u77e5\u8bc6"}, {"source": "DCNN based human activity recognition framework with depth vision guiding.pdf", "target": "joints", "value": "\u77e5\u8bc6"}, {"source": "DCNN based human activity recognition framework with depth vision guiding.pdf", "target": "HCI", "value": "\u77e5\u8bc6"}, {"source": "DCNN based human activity recognition framework with depth vision guiding.pdf", "target": "Kinect\u8bbe\u5907", "value": "\u77e5\u8bc6"}, {"source": "DCNN based human activity recognition framework with depth vision guiding.pdf", "target": "Mechatronics", "value": "\u77e5\u8bc6"}, {"source": "DCNN based human activity recognition framework with depth vision guiding.pdf", "target": "\u53cc\u91cd\u8fdc\u7a0b\u64cd\u4f5c", "value": "\u77e5\u8bc6"}, {"source": "DCNN based human activity recognition framework with depth vision guiding.pdf", "target": "data processing units", "value": "\u77e5\u8bc6"}, {"source": "DCNN based human activity recognition framework with depth vision guiding.pdf", "target": "earable \u4f20\u611f\u5668", "value": "\u77e5\u8bc6"}, {"source": "DCNN based human activity recognition framework with depth vision guiding.pdf", "target": "Complexity", "value": "\u77e5\u8bc6"}, {"source": "DCNN based human activity recognition framework with depth vision guiding.pdf", "target": "drifting\u566a\u58f0", "value": "\u77e5\u8bc6"}, {"source": "DCNN based human activity recognition framework with depth vision guiding.pdf", "target": "signal sequences", "value": "\u77e5\u8bc6"}, {"source": "DCNN based human activity recognition framework with depth vision guiding.pdf", "target": "Hk-medoids model", "value": "\u77e5\u8bc6"}, {"source": "DCNN based human activity recognition framework with depth vision guiding.pdf", "target": "\u6df1\u5ea6\u6570\u636e guild.framework", "value": "\u77e5\u8bc6"}, {"source": "DCNN based human activity recognition framework with depth vision guiding.pdf", "target": "\u4e24\u5411\u8fdc\u7a0b\u64cd\u4f5c", "value": "\u77e5\u8bc6"}, {"source": "DCNN based human activity recognition framework with depth vision guiding.pdf", "target": "Neuro\u8ba1\u7b97\u673a", "value": "\u77e5\u8bc6"}, {"source": "Deep learning for sensor-based human activity recognition Overview, challenges, and opportunities.pdf", "target": "summarization", "value": "\u77e5\u8bc6"}, {"source": "Deep learning for sensor-based human activity recognition Overview, challenges, and opportunities.pdf", "target": "\u4eba\u5de5\u667a\u80fd", "value": "\u77e5\u8bc6"}, {"source": "Deep learning for sensor-based human activity recognition Overview, challenges, and opportunities.pdf", "target": "\u53cd\u590d\u795e\u7ecf\u7f51\u7edc", "value": "\u77e5\u8bc6"}, {"source": "Deep learning for sensor-based human activity recognition Overview, challenges, and opportunities.pdf", "target": "\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc", "value": "\u77e5\u8bc6"}, {"source": "Deep learning for sensor-based human activity recognition Overview, challenges, and opportunities.pdf", "target": "Fully convolutional networks", "value": "\u77e5\u8bc6"}, {"source": "Deep learning for sensor-based human activity recognition Overview, challenges, and opportunities.pdf", "target": "pooling", "value": "\u77e5\u8bc6"}, {"source": "Deep learning for sensor-based human activity recognition Overview, challenges, and opportunities.pdf", "target": "fine-tuning", "value": "\u77e5\u8bc6"}, {"source": "Deep learning for sensor-based human activity recognition Overview, challenges, and opportunities.pdf", "target": "LSTM", "value": "\u77e5\u8bc6"}, {"source": "Deep learning for sensor-based human activity recognition Overview, challenges, and opportunities.pdf", "target": "LSTM\u7f51\u7edc", "value": "\u77e5\u8bc6"}, {"source": "Deep learning for sensor-based human activity recognition Overview, challenges, and opportunities.pdf", "target": "data augmentation", "value": "\u77e5\u8bc6"}, {"source": "Deep learning for sensor-based human activity recognition Overview, challenges, and opportunities.pdf", "target": "convolutional neural networks", "value": "\u77e5\u8bc6"}, {"source": "Deep learning for sensor-based human activity recognition Overview, challenges, and opportunities.pdf", "target": "CNNs", "value": "\u77e5\u8bc6"}, {"source": "Deep learning for sensor-based human activity recognition Overview, challenges, and opportunities.pdf", "target": "action recognition", "value": "\u77e5\u8bc6"}, {"source": "Deep learning for sensor-based human activity recognition Overview, challenges, and opportunities.pdf", "target": "neural network", "value": "\u77e5\u8bc6"}, {"source": "Deep learning for sensor-based human activity recognition Overview, challenges, and opportunities.pdf", "target": "CNN", "value": "\u77e5\u8bc6"}, {"source": "Deep learning for sensor-based human activity recognition Overview, challenges, and opportunities.pdf", "target": "semantic segmentation", "value": "\u77e5\u8bc6"}, {"source": "Deep learning for sensor-based human activity recognition Overview, challenges, and opportunities.pdf", "target": "LSTMs", "value": "\u77e5\u8bc6"}, {"source": "Deep learning for sensor-based human activity recognition Overview, challenges, and opportunities.pdf", "target": "\u795e\u7ecf\u7f51\u7edc", "value": "\u77e5\u8bc6"}, {"source": "Deep learning for sensor-based human activity recognition Overview, challenges, and opportunities.pdf", "target": "\u65e0\u76d1\u7763\u5b66\u4e60", "value": "\u77e5\u8bc6"}, {"source": "Deep learning for sensor-based human activity recognition Overview, challenges, and opportunities.pdf", "target": "RNNs", "value": "\u77e5\u8bc6"}, {"source": "Deep learning for sensor-based human activity recognition Overview, challenges, and opportunities.pdf", "target": "\u6570\u636e\u589e\u5f3a", "value": "\u77e5\u8bc6"}, {"source": "Deep learning for sensor-based human activity recognition Overview, challenges, and opportunities.pdf", "target": "AlexNet", "value": "\u77e5\u8bc6"}, {"source": "Deep learning for sensor-based human activity recognition Overview, challenges, and opportunities.pdf", "target": "\u4eba\u673a\u4ea4\u4e92", "value": "\u77e5\u8bc6"}, {"source": "Deep learning for sensor-based human activity recognition Overview, challenges, and opportunities.pdf", "target": "autoencoder", "value": "\u77e5\u8bc6"}, {"source": "Deep learning for sensor-based human activity recognition Overview, challenges, and opportunities.pdf", "target": "\u6df1\u5ea6\u5b66\u4e60", "value": "\u77e5\u8bc6"}, {"source": "Deep learning for sensor-based human activity recognition Overview, challenges, and opportunities.pdf", "target": "attention mechanism", "value": "\u77e5\u8bc6"}, {"source": "Deep learning for sensor-based human activity recognition Overview, challenges, and opportunities.pdf", "target": "\u6ce8\u610f\u529b\u673a\u5236", "value": "\u77e5\u8bc6"}, {"source": "Deep learning for sensor-based human activity recognition Overview, challenges, and opportunities.pdf", "target": "Distribution Shift", "value": "\u77e5\u8bc6"}, {"source": "Deep learning for sensor-based human activity recognition Overview, challenges, and opportunities.pdf", "target": "network", "value": "\u77e5\u8bc6"}, {"source": "Deep learning for sensor-based human activity recognition Overview, challenges, and opportunities.pdf", "target": "ArtificialIntelligence", "value": "\u77e5\u8bc6"}, {"source": "Deep learning for sensor-based human activity recognition Overview, challenges, and opportunities.pdf", "target": "\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b", "value": "\u77e5\u8bc6"}, {"source": "Deep learning for sensor-based human activity recognition Overview, challenges, and opportunities.pdf", "target": "software", "value": "\u77e5\u8bc6"}, {"source": "Deep learning for sensor-based human activity recognition Overview, challenges, and opportunities.pdf", "target": "\u673a\u5668\u5b66\u4e60", "value": "\u77e5\u8bc6"}, {"source": "Deep learning for sensor-based human activity recognition Overview, challenges, and opportunities.pdf", "target": "users", "value": "\u77e5\u8bc6"}, {"source": "Deep learning for sensor-based human activity recognition Overview, challenges, and opportunities.pdf", "target": "\u5927\u6570\u636e", "value": "\u77e5\u8bc6"}, {"source": "Deep learning for sensor-based human activity recognition Overview, challenges, and opportunities.pdf", "target": "S3\u5b58\u50a8\u670d\u52a1", "value": "\u77e5\u8bc6"}, {"source": "Deep learning for sensor-based human activity recognition Overview, challenges, and opportunities.pdf", "target": "\u68af\u5ea6\u6d88\u5931", "value": "\u77e5\u8bc6"}, {"source": "Deep learning for sensor-based human activity recognition Overview, challenges, and opportunities.pdf", "target": "concept drift", "value": "\u77e5\u8bc6"}, {"source": "Deep learning for sensor-based human activity recognition Overview, challenges, and opportunities.pdf", "target": "GPU", "value": "\u77e5\u8bc6"}, {"source": "Deep learning for sensor-based human activity recognition Overview, challenges, and opportunities.pdf", "target": "DNN", "value": "\u77e5\u8bc6"}, {"source": "Deep learning for sensor-based human activity recognition Overview, challenges, and opportunities.pdf", "target": "\u6df1\u5b66\u4e60", "value": "\u77e5\u8bc6"}, {"source": "Deep learning for sensor-based human activity recognition Overview, challenges, and opportunities.pdf", "target": "depth camera", "value": "\u77e5\u8bc6"}, {"source": "Deep learning for sensor-based human activity recognition Overview, challenges, and opportunities.pdf", "target": "Network", "value": "\u77e5\u8bc6"}, {"source": "Deep learning for sensor-based human activity recognition Overview, challenges, and opportunities.pdf", "target": "Convolutional Neural Networks", "value": "\u77e5\u8bc6"}, {"source": "Deep learning for sensor-based human activity recognition Overview, challenges, and opportunities.pdf", "target": "\u5bb9\u5668\u7f16\u6392", "value": "\u77e5\u8bc6"}, {"source": "Deep learning for sensor-based human activity recognition Overview, challenges, and opportunities.pdf", "target": "natural language processing", "value": "\u77e5\u8bc6"}, {"source": "Deep learning for sensor-based human activity recognition Overview, challenges, and opportunities.pdf", "target": "LSTM networks", "value": "\u77e5\u8bc6"}, {"source": "Deep learning for sensor-based human activity recognition Overview, challenges, and opportunities.pdf", "target": "\u6807\u51c6\u5316", "value": "\u77e5\u8bc6"}, {"source": "Deep learning for sensor-based human activity recognition Overview, challenges, and opportunities.pdf", "target": "Channel-based late fusion", "value": "\u77e5\u8bc6"}, {"source": "Deep learning for sensor-based human activity recognition Overview, challenges, and opportunities.pdf", "target": "Convolutional Neural Network", "value": "\u77e5\u8bc6"}, {"source": "1-s2", "target": "Kubernetes", "value": "\u77e5\u8bc6"}, {"source": "1-s2", "target": "network", "value": "\u77e5\u8bc6"}, {"source": "1-s2", "target": "graphics", "value": "\u77e5\u8bc6"}, {"source": "1-s2", "target": "cloud computing platform", "value": "\u77e5\u8bc6"}, {"source": "1-s2", "target": "global", "value": "\u77e5\u8bc6"}, {"source": "1-s2", "target": "Python", "value": "\u77e5\u8bc6"}, {"source": "1-s2", "target": "model", "value": "\u77e5\u8bc6"}, {"source": "1-s2", "target": "PoseNet", "value": "\u77e5\u8bc6"}, {"source": "1-s2", "target": "\u4eba\u4f53\u59ff\u52bf\u4f30\u8ba1", "value": "\u77e5\u8bc6"}, {"source": "1-s2", "target": "Android", "value": "\u77e5\u8bc6"}, {"source": "1-s2", "target": "DNN", "value": "\u77e5\u8bc6"}, {"source": "1-s2", "target": "classification", "value": "\u77e5\u8bc6"}, {"source": "1-s2", "target": "mapping", "value": "\u77e5\u8bc6"}, {"source": "1-s2", "target": "Docker\u5bb9\u5668", "value": "\u77e5\u8bc6"}, {"source": "1-s2", "target": "planning", "value": "\u77e5\u8bc6"}, {"source": "1-s2", "target": "reliability", "value": "\u77e5\u8bc6"}, {"source": "1-s2", "target": "\u81ea\u52a8\u5316\u90e8\u7f72", "value": "\u77e5\u8bc6"}, {"source": "1-s2", "target": "cluster", "value": "\u77e5\u8bc6"}, {"source": "1-s2", "target": "speed", "value": "\u77e5\u8bc6"}, {"source": "1-s2", "target": "parallel", "value": "\u77e5\u8bc6"}, {"source": "1-s2", "target": "features", "value": "\u77e5\u8bc6"}, {"source": "1-s2", "target": "classi\ufb01cation experiments", "value": "\u77e5\u8bc6"}, {"source": "1-s2", "target": "human motion", "value": "\u77e5\u8bc6"}, {"source": "1-s2", "target": "robustness", "value": "\u77e5\u8bc6"}, {"source": "1-s2", "target": "eigenvector", "value": "\u77e5\u8bc6"}, {"source": "1-s2", "target": "distance measurement", "value": "\u77e5\u8bc6"}, {"source": "1-s2", "target": "motion\u7279\u5f81", "value": "\u77e5\u8bc6"}, {"source": "1-s2", "target": "Distance Measurement", "value": "\u77e5\u8bc6"}, {"source": "1-s2", "target": "limbs", "value": "\u77e5\u8bc6"}, {"source": "1-s2", "target": "self-similarity plot", "value": "\u77e5\u8bc6"}, {"source": "1-s2", "target": "regions", "value": "\u77e5\u8bc6"}, {"source": "1-s2", "target": "Central Nervous System", "value": "\u77e5\u8bc6"}, {"source": "1-s2", "target": "matrix", "value": "\u77e5\u8bc6"}, {"source": "1-s2", "target": "aerobics", "value": "\u77e5\u8bc6"}, {"source": "1-s2", "target": "gradient", "value": "\u77e5\u8bc6"}, {"source": "1-s2", "target": "freno-pa\u4eba\u5de5\u667a\u80fd", "value": "\u77e5\u8bc6"}, {"source": "1-s2", "target": "filtering", "value": "\u77e5\u8bc6"}, {"source": "1-s2", "target": "Visual motion perception", "value": "\u77e5\u8bc6"}, {"source": "1-s2", "target": "data selection", "value": "\u77e5\u8bc6"}, {"source": "1-s2", "target": "experiments", "value": "\u77e5\u8bc6"}, {"source": "1-s2", "target": "\u4eba\u4f53\u8fd0\u52a8\u8bc6\u522b\uff0c\u964d\u7ef4\u7a7a\u95f4", "value": "\u77e5\u8bc6"}, {"source": "1-s2", "target": "non-linear", "value": "\u77e5\u8bc6"}, {"source": "1-s2", "target": "D.L. Swetscontrast", "value": "\u77e5\u8bc6"}, {"source": "1-s2", "target": "Human Motion Model", "value": "\u77e5\u8bc6"}, {"source": "1-s2", "target": "3D model-basedtracking", "value": "\u77e5\u8bc6"}, {"source": "1-s2", "target": "bio\u52a8\u753b\u7684\u89c6\u89c9\u611f\u77e5\u548c\u5176\u5206\u6790\u6a21\u578bysis", "value": "\u77e5\u8bc6"}, {"source": "1-s2", "target": "spread", "value": "\u77e5\u8bc6"}, {"source": "1-s2", "target": "eigenvalue", "value": "\u77e5\u8bc6"}, {"source": "1-s2", "target": "\u751f\u7269\u4f53\u8fd0\u52a8\u611f\u77e5", "value": "\u77e5\u8bc6"}, {"source": "1-s2", "target": "\u51b2usions plots", "value": "\u77e5\u8bc6"}, {"source": "1-s2", "target": "Kubernetes", "value": "\u77e5\u8bc6"}, {"source": "1-s2", "target": "network", "value": "\u77e5\u8bc6"}, {"source": "1-s2", "target": "graphics", "value": "\u77e5\u8bc6"}, {"source": "1-s2", "target": "cloud computing platform", "value": "\u77e5\u8bc6"}, {"source": "1-s2", "target": "global", "value": "\u77e5\u8bc6"}, {"source": "1-s2", "target": "Python", "value": "\u77e5\u8bc6"}, {"source": "1-s2", "target": "model", "value": "\u77e5\u8bc6"}, {"source": "1-s2", "target": "PoseNet", "value": "\u77e5\u8bc6"}, {"source": "1-s2", "target": "\u4eba\u4f53\u59ff\u52bf\u4f30\u8ba1", "value": "\u77e5\u8bc6"}, {"source": "1-s2", "target": "Android", "value": "\u77e5\u8bc6"}, {"source": "1-s2", "target": "DNN", "value": "\u77e5\u8bc6"}, {"source": "1-s2", "target": "classification", "value": "\u77e5\u8bc6"}, {"source": "1-s2", "target": "mapping", "value": "\u77e5\u8bc6"}, {"source": "1-s2", "target": "Docker\u5bb9\u5668", "value": "\u77e5\u8bc6"}, {"source": "1-s2", "target": "planning", "value": "\u77e5\u8bc6"}, {"source": "1-s2", "target": "reliability", "value": "\u77e5\u8bc6"}, {"source": "1-s2", "target": "\u81ea\u52a8\u5316\u90e8\u7f72", "value": "\u77e5\u8bc6"}, {"source": "1-s2", "target": "cluster", "value": "\u77e5\u8bc6"}, {"source": "1-s2", "target": "speed", "value": "\u77e5\u8bc6"}, {"source": "1-s2", "target": "features", "value": "\u77e5\u8bc6"}, {"source": "1-s2", "target": "robustness", "value": "\u77e5\u8bc6"}, {"source": "1-s2", "target": "gradient", "value": "\u77e5\u8bc6"}, {"source": "1-s2", "target": "measurement", "value": "\u77e5\u8bc6"}, {"source": "1-s2", "target": "action classes", "value": "\u77e5\u8bc6"}, {"source": "1-s2", "target": "Temporal segmentation", "value": "\u77e5\u8bc6"}, {"source": "1-s2", "target": "Motion analysis", "value": "\u77e5\u8bc6"}, {"source": "1-s2", "target": "GestureRecognition", "value": "\u77e5\u8bc6"}, {"source": "1-s2", "target": "HMMs", "value": "\u77e5\u8bc6"}, {"source": "1-s2", "target": "dimensions", "value": "\u77e5\u8bc6"}, {"source": "1-s2", "target": "manifold", "value": "\u77e5\u8bc6"}, {"source": "1-s2", "target": "silhouettes", "value": "\u77e5\u8bc6"}, {"source": "1-s2", "target": "dynamic time warping", "value": "\u77e5\u8bc6"}, {"source": "1-s2", "target": "human movement", "value": "\u77e5\u8bc6"}, {"source": "1-s2", "target": "Pattern Recognition", "value": "\u77e5\u8bc6"}, {"source": "1-s2", "target": "PCA", "value": "\u77e5\u8bc6"}, {"source": "1-s2", "target": "action performance", "value": "\u77e5\u8bc6"}, {"source": "1-s2", "target": "key pose matching", "value": "\u77e5\u8bc6"}, {"source": "1-s2", "target": "Actions as space-time shapes", "value": "\u77e5\u8bc6"}, {"source": "1-s2", "target": "sequences", "value": "\u77e5\u8bc6"}, {"source": "1-s2", "target": "RANSAC", "value": "\u77e5\u8bc6"}, {"source": "1-s2", "target": "split-based representation", "value": "\u77e5\u8bc6"}, {"source": "1-s2", "target": "stability analysis", "value": "\u77e5\u8bc6"}, {"source": "1-s2", "target": "trackingearning appearance", "value": "\u77e5\u8bc6"}, {"source": "1-s2", "target": "European Conference on Computer Vision", "value": "\u77e5\u8bc6"}, {"source": "1-s2", "target": "Image Segmentation by Region-based Affinity Fields", "value": "\u77e5\u8bc6"}, {"source": "1-s2", "target": "HOF descriptors", "value": "\u77e5\u8bc6"}, {"source": "1-s2", "target": "periodicity", "value": "\u77e5\u8bc6"}, {"source": "1-s2", "target": "Isomap", "value": "\u77e5\u8bc6"}, {"source": "1-s2", "target": "flexibility", "value": "\u77e5\u8bc6"}, {"source": "1-s2", "target": "evaluation practice", "value": "\u77e5\u8bc6"}, {"source": "1-s2", "target": "Kubernetes", "value": "\u77e5\u8bc6"}, {"source": "1-s2", "target": "network", "value": "\u77e5\u8bc6"}, {"source": "1-s2", "target": "graphics", "value": "\u77e5\u8bc6"}, {"source": "1-s2", "target": "cloud computing platform", "value": "\u77e5\u8bc6"}, {"source": "1-s2", "target": "Python", "value": "\u77e5\u8bc6"}, {"source": "1-s2", "target": "model", "value": "\u77e5\u8bc6"}, {"source": "1-s2", "target": "PoseNet", "value": "\u77e5\u8bc6"}, {"source": "1-s2", "target": "\u4eba\u4f53\u59ff\u52bf\u4f30\u8ba1", "value": "\u77e5\u8bc6"}, {"source": "1-s2", "target": "Android", "value": "\u77e5\u8bc6"}, {"source": "1-s2", "target": "DNN", "value": "\u77e5\u8bc6"}, {"source": "1-s2", "target": "classification", "value": "\u77e5\u8bc6"}, {"source": "1-s2", "target": "planning", "value": "\u77e5\u8bc6"}, {"source": "1-s2", "target": "reliability", "value": "\u77e5\u8bc6"}, {"source": "1-s2", "target": "\u81ea\u52a8\u5316\u90e8\u7f72", "value": "\u77e5\u8bc6"}, {"source": "1-s2", "target": "speed", "value": "\u77e5\u8bc6"}, {"source": "1-s2", "target": "features", "value": "\u77e5\u8bc6"}, {"source": "1-s2", "target": "robustness", "value": "\u77e5\u8bc6"}, {"source": "1-s2", "target": "measurement", "value": "\u77e5\u8bc6"}, {"source": "1-s2", "target": "dimensions", "value": "\u77e5\u8bc6"}, {"source": "1-s2", "target": "dynamic time warping", "value": "\u77e5\u8bc6"}, {"source": "1-s2", "target": "human movement", "value": "\u77e5\u8bc6"}, {"source": "1-s2", "target": "tracking", "value": "\u77e5\u8bc6"}, {"source": "1-s2", "target": "background", "value": "\u77e5\u8bc6"}, {"source": "1-s2", "target": "correlation", "value": "\u77e5\u8bc6"}, {"source": "1-s2", "target": "pose estimation", "value": "\u77e5\u8bc6"}, {"source": "1-s2", "target": "movement", "value": "\u77e5\u8bc6"}, {"source": "1-s2", "target": "value of feedback in physical education", "value": "\u77e5\u8bc6"}, {"source": "1-s2", "target": "overall performance", "value": "\u77e5\u8bc6"}, {"source": "1-s2", "target": "\u52a8\u6001\u65f6\u95f4\u53d8\u6362", "value": "\u77e5\u8bc6"}, {"source": "1-s2", "target": "\u591a\u79cd\u7c7b\u578b\u7684\u953b\u70bc", "value": "\u77e5\u8bc6"}, {"source": "1-s2", "target": "Teleccommunications Research Institute", "value": "\u77e5\u8bc6"}, {"source": "1-s2", "target": "correctionsmotor variability", "value": "\u77e5\u8bc6"}, {"source": "1-s2", "target": "Camera-based(web camera)", "value": "\u77e5\u8bc6"}, {"source": "1-s2", "target": "Mediapipe", "value": "\u77e5\u8bc6"}, {"source": "1-s2", "target": "usability issues", "value": "\u77e5\u8bc6"}, {"source": "1-s2", "target": "comparisoGradient Boosting\u667a\u80fd yoga\u8bad\u7ec3\u7cfb\u7edf", "value": "\u77e5\u8bc6"}, {"source": "1-s2", "target": "reviewed applications of pose estimation in motionhit distance", "value": "\u77e5\u8bc6"}, {"source": "1-s2", "target": "alignment2D pose estimation", "value": "\u77e5\u8bc6"}, {"source": "1-s2", "target": "CrossFit", "value": "\u77e5\u8bc6"}, {"source": "1-s2", "target": "\u89d2\u5ea6", "value": "\u77e5\u8bc6"}, {"source": "1-s2", "target": "iPad Pro", "value": "\u77e5\u8bc6"}, {"source": "1-s2", "target": "Poseestimation", "value": "\u77e5\u8bc6"}, {"source": "1-s2", "target": "convolutional layers", "value": "\u77e5\u8bc6"}, {"source": "1-s2", "target": "audio-verbal", "value": "\u77e5\u8bc6"}, {"source": "1-s2", "target": "augmented feedback", "value": "\u77e5\u8bc6"}, {"source": "1-s2", "target": "\u89c4\u5212\u9002\u5e94\uff0cIntelliigent data analysis methods", "value": "\u77e5\u8bc6"}, {"source": "1-s2", "target": "motion evaluation", "value": "\u77e5\u8bc6"}, {"source": "1-s2", "target": "Relationship Encoding", "value": "\u77e5\u8bc6"}, {"source": "1-s2", "target": "patient Performance", "value": "\u77e5\u8bc6"}, {"source": "1-s2", "target": "ACM International Conference Proceeding Series", "value": "\u77e5\u8bc6"}, {"source": "2312", "target": "optimization", "value": "\u77e5\u8bc6"}, {"source": "2312", "target": "network", "value": "\u77e5\u8bc6"}, {"source": "2312", "target": "\u56fe\u50cf\u9884\u5904\u7406", "value": "\u77e5\u8bc6"}, {"source": "2312", "target": "TensorFlow", "value": "\u77e5\u8bc6"}, {"source": "2312", "target": "model", "value": "\u77e5\u8bc6"}, {"source": "2312", "target": "Recognition", "value": "\u77e5\u8bc6"}, {"source": "2312", "target": "Pattern Recognition", "value": "\u77e5\u8bc6"}, {"source": "2312", "target": "European Conference on Computer Vision", "value": "\u77e5\u8bc6"}, {"source": "2312", "target": "motion prediction", "value": "\u77e5\u8bc6"}, {"source": "2312", "target": "multiple instance learning", "value": "\u77e5\u8bc6"}, {"source": "2312", "target": "motions", "value": "\u77e5\u8bc6"}, {"source": "2312", "target": "dense human-carrier representation", "value": "\u77e5\u8bc6"}, {"source": "2312", "target": "deep featur", "value": "\u77e5\u8bc6"}, {"source": "2312", "target": "Forecasting", "value": "\u77e5\u8bc6"}, {"source": "2312", "target": "global frameionship", "value": "\u77e5\u8bc6"}, {"source": "2312", "target": "Spatio-temporal Transformer", "value": "\u77e5\u8bc6"}, {"source": "2312", "target": "4D\u8fd0\u52a8\u53d8\u6362", "value": "\u77e5\u8bc6"}, {"source": "2312", "target": "Advn ces in neural informa", "value": "\u77e5\u8bc6"}, {"source": "2312", "target": "Desire", "value": "\u77e5\u8bc6"}, {"source": "2312", "target": "\u7ebf\u6027\u7f16\u7801", "value": "\u77e5\u8bc6"}, {"source": "2312", "target": "Learned Local Frame", "value": "\u77e5\u8bc6"}, {"source": "2312", "target": "Graph\u795e\u7ecf\u7f51\u7edc", "value": "\u77e5\u8bc6"}, {"source": "2312", "target": "CANonicalization", "value": "\u77e5\u8bc6"}, {"source": "2312", "target": "Method FID", "value": "\u77e5\u8bc6"}, {"source": "2312", "target": "Classification Accuracy", "value": "\u77e5\u8bc6"}, {"source": "2312", "target": "encoderan-machine interaction", "value": "\u77e5\u8bc6"}, {"source": "2312", "target": "Geometric Vector Perceptrons", "value": "\u77e5\u8bc6"}, {"source": "2312", "target": "6D_transform", "value": "\u77e5\u8bc6"}, {"source": "2312", "target": "EquivLayer", "value": "\u77e5\u8bc6"}, {"source": "2312", "target": "Human-Whole-Body-Motion-Reaction", "value": "\u77e5\u8bc6"}, {"source": "2312", "target": "canonical", "value": "\u77e5\u8bc6"}, {"source": "2312", "target": "Handshake", "value": "\u77e5\u8bc6"}, {"source": "2312", "target": "Motion Analysis", "value": "\u77e5\u8bc6"}, {"source": "2312", "target": "Social affordance forecasting scheme", "value": "\u77e5\u8bc6"}, {"source": "2312", "target": "Transformer", "value": "\u77e5\u8bc6"}, {"source": "2312", "target": "human actor's motion coding", "value": "\u77e5\u8bc6"}, {"source": "2312", "target": "Motion", "value": "\u77e5\u8bc6"}, {"source": "2312", "target": "Action-conditioned", "value": "\u77e5\u8bc6"}, {"source": "2312", "target": "HUMAN MOTION", "value": "\u77e5\u8bc6"}, {"source": "2312", "target": "human actor motionsdataset", "value": "\u77e5\u8bc6"}, {"source": "2312", "target": "4D backbone", "value": "\u77e5\u8bc6"}, {"source": "2312", "target": "InterFormer", "value": "\u77e5\u8bc6"}, {"source": "2312", "target": "Temporal attention", "value": "\u77e5\u8bc6"}, {"source": "2312", "target": "Conditioned gen", "value": "\u77e5\u8bc6"}, {"source": "2312", "target": "agents", "value": "\u77e5\u8bc6"}, {"source": "2312", "target": "D-grasp", "value": "\u77e5\u8bc6"}, {"source": "2312", "target": "User Preferencence", "value": "\u77e5\u8bc6"}, {"source": "2312", "target": "humanoid reactor", "value": "\u77e5\u8bc6"}, {"source": "2312", "target": "whole-body motion capture", "value": "\u77e5\u8bc6"}, {"source": "2312", "target": "Ai choreographer", "value": "\u77e5\u8bc6"}, {"source": "2411", "target": "operator", "value": "\u77e5\u8bc6"}, {"source": "2411", "target": "optimization", "value": "\u77e5\u8bc6"}, {"source": "2411", "target": "\u673a\u5668\u5b66\u4e60\u7b97\u6cd5", "value": "\u77e5\u8bc6"}, {"source": "2411", "target": "model", "value": "\u77e5\u8bc6"}, {"source": "2411", "target": "kernel", "value": "\u77e5\u8bc6"}, {"source": "2411", "target": "modules", "value": "\u77e5\u8bc6"}, {"source": "2411", "target": "human motion", "value": "\u77e5\u8bc6"}, {"source": "2411", "target": "centroid", "value": "\u77e5\u8bc6"}, {"source": "2411", "target": "robotics", "value": "\u77e5\u8bc6"}, {"source": "2411", "target": "information", "value": "\u77e5\u8bc6"}, {"source": "2411", "target": "Fourier\u53d8\u6362", "value": "\u77e5\u8bc6"}, {"source": "2411", "target": "movements", "value": "\u77e5\u8bc6"}, {"source": "2411", "target": "joint locations", "value": "\u77e5\u8bc6"}, {"source": "2411", "target": "Computer Vis", "value": "\u77e5\u8bc6"}, {"source": "2411", "target": "Machine Learning", "value": "\u77e5\u8bc6"}, {"source": "2411", "target": "video analysis", "value": "\u77e5\u8bc6"}, {"source": "2411", "target": "2D keypoints", "value": "\u77e5\u8bc6"}, {"source": "2411", "target": "Euclidean distance", "value": "\u77e5\u8bc6"}, {"source": "2411", "target": "evaluation", "value": "\u77e5\u8bc6"}, {"source": "2411", "target": "Transformer", "value": "\u77e5\u8bc6"}, {"source": "2411", "target": "forecasting", "value": "\u77e5\u8bc6"}, {"source": "2411", "target": "MSE", "value": "\u77e5\u8bc6"}, {"source": "2411", "target": "transformer", "value": "\u77e5\u8bc6"}, {"source": "2411", "target": "singles tennis games", "value": "\u77e5\u8bc6"}, {"source": "2411", "target": "recognizing", "value": "\u77e5\u8bc6"}, {"source": "2411", "target": "Mean Euclidean Distance Error", "value": "\u77e5\u8bc6"}, {"source": "2411", "target": "Bahdanau", "value": "\u77e5\u8bc6"}, {"source": "2411", "target": "IceCV", "value": "\u77e5\u8bc6"}, {"source": "2411", "target": "\u5e8f\u5217\u5bf9\u5e8f\u5217\u95ee\u9898\uff0ccentroid", "value": "\u77e5\u8bc6"}, {"source": "2411", "target": "Body Pose", "value": "\u77e5\u8bc6"}, {"source": "2411", "target": "time vec", "value": "\u77e5\u8bc6"}, {"source": "2411", "target": "orientation", "value": "\u77e5\u8bc6"}, {"source": "2411", "target": "Trajectory", "value": "\u77e5\u8bc6"}, {"source": "2411", "target": "Tennis Player Trajectory", "value": "\u77e5\u8bc6"}, {"source": "2411", "target": "2D\u56fe\u50cf\u5904\u7406", "value": "\u77e5\u8bc6"}, {"source": "2411", "target": "normalization layer", "value": "\u77e5\u8bc6"}, {"source": "2411", "target": "GUI\u811a\u672c\u56fe\u50cf\u6807\u8bb0", "value": "\u77e5\u8bc6"}, {"source": "2411", "target": "Generative Pre-Training", "value": "\u77e5\u8bc6"}, {"source": "2411", "target": "\u70ed\u56fe\uff0cBERT\uff0c\u5f02\u5e38\u4eba\u7fa4\u884c\u4e3a\u68c0\u6d4b\u963f\u59c6\u65af\u7279\u4e39\uff0c\u6bcf\u79d2\u6846\u67b6\u6570\uff0c\u73a9\u5bb6\u51e0\u4f55\u5f62\u72b6\uff0c\u5e8f\u5217\u9884\u6d4b\uff0c\u6a21\u578b\u9884\u6d4b\uff0c\u4f24\u5bb3\u9632\u6cbb\uff0c\u6ce8\u610f\u673a\u5236", "value": "\u77e5\u8bc6"}, {"source": "2411", "target": "sensor information", "value": "\u77e5\u8bc6"}, {"source": "2411", "target": "deep transformer", "value": "\u77e5\u8bc6"}, {"source": "2411", "target": "Springer handbook of robotics", "value": "\u77e5\u8bc6"}, {"source": "2411", "target": "body joint data model", "value": "\u77e5\u8bc6"}, {"source": "2411", "target": "analysisgan", "value": "\u77e5\u8bc6"}, {"source": "2411", "target": "Learning", "value": "\u77e5\u8bc6"}, {"source": "2411", "target": "TrackNet\u6a21\u578b", "value": "\u77e5\u8bc6"}, {"source": "2411", "target": "NBA", "value": "\u77e5\u8bc6"}, {"source": "2411", "target": "broadcasting", "value": "\u77e5\u8bc6"}, {"source": "2411", "target": "ball detection", "value": "\u77e5\u8bc6"}, {"source": "2411", "target": "Deep learningassociation metric", "value": "\u77e5\u8bc6"}, {"source": "3D Ball Localization From A Single Calibrated Image_zh", "target": "TensorFlow", "value": "\u77e5\u8bc6"}, {"source": "3D Ball Localization From A Single Calibrated Image_zh", "target": "spatiotemporal approach", "value": "\u77e5\u8bc6"}, {"source": "3D Ball Localization From A Single Calibrated Image_zh", "target": "survey", "value": "\u77e5\u8bc6"}, {"source": "3D Ball Localization From A Single Calibrated Image_zh", "target": "Artificial Intelligence", "value": "\u77e5\u8bc6"}, {"source": "3D Ball Localization From A Single Calibrated Image_zh", "target": "\u9ad8\u8d28\u91cf\u7403\u4f53\u7ef4\u5b9a\u4f4d", "value": "\u77e5\u8bc6"}, {"source": "3D Ball Localization From A Single Calibrated Image_zh", "target": "\u6807\u51c6\u504f\u5dee", "value": "\u77e5\u8bc6"}, {"source": "3D Ball Localization From A Single Calibrated Image_zh", "target": "calibrated\u6444\u50cf\u5934\uff0cProjection\u65b9\u6cd5\uff0c\u03b1\uff08\u6743\u503c\uff09\uff0c\u4e09\u7ef4\u5b9a", "value": "\u77e5\u8bc6"}, {"source": "3D Ball Localization From A Single Calibrated Image_zh", "target": "\u970d\u592b\u5706\u53d8\u6362", "value": "\u77e5\u8bc6"}, {"source": "3D Ball Localization From A Single Calibrated Image_zh", "target": "BallSeg-top1", "value": "\u77e5\u8bc6"}, {"source": "3D Ball Localization From A Single Calibrated Image_zh", "target": "3D trajectory", "value": "\u77e5\u8bc6"}, {"source": "3D Ball Localization From A Single Calibrated Image_zh", "target": "\u8bc6\u522b\u5f39\u9053\u8f68\u8ff9", "value": "\u77e5\u8bc6"}, {"source": "3D Ball Localization From A Single Calibrated Image_zh", "target": "\u76f8\u673a\u77e9\u9635K", "value": "\u77e5\u8bc6"}, {"source": "3D Ball Localization From A Single Calibrated Image_zh", "target": "DeepSport testset", "value": "\u77e5\u8bc6"}, {"source": "3D Ball Localization From A Single Calibrated Image_zh", "target": "Hohl\u5706\u53d8\u6362\uff0cICNet\uff0c\u56fe\u50cf\u68af\u5ea6\uff0c\u5706\u5f62\u6ee4\u6ce2\u5668\uff0c\u81ea\u9002\u5e94\u9608\u503c\u6cd5\uff0c\u5377\u79ef\u795e\u7ecf\u7f51\u7edc", "value": "\u77e5\u8bc6"}, {"source": "3D Ball Localization From A Single Calibrated Image_zh", "target": "Virtual replay", "value": "\u77e5\u8bc6"}, {"source": "3D Ball Localization From A Single Calibrated Image_zh", "target": "LectureNotesinComputerScience", "value": "\u77e5\u8bc6"}, {"source": "3D Ball Localization From A Single Calibrated Image_zh", "target": "Hoffmann\u5706\u53d8\u6362", "value": "\u77e5\u8bc6"}, {"source": "3D Ball Localization From A Single Calibrated Image_zh", "target": "\u5355\u76f8\u673a\u8ffd\u8e2a", "value": "\u77e5\u8bc6"}, {"source": "3D Ball Localization From A Single Calibrated Image_zh", "target": "DIP", "value": "\u77e5\u8bc6"}, {"source": "3D Ball Localization From A Single Calibrated Image_zh", "target": "BallSeg", "value": "\u77e5\u8bc6"}, {"source": "3D Ball Localization From A Single Calibrated Image_zh", "target": "Ball tracking", "value": "\u77e5\u8bc6"}, {"source": "3D Ball Localization From A Single Calibrated Image_zh", "target": "Diederik P.Kingma", "value": "\u77e5\u8bc6"}, {"source": "3D Ball Localization From A Single Calibrated Image_zh", "target": "\u7403\u4f53\u5b58\u50a8CNN\u65b9\u6cd5", "value": "\u77e5\u8bc6"}, {"source": "3D Ball Localization From A Single Calibrated Image_zh", "target": "\u76d1\u89c6\u5b66\u4e60", "value": "\u77e5\u8bc6"}, {"source": "3D Ball Localization From A Single Calibrated Image_zh", "target": "Fonds de la Recherche Scientifique - FNRS", "value": "\u77e5\u8bc6"}, {"source": "3D Ball Localization From A Single Calibrated Image_zh", "target": "Gradient-based learning\u68c0\u6d4b", "value": "\u77e5\u8bc6"}, {"source": "3D Ball Localization From A Single Calibrated Image_zh", "target": "\u7cbe\u5ea6\u8bc4\u4f30\u96c6", "value": "\u77e5\u8bc6"}, {"source": "3D Ball Localization From A Single Calibrated Image_zh", "target": "Basket-APIDIS", "value": "\u77e5\u8bc6"}, {"source": "3D Ball Localization From A Single Calibrated Image_zh", "target": "\u6e05\u6670\u53ef\u89c1\u6027", "value": "\u77e5\u8bc6"}, {"source": "3D Ball Localization From A Single Calibrated Image_zh", "target": "\u5143\u53c2\u6570\uff08\u03b4\uff09y\u4f30\u8ba1", "value": "\u77e5\u8bc6"}, {"source": "3D Ball Localization From A Single Calibrated Image_zh", "target": "annotation", "value": "\u77e5\u8bc6"}, {"source": "3D Ball Localization From A Single Calibrated Image_zh", "target": "\u8bef\u62a5\u7387", "value": "\u77e5\u8bc6"}, {"source": "3D Ball Localization From A Single Calibrated Image_zh", "target": "\u7ec6\u80de\u5206\u5272", "value": "\u77e5\u8bc6"}, {"source": "3D Ball Localization From A Single Calibrated Image_zh", "target": "Dock\u5f39\u9053\u8f68\u8ff9", "value": "\u77e5\u8bc6"}, {"source": "3D Ball Localization From A Single Calibrated Image_zh", "target": "PAMI-8(6)", "value": "\u77e5\u8bc6"}, {"source": "3D Ball Localization From A Single Calibrated Image_zh", "target": "physically constrained interaction", "value": "\u77e5\u8bc6"}, {"source": "3D Ball Localization From A Single Calibrated Image_zh", "target": "Glorot initializer", "value": "\u77e5\u8bc6"}, {"source": "3D Ball Localization From A Single Calibrated Image_zh", "target": "Dis-tributed video acquisition", "value": "\u77e5\u8bc6"}, {"source": "3D Ball Localization From A Single Calibrated Image_zh", "target": "Graph-based filtering of ballistictrajectory", "value": "\u77e5\u8bc6"}, {"source": "3D Ball Localization From A Single Calibrated Image_zh", "target": "\u89c6\u9891\u6280\u672f", "value": "\u77e5\u8bc6"}, {"source": "3D Ball Localization From A Single Calibrated Image_zh", "target": "APIDIS\u6570\u636e\u96c6", "value": "\u77e5\u8bc6"}, {"source": "3D Ball Localization From A Single Calibrated Image_zh", "target": "\u7403\u8f68\u8ff9\u4f30\u8ba1", "value": "\u77e5\u8bc6"}, {"source": "3D Ball Localization From A Single Calibrated Image_zh", "target": "3D\u7403\u4f53\u4f4d\u7f6e\u6807\u6ce8", "value": "\u77e5\u8bc6"}, {"source": "3D Ball Localization From A Single Calibrated Image_zh", "target": "Huber\u635f\u5931", "value": "\u77e5\u8bc6"}, {"source": "3D Ball Localization From A Single Calibrated Image_zh", "target": "\u5206\u6790\u4f53\u80b2", "value": "\u77e5\u8bc6"}, {"source": "3D Ball Localization From A Single Calibrated Image_zh", "target": "ball trajectory tracking", "value": "\u77e5\u8bc6"}, {"source": "3D Ball Localization From A Single Calibrated Image_zh", "target": "Andrew Zisserman", "value": "\u77e5\u8bc6"}, {"source": "3D Ball Localization From A Single Calibrated Image_zh", "target": "LdJournal of Real-Time Image Processing", "value": "\u77e5\u8bc6"}, {"source": "3D Ball Localization From A Single Calibrated Image_zh", "target": "\u4e2d\u5fc3+\u6295\u5f71\u65b9\u6cd5", "value": "\u77e5\u8bc6"}, {"source": "3D Ball Localization From A Single Calibrated Image_zh", "target": "ICNet", "value": "\u77e5\u8bc6"}, {"source": "3D_Convolutional_Neural_Networks_for_Human_Action_Recognition", "target": "classifier", "value": "\u77e5\u8bc6"}, {"source": "3D_Convolutional_Neural_Networks_for_Human_Action_Recognition", "target": "DNN", "value": "\u77e5\u8bc6"}, {"source": "3D_Convolutional_Neural_Networks_for_Human_Action_Recognition", "target": "kernel", "value": "\u77e5\u8bc6"}, {"source": "3D_Convolutional_Neural_Networks_for_Human_Action_Recognition", "target": "Kernel", "value": "\u77e5\u8bc6"}, {"source": "3D_Convolutional_Neural_Networks_for_Human_Action_Recognition", "target": "gradient", "value": "\u77e5\u8bc6"}, {"source": "3D_Convolutional_Neural_Networks_for_Human_Action_Recognition", "target": "human action recognition", "value": "\u77e5\u8bc6"}, {"source": "3D_Convolutional_Neural_Networks_for_Human_Action_Recognition", "target": "concatenation", "value": "\u77e5\u8bc6"}, {"source": "3D_Convolutional_Neural_Networks_for_Human_Action_Recognition", "target": "motion information", "value": "\u77e5\u8bc6"}, {"source": "3D_Convolutional_Neural_Networks_for_Human_Action_Recognition", "target": "unsupervised learning", "value": "\u77e5\u8bc6"}, {"source": "3D_Convolutional_Neural_Networks_for_Human_Action_Recognition", "target": "tracking", "value": "\u77e5\u8bc6"}, {"source": "3D_Convolutional_Neural_Networks_for_Human_Action_Recognition", "target": "PAMI", "value": "\u77e5\u8bc6"}, {"source": "3D_Convolutional_Neural_Networks_for_Human_Action_Recognition", "target": "human action categories", "value": "\u77e5\u8bc6"}, {"source": "3D_Convolutional_Neural_Networks_for_Human_Action_Recognition", "target": "Gabor filters", "value": "\u77e5\u8bc6"}, {"source": "3D_Convolutional_Neural_Networks_for_Human_Action_Recognition", "target": "detector", "value": "\u77e5\u8bc6"}, {"source": "3D_Convolutional_Neural_Networks_for_Human_Action_Recognition", "target": "scheme", "value": "\u77e5\u8bc6"}, {"source": "3D_Convolutional_Neural_Networks_for_Human_Action_Recognition", "target": "bounding box", "value": "\u77e5\u8bc6"}, {"source": "3D_Convolutional_Neural_Networks_for_Human_Action_Recognition", "target": "predictor", "value": "\u77e5\u8bc6"}, {"source": "3D_Convolutional_Neural_Networks_for_Human_Action_Recognition", "target": "Evaluation", "value": "\u77e5\u8bc6"}, {"source": "3D_Convolutional_Neural_Networks_for_Human_Action_Recognition", "target": "multimodalp", "value": "\u77e5\u8bc6"}, {"source": "3D_Convolutional_Neural_Networks_for_Human_Action_Recognition", "target": "Brain-Computer Interfaces", "value": "\u77e5\u8bc6"}, {"source": "3D_Convolutional_Neural_Networks_for_Human_Action_Recognition", "target": "Sparse Features with Limited Receptive Fields", "value": "\u77e5\u8bc6"}, {"source": "3D_Convolutional_Neural_Networks_for_Human_Action_Recognition", "target": "L. Bottou", "value": "\u77e5\u8bc6"}, {"source": "3D_Convolutional_Neural_Networks_for_Human_Action_Recognition", "target": "CNN for action recognition", "value": "\u77e5\u8bc6"}, {"source": "3D_Convolutional_Neural_Networks_for_Human_Action_Recognition", "target": "video\u901a\u4fe1", "value": "\u77e5\u8bc6"}, {"source": "3D_Convolutional_Neural_Networks_for_Human_Action_Recognition", "target": "Spatial dimensionson", "value": "\u77e5\u8bc6"}, {"source": "3D_Convolutional_Neural_Networks_for_Human_Action_Recognition", "target": "IEEE ConfComputer Vision", "value": "\u77e5\u8bc6"}, {"source": "3D_Convolutional_Neural_Networks_for_Human_Action_Recognition", "target": "Action Recognitionting invariance", "value": "\u77e5\u8bc6"}, {"source": "3D_Convolutional_Neural_Networks_for_Human_Action_Recognition", "target": "Unsupervised Learning", "value": "\u77e5\u8bc6"}, {"source": "3D_Convolutional_Neural_Networks_for_Human_Action_Recognition", "target": "\u667a\u80fd\u591a\u5a92\u4f53\u5185\u5bb9\u5206\u6790", "value": "\u77e5\u8bc6"}, {"source": "3D_Convolutional_Neural_Networks_for_Human_Action_Recognition", "target": "Carnegie Mellon University (CMU)", "value": "\u77e5\u8bc6"}, {"source": "3D_Convolutional_Neural_Networks_for_Human_Action_Recognition", "target": "NEC\u7684\u4eba\u884c\u4e3a\u8bc6\u522b\u7cfb\u7edf", "value": "\u77e5\u8bc6"}, {"source": "3D_Convolutional_Neural_Networks_for_Human_Action_Recognition", "target": "ME degree", "value": "\u77e5\u8bc6"}, {"source": "3D_Convolutional_Neural_Networks_for_Human_Action_Recognition", "target": "bioinformatics", "value": "\u77e5\u8bc6"}, {"source": "3D_Convolutional_Neural_Networks_for_Human_Action_Recognition", "target": "CellToEar", "value": "\u77e5\u8bc6"}, {"source": "3D_Convolutional_Neural_Networks_for_Human_Action_Recognition", "target": "\u9ad8\u7ea7\u8fd0\u52a8\u7279\u5f81", "value": "\u77e5\u8bc6"}, {"source": "3D_Convolutional_Neural_Networks_for_Human_Action_Recognition", "target": "A Fast Learning Algorithm for Deep Belief Nets", "value": "\u77e5\u8bc6"}, {"source": "3D_Convolutional_Neural_Networks_for_Human_Action_Recognition", "target": "unsupervised learning of human action", "value": "\u77e5\u8bc6"}, {"source": "3D_Convolutional_Neural_Networks_for_Human_Action_Recognition", "target": "3D CNN architectures", "value": "\u77e5\u8bc6"}, {"source": "3D_Convolutional_Neural_Networks_for_Human_Action_Recognition", "target": "spatiotemporal feature", "value": "\u77e5\u8bc6"}, {"source": "3D_Convolutional_Neural_Networks_for_Human_Action_Recognition", "target": "proposal-based 3D\u5377\u79ef", "value": "\u77e5\u8bc6"}, {"source": "3D_Convolutional_Neural_Networks_for_Human_Action_Recognition", "target": "unsupervisedfeaturelearning", "value": "\u77e5\u8bc6"}, {"source": "3D_Convolutional_Neural_Networks_for_Human_Action_Recognition", "target": "recall", "value": "\u77e5\u8bc6"}, {"source": "3D_Convolutional_Neural_Networks_for_Human_Action_Recognition", "target": "\u8f85\u52a9\u5355\u5143Local Spatio-Temporal Features", "value": "\u77e5\u8bc6"}, {"source": "3D_Convolutional_Neural_Networks_for_Human_Action_Recognition", "target": "Samples Action", "value": "\u77e5\u8bc6"}, {"source": "3D_Convolutional_Neural_Networks_for_Human_Action_Recognition", "target": "Learning Hierarchical Invariant Spatio-Temporal Feature3D\u5377\u79ef", "value": "\u77e5\u8bc6"}, {"source": "3D_Convolutional_Neural_Networks_for_Human_Action_Recognition", "target": "hyperbolic tasigmoid\u51fd\u6570", "value": "\u77e5\u8bc6"}, {"source": "3D_Convolutional_Neural_Networks_for_Human_Action_Recognition", "target": "visual object recognition", "value": "\u77e5\u8bc6"}, {"source": "3D_Convolutional_Neural_Networks_for_Human_Action_Recognition", "target": "CNN model", "value": "\u77e5\u8bc6"}, {"source": "3D_Convolutional_Neural_Networks_for_Human_Action_Recognition", "target": "Outstaconvolutions", "value": "\u77e5\u8bc6"}, {"source": "3D_Convolutional_Neural_Networks_for_Human_Action_Recognition", "target": "\u591a\u91cd\u7279\u5f81\u62bd\u53d6", "value": "\u77e5\u8bc6"}, {"source": "923-Article Text-1720-2-10-20220519", "target": "motion recognition", "value": "\u77e5\u8bc6"}, {"source": "923-Article Text-1720-2-10-20220519", "target": "flexibility", "value": "\u77e5\u8bc6"}, {"source": "923-Article Text-1720-2-10-20220519", "target": "feature extraction", "value": "\u77e5\u8bc6"}, {"source": "923-Article Text-1720-2-10-20220519", "target": "movements", "value": "\u77e5\u8bc6"}, {"source": "923-Article Text-1720-2-10-20220519", "target": "pose estimation", "value": "\u77e5\u8bc6"}, {"source": "923-Article Text-1720-2-10-20220519", "target": "Mobilenetv2", "value": "\u77e5\u8bc6"}, {"source": "923-Article Text-1720-2-10-20220519", "target": "\u4eba\u4f53\u59ff\u52bf\u4f30\u7b97", "value": "\u77e5\u8bc6"}, {"source": "923-Article Text-1720-2-10-20220519", "target": "Human Pose Estimation", "value": "\u77e5\u8bc6"}, {"source": "923-Article Text-1720-2-10-20220519", "target": "human-computer interaction", "value": "\u77e5\u8bc6"}, {"source": "923-Article Text-1720-2-10-20220519", "target": "estimation", "value": "\u77e5\u8bc6"}, {"source": "923-Article Text-1720-2-10-20220519", "target": "pose\u4f30\u8ba1", "value": "\u77e5\u8bc6"}, {"source": "923-Article Text-1720-2-10-20220519", "target": "motion capture", "value": "\u77e5\u8bc6"}, {"source": "923-Article Text-1720-2-10-20220519", "target": "Object Recognition", "value": "\u77e5\u8bc6"}, {"source": "923-Article Text-1720-2-10-20220519", "target": "channels", "value": "\u77e5\u8bc6"}, {"source": "923-Article Text-1720-2-10-20220519", "target": "nodal point attribution", "value": "\u77e5\u8bc6"}, {"source": "923-Article Text-1720-2-10-20220519", "target": "reasonnable way", "value": "\u77e5\u8bc6"}, {"source": "923-Article Text-1720-2-10-20220519", "target": "perceptual field", "value": "\u77e5\u8bc6"}, {"source": "923-Article Text-1720-2-10-20220519", "target": "\u7ec6\u80de\u751f\u7269\u529b\u5b66", "value": "\u77e5\u8bc6"}, {"source": "923-Article Text-1720-2-10-20220519", "target": "Paf heat map", "value": "\u77e5\u8bc6"}, {"source": "923-Article Text-1720-2-10-20220519", "target": "enthusiasts", "value": "\u77e5\u8bc6"}, {"source": "923-Article Text-1720-2-10-20220519", "target": "Network learning", "value": "\u77e5\u8bc6"}, {"source": "923-Article Text-1720-2-10-20220519", "target": "bottom-up detection", "value": "\u77e5\u8bc6"}, {"source": "923-Article Text-1720-2-10-20220519", "target": "PointwiseConvolution", "value": "\u77e5\u8bc6"}, {"source": "923-Article Text-1720-2-10-20220519", "target": "Network Optimizing", "value": "\u77e5\u8bc6"}, {"source": "923-Article Text-1720-2-10-20220519", "target": "human pose estimationion", "value": "\u77e5\u8bc6"}, {"source": "923-Article Text-1720-2-10-20220519", "target": "Keypoint Confidence Mapints", "value": "\u77e5\u8bc6"}, {"source": "923-Article Text-1720-2-10-20220519", "target": "joint embedding", "value": "\u77e5\u8bc6"}, {"source": "923-Article Text-1720-2-10-20220519", "target": "heat map", "value": "\u77e5\u8bc6"}, {"source": "923-Article Text-1720-2-10-20220519", "target": "badminton", "value": "\u77e5\u8bc6"}, {"source": "923-Article Text-1720-2-10-20220519", "target": "figure", "value": "\u77e5\u8bc6"}, {"source": "923-Article Text-1720-2-10-20220519", "target": "C-feature maps", "value": "\u77e5\u8bc6"}, {"source": "923-Article Text-1720-2-10-20220519", "target": "Python 3.8", "value": "\u77e5\u8bc6"}, {"source": "923-Article Text-1720-2-10-20220519", "target": "part affinity fields", "value": "\u77e5\u8bc6"}, {"source": "923-Article Text-1720-2-10-20220519", "target": "Depthwise Separable Convolution", "value": "\u77e5\u8bc6"}, {"source": "923-Article Text-1720-2-10-20220519", "target": "XC(3)", "value": "\u77e5\u8bc6"}, {"source": "923-Article Text-1720-2-10-20220519", "target": "multiscale feature fusion", "value": "\u77e5\u8bc6"}, {"source": "923-Article Text-1720-2-10-20220519", "target": "Polarized Self-Attention", "value": "\u77e5\u8bc6"}, {"source": "923-Article Text-1720-2-10-20220519", "target": "OpenPose\u6a21\u578b", "value": "\u77e5\u8bc6"}, {"source": "923-Article Text-1720-2-10-20220519", "target": "Mobilenets", "value": "\u77e5\u8bc6"}, {"source": "923-Article Text-1720-2-10-20220519", "target": "Polarized Self-Attention Module", "value": "\u77e5\u8bc6"}, {"source": "923-Article Text-1720-2-10-20220519", "target": "convolutional kernel", "value": "\u77e5\u8bc6"}, {"source": "923-Article Text-1720-2-10-20220519", "target": "regular convolution", "value": "\u77e5\u8bc6"}, {"source": "923-Article Text-1720-2-10-20220519", "target": "Conv DW", "value": "\u77e5\u8bc6"}, {"source": "923-Article Text-1720-2-10-20220519", "target": "VConvolution", "value": "\u77e5\u8bc6"}, {"source": "923-Article Text-1720-2-10-20220519", "target": "channel-by-channel convolution", "value": "\u77e5\u8bc6"}, {"source": "923-Article Text-1720-2-10-20220519", "target": "Detectionman pose estimation", "value": "\u77e5\u8bc6"}, {"source": "923-Article Text-1720-2-10-20220519", "target": "\u6570\u636ePose Estimationmotion", "value": "\u77e5\u8bc6"}, {"source": "923-Article Text-1720-2-10-20220519", "target": "\u4eba\u4f53\u5173\u952e\u70b9\u68c0\u6d4b", "value": "\u77e5\u8bc6"}, {"source": "923-Article Text-1720-2-10-20220519", "target": "\u5e8f\u5217\u578b\u591a\u5c3a\u5ea6\u7279\u5f81\u878d\u5408", "value": "\u77e5\u8bc6"}, {"source": "923-Article Text-1720-2-10-20220519", "target": "image screening", "value": "\u77e5\u8bc6"}, {"source": "A survey on deep learning-based real-time crowd anomaly detection", "target": "\u673a\u5668\u5b66\u4e60\u7b97\u6cd5", "value": "\u77e5\u8bc6"}, {"source": "A survey on deep learning-based real-time crowd anomaly detection", "target": "application", "value": "\u77e5\u8bc6"}, {"source": "A survey on deep learning-based real-time crowd anomaly detection", "target": "\u7269\u8054\u7f51", "value": "\u77e5\u8bc6"}, {"source": "A survey on deep learning-based real-time crowd anomaly detection", "target": "IoT", "value": "\u77e5\u8bc6"}, {"source": "A survey on deep learning-based real-time crowd anomaly detection", "target": "DNN", "value": "\u77e5\u8bc6"}, {"source": "A survey on deep learning-based real-time crowd anomaly detection", "target": "classification", "value": "\u77e5\u8bc6"}, {"source": "A survey on deep learning-based real-time crowd anomaly detection", "target": "cluster", "value": "\u77e5\u8bc6"}, {"source": "A survey on deep learning-based real-time crowd anomaly detection", "target": "SVC", "value": "\u77e5\u8bc6"}, {"source": "A survey on deep learning-based real-time crowd anomaly detection", "target": "features", "value": "\u77e5\u8bc6"}, {"source": "A survey on deep learning-based real-time crowd anomaly detection", "target": "human motion", "value": "\u77e5\u8bc6"}, {"source": "A survey on deep learning-based real-time crowd anomaly detection", "target": "dimensions", "value": "\u77e5\u8bc6"}, {"source": "A survey on deep learning-based real-time crowd anomaly detection", "target": "motion detection", "value": "\u77e5\u8bc6"}, {"source": "A survey on deep learning-based real-time crowd anomaly detection", "target": "surveillance", "value": "\u77e5\u8bc6"}, {"source": "A survey on deep learning-based real-time crowd anomaly detection", "target": "local descriptor", "value": "\u77e5\u8bc6"}, {"source": "A survey on deep learning-based real-time crowd anomaly detection", "target": "optical\u6d41", "value": "\u77e5\u8bc6"}, {"source": "A survey on deep learning-based real-time crowd anomaly detection", "target": "datasets", "value": "\u77e5\u8bc6"}, {"source": "A survey on deep learning-based real-time crowd anomaly detection", "target": "video analysis", "value": "\u77e5\u8bc6"}, {"source": "A survey on deep learning-based real-time crowd anomaly detection", "target": "networks", "value": "\u77e5\u8bc6"}, {"source": "A survey on deep learning-based real-time crowd anomaly detection", "target": "visual analytics", "value": "\u77e5\u8bc6"}, {"source": "A survey on deep learning-based real-time crowd anomaly detection", "target": "video\u5e8f\u5217", "value": "\u77e5\u8bc6"}, {"source": "A survey on deep learning-based real-time crowd anomaly detection", "target": "uncertainty", "value": "\u77e5\u8bc6"}, {"source": "A survey on deep learning-based real-time crowd anomaly detection", "target": "deep learning", "value": "\u77e5\u8bc6"}, {"source": "A survey on deep learning-based real-time crowd anomaly detection", "target": "Kalman filter", "value": "\u77e5\u8bc6"}, {"source": "A survey on deep learning-based real-time crowd anomaly detection", "target": "\u56fe\u50cf\u5206\u6790", "value": "\u77e5\u8bc6"}, {"source": "A survey on deep learning-based real-time crowd anomaly detection", "target": "convolutional neural network", "value": "\u77e5\u8bc6"}, {"source": "A survey on deep learning-based real-time crowd anomaly detection", "target": "hybrid model", "value": "\u77e5\u8bc6"}, {"source": "A survey on deep learning-based real-time crowd anomaly detection", "target": "\u533a\u57df\u6df1\u5ea6\u5377\u79ef\u795e\u7ecf\u7f51\u7edc", "value": "\u77e5\u8bc6"}, {"source": "A survey on deep learning-based real-time crowd anomaly detection", "target": "uncertainty analysis", "value": "\u77e5\u8bc6"}, {"source": "A survey on deep learning-based real-time crowd anomaly detection", "target": "Pedestrian behavior understanding", "value": "\u77e5\u8bc6"}, {"source": "A survey on deep learning-based real-time crowd anomaly detection", "target": "fuzzy cognitive deep learning framework", "value": "\u77e5\u8bc6"}, {"source": "A survey on deep learning-based real-time crowd anomaly detection", "target": "visual feature extraction", "value": "\u77e5\u8bc6"}, {"source": "A survey on deep learning-based real-time crowd anomaly detection", "target": "\u4eba\u7c7b\u8fd0\u52a8\u68c0\u6d4b", "value": "\u77e5\u8bc6"}, {"source": "A survey on deep learning-based real-time crowd anomaly detection", "target": "mixed\u51b3\u7b56\u7cfb\u7edf", "value": "\u77e5\u8bc6"}, {"source": "A survey on deep learning-based real-time crowd anomaly detection", "target": "optimal responses", "value": "\u77e5\u8bc6"}, {"source": "A survey on deep learning-based real-time crowd anomaly detection", "target": "adjusted procedures", "value": "\u77e5\u8bc6"}, {"source": "A survey on deep learning-based real-time crowd anomaly detection", "target": "\u96c6\u4f53", "value": "\u77e5\u8bc6"}, {"source": "A survey on deep learning-based real-time crowd anomaly detection", "target": "swarm intelligence", "value": "\u77e5\u8bc6"}, {"source": "A survey on deep learning-based real-time crowd anomaly detection", "target": "\u7a7a\u95f4\u65f6\u95f4\u7279\u5f81", "value": "\u77e5\u8bc6"}, {"source": "A survey on deep learning-based real-time crowd anomaly detection", "target": "\u89c6\u9891\u4fe1\u606f\u5904\u7406", "value": "\u77e5\u8bc6"}, {"source": "A survey on deep learning-based real-time crowd anomaly detection", "target": "\u81ea\u884c\u8f66", "value": "\u77e5\u8bc6"}, {"source": "A survey on deep learning-based real-time crowd anomaly detection", "target": "EM\u7b97\u6cd5", "value": "\u77e5\u8bc6"}, {"source": "A survey on deep learning-based real-time crowd anomaly detection", "target": "hollystic", "value": "\u77e5\u8bc6"}, {"source": "A survey on deep learning-based real-time crowd anomaly detection", "target": "distance-based margin", "value": "\u77e5\u8bc6"}, {"source": "A survey on deep learning-based real-time crowd anomaly detection", "target": "regular convolutional layers", "value": "\u77e5\u8bc6"}, {"source": "A survey on deep learning-based real-time crowd anomaly detection", "target": "human error", "value": "\u77e5\u8bc6"}, {"source": "A survey on deep learning-based real-time crowd anomaly detection", "target": "\u73af\u5883\u76d1\u63a7", "value": "\u77e5\u8bc6"}, {"source": "A survey on deep learning-based real-time crowd anomaly detection", "target": "Gaussian\u6df7\u5408\u6a21\u578b", "value": "\u77e5\u8bc6"}, {"source": "A survey on deep learning-based real-time crowd anomaly detection", "target": "K-means++", "value": "\u77e5\u8bc6"}, {"source": "A survey on deep learning-based real-time crowd anomaly detection", "target": "behavioral patternern detection", "value": "\u77e5\u8bc6"}, {"source": "A survey on deep learning-based real-time crowd anomaly detection", "target": "attribute-based approach", "value": "\u77e5\u8bc6"}, {"source": "Deep learning in computer vision principles and applications (Mahmoud Hassaballah, Ali Ismail Awad) (Z-Library).pdf", "target": "automated mapping", "value": "\u77e5\u8bc6"}, {"source": "Deep learning in computer vision principles and applications (Mahmoud Hassaballah, Ali Ismail Awad) (Z-Library).pdf", "target": "empirical study", "value": "\u77e5\u8bc6"}, {"source": "Deep learning in computer vision principles and applications (Mahmoud Hassaballah, Ali Ismail Awad) (Z-Library).pdf", "target": "summarization", "value": "\u77e5\u8bc6"}, {"source": "Deep learning in computer vision principles and applications (Mahmoud Hassaballah, Ali Ismail Awad) (Z-Library).pdf", "target": "\u4eba\u5de5\u667a\u80fd", "value": "\u77e5\u8bc6"}, {"source": "Deep learning in computer vision principles and applications (Mahmoud Hassaballah, Ali Ismail Awad) (Z-Library).pdf", "target": "\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc", "value": "\u77e5\u8bc6"}, {"source": "Deep learning in computer vision principles and applications (Mahmoud Hassaballah, Ali Ismail Awad) (Z-Library).pdf", "target": "single-shot refinement object detection", "value": "\u77e5\u8bc6"}, {"source": "Deep learning in computer vision principles and applications (Mahmoud Hassaballah, Ali Ismail Awad) (Z-Library).pdf", "target": "learning", "value": "\u77e5\u8bc6"}, {"source": "Deep learning in computer vision principles and applications (Mahmoud Hassaballah, Ali Ismail Awad) (Z-Library).pdf", "target": "cvpr", "value": "\u77e5\u8bc6"}, {"source": "Deep learning in computer vision principles and applications (Mahmoud Hassaballah, Ali Ismail Awad) (Z-Library).pdf", "target": "image features", "value": "\u77e5\u8bc6"}, {"source": "Deep learning in computer vision principles and applications (Mahmoud Hassaballah, Ali Ismail Awad) (Z-Library).pdf", "target": "LSTM", "value": "\u77e5\u8bc6"}, {"source": "Deep learning in computer vision principles and applications (Mahmoud Hassaballah, Ali Ismail Awad) (Z-Library).pdf", "target": "\u6df1\u5ea6\u5377\u79ef\u7f51\u7edc", "value": "\u77e5\u8bc6"}, {"source": "Deep learning in computer vision principles and applications (Mahmoud Hassaballah, Ali Ismail Awad) (Z-Library).pdf", "target": "\u4eba\u8138\u8bc6\u522b", "value": "\u77e5\u8bc6"}, {"source": "Deep learning in computer vision principles and applications (Mahmoud Hassaballah, Ali Ismail Awad) (Z-Library).pdf", "target": "data augmentation", "value": "\u77e5\u8bc6"}, {"source": "Deep learning in computer vision principles and applications (Mahmoud Hassaballah, Ali Ismail Awad) (Z-Library).pdf", "target": "neural networks", "value": "\u77e5\u8bc6"}, {"source": "Deep learning in computer vision principles and applications (Mahmoud Hassaballah, Ali Ismail Awad) (Z-Library).pdf", "target": "segmentation", "value": "\u77e5\u8bc6"}, {"source": "Deep learning in computer vision principles and applications (Mahmoud Hassaballah, Ali Ismail Awad) (Z-Library).pdf", "target": "convolutional neural networks", "value": "\u77e5\u8bc6"}, {"source": "Deep learning in computer vision principles and applications (Mahmoud Hassaballah, Ali Ismail Awad) (Z-Library).pdf", "target": "CNNs", "value": "\u77e5\u8bc6"}, {"source": "Deep learning in computer vision principles and applications (Mahmoud Hassaballah, Ali Ismail Awad) (Z-Library).pdf", "target": "\u6df1\u5ea6\u5377\u79ef\u795e\u7ecf\u7f51\u7edc", "value": "\u77e5\u8bc6"}, {"source": "Deep learning in computer vision principles and applications (Mahmoud Hassaballah, Ali Ismail Awad) (Z-Library).pdf", "target": "action recognition", "value": "\u77e5\u8bc6"}, {"source": "Deep learning in computer vision principles and applications (Mahmoud Hassaballah, Ali Ismail Awad) (Z-Library).pdf", "target": "neural network", "value": "\u77e5\u8bc6"}, {"source": "Deep learning in computer vision principles and applications (Mahmoud Hassaballah, Ali Ismail Awad) (Z-Library).pdf", "target": "CNN", "value": "\u77e5\u8bc6"}, {"source": "Deep learning in computer vision principles and applications (Mahmoud Hassaballah, Ali Ismail Awad) (Z-Library).pdf", "target": "semantic segmentation", "value": "\u77e5\u8bc6"}, {"source": "Deep learning in computer vision principles and applications (Mahmoud Hassaballah, Ali Ismail Awad) (Z-Library).pdf", "target": "Malignant Melanomas", "value": "\u77e5\u8bc6"}, {"source": "Deep learning in computer vision principles and applications (Mahmoud Hassaballah, Ali Ismail Awad) (Z-Library).pdf", "target": "SVM", "value": "\u77e5\u8bc6"}, {"source": "Deep learning in computer vision principles and applications (Mahmoud Hassaballah, Ali Ismail Awad) (Z-Library).pdf", "target": "\u795e\u7ecf\u7f51\u7edc", "value": "\u77e5\u8bc6"}, {"source": "Deep learning in computer vision principles and applications (Mahmoud Hassaballah, Ali Ismail Awad) (Z-Library).pdf", "target": "geometry", "value": "\u77e5\u8bc6"}, {"source": "Deep learning in computer vision principles and applications (Mahmoud Hassaballah, Ali Ismail Awad) (Z-Library).pdf", "target": "VGGnet", "value": "\u77e5\u8bc6"}, {"source": "Deep learning in computer vision principles and applications (Mahmoud Hassaballah, Ali Ismail Awad) (Z-Library).pdf", "target": "AlexNet", "value": "\u77e5\u8bc6"}, {"source": "Deep learning in computer vision principles and applications (Mahmoud Hassaballah, Ali Ismail Awad) (Z-Library).pdf", "target": "NIPS", "value": "\u77e5\u8bc6"}, {"source": "Deep learning in computer vision principles and applications (Mahmoud Hassaballah, Ali Ismail Awad) (Z-Library).pdf", "target": "Unsupervised learning", "value": "\u77e5\u8bc6"}, {"source": "Deep learning in computer vision principles and applications (Mahmoud Hassaballah, Ali Ismail Awad) (Z-Library).pdf", "target": "\u6df1\u5ea6\u5b66\u4e60", "value": "\u77e5\u8bc6"}, {"source": "Deep learning in computer vision principles and applications (Mahmoud Hassaballah, Ali Ismail Awad) (Z-Library).pdf", "target": "ICML", "value": "\u77e5\u8bc6"}, {"source": "Deep learning in computer vision principles and applications (Mahmoud Hassaballah, Ali Ismail Awad) (Z-Library).pdf", "target": "multimedia big data", "value": "\u77e5\u8bc6"}, {"source": "Deep learning in computer vision principles and applications (Mahmoud Hassaballah, Ali Ismail Awad) (Z-Library).pdf", "target": "FPGAeleration", "value": "\u77e5\u8bc6"}, {"source": "Deep learning in computer vision principles and applications (Mahmoud Hassaballah, Ali Ismail Awad) (Z-Library).pdf", "target": "AlexNet\u7ea7\u522b\u7684\u51c6\u786e\u7387", "value": "\u77e5\u8bc6"}, {"source": "Deep learning in computer vision principles and applications (Mahmoud Hassaballah, Ali Ismail Awad) (Z-Library).pdf", "target": "Tensor", "value": "\u77e5\u8bc6"}, {"source": "Deep learning in computer vision principles and applications (Mahmoud Hassaballah, Ali Ismail Awad) (Z-Library).pdf", "target": "Softmax\u51fd\u6570", "value": "\u77e5\u8bc6"}, {"source": "Deep learning in computer vision principles and applications (Mahmoud Hassaballah, Ali Ismail Awad) (Z-Library).pdf", "target": "multi-layer perceptron", "value": "\u77e5\u8bc6"}, {"source": "Deep learning in computer vision principles and applications (Mahmoud Hassaballah, Ali Ismail Awad) (Z-Library).pdf", "target": "ISCA\u7ed3\u6784\u7ea6\u675f", "value": "\u77e5\u8bc6"}, {"source": "Deep learning in computer vision principles and applications (Mahmoud Hassaballah, Ali Ismail Awad) (Z-Library).pdf", "target": "Backpropagation", "value": "\u77e5\u8bc6"}, {"source": "Deep learning in computer vision principles and applications (Mahmoud Hassaballah, Ali Ismail Awad) (Z-Library).pdf", "target": "Subcategory-aware convolutional neural networks", "value": "\u77e5\u8bc6"}, {"source": "Deep learning in computer vision principles and applications (Mahmoud Hassaballah, Ali Ismail Awad) (Z-Library).pdf", "target": "Dynamic F\u00d7P", "value": "\u77e5\u8bc6"}, {"source": "Deep learning in computer vision principles and applications (Mahmoud Hassaballah, Ali Ismail Awad) (Z-Library).pdf", "target": "KD-tree", "value": "\u77e5\u8bc6"}, {"source": "Deep learning in computer vision principles and applications (Mahmoud Hassaballah, Ali Ismail Awad) (Z-Library).pdf", "target": "\u6743\u5229\u4fdd\u62a4", "value": "\u77e5\u8bc6"}, {"source": "Deep learning in computer vision principles and applications (Mahmoud Hassaballah, Ali Ismail Awad) (Z-Library).pdf", "target": "openblas", "value": "\u77e5\u8bc6"}, {"source": "Deep learning in computer vision principles and applications (Mahmoud Hassaballah, Ali Ismail Awad) (Z-Library).pdf", "target": "Fixed-Point Arithmetic", "value": "\u77e5\u8bc6"}, {"source": "Deep learning in computer vision principles and applications (Mahmoud Hassaballah, Ali Ismail Awad) (Z-Library).pdf", "target": "self-driving car", "value": "\u77e5\u8bc6"}, {"source": "Deep learning in computer vision principles and applications (Mahmoud Hassaballah, Ali Ismail Awad) (Z-Library).pdf", "target": "Entry Network", "value": "\u77e5\u8bc6"}, {"source": "Deep learning in computer vision principles and applications (Mahmoud Hassaballah, Ali Ismail Awad) (Z-Library).pdf", "target": "fused-layer-accelerator", "value": "\u77e5\u8bc6"}, {"source": "Deep learning in computer vision principles and applications (Mahmoud Hassaballah, Ali Ismail Awad) (Z-Library).pdf", "target": "\u56fe\u50cf\u8bc6\u522b", "value": "\u77e5\u8bc6"}, {"source": "Action recognition using optimized deep autoencoder and CNN for", "target": "classifier", "value": "\u77e5\u8bc6"}, {"source": "Action recognition using optimized deep autoencoder and CNN for", "target": "activation", "value": "\u77e5\u8bc6"}, {"source": "Action recognition using optimized deep autoencoder and CNN for", "target": "classification", "value": "\u77e5\u8bc6"}, {"source": "Action recognition using optimized deep autoencoder and CNN for", "target": "actionrecognition", "value": "\u77e5\u8bc6"}, {"source": "Action recognition using optimized deep autoencoder and CNN for", "target": "motion information", "value": "\u77e5\u8bc6"}, {"source": "Action recognition using optimized deep autoencoder and CNN for", "target": "duration", "value": "\u77e5\u8bc6"}, {"source": "Action recognition using optimized deep autoencoder and CNN for", "target": "Recognition", "value": "\u77e5\u8bc6"}, {"source": "Action recognition using optimized deep autoencoder and CNN for", "target": "surveillance", "value": "\u77e5\u8bc6"}, {"source": "Action recognition using optimized deep autoencoder and CNN for", "target": "occlusion", "value": "\u77e5\u8bc6"}, {"source": "Action recognition using optimized deep autoencoder and CNN for", "target": "\u5206\u7c7b\u7b97\u6cd5", "value": "\u77e5\u8bc6"}, {"source": "Action recognition using optimized deep autoencoder and CNN for", "target": "optical flow", "value": "\u77e5\u8bc6"}, {"source": "Action recognition using optimized deep autoencoder and CNN for", "target": "movement", "value": "\u77e5\u8bc6"}, {"source": "Action recognition using optimized deep autoencoder and CNN for", "target": "deeplearning", "value": "\u77e5\u8bc6"}, {"source": "Action recognition using optimized deep autoencoder and CNN for", "target": "MATLAB", "value": "\u77e5\u8bc6"}, {"source": "Action recognition using optimized deep autoencoder and CNN for", "target": "Diversity", "value": "\u77e5\u8bc6"}, {"source": "Action recognition using optimized deep autoencoder and CNN for", "target": "MSE", "value": "\u77e5\u8bc6"}, {"source": "Action recognition using optimized deep autoencoder and CNN for", "target": "orientation", "value": "\u77e5\u8bc6"}, {"source": "Action recognition using optimized deep autoencoder and CNN for", "target": "deep learning", "value": "\u77e5\u8bc6"}, {"source": "Action recognition using optimized deep autoencoder and CNN for", "target": "recall", "value": "\u77e5\u8bc6"}, {"source": "Action recognition using optimized deep autoencoder and CNN for", "target": "CNNarchitecture", "value": "\u77e5\u8bc6"}, {"source": "Action recognition using optimized deep autoencoder and CNN for", "target": "3D CNN", "value": "\u77e5\u8bc6"}, {"source": "Action recognition using optimized deep autoencoder and CNN for", "target": "CNN models", "value": "\u77e5\u8bc6"}, {"source": "Action recognition using optimized deep autoencoder and CNN for", "target": "precision", "value": "\u77e5\u8bc6"}, {"source": "Action recognition using optimized deep autoencoder and CNN for", "target": "Detection", "value": "\u77e5\u8bc6"}, {"source": "Action recognition using optimized deep autoencoder and CNN for", "target": "ConvNets", "value": "\u77e5\u8bc6"}, {"source": "Action recognition using optimized deep autoencoder and CNN for", "target": "VGG-16", "value": "\u77e5\u8bc6"}, {"source": "Action recognition using optimized deep autoencoder and CNN for", "target": "backpropagation", "value": "\u77e5\u8bc6"}, {"source": "Action recognition using optimized deep autoencoder and CNN for", "target": "VGG", "value": "\u77e5\u8bc6"}, {"source": "Action recognition using optimized deep autoencoder and CNN for", "target": "Adeeplearningtoolbox", "value": "\u77e5\u8bc6"}, {"source": "Action recognition using optimized deep autoencoder and CNN for", "target": "onlinevideo-stream", "value": "\u77e5\u8bc6"}, {"source": "Action recognition using optimized deep autoencoder and CNN for", "target": "one-vs-all", "value": "\u77e5\u8bc6"}, {"source": "Action recognition using optimized deep autoencoder and CNN for", "target": "Dense Autoencoder", "value": "\u77e5\u8bc6"}, {"source": "Action recognition using optimized deep autoencoder and CNN for", "target": "Adjacent Predictions", "value": "\u77e5\u8bc6"}, {"source": "Action recognition using optimized deep autoencoder and CNN for", "target": "Conv4b", "value": "\u77e5\u8bc6"}, {"source": "Action recognition using optimized deep autoencoder and CNN for", "target": "deepcnns", "value": "\u77e5\u8bc6"}, {"source": "Action recognition using optimized deep autoencoder and CNN for", "target": "Modelbehavior", "value": "\u77e5\u8bc6"}, {"source": "Action recognition using optimized deep autoencoder and CNN for", "target": "texture", "value": "\u77e5\u8bc6"}, {"source": "Action recognition using optimized deep autoencoder and CNN for", "target": "inPatternRecognition(ICPR)", "value": "\u77e5\u8bc6"}, {"source": "Action recognition using optimized deep autoencoder and CNN for", "target": "Sensor-based activity recognition", "value": "\u77e5\u8bc6"}, {"source": "Action recognition using optimized deep autoencoder and CNN for", "target": "SCIfusion", "value": "\u77e5\u8bc6"}, {"source": "Action recognition using optimized deep autoencoder and CNN for", "target": "IterativeModel", "value": "\u77e5\u8bc6"}, {"source": "Action recognition using optimized deep autoencoder and CNN for", "target": "VGG-16CNNmodel", "value": "\u77e5\u8bc6"}, {"source": "Action recognition using optimized deep autoencoder and CNN for", "target": "horseracing", "value": "\u77e5\u8bc6"}, {"source": "Action recognition using optimized deep autoencoder and CNN for", "target": "opticalflow", "value": "\u77e5\u8bc6"}, {"source": "Action recognition using optimized deep autoencoder and CNN for", "target": "integralvideorepresentation", "value": "\u77e5\u8bc6"}, {"source": "Action recognition using optimized deep autoencoder and CNN for", "target": "Actionrecognitionbydensetrajectories", "value": "\u77e5\u8bc6"}, {"source": "Action recognition using optimized deep autoencoder and CNN for", "target": "humanmotionrecognitio", "value": "\u77e5\u8bc6"}, {"source": "Action recognition using optimized deep autoencoder and CNN for", "target": "optimizationproblemitymodel", "value": "\u77e5\u8bc6"}, {"source": "Action recognition using optimized deep autoencoder and CNN for", "target": "online datasream mining", "value": "\u77e5\u8bc6"}, {"source": "Action recognition using optimized deep autoencoder and CNN for", "target": "datastreamconfidencescores", "value": "\u77e5\u8bc6"}, {"source": "Ball tracking and trajectory prediction system for tennis robots", "target": "model", "value": "\u77e5\u8bc6"}, {"source": "Ball tracking and trajectory prediction system for tennis robots", "target": "measurement", "value": "\u77e5\u8bc6"}, {"source": "Ball tracking and trajectory prediction system for tennis robots", "target": "robotics", "value": "\u77e5\u8bc6"}, {"source": "Ball tracking and trajectory prediction system for tennis robots", "target": "camera setup", "value": "\u77e5\u8bc6"}, {"source": "Ball tracking and trajectory prediction system for tennis robots", "target": "noise reduction", "value": "\u77e5\u8bc6"}, {"source": "Ball tracking and trajectory prediction system for tennis robots", "target": "background subtraction", "value": "\u77e5\u8bc6"}, {"source": "Ball tracking and trajectory prediction system for tennis robots", "target": "movement", "value": "\u77e5\u8bc6"}, {"source": "Ball tracking and trajectory prediction system for tennis robots", "target": "ball detection", "value": "\u77e5\u8bc6"}, {"source": "Ball tracking and trajectory prediction system for tennis robots", "target": "resolution", "value": "\u77e5\u8bc6"}, {"source": "Ball tracking and trajectory prediction system for tennis robots", "target": "image classification", "value": "\u77e5\u8bc6"}, {"source": "Ball tracking and trajectory prediction system for tennis robots", "target": "\u8fd0\u52a8\u68c0\u6d4b", "value": "\u77e5\u8bc6"}, {"source": "Ball tracking and trajectory prediction system for tennis robots", "target": "confusion matrix", "value": "\u77e5\u8bc6"}, {"source": "Ball tracking and trajectory prediction system for tennis robots", "target": "robot vision", "value": "\u77e5\u8bc6"}, {"source": "Ball tracking and trajectory prediction system for tennis robots", "target": "euclidean\u8ddd\u79bb", "value": "\u77e5\u8bc6"}, {"source": "Ball tracking and trajectory prediction system for tennis robots", "target": "Hawk-eye", "value": "\u77e5\u8bc6"}, {"source": "Ball tracking and trajectory prediction system for tennis robots", "target": "Real-time tracking", "value": "\u77e5\u8bc6"}, {"source": "Ball tracking and trajectory prediction system for tennis robots", "target": "Tennis ball tracking", "value": "\u77e5\u8bc6"}, {"source": "Ball tracking and trajectory prediction system for tennis robots", "target": "Reithler Ltime point", "value": "\u77e5\u8bc6"}, {"source": "Ball tracking and trajectory prediction system for tennis robots", "target": "Creative Commons", "value": "\u77e5\u8bc6"}, {"source": "Ball tracking and trajectory prediction system for tennis robots", "target": "\u5149\u5ea6\u5b66", "value": "\u77e5\u8bc6"}, {"source": "Ball tracking and trajectory prediction system for tennis robots", "target": "vision system", "value": "\u77e5\u8bc6"}, {"source": "Ball tracking and trajectory prediction system for tennis robots", "target": "error bound positiona", "value": "\u77e5\u8bc6"}, {"source": "Ball tracking and trajectory prediction system for tennis robots", "target": "L \u2212 n X c", "value": "\u77e5\u8bc6"}, {"source": "Ball tracking and trajectory prediction system for tennis robots", "target": "Pattern Analysis and Applications", "value": "\u77e5\u8bc6"}, {"source": "Ball tracking and trajectory prediction system for tennis robots", "target": "connected component labelling", "value": "\u77e5\u8bc6"}, {"source": "Ball tracking and trajectory prediction system for tennis robots", "target": "feature point matching", "value": "\u77e5\u8bc6"}, {"source": "Ball tracking and trajectory prediction system for tennis robots", "target": "\u7403\u4f53\u4f4d\u7f6e\u8f6c\u6362", "value": "\u77e5\u8bc6"}, {"source": "Ball tracking and trajectory prediction system for tennis robots", "target": "\u6df1\u5ea6\u56fe\u50cf\u5904\u7406", "value": "\u77e5\u8bc6"}, {"source": "Ball tracking and trajectory prediction system for tennis robots", "target": "Two-pass connected analysis", "value": "\u77e5\u8bc6"}, {"source": "Ball tracking and trajectory prediction system for tennis robots", "target": "neural\u7f51\u7edc\u7f16\u7801\u5668", "value": "\u77e5\u8bc6"}, {"source": "Ball tracking and trajectory prediction system for tennis robots", "target": "z-axis", "value": "\u77e5\u8bc6"}, {"source": "Ball tracking and trajectory prediction system for tennis robots", "target": "Ball Motion", "value": "\u77e5\u8bc6"}, {"source": "Ball tracking and trajectory prediction system for tennis robots", "target": "A co s(45\u25e6\u2213co s-1A)", "value": "\u77e5\u8bc6"}, {"source": "Ball tracking and trajectory prediction system for tennis robots", "target": "ference on Computer Vision", "value": "\u77e5\u8bc6"}, {"source": "Ball tracking and trajectory prediction system for tennis robots", "target": "Prediction Model", "value": "\u77e5\u8bc6"}, {"source": "Ball tracking and trajectory prediction system for tennis robots", "target": "vision\u7cfb\u7edf", "value": "\u77e5\u8bc6"}, {"source": "Ball tracking and trajectory prediction system for tennis robots", "target": "Binarized deconvolution engine", "value": "\u77e5\u8bc6"}, {"source": "Ball tracking and trajectory prediction system for tennis robots", "target": "Creative Commons Attribution-NonCommercial License", "value": "\u77e5\u8bc6"}, {"source": "Ball tracking and trajectory prediction system for tennis robots", "target": "neural net-work", "value": "\u77e5\u8bc6"}, {"source": "Ball tracking and trajectory prediction system for tennis robots", "target": "y ball trajectory prediction", "value": "\u77e5\u8bc6"}, {"source": "Ball tracking and trajectory prediction system for tennis robots", "target": "MOG2 background subtract", "value": "\u77e5\u8bc6"}, {"source": "Ball tracking and trajectory prediction system for tennis robots", "target": "real-world data", "value": "\u77e5\u8bc6"}, {"source": "Ball tracking and trajectory prediction system for tennis robots", "target": "commercial reuse", "value": "\u77e5\u8bc6"}, {"source": "Ball tracking and trajectory prediction system for tennis robots", "target": "dr a g\u7cfb\u6570", "value": "\u77e5\u8bc6"}, {"source": "Ball tracking and trajectory prediction system for tennis robots", "target": "broadcast view", "value": "\u77e5\u8bc6"}, {"source": "Ball tracking and trajectory prediction system for tennis robots", "target": "SPIE", "value": "\u77e5\u8bc6"}, {"source": "Ball tracking and trajectory prediction system for tennis robots", "target": "upsampling layer", "value": "\u77e5\u8bc6"}, {"source": "Ball tracking and trajectory prediction system for tennis robots", "target": "Tennis Robot", "value": "\u77e5\u8bc6"}, {"source": "Ball tracking and trajectory prediction system for tennis robots", "target": "Owens Ngineering", "value": "\u77e5\u8bc6"}, {"source": "Ball tracking and trajectory prediction system for tennis robots", "target": "tan \u22121", "value": "\u77e5\u8bc6"}, {"source": "Bilen_Dynamic_Image_Networks_CVPR_2016_paper", "target": "operator", "value": "\u77e5\u8bc6"}, {"source": "Bilen_Dynamic_Image_Networks_CVPR_2016_paper", "target": "optimization", "value": "\u77e5\u8bc6"}, {"source": "Bilen_Dynamic_Image_Networks_CVPR_2016_paper", "target": "network", "value": "\u77e5\u8bc6"}, {"source": "Bilen_Dynamic_Image_Networks_CVPR_2016_paper", "target": "DNN", "value": "\u77e5\u8bc6"}, {"source": "Bilen_Dynamic_Image_Networks_CVPR_2016_paper", "target": "gradient", "value": "\u77e5\u8bc6"}, {"source": "Bilen_Dynamic_Image_Networks_CVPR_2016_paper", "target": "video sequence", "value": "\u77e5\u8bc6"}, {"source": "Bilen_Dynamic_Image_Networks_CVPR_2016_paper", "target": "video features", "value": "\u77e5\u8bc6"}, {"source": "Bilen_Dynamic_Image_Networks_CVPR_2016_paper", "target": "datasets", "value": "\u77e5\u8bc6"}, {"source": "Bilen_Dynamic_Image_Networks_CVPR_2016_paper", "target": "video", "value": "\u77e5\u8bc6"}, {"source": "Bilen_Dynamic_Image_Networks_CVPR_2016_paper", "target": "max pooling", "value": "\u77e5\u8bc6"}, {"source": "Bilen_Dynamic_Image_Networks_CVPR_2016_paper", "target": "3D convolution", "value": "\u77e5\u8bc6"}, {"source": "Bilen_Dynamic_Image_Networks_CVPR_2016_paper", "target": "convolutional layer", "value": "\u77e5\u8bc6"}, {"source": "Bilen_Dynamic_Image_Networks_CVPR_2016_paper", "target": "state-of-the-art", "value": "\u77e5\u8bc6"}, {"source": "Bilen_Dynamic_Image_Networks_CVPR_2016_paper", "target": "backpropagation", "value": "\u77e5\u8bc6"}, {"source": "Bilen_Dynamic_Image_Networks_CVPR_2016_paper", "target": "deep learning\u65b9\u6cd5", "value": "\u77e5\u8bc6"}, {"source": "Bilen_Dynamic_Image_Networks_CVPR_2016_paper", "target": "_gradients", "value": "\u77e5\u8bc6"}, {"source": "Bilen_Dynamic_Image_Networks_CVPR_2016_paper", "target": "input RGB video frames", "value": "\u77e5\u8bc6"}, {"source": "Bilen_Dynamic_Image_Networks_CVPR_2016_paper", "target": "SVMs", "value": "\u77e5\u8bc6"}, {"source": "Bilen_Dynamic_Image_Networks_CVPR_2016_paper", "target": "\u652f\u6301\u5411\u91cf regressi\u00f3n", "value": "\u77e5\u8bc6"}, {"source": "Bilen_Dynamic_Image_Networks_CVPR_2016_paper", "target": "UCF101 dataset", "value": "\u77e5\u8bc6"}, {"source": "Bilen_Dynamic_Image_Networks_CVPR_2016_paper", "target": "recurrent architectures", "value": "\u77e5\u8bc6"}, {"source": "Bilen_Dynamic_Image_Networks_CVPR_2016_paper", "target": "time-averaged feature frames \u03c8t", "value": "\u77e5\u8bc6"}, {"source": "Bilen_Dynamic_Image_Networks_CVPR_2016_paper", "target": "3D\u6df1\u5ea6\u5377\u79ef\u795e\u7ecf\u7f51\u7edc", "value": "\u77e5\u8bc6"}, {"source": "Bilen_Dynamic_Image_Networks_CVPR_2016_paper", "target": "\u52a8\u6001\u6620\u5c04", "value": "\u77e5\u8bc6"}, {"source": "Bilen_Dynamic_Image_Networks_CVPR_2016_paper", "target": "metricsoptical flow", "value": "\u77e5\u8bc6"}, {"source": "Bilen_Dynamic_Image_Networks_CVPR_2016_paper", "target": "\u7ebf\u6027\u64cd\u4f5c", "value": "\u77e5\u8bc6"}, {"source": "Bilen_Dynamic_Image_Networks_CVPR_2016_paper", "target": "d\u2217\u52a8\u529b\u56fe\uff0c\u6700\u5927\u503c\u51fd\u6570", "value": "\u77e5\u8bc6"}, {"source": "Bilen_Dynamic_Image_Networks_CVPR_2016_paper", "target": "Soccer Juggling", "value": "\u77e5\u8bc6"}, {"source": "Bilen_Dynamic_Image_Networks_CVPR_2016_paper", "target": "local features", "value": "\u77e5\u8bc6"}, {"source": "Bilen_Dynamic_Image_Networks_CVPR_2016_paper", "target": "hand-crafted features", "value": "\u77e5\u8bc6"}, {"source": "Bilen_Dynamic_Image_Networks_CVPR_2016_paper", "target": "\u5355\u52a8\u6001\u56fe\u50cf (SDI)", "value": "\u77e5\u8bc6"}, {"source": "Bilen_Dynamic_Image_Networks_CVPR_2016_paper", "target": "im-age features", "value": "\u77e5\u8bc6"}, {"source": "Bilen_Dynamic_Image_Networks_CVPR_2016_paper", "target": "Dynamics at Image Pixel Level", "value": "\u77e5\u8bc6"}, {"source": "Bilen_Dynamic_Image_Networks_CVPR_2016_paper", "target": "longtermrecurrerecognitionconvolutional layers", "value": "\u77e5\u8bc6"}, {"source": "Bilen_Dynamic_Image_Networks_CVPR_2016_paper", "target": "actionrecognition datasets", "value": "\u77e5\u8bc6"}, {"source": "Bilen_Dynamic_Image_Networks_CVPR_2016_paper", "target": "RGB framenetworks", "value": "\u77e5\u8bc6"}, {"source": "Bilen_Dynamic_Image_Networks_CVPR_2016_paper", "target": "approximate rank pooling", "value": "\u77e5\u8bc6"}, {"source": "Bilen_Dynamic_Image_Networks_CVPR_2016_paper", "target": "hinge\u635f\u5931", "value": "\u77e5\u8bc6"}, {"source": "Bilen_Dynamic_Image_Networks_CVPR_2016_paper", "target": "RankSVM", "value": "\u77e5\u8bc6"}, {"source": "Bilen_Dynamic_Image_Networks_CVPR_2016_paper", "target": "\u94a2\u7434\u6f14\u594f", "value": "\u77e5\u8bc6"}, {"source": "Bilen_Dynamic_Image_Networks_CVPR_2016_paper", "target": "rank pool-ing weighti", "value": "\u77e5\u8bc6"}, {"source": "Bilen_Dynamic_Image_Networks_CVPR_2016_paper", "target": "Dual Representational learning", "value": "\u77e5\u8bc6"}, {"source": "Bilen_Dynamic_Image_Networks_CVPR_2016_paper", "target": "\u68af\u5ea6\u53cd\u5411\u4f20\u64ad", "value": "\u77e5\u8bc6"}, {"source": "Bilen_Dynamic_Image_Networks_CVPR_2016_paper", "target": "BVLC reference CaffeNet model", "value": "\u77e5\u8bc6"}, {"source": "Bilen_Dynamic_Image_Networks_CVPR_2016_paper", "target": "motion\u56fe\u50cf", "value": "\u77e5\u8bc6"}, {"source": "Bilen_Dynamic_Image_Networks_CVPR_2016_paper", "target": "net-works", "value": "\u77e5\u8bc6"}, {"source": "Bilen_Dynamic_Image_Networks_CVPR_2016_paper", "target": "\u89c6\u9891\u957f\u671f\u52a8\u529b\u5b66", "value": "\u77e5\u8bc6"}, {"source": "Bilen_Dynamic_Image_Networks_CVPR_2016_paper", "target": "reconstruction", "value": "\u77e5\u8bc6"}, {"source": "Bilen_Dynamic_Image_Networks_CVPR_2016_paper", "target": "pixel intensities", "value": "\u77e5\u8bc6"}, {"source": "Bilen_Dynamic_Image_Networks_CVPR_2016_paper", "target": "\u72b6\u6001-of-the-artCNN\u67b6\u6784", "value": "\u77e5\u8bc6"}, {"source": "Estimation of Camera Pose, Nonlinear.pdf", "target": "quaternions", "value": "\u77e5\u8bc6"}, {"source": "Estimation of Camera Pose, Nonlinear.pdf", "target": "image plane", "value": "\u77e5\u8bc6"}, {"source": "Estimation of Camera Pose, Nonlinear.pdf", "target": "camera", "value": "\u77e5\u8bc6"}, {"source": "Estimation of Camera Pose, Nonlinear.pdf", "target": "estimation of normalized camera projection matrix", "value": "\u77e5\u8bc6"}, {"source": "Estimation of Camera Pose, Nonlinear.pdf", "target": "linear estimation for initial estimate", "value": "\u77e5\u8bc6"}, {"source": "Estimation of Camera Pose, Nonlinear.pdf", "target": "camera projection matrix", "value": "\u77e5\u8bc6"}, {"source": "Estimation of Camera Pose, Nonlinear.pdf", "target": "iterative estimation", "value": "\u77e5\u8bc6"}, {"source": "Estimation of Camera Pose, Nonlinear.pdf", "target": "CALIBRATION", "value": "\u77e5\u8bc6"}, {"source": "Estimation of Camera Pose, Nonlinear.pdf", "target": "Rotation matrix", "value": "\u77e5\u8bc6"}, {"source": "Estimation of Camera Pose, Nonlinear.pdf", "target": "axis representation", "value": "\u77e5\u8bc6"}, {"source": "Estimation of Camera Pose, Nonlinear.pdf", "target": "\u6b63\u5e38\u5316\u5750\u6807", "value": "\u77e5\u8bc6"}, {"source": "Estimation of Camera Pose, Nonlinear.pdf", "target": "SO(3)", "value": "\u77e5\u8bc6"}, {"source": "Estimation of Camera Pose, Nonlinear.pdf", "target": "Stereo \u89c6\u89c9", "value": "\u77e5\u8bc6"}, {"source": "Estimation of Camera Pose, Nonlinear.pdf", "target": "Levenberg-Marquardt algorithm", "value": "\u77e5\u8bc6"}, {"source": "Estimation of Camera Pose, Nonlinear.pdf", "target": "minimal parameterization", "value": "\u77e5\u8bc6"}, {"source": "Estimation of Camera Pose, Nonlinear.pdf", "target": "\u76f8\u673a\u6a21\u578b", "value": "\u77e5\u8bc6"}, {"source": "Estimation of Camera Pose, Nonlinear.pdf", "target": "Euclidean transformation", "value": "\u77e5\u8bc6"}, {"source": "Estimation of Camera Pose, Nonlinear.pdf", "target": "covariance propagation", "value": "\u77e5\u8bc6"}, {"source": "Estimation of Camera Pose, Nonlinear.pdf", "target": "cam\u0435\u0440aprojection", "value": "\u77e5\u8bc6"}, {"source": "Estimation of Camera Pose, Nonlinear.pdf", "target": "Nonlinear estimation", "value": "\u77e5\u8bc6"}, {"source": "Estimation of Camera Pose, Nonlinear.pdf", "target": "\u6b27\u62c9\u65cb\u8f6c\u5b9a\u7406", "value": "\u77e5\u8bc6"}, {"source": "Estimation of Camera Pose, Nonlinear.pdf", "target": "Euler axis and angle", "value": "\u77e5\u8bc6"}, {"source": "Estimation of Camera Pose, Nonlinear.pdf", "target": "\u89d2\u8f74\u8868\u793a", "value": "\u77e5\u8bc6"}, {"source": "Estimation of Camera Pose, Nonlinear.pdf", "target": "Spherical linear interpolation (Slerp)", "value": "\u77e5\u8bc6"}, {"source": "Estimation of Camera Pose, Nonlinear.pdf", "target": "camera translation vector", "value": "\u77e5\u8bc6"}, {"source": "Estimation of Camera Pose, Nonlinear.pdf", "target": "CSE 252B", "value": "\u77e5\u8bc6"}, {"source": "Estimation of Camera Pose, Nonlinear.pdf", "target": "normalized camera projectionection matrix", "value": "\u77e5\u8bc6"}, {"source": "Estimation of Camera Pose, Nonlinear.pdf", "target": "\u50cf\u7d20\u77e9\u9635", "value": "\u77e5\u8bc6"}, {"source": "Estimation of Camera Pose, Nonlinear.pdf", "target": "\u65cb\u8f6c\u89d2\u5ea6\u5173\u4e8e\u8f74\u7684\u5b9a\u4f4dterpol", "value": "\u77e5\u8bc6"}, {"source": "Estimation of Camera Pose, Nonlinear.pdf", "target": "rotation matrix", "value": "\u77e5\u8bc6"}, {"source": "Estimation of Camera Pose, Nonlinear.pdf", "target": "\u89d2\u8f74\u8868\u793a\u6cd5", "value": "\u77e5\u8bc6"}, {"source": "Estimation of Camera Pose, Nonlinear.pdf", "target": "Computervision II", "value": "\u77e5\u8bc6"}, {"source": "Estimation of Camera Pose, Nonlinear.pdf", "target": "Scheduling", "value": "\u77e5\u8bc6"}, {"source": "Estimation of Camera Pose, Nonlinear.pdf", "target": "3D\u70b9\u5750\u6807\u7cfb", "value": "\u77e5\u8bc6"}, {"source": "Estimation of Camera Pose, Nonlinear.pdf", "target": "\u4e09\u70b9\u76f8\u673a\u89c6\u89c9", "value": "\u77e5\u8bc6"}, {"source": "Estimation of Camera Pose, Nonlinear.pdf", "target": "normalizedprojectionmatrixcross-correlation", "value": "\u77e5\u8bc6"}, {"source": "Estimation of Camera Pose, Nonlinear.pdf", "target": "\u5355\u89c6\u89c9\u51e0\u4f55", "value": "\u77e5\u8bc6"}, {"source": "Estimation of Camera Pose, Nonlinear.pdf", "target": "calibrated camera", "value": "\u77e5\u8bc6"}, {"source": "Estimation of Camera Pose, Nonlinear.pdf", "target": "adjustment", "value": "\u77e5\u8bc6"}, {"source": "Estimation of Camera Pose, Nonlinear.pdf", "target": "Levenberg-Marquardt\u7b97\u6cd5", "value": "\u77e5\u8bc6"}, {"source": "Estimation of Camera Pose, Nonlinear.pdf", "target": "angle-axis", "value": "\u77e5\u8bc6"}, {"source": "Estimation of Camera Pose, Nonlinear.pdf", "target": "Camera Projection\u77e9\u9635", "value": "\u77e5\u8bc6"}, {"source": "Estimation of Camera Pose, Nonlinear.pdf", "target": "3D \u65cb\u8f6c", "value": "\u77e5\u8bc6"}, {"source": "Estimation of Camera Pose, Nonlinear.pdf", "target": "Quaternion", "value": "\u77e5\u8bc6"}, {"source": "Estimation of Camera Pose, Nonlinear.pdf", "target": "Linear estimation of normal", "value": "\u77e5\u8bc6"}, {"source": "Estimation of Camera Pose, Nonlinear.pdf", "target": "Euler\u89d2\u5ea6", "value": "\u77e5\u8bc6"}, {"source": "Estimation of Camera Pose, Nonlinear.pdf", "target": "3D\u91cd\u5efa", "value": "\u77e5\u8bc6"}, {"source": "Estimation of Camera Pose, Nonlinear.pdf", "target": "\u6b27\u62c9\u8f6c\u6362\u5b9a\u7406", "value": "\u77e5\u8bc6"}, {"source": "Estimation of Camera Pose, Nonlinear.pdf", "target": "Camera projection matrix", "value": "\u77e5\u8bc6"}, {"source": "Estimation of Camera Pose, Nonlinear.pdf", "target": "3D\u65cb\u8f6c", "value": "\u77e5\u8bc6"}, {"source": "Fast R-CNN.pdf", "target": "max-pooling", "value": "\u77e5\u8bc6"}, {"source": "Fast R-CNN.pdf", "target": "pooling", "value": "\u77e5\u8bc6"}, {"source": "Fast R-CNN.pdf", "target": "fine-tuning", "value": "\u77e5\u8bc6"}, {"source": "Fast R-CNN.pdf", "target": "ImageNet", "value": "\u77e5\u8bc6"}, {"source": "Fast R-CNN.pdf", "target": "data augmentation", "value": "\u77e5\u8bc6"}, {"source": "Fast R-CNN.pdf", "target": "neural networks", "value": "\u77e5\u8bc6"}, {"source": "Fast R-CNN.pdf", "target": "segmentation", "value": "\u77e5\u8bc6"}, {"source": "Fast R-CNN.pdf", "target": "\u6df1\u5ea6\u5377\u79ef\u795e\u7ecf\u7f51\u7edc", "value": "\u77e5\u8bc6"}, {"source": "Fast R-CNN.pdf", "target": "CaffeNet", "value": "\u77e5\u8bc6"}, {"source": "Fast R-CNN.pdf", "target": "CNN", "value": "\u77e5\u8bc6"}, {"source": "Fast R-CNN.pdf", "target": "SVM", "value": "\u77e5\u8bc6"}, {"source": "Fast R-CNN.pdf", "target": "\u795e\u7ecf\u7f51\u7edc", "value": "\u77e5\u8bc6"}, {"source": "Fast R-CNN.pdf", "target": "AlexNet", "value": "\u77e5\u8bc6"}, {"source": "Fast R-CNN.pdf", "target": "\u6df1\u5ea6\u5b66\u4e60", "value": "\u77e5\u8bc6"}, {"source": "Fast R-CNN.pdf", "target": "\u5377\u79ef\u5c42", "value": "\u77e5\u8bc6"}, {"source": "Fast R-CNN.pdf", "target": "\u6df1\u5ea6\u7f51\u7edc", "value": "\u77e5\u8bc6"}, {"source": "Fast R-CNN.pdf", "target": "softmax", "value": "\u77e5\u8bc6"}, {"source": "Fast R-CNN.pdf", "target": "IoU", "value": "\u77e5\u8bc6"}, {"source": "Fast R-CNN.pdf", "target": "Python", "value": "\u77e5\u8bc6"}, {"source": "Fast R-CNN.pdf", "target": "Dense", "value": "\u77e5\u8bc6"}, {"source": "Fast R-CNN.pdf", "target": "SGD", "value": "\u77e5\u8bc6"}, {"source": "Fast R-CNN.pdf", "target": "loss function", "value": "\u77e5\u8bc6"}, {"source": "Fast R-CNN.pdf", "target": "VGG16", "value": "\u77e5\u8bc6"}, {"source": "Fast R-CNN.pdf", "target": "accuracy", "value": "\u77e5\u8bc6"}, {"source": "Fast R-CNN.pdf", "target": "object detection", "value": "\u77e5\u8bc6"}, {"source": "Fast R-CNN.pdf", "target": "R-CNN", "value": "\u77e5\u8bc6"}, {"source": "Fast R-CNN.pdf", "target": "Detection object", "value": "\u77e5\u8bc6"}, {"source": "Fast R-CNN.pdf", "target": "Convolutions", "value": "\u77e5\u8bc6"}, {"source": "Fast R-CNN.pdf", "target": "bird", "value": "\u77e5\u8bc6"}, {"source": "Fast R-CNN.pdf", "target": "classi\ufb01cation", "value": "\u77e5\u8bc6"}, {"source": "Fast R-CNN.pdf", "target": "computer vision", "value": "\u77e5\u8bc6"}, {"source": "Fast R-CNN.pdf", "target": "fully connected layers", "value": "\u77e5\u8bc6"}, {"source": "Fast R-CNN.pdf", "target": "multi-task learning", "value": "\u77e5\u8bc6"}, {"source": "Fast R-CNN.pdf", "target": "training data", "value": "\u77e5\u8bc6"}, {"source": "Fast R-CNN.pdf", "target": "projection", "value": "\u77e5\u8bc6"}, {"source": "Fast R-CNN.pdf", "target": "heuristic", "value": "\u77e5\u8bc6"}, {"source": "Fast R-CNN.pdf", "target": "C++", "value": "\u77e5\u8bc6"}, {"source": "Fast R-CNN.pdf", "target": "max pooling", "value": "\u77e5\u8bc6"}, {"source": "Fast R-CNN.pdf", "target": "Convolutional Networks", "value": "\u77e5\u8bc6"}, {"source": "Fast R-CNN.pdf", "target": "ConvNets", "value": "\u77e5\u8bc6"}, {"source": "Fast R-CNN.pdf", "target": "localization", "value": "\u77e5\u8bc6"}, {"source": "Fast R-CNN.pdf", "target": "selective search", "value": "\u77e5\u8bc6"}, {"source": "Fast R-CNN.pdf", "target": "SVMs", "value": "\u77e5\u8bc6"}, {"source": "Fast R-CNN.pdf", "target": "back-propagation", "value": "\u77e5\u8bc6"}, {"source": "Fast R-CNN.pdf", "target": "fast R-CNN", "value": "\u77e5\u8bc6"}, {"source": "Fast R-CNN.pdf", "target": "Caffe", "value": "\u77e5\u8bc6"}, {"source": "Fast R-CNN.pdf", "target": "Object detection", "value": "\u77e5\u8bc6"}, {"source": "Fast R-CNN.pdf", "target": "SVD", "value": "\u77e5\u8bc6"}, {"source": "Fast R-CNN.pdf", "target": "bounding-box regression", "value": "\u77e5\u8bc6"}, {"source": "Fast R-CNN.pdf", "target": "proposalfeature extraction", "value": "\u77e5\u8bc6"}, {"source": "Faster R-CNN.pdf", "target": "\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc", "value": "\u77e5\u8bc6"}, {"source": "Faster R-CNN.pdf", "target": "ImageNet", "value": "\u77e5\u8bc6"}, {"source": "Faster R-CNN.pdf", "target": "neural networks", "value": "\u77e5\u8bc6"}, {"source": "Faster R-CNN.pdf", "target": "segmentation", "value": "\u77e5\u8bc6"}, {"source": "Faster R-CNN.pdf", "target": "CNNs", "value": "\u77e5\u8bc6"}, {"source": "Faster R-CNN.pdf", "target": "CNN", "value": "\u77e5\u8bc6"}, {"source": "Faster R-CNN.pdf", "target": "semantic segmentation", "value": "\u77e5\u8bc6"}, {"source": "Faster R-CNN.pdf", "target": "SVM", "value": "\u77e5\u8bc6"}, {"source": "Faster R-CNN.pdf", "target": "NIPS", "value": "\u77e5\u8bc6"}, {"source": "Faster R-CNN.pdf", "target": "ReLU\u6fc0\u6d3b\u51fd\u6570", "value": "\u77e5\u8bc6"}, {"source": "Faster R-CNN.pdf", "target": "\u53cd\u5411\u4f20\u64ad", "value": "\u77e5\u8bc6"}, {"source": "Faster R-CNN.pdf", "target": "attention mechanism", "value": "\u77e5\u8bc6"}, {"source": "Faster R-CNN.pdf", "target": "CPU", "value": "\u77e5\u8bc6"}, {"source": "Faster R-CNN.pdf", "target": "feature map", "value": "\u77e5\u8bc6"}, {"source": "Faster R-CNN.pdf", "target": "Kubernetes\u7ba1\u7406\u7cfb\u7edf", "value": "\u77e5\u8bc6"}, {"source": "Faster R-CNN.pdf", "target": "\u6df1\u5ea6\u7f51\u7edc", "value": "\u77e5\u8bc6"}, {"source": "Faster R-CNN.pdf", "target": "softmax", "value": "\u77e5\u8bc6"}, {"source": "Faster R-CNN.pdf", "target": "S3\u5b58\u50a8\u670d\u52a1", "value": "\u77e5\u8bc6"}, {"source": "Faster R-CNN.pdf", "target": "anchors", "value": "\u77e5\u8bc6"}, {"source": "Faster R-CNN.pdf", "target": "momentum", "value": "\u77e5\u8bc6"}, {"source": "Faster R-CNN.pdf", "target": "ReLU", "value": "\u77e5\u8bc6"}, {"source": "Faster R-CNN.pdf", "target": "IoU", "value": "\u77e5\u8bc6"}, {"source": "Faster R-CNN.pdf", "target": "classifier", "value": "\u77e5\u8bc6"}, {"source": "Faster R-CNN.pdf", "target": "SGD", "value": "\u77e5\u8bc6"}, {"source": "Faster R-CNN.pdf", "target": "Gaussian\u5206\u5e03", "value": "\u77e5\u8bc6"}, {"source": "Faster R-CNN.pdf", "target": "GPU\u52a0\u901f", "value": "\u77e5\u8bc6"}, {"source": "Faster R-CNN.pdf", "target": "GPU", "value": "\u77e5\u8bc6"}, {"source": "Faster R-CNN.pdf", "target": "DNN", "value": "\u77e5\u8bc6"}, {"source": "Faster R-CNN.pdf", "target": "layer", "value": "\u77e5\u8bc6"}, {"source": "Faster R-CNN.pdf", "target": "models", "value": "\u77e5\u8bc6"}, {"source": "Faster R-CNN.pdf", "target": "Convolutional Neural Networks", "value": "\u77e5\u8bc6"}, {"source": "Faster R-CNN.pdf", "target": "classification", "value": "\u77e5\u8bc6"}, {"source": "Faster R-CNN.pdf", "target": "cloud platform", "value": "\u77e5\u8bc6"}, {"source": "Faster R-CNN.pdf", "target": "feature maps", "value": "\u77e5\u8bc6"}, {"source": "Faster R-CNN.pdf", "target": "Convolutional Neural Network", "value": "\u77e5\u8bc6"}, {"source": "Faster R-CNN.pdf", "target": "Docker\u5bb9\u5668", "value": "\u77e5\u8bc6"}, {"source": "Faster R-CNN.pdf", "target": "Neural Information Processing Systems", "value": "\u77e5\u8bc6"}, {"source": "Faster R-CNN.pdf", "target": "\u5377\u79ef\u795e\u7ecf\u7f51\u7edc", "value": "\u77e5\u8bc6"}, {"source": "Faster R-CNN.pdf", "target": "region proposal network", "value": "\u77e5\u8bc6"}, {"source": "Faster R-CNN.pdf", "target": "accuracy", "value": "\u77e5\u8bc6"}, {"source": "Faster R-CNN.pdf", "target": "object detection", "value": "\u77e5\u8bc6"}, {"source": "Faster R-CNN.pdf", "target": "\u5168\u8fde\u63a5\u5c42", "value": "\u77e5\u8bc6"}, {"source": "Faster R-CNN.pdf", "target": "R-CNN", "value": "\u77e5\u8bc6"}, {"source": "Faster R-CNN.pdf", "target": "\u81ea\u52a8\u5316\u90e8\u7f72", "value": "\u77e5\u8bc6"}, {"source": "Faster R-CNN.pdf", "target": "arXiv", "value": "\u77e5\u8bc6"}, {"source": "Faster R-CNN.pdf", "target": "AWS", "value": "\u77e5\u8bc6"}, {"source": "Faster R-CNN.pdf", "target": "mouse", "value": "\u77e5\u8bc6"}, {"source": "Faster R-CNN.pdf", "target": "bird", "value": "\u77e5\u8bc6"}, {"source": "Faster R-CNN.pdf", "target": "sliding window", "value": "\u77e5\u8bc6"}, {"source": "Faster R-CNN.pdf", "target": "\u5fae\u8c03\u5b66\u4e60\u7387", "value": "\u77e5\u8bc6"}, {"source": "Human segmentation in surveillance video with deep learning.pdf", "target": "\u4eba\u5de5\u667a\u80fd", "value": "\u77e5\u8bc6"}, {"source": "Human segmentation in surveillance video with deep learning.pdf", "target": "\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc", "value": "\u77e5\u8bc6"}, {"source": "Human segmentation in surveillance video with deep learning.pdf", "target": "max-pooling", "value": "\u77e5\u8bc6"}, {"source": "Human segmentation in surveillance video with deep learning.pdf", "target": "ImageNet", "value": "\u77e5\u8bc6"}, {"source": "Human segmentation in surveillance video with deep learning.pdf", "target": "data augmentation", "value": "\u77e5\u8bc6"}, {"source": "Human segmentation in surveillance video with deep learning.pdf", "target": "segmentation", "value": "\u77e5\u8bc6"}, {"source": "Human segmentation in surveillance video with deep learning.pdf", "target": "motion blur", "value": "\u77e5\u8bc6"}, {"source": "Human segmentation in surveillance video with deep learning.pdf", "target": "\u6df1\u5ea6\u5377\u79ef\u795e\u7ecf\u7f51\u7edc", "value": "\u77e5\u8bc6"}, {"source": "Human segmentation in surveillance video with deep learning.pdf", "target": "neural network", "value": "\u77e5\u8bc6"}, {"source": "Human segmentation in surveillance video with deep learning.pdf", "target": "RGB image", "value": "\u77e5\u8bc6"}, {"source": "Human segmentation in surveillance video with deep learning.pdf", "target": "semantic segmentation", "value": "\u77e5\u8bc6"}, {"source": "Human segmentation in surveillance video with deep learning.pdf", "target": "\u795e\u7ecf\u7f51\u7edc", "value": "\u77e5\u8bc6"}, {"source": "Human segmentation in surveillance video with deep learning.pdf", "target": "\u4eba\u673a\u4ea4\u4e92", "value": "\u77e5\u8bc6"}, {"source": "Human segmentation in surveillance video with deep learning.pdf", "target": "NIPS", "value": "\u77e5\u8bc6"}, {"source": "Human segmentation in surveillance video with deep learning.pdf", "target": "\u6df1\u5ea6\u5b66\u4e60", "value": "\u77e5\u8bc6"}, {"source": "Human segmentation in surveillance video with deep learning.pdf", "target": "network", "value": "\u77e5\u8bc6"}, {"source": "Human segmentation in surveillance video with deep learning.pdf", "target": "\u56fe\u50cf\u8bc6\u522b", "value": "\u77e5\u8bc6"}, {"source": "Human segmentation in surveillance video with deep learning.pdf", "target": "\u56fe\u50cf\u5904\u7406", "value": "\u77e5\u8bc6"}, {"source": "Human segmentation in surveillance video with deep learning.pdf", "target": "uniform", "value": "\u77e5\u8bc6"}, {"source": "Human segmentation in surveillance video with deep learning.pdf", "target": "\u7f16\u7801\u5668", "value": "\u77e5\u8bc6"}, {"source": "Human segmentation in surveillance video with deep learning.pdf", "target": "NVIDIA", "value": "\u77e5\u8bc6"}, {"source": "Human segmentation in surveillance video with deep learning.pdf", "target": "Class", "value": "\u77e5\u8bc6"}, {"source": "Human segmentation in surveillance video with deep learning.pdf", "target": "Accuracy", "value": "\u77e5\u8bc6"}, {"source": "Human segmentation in surveillance video with deep learning.pdf", "target": "\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b", "value": "\u77e5\u8bc6"}, {"source": "Human segmentation in surveillance video with deep learning.pdf", "target": "video processing", "value": "\u77e5\u8bc6"}, {"source": "Human segmentation in surveillance video with deep learning.pdf", "target": "\u673a\u5668\u5b66\u4e60", "value": "\u77e5\u8bc6"}, {"source": "Human segmentation in surveillance video with deep learning.pdf", "target": "convolution", "value": "\u77e5\u8bc6"}, {"source": "Human segmentation in surveillance video with deep learning.pdf", "target": "ReLU", "value": "\u77e5\u8bc6"}, {"source": "Human segmentation in surveillance video with deep learning.pdf", "target": "SegNet", "value": "\u77e5\u8bc6"}, {"source": "Human segmentation in surveillance video with deep learning.pdf", "target": "IoU", "value": "\u77e5\u8bc6"}, {"source": "Human segmentation in surveillance video with deep learning.pdf", "target": "\u56fe\u50cf\u5206\u7c7b", "value": "\u77e5\u8bc6"}, {"source": "Human segmentation in surveillance video with deep learning.pdf", "target": "DNN", "value": "\u77e5\u8bc6"}, {"source": "Human segmentation in surveillance video with deep learning.pdf", "target": "kernel", "value": "\u77e5\u8bc6"}, {"source": "Human segmentation in surveillance video with deep learning.pdf", "target": "Deep learning", "value": "\u77e5\u8bc6"}, {"source": "Human segmentation in surveillance video with deep learning.pdf", "target": "loss function", "value": "\u77e5\u8bc6"}, {"source": "Human segmentation in surveillance video with deep learning.pdf", "target": "epoch", "value": "\u77e5\u8bc6"}, {"source": "Human segmentation in surveillance video with deep learning.pdf", "target": "Convolutional Neural Networks", "value": "\u77e5\u8bc6"}, {"source": "Human segmentation in surveillance video with deep learning.pdf", "target": "\u5377\u79ef\u795e\u7ecf\u7f51\u7edc", "value": "\u77e5\u8bc6"}, {"source": "Human segmentation in surveillance video with deep learning.pdf", "target": "\u6fc0\u6d3b\u51fd\u6570", "value": "\u77e5\u8bc6"}, {"source": "Human segmentation in surveillance video with deep learning.pdf", "target": "semantic image segmentation", "value": "\u77e5\u8bc6"}, {"source": "Human segmentation in surveillance video with deep learning.pdf", "target": "\u8ba1\u7b97\u673a\u89c6\u89c9", "value": "\u77e5\u8bc6"}, {"source": "Human segmentation in surveillance video with deep learning.pdf", "target": "accuracy", "value": "\u77e5\u8bc6"}, {"source": "Human segmentation in surveillance video with deep learning.pdf", "target": "object detection", "value": "\u77e5\u8bc6"}, {"source": "Human segmentation in surveillance video with deep learning.pdf", "target": "\u5168\u8fde\u63a5\u5c42", "value": "\u77e5\u8bc6"}, {"source": "Human segmentation in surveillance video with deep learning.pdf", "target": "\u673a\u5668\u89c6\u89c9", "value": "\u77e5\u8bc6"}, {"source": "Human segmentation in surveillance video with deep learning.pdf", "target": "encoder", "value": "\u77e5\u8bc6"}, {"source": "Human segmentation in surveillance video with deep learning.pdf", "target": "Adam\u7b97\u6cd5", "value": "\u77e5\u8bc6"}, {"source": "Human segmentation in surveillance video with deep learning.pdf", "target": "dataset", "value": "\u77e5\u8bc6"}, {"source": "Human segmentation in surveillance video with deep learning.pdf", "target": "\u56fe\u50cf\u5206\u5272", "value": "\u77e5\u8bc6"}, {"source": "Human segmentation in surveillance video with deep learning.pdf", "target": "Semantic Segmentation", "value": "\u77e5\u8bc6"}, {"source": "Human_Action_Recognition_From_Various_Data_Modalities_A_Review.pdf", "target": "motion patterns", "value": "\u77e5\u8bc6"}, {"source": "Human_Action_Recognition_From_Various_Data_Modalities_A_Review.pdf", "target": "\u4eba\u5de5\u667a\u80fd", "value": "\u77e5\u8bc6"}, {"source": "Human_Action_Recognition_From_Various_Data_Modalities_A_Review.pdf", "target": "3D filters", "value": "\u77e5\u8bc6"}, {"source": "Human_Action_Recognition_From_Various_Data_Modalities_A_Review.pdf", "target": "\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc", "value": "\u77e5\u8bc6"}, {"source": "Human_Action_Recognition_From_Various_Data_Modalities_A_Review.pdf", "target": "LSTM", "value": "\u77e5\u8bc6"}, {"source": "Human_Action_Recognition_From_Various_Data_Modalities_A_Review.pdf", "target": "LSTM\u7f51\u7edc", "value": "\u77e5\u8bc6"}, {"source": "Human_Action_Recognition_From_Various_Data_Modalities_A_Review.pdf", "target": "data augmentation", "value": "\u77e5\u8bc6"}, {"source": "Human_Action_Recognition_From_Various_Data_Modalities_A_Review.pdf", "target": "Human Action Recognition", "value": "\u77e5\u8bc6"}, {"source": "Human_Action_Recognition_From_Various_Data_Modalities_A_Review.pdf", "target": "convolutional neural networks", "value": "\u77e5\u8bc6"}, {"source": "Human_Action_Recognition_From_Various_Data_Modalities_A_Review.pdf", "target": "CNNs", "value": "\u77e5\u8bc6"}, {"source": "Human_Action_Recognition_From_Various_Data_Modalities_A_Review.pdf", "target": "action recognition", "value": "\u77e5\u8bc6"}, {"source": "Human_Action_Recognition_From_Various_Data_Modalities_A_Review.pdf", "target": "neural network", "value": "\u77e5\u8bc6"}, {"source": "Human_Action_Recognition_From_Various_Data_Modalities_A_Review.pdf", "target": "feature", "value": "\u77e5\u8bc6"}, {"source": "Human_Action_Recognition_From_Various_Data_Modalities_A_Review.pdf", "target": "CNN", "value": "\u77e5\u8bc6"}, {"source": "Human_Action_Recognition_From_Various_Data_Modalities_A_Review.pdf", "target": "\u795e\u7ecf\u7f51\u7edc", "value": "\u77e5\u8bc6"}, {"source": "Human_Action_Recognition_From_Various_Data_Modalities_A_Review.pdf", "target": "RNNs", "value": "\u77e5\u8bc6"}, {"source": "Human_Action_Recognition_From_Various_Data_Modalities_A_Review.pdf", "target": "\u4eba\u673a\u4ea4\u4e92", "value": "\u77e5\u8bc6"}, {"source": "Human_Action_Recognition_From_Various_Data_Modalities_A_Review.pdf", "target": "autoencoder", "value": "\u77e5\u8bc6"}, {"source": "Human_Action_Recognition_From_Various_Data_Modalities_A_Review.pdf", "target": "\u6df1\u5ea6\u5b66\u4e60", "value": "\u77e5\u8bc6"}, {"source": "Human_Action_Recognition_From_Various_Data_Modalities_A_Review.pdf", "target": "rank pooling", "value": "\u77e5\u8bc6"}, {"source": "Human_Action_Recognition_From_Various_Data_Modalities_A_Review.pdf", "target": "NLP", "value": "\u77e5\u8bc6"}, {"source": "Human_Action_Recognition_From_Various_Data_Modalities_A_Review.pdf", "target": "multi-layer perceptron", "value": "\u77e5\u8bc6"}, {"source": "Human_Action_Recognition_From_Various_Data_Modalities_A_Review.pdf", "target": "network", "value": "\u77e5\u8bc6"}, {"source": "Human_Action_Recognition_From_Various_Data_Modalities_A_Review.pdf", "target": "CPU", "value": "\u77e5\u8bc6"}, {"source": "Human_Action_Recognition_From_Various_Data_Modalities_A_Review.pdf", "target": "semi-supervised learning", "value": "\u77e5\u8bc6"}, {"source": "Human_Action_Recognition_From_Various_Data_Modalities_A_Review.pdf", "target": "\u56fe\u50cf\u5904\u7406", "value": "\u77e5\u8bc6"}, {"source": "Human_Action_Recognition_From_Various_Data_Modalities_A_Review.pdf", "target": "Computer Vision", "value": "\u77e5\u8bc6"}, {"source": "Human_Action_Recognition_From_Various_Data_Modalities_A_Review.pdf", "target": "\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b", "value": "\u77e5\u8bc6"}, {"source": "Human_Action_Recognition_From_Various_Data_Modalities_A_Review.pdf", "target": "video processing", "value": "\u77e5\u8bc6"}, {"source": "Human_Action_Recognition_From_Various_Data_Modalities_A_Review.pdf", "target": "sparse representation", "value": "\u77e5\u8bc6"}, {"source": "Human_Action_Recognition_From_Various_Data_Modalities_A_Review.pdf", "target": "convolution", "value": "\u77e5\u8bc6"}, {"source": "Human_Action_Recognition_From_Various_Data_Modalities_A_Review.pdf", "target": "S3\u5b58\u50a8\u670d\u52a1", "value": "\u77e5\u8bc6"}, {"source": "Human_Action_Recognition_From_Various_Data_Modalities_A_Review.pdf", "target": "DeepLearning", "value": "\u77e5\u8bc6"}, {"source": "Human_Action_Recognition_From_Various_Data_Modalities_A_Review.pdf", "target": "Deep LSTM", "value": "\u77e5\u8bc6"}, {"source": "Human_Action_Recognition_From_Various_Data_Modalities_A_Review.pdf", "target": "performance", "value": "\u77e5\u8bc6"}, {"source": "Human_Action_Recognition_From_Various_Data_Modalities_A_Review.pdf", "target": "classifier", "value": "\u77e5\u8bc6"}, {"source": "Human_Action_Recognition_From_Various_Data_Modalities_A_Review.pdf", "target": "GPU", "value": "\u77e5\u8bc6"}, {"source": "Human_Action_Recognition_From_Various_Data_Modalities_A_Review.pdf", "target": "DNN", "value": "\u77e5\u8bc6"}, {"source": "Human_Action_Recognition_From_Various_Data_Modalities_A_Review.pdf", "target": "\u534f\u540c\u5b66\u4e60", "value": "\u77e5\u8bc6"}, {"source": "Human_Action_Recognition_From_Various_Data_Modalities_A_Review.pdf", "target": "VLSI", "value": "\u77e5\u8bc6"}, {"source": "Human_Action_Recognition_From_Various_Data_Modalities_A_Review.pdf", "target": "depth camera", "value": "\u77e5\u8bc6"}, {"source": "Human_Action_Recognition_From_Various_Data_Modalities_A_Review.pdf", "target": "Convolutional Neural Networks", "value": "\u77e5\u8bc6"}, {"source": "Human_Action_Recognition_From_Various_Data_Modalities_A_Review.pdf", "target": "LSTM networks", "value": "\u77e5\u8bc6"}, {"source": "Human_Action_Recognition_From_Various_Data_Modalities_A_Review.pdf", "target": "feature maps", "value": "\u77e5\u8bc6"}, {"source": "Human_Action_Recognition_From_Various_Data_Modalities_A_Review.pdf", "target": "Docker\u5bb9\u5668", "value": "\u77e5\u8bc6"}, {"source": "Human_Action_Recognition_From_Various_Data_Modalities_A_Review.pdf", "target": "\u5377\u79ef\u795e\u7ecf\u7f51\u7edc", "value": "\u77e5\u8bc6"}, {"source": "Human_Action_Recognition_From_Various_Data_Modalities_A_Review.pdf", "target": "attention", "value": "\u77e5\u8bc6"}, {"source": "Human_Action_Recognition_From_Various_Data_Modalities_A_Review.pdf", "target": "\u8ba1\u7b97\u673a\u89c6\u89c9", "value": "\u77e5\u8bc6"}, {"source": "Human_Action_Recognition_From_Various_Data_Modalities_A_Review.pdf", "target": "Neural Network", "value": "\u77e5\u8bc6"}, {"source": "Human_Action_Recognition_From_Various_Data_Modalities_A_Review.pdf", "target": "GRU", "value": "\u77e5\u8bc6"}, {"source": "IJCS_48_4_02.pdf", "target": "\u4eba\u5de5\u667a\u80fd", "value": "\u77e5\u8bc6"}, {"source": "IJCS_48_4_02.pdf", "target": "action recognition", "value": "\u77e5\u8bc6"}, {"source": "IJCS_48_4_02.pdf", "target": "SVM\u5206\u7c7b\u5668", "value": "\u77e5\u8bc6"}, {"source": "IJCS_48_4_02.pdf", "target": "CNN", "value": "\u77e5\u8bc6"}, {"source": "IJCS_48_4_02.pdf", "target": "\u795e\u7ecf\u7f51\u7edc", "value": "\u77e5\u8bc6"}, {"source": "IJCS_48_4_02.pdf", "target": "\u4eba\u673a\u4ea4\u4e92", "value": "\u77e5\u8bc6"}, {"source": "IJCS_48_4_02.pdf", "target": "\u6df1\u5ea6\u5b66\u4e60", "value": "\u77e5\u8bc6"}, {"source": "IJCS_48_4_02.pdf", "target": "knn", "value": "\u77e5\u8bc6"}, {"source": "IJCS_48_4_02.pdf", "target": "PyTorch", "value": "\u77e5\u8bc6"}, {"source": "IJCS_48_4_02.pdf", "target": "NVIDIA", "value": "\u77e5\u8bc6"}, {"source": "IJCS_48_4_02.pdf", "target": "\u673a\u5668\u5b66\u4e60", "value": "\u77e5\u8bc6"}, {"source": "IJCS_48_4_02.pdf", "target": "TensorFlow", "value": "\u77e5\u8bc6"}, {"source": "IJCS_48_4_02.pdf", "target": "TensorFlow Lite", "value": "\u77e5\u8bc6"}, {"source": "IJCS_48_4_02.pdf", "target": "epochs", "value": "\u77e5\u8bc6"}, {"source": "IJCS_48_4_02.pdf", "target": "Keras", "value": "\u77e5\u8bc6"}, {"source": "IJCS_48_4_02.pdf", "target": "\u4eba\u4f53\u59ff\u52bf\u4f30\u8ba1", "value": "\u77e5\u8bc6"}, {"source": "IJCS_48_4_02.pdf", "target": "OpenCV", "value": "\u77e5\u8bc6"}, {"source": "IJCS_48_4_02.pdf", "target": "VGG16", "value": "\u77e5\u8bc6"}, {"source": "IJCS_48_4_02.pdf", "target": "Convolutional Neural Network", "value": "\u77e5\u8bc6"}, {"source": "IJCS_48_4_02.pdf", "target": "\u591a\u6837\u6027", "value": "\u77e5\u8bc6"}, {"source": "IJCS_48_4_02.pdf", "target": "dropout", "value": "\u77e5\u8bc6"}, {"source": "IJCS_48_4_02.pdf", "target": "\u8ba1\u7b97\u673a\u89c6\u89c9", "value": "\u77e5\u8bc6"}, {"source": "IJCS_48_4_02.pdf", "target": "accuracy", "value": "\u77e5\u8bc6"}, {"source": "IJCS_48_4_02.pdf", "target": "Neural Network", "value": "\u77e5\u8bc6"}, {"source": "IJCS_48_4_02.pdf", "target": "dataset", "value": "\u77e5\u8bc6"}, {"source": "IJCS_48_4_02.pdf", "target": "\u4eba\u884c\u4e3a\u8bc6\u522b", "value": "\u77e5\u8bc6"}, {"source": "IJCS_48_4_02.pdf", "target": "Sensors", "value": "\u77e5\u8bc6"}, {"source": "IJCS_48_4_02.pdf", "target": "human activity recognition", "value": "\u77e5\u8bc6"}, {"source": "IJCS_48_4_02.pdf", "target": "\u4eba\u5de5\u795e\u7ecf\u7f51\u7edc", "value": "\u77e5\u8bc6"}, {"source": "IJCS_48_4_02.pdf", "target": "\u4eba\u673a\u8bc6\u522b", "value": "\u77e5\u8bc6"}, {"source": "IJCS_48_4_02.pdf", "target": "CNN\u7ed3\u6784", "value": "\u77e5\u8bc6"}, {"source": "IJCS_48_4_02.pdf", "target": "Kernel", "value": "\u77e5\u8bc6"}, {"source": "IJCS_48_4_02.pdf", "target": "network depth", "value": "\u77e5\u8bc6"}, {"source": "IJCS_48_4_02.pdf", "target": "Pattern Recognition", "value": "\u77e5\u8bc6"}, {"source": "IJCS_48_4_02.pdf", "target": "Machine Learning", "value": "\u77e5\u8bc6"}, {"source": "IJCS_48_4_02.pdf", "target": "Pose estimation", "value": "\u77e5\u8bc6"}, {"source": "IJCS_48_4_02.pdf", "target": "Dataset", "value": "\u77e5\u8bc6"}, {"source": "IJCS_48_4_02.pdf", "target": "COCOdataset", "value": "\u77e5\u8bc6"}, {"source": "IJCS_48_4_02.pdf", "target": "image resolution", "value": "\u77e5\u8bc6"}, {"source": "IJCS_48_4_02.pdf", "target": "recall", "value": "\u77e5\u8bc6"}, {"source": "IJCS_48_4_02.pdf", "target": "\u4eba\u4f53\u52a8\u4f5c\u8bc6\u522b", "value": "\u77e5\u8bc6"}, {"source": "IJCS_48_4_02.pdf", "target": "precision", "value": "\u77e5\u8bc6"}, {"source": "IJCS_48_4_02.pdf", "target": "Part Affinity Fields", "value": "\u77e5\u8bc6"}, {"source": "IJCS_48_4_02.pdf", "target": "OpenPose", "value": "\u77e5\u8bc6"}, {"source": "IJCS_48_4_02.pdf", "target": "confidence", "value": "\u77e5\u8bc6"}, {"source": "IJCS_48_4_02.pdf", "target": "EfficientNet", "value": "\u77e5\u8bc6"}, {"source": "IJCS_48_4_02.pdf", "target": "Caffe", "value": "\u77e5\u8bc6"}, {"source": "IJCS_48_4_02.pdf", "target": "GPU memory", "value": "\u77e5\u8bc6"}, {"source": "IJCS_48_4_02.pdf", "target": "Object Detection", "value": "\u77e5\u8bc6"}, {"source": "IJCS_48_4_02.pdf", "target": "Fusion", "value": "\u77e5\u8bc6"}, {"source": "Intelligent Video Analytics for Human Action Recognition The State of Knowledge.pdf", "target": "\u4eba\u5de5\u667a\u80fd", "value": "\u77e5\u8bc6"}, {"source": "Intelligent Video Analytics for Human Action Recognition The State of Knowledge.pdf", "target": "\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc", "value": "\u77e5\u8bc6"}, {"source": "Intelligent Video Analytics for Human Action Recognition The State of Knowledge.pdf", "target": "LSTM", "value": "\u77e5\u8bc6"}, {"source": "Intelligent Video Analytics for Human Action Recognition The State of Knowledge.pdf", "target": "\u4eba\u8138\u8bc6\u522b", "value": "\u77e5\u8bc6"}, {"source": "Intelligent Video Analytics for Human Action Recognition The State of Knowledge.pdf", "target": "ImageNet", "value": "\u77e5\u8bc6"}, {"source": "Intelligent Video Analytics for Human Action Recognition The State of Knowledge.pdf", "target": "Human Action Recognition", "value": "\u77e5\u8bc6"}, {"source": "Intelligent Video Analytics for Human Action Recognition The State of Knowledge.pdf", "target": "segmentation", "value": "\u77e5\u8bc6"}, {"source": "Intelligent Video Analytics for Human Action Recognition The State of Knowledge.pdf", "target": "CNNs", "value": "\u77e5\u8bc6"}, {"source": "Intelligent Video Analytics for Human Action Recognition The State of Knowledge.pdf", "target": "action recognition", "value": "\u77e5\u8bc6"}, {"source": "Intelligent Video Analytics for Human Action Recognition The State of Knowledge.pdf", "target": "UCF101", "value": "\u77e5\u8bc6"}, {"source": "Intelligent Video Analytics for Human Action Recognition The State of Knowledge.pdf", "target": "RGB image", "value": "\u77e5\u8bc6"}, {"source": "Intelligent Video Analytics for Human Action Recognition The State of Knowledge.pdf", "target": "CNN", "value": "\u77e5\u8bc6"}, {"source": "Intelligent Video Analytics for Human Action Recognition The State of Knowledge.pdf", "target": "semantic segmentation", "value": "\u77e5\u8bc6"}, {"source": "Intelligent Video Analytics for Human Action Recognition The State of Knowledge.pdf", "target": "SVM", "value": "\u77e5\u8bc6"}, {"source": "Intelligent Video Analytics for Human Action Recognition The State of Knowledge.pdf", "target": "\u795e\u7ecf\u7f51\u7edc", "value": "\u77e5\u8bc6"}, {"source": "Intelligent Video Analytics for Human Action Recognition The State of Knowledge.pdf", "target": "3D\u5377\u79ef\u795e\u7ecf\u7f51\u7edc", "value": "\u77e5\u8bc6"}, {"source": "Intelligent Video Analytics for Human Action Recognition The State of Knowledge.pdf", "target": "RNNs", "value": "\u77e5\u8bc6"}, {"source": "Intelligent Video Analytics for Human Action Recognition The State of Knowledge.pdf", "target": "AlexNet", "value": "\u77e5\u8bc6"}, {"source": "Intelligent Video Analytics for Human Action Recognition The State of Knowledge.pdf", "target": "motion boundary description", "value": "\u77e5\u8bc6"}, {"source": "Intelligent Video Analytics for Human Action Recognition The State of Knowledge.pdf", "target": "\u6df1\u5ea6\u5b66\u4e60", "value": "\u77e5\u8bc6"}, {"source": "Intelligent Video Analytics for Human Action Recognition The State of Knowledge.pdf", "target": "\u52a8\u6001\u56fe\u50cf\u7f51\u7edc", "value": "\u77e5\u8bc6"}, {"source": "Intelligent Video Analytics for Human Action Recognition The State of Knowledge.pdf", "target": "\u53cd\u5411\u4f20\u64ad", "value": "\u77e5\u8bc6"}, {"source": "Intelligent Video Analytics for Human Action Recognition The State of Knowledge.pdf", "target": "CNN\u67b6\u6784", "value": "\u77e5\u8bc6"}, {"source": "Intelligent Video Analytics for Human Action Recognition The State of Knowledge.pdf", "target": "Bert", "value": "\u77e5\u8bc6"}, {"source": "Intelligent Video Analytics for Human Action Recognition The State of Knowledge.pdf", "target": "Optimization", "value": "\u77e5\u8bc6"}, {"source": "Intelligent Video Analytics for Human Action Recognition The State of Knowledge.pdf", "target": "\u56fe\u50cf\u8bc6\u522b", "value": "\u77e5\u8bc6"}, {"source": "Intelligent Video Analytics for Human Action Recognition The State of Knowledge.pdf", "target": "\u6b63\u5219\u5316", "value": "\u77e5\u8bc6"}, {"source": "Intelligent Video Analytics for Human Action Recognition The State of Knowledge.pdf", "target": "\u56fe\u50cf\u5904\u7406", "value": "\u77e5\u8bc6"}, {"source": "Intelligent Video Analytics for Human Action Recognition The State of Knowledge.pdf", "target": "Computer Vision", "value": "\u77e5\u8bc6"}, {"source": "Intelligent Video Analytics for Human Action Recognition The State of Knowledge.pdf", "target": "storage", "value": "\u77e5\u8bc6"}, {"source": "Intelligent Video Analytics for Human Action Recognition The State of Knowledge.pdf", "target": "Dense", "value": "\u77e5\u8bc6"}, {"source": "Intelligent Video Analytics for Human Action Recognition The State of Knowledge.pdf", "target": "TensorFlow", "value": "\u77e5\u8bc6"}, {"source": "Intelligent Video Analytics for Human Action Recognition The State of Knowledge.pdf", "target": "IoT", "value": "\u77e5\u8bc6"}, {"source": "Intelligent Video Analytics for Human Action Recognition The State of Knowledge.pdf", "target": "\u4eba\u4f53\u59ff\u52bf\u4f30\u8ba1", "value": "\u77e5\u8bc6"}, {"source": "Intelligent Video Analytics for Human Action Recognition The State of Knowledge.pdf", "target": "DNN", "value": "\u77e5\u8bc6"}, {"source": "Intelligent Video Analytics for Human Action Recognition The State of Knowledge.pdf", "target": "surveillance videos", "value": "\u77e5\u8bc6"}, {"source": "Intelligent Video Analytics for Human Action Recognition The State of Knowledge.pdf", "target": "cloud computing", "value": "\u77e5\u8bc6"}, {"source": "Intelligent Video Analytics for Human Action Recognition The State of Knowledge.pdf", "target": "\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5", "value": "\u77e5\u8bc6"}, {"source": "Intelligent Video Analytics for Human Action Recognition The State of Knowledge.pdf", "target": "Network", "value": "\u77e5\u8bc6"}, {"source": "Intelligent Video Analytics for Human Action Recognition The State of Knowledge.pdf", "target": "Deep Learning", "value": "\u77e5\u8bc6"}, {"source": "Intelligent Video Analytics for Human Action Recognition The State of Knowledge.pdf", "target": "LSTM networks", "value": "\u77e5\u8bc6"}, {"source": "Intelligent Video Analytics for Human Action Recognition The State of Knowledge.pdf", "target": "object tracking", "value": "\u77e5\u8bc6"}, {"source": "Intelligent Video Analytics for Human Action Recognition The State of Knowledge.pdf", "target": "Hessian", "value": "\u77e5\u8bc6"}, {"source": "Intelligent Video Analytics for Human Action Recognition The State of Knowledge.pdf", "target": "\u7b97\u6cd5", "value": "\u77e5\u8bc6"}, {"source": "Intelligent Video Analytics for Human Action Recognition The State of Knowledge.pdf", "target": "attention", "value": "\u77e5\u8bc6"}, {"source": "Intelligent Video Analytics for Human Action Recognition The State of Knowledge.pdf", "target": "\u8ba1\u7b97\u673a\u89c6\u89c9", "value": "\u77e5\u8bc6"}, {"source": "Intelligent Video Analytics for Human Action Recognition The State of Knowledge.pdf", "target": "Neural Network", "value": "\u77e5\u8bc6"}, {"source": "Intelligent Video Analytics for Human Action Recognition The State of Knowledge.pdf", "target": "object detection", "value": "\u77e5\u8bc6"}, {"source": "Intelligent Video Analytics for Human Action Recognition The State of Knowledge.pdf", "target": "Intel", "value": "\u77e5\u8bc6"}, {"source": "Intelligent Video Analytics for Human Action Recognition The State of Knowledge.pdf", "target": "ResNet", "value": "\u77e5\u8bc6"}, {"source": "International Journal of Intelligent Systems - 2024 - Dastbaravardeh - Channel Attention\u2010Based Approach with Autoencoder.pdf", "target": "\u4eba\u5de5\u667a\u80fd", "value": "\u77e5\u8bc6"}, {"source": "International Journal of Intelligent Systems - 2024 - Dastbaravardeh - Channel Attention\u2010Based Approach with Autoencoder.pdf", "target": "\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc", "value": "\u77e5\u8bc6"}, {"source": "International Journal of Intelligent Systems - 2024 - Dastbaravardeh - Channel Attention\u2010Based Approach with Autoencoder.pdf", "target": "learning", "value": "\u77e5\u8bc6"}, {"source": "International Journal of Intelligent Systems - 2024 - Dastbaravardeh - Channel Attention\u2010Based Approach with Autoencoder.pdf", "target": "pooling", "value": "\u77e5\u8bc6"}, {"source": "International Journal of Intelligent Systems - 2024 - Dastbaravardeh - Channel Attention\u2010Based Approach with Autoencoder.pdf", "target": "fine-tuning", "value": "\u77e5\u8bc6"}, {"source": "International Journal of Intelligent Systems - 2024 - Dastbaravardeh - Channel Attention\u2010Based Approach with Autoencoder.pdf", "target": "LSTM", "value": "\u77e5\u8bc6"}, {"source": "International Journal of Intelligent Systems - 2024 - Dastbaravardeh - Channel Attention\u2010Based Approach with Autoencoder.pdf", "target": "neural networks", "value": "\u77e5\u8bc6"}, {"source": "International Journal of Intelligent Systems - 2024 - Dastbaravardeh - Channel Attention\u2010Based Approach with Autoencoder.pdf", "target": "CNNs", "value": "\u77e5\u8bc6"}, {"source": "International Journal of Intelligent Systems - 2024 - Dastbaravardeh - Channel Attention\u2010Based Approach with Autoencoder.pdf", "target": "action recognition", "value": "\u77e5\u8bc6"}, {"source": "International Journal of Intelligent Systems - 2024 - Dastbaravardeh - Channel Attention\u2010Based Approach with Autoencoder.pdf", "target": "UCF101", "value": "\u77e5\u8bc6"}, {"source": "International Journal of Intelligent Systems - 2024 - Dastbaravardeh - Channel Attention\u2010Based Approach with Autoencoder.pdf", "target": "CNN", "value": "\u77e5\u8bc6"}, {"source": "International Journal of Intelligent Systems - 2024 - Dastbaravardeh - Channel Attention\u2010Based Approach with Autoencoder.pdf", "target": "\u795e\u7ecf\u7f51\u7edc", "value": "\u77e5\u8bc6"}, {"source": "International Journal of Intelligent Systems - 2024 - Dastbaravardeh - Channel Attention\u2010Based Approach with Autoencoder.pdf", "target": "videoframes", "value": "\u77e5\u8bc6"}, {"source": "International Journal of Intelligent Systems - 2024 - Dastbaravardeh - Channel Attention\u2010Based Approach with Autoencoder.pdf", "target": "video frames", "value": "\u77e5\u8bc6"}, {"source": "International Journal of Intelligent Systems - 2024 - Dastbaravardeh - Channel Attention\u2010Based Approach with Autoencoder.pdf", "target": "3D\u5377\u79ef", "value": "\u77e5\u8bc6"}, {"source": "International Journal of Intelligent Systems - 2024 - Dastbaravardeh - Channel Attention\u2010Based Approach with Autoencoder.pdf", "target": "\u6df1\u5ea6\u5b66\u4e60", "value": "\u77e5\u8bc6"}, {"source": "International Journal of Intelligent Systems - 2024 - Dastbaravardeh - Channel Attention\u2010Based Approach with Autoencoder.pdf", "target": "CNN\u67b6\u6784", "value": "\u77e5\u8bc6"}, {"source": "International Journal of Intelligent Systems - 2024 - Dastbaravardeh - Channel Attention\u2010Based Approach with Autoencoder.pdf", "target": "flatten", "value": "\u77e5\u8bc6"}, {"source": "International Journal of Intelligent Systems - 2024 - Dastbaravardeh - Channel Attention\u2010Based Approach with Autoencoder.pdf", "target": "\u56fe\u50cf\u5904\u7406", "value": "\u77e5\u8bc6"}, {"source": "International Journal of Intelligent Systems - 2024 - Dastbaravardeh - Channel Attention\u2010Based Approach with Autoencoder.pdf", "target": "image recognition", "value": "\u77e5\u8bc6"}, {"source": "International Journal of Intelligent Systems - 2024 - Dastbaravardeh - Channel Attention\u2010Based Approach with Autoencoder.pdf", "target": "Accuracy", "value": "\u77e5\u8bc6"}, {"source": "International Journal of Intelligent Systems - 2024 - Dastbaravardeh - Channel Attention\u2010Based Approach with Autoencoder.pdf", "target": "Kubernetes\u7ba1\u7406\u7cfb\u7edf", "value": "\u77e5\u8bc6"}, {"source": "International Journal of Intelligent Systems - 2024 - Dastbaravardeh - Channel Attention\u2010Based Approach with Autoencoder.pdf", "target": "video processing", "value": "\u77e5\u8bc6"}, {"source": "International Journal of Intelligent Systems - 2024 - Dastbaravardeh - Channel Attention\u2010Based Approach with Autoencoder.pdf", "target": "\u673a\u5668\u5b66\u4e60", "value": "\u77e5\u8bc6"}, {"source": "International Journal of Intelligent Systems - 2024 - Dastbaravardeh - Channel Attention\u2010Based Approach with Autoencoder.pdf", "target": "convolution", "value": "\u77e5\u8bc6"}, {"source": "International Journal of Intelligent Systems - 2024 - Dastbaravardeh - Channel Attention\u2010Based Approach with Autoencoder.pdf", "target": "S3\u5b58\u50a8\u670d\u52a1", "value": "\u77e5\u8bc6"}, {"source": "International Journal of Intelligent Systems - 2024 - Dastbaravardeh - Channel Attention\u2010Based Approach with Autoencoder.pdf", "target": "DeepLearning", "value": "\u77e5\u8bc6"}, {"source": "International Journal of Intelligent Systems - 2024 - Dastbaravardeh - Channel Attention\u2010Based Approach with Autoencoder.pdf", "target": "ReLU", "value": "\u77e5\u8bc6"}, {"source": "International Journal of Intelligent Systems - 2024 - Dastbaravardeh - Channel Attention\u2010Based Approach with Autoencoder.pdf", "target": "Training", "value": "\u77e5\u8bc6"}, {"source": "International Journal of Intelligent Systems - 2024 - Dastbaravardeh - Channel Attention\u2010Based Approach with Autoencoder.pdf", "target": "SGD", "value": "\u77e5\u8bc6"}, {"source": "International Journal of Intelligent Systems - 2024 - Dastbaravardeh - Channel Attention\u2010Based Approach with Autoencoder.pdf", "target": "IoT", "value": "\u77e5\u8bc6"}, {"source": "International Journal of Intelligent Systems - 2024 - Dastbaravardeh - Channel Attention\u2010Based Approach with Autoencoder.pdf", "target": "Deep learning", "value": "\u77e5\u8bc6"}, {"source": "International Journal of Intelligent Systems - 2024 - Dastbaravardeh - Channel Attention\u2010Based Approach with Autoencoder.pdf", "target": "transfer", "value": "\u77e5\u8bc6"}, {"source": "International Journal of Intelligent Systems - 2024 - Dastbaravardeh - Channel Attention\u2010Based Approach with Autoencoder.pdf", "target": "Convolutional Neural Networks", "value": "\u77e5\u8bc6"}, {"source": "International Journal of Intelligent Systems - 2024 - Dastbaravardeh - Channel Attention\u2010Based Approach with Autoencoder.pdf", "target": "license", "value": "\u77e5\u8bc6"}, {"source": "International Journal of Intelligent Systems - 2024 - Dastbaravardeh - Channel Attention\u2010Based Approach with Autoencoder.pdf", "target": "feature maps", "value": "\u77e5\u8bc6"}, {"source": "International Journal of Intelligent Systems - 2024 - Dastbaravardeh - Channel Attention\u2010Based Approach with Autoencoder.pdf", "target": "\u5377\u79ef\u795e\u7ecf\u7f51\u7edc", "value": "\u77e5\u8bc6"}, {"source": "International Journal of Intelligent Systems - 2024 - Dastbaravardeh - Channel Attention\u2010Based Approach with Autoencoder.pdf", "target": "\u6fc0\u6d3b\u51fd\u6570", "value": "\u77e5\u8bc6"}, {"source": "International Journal of Intelligent Systems - 2024 - Dastbaravardeh - Channel Attention\u2010Based Approach with Autoencoder.pdf", "target": "training", "value": "\u77e5\u8bc6"}, {"source": "International Journal of Intelligent Systems - 2024 - Dastbaravardeh - Channel Attention\u2010Based Approach with Autoencoder.pdf", "target": "inference", "value": "\u77e5\u8bc6"}, {"source": "International Journal of Intelligent Systems - 2024 - Dastbaravardeh - Channel Attention\u2010Based Approach with Autoencoder.pdf", "target": "accuracy", "value": "\u77e5\u8bc6"}, {"source": "International Journal of Intelligent Systems - 2024 - Dastbaravardeh - Channel Attention\u2010Based Approach with Autoencoder.pdf", "target": "ReLU\u51fd\u6570", "value": "\u77e5\u8bc6"}, {"source": "International Journal of Intelligent Systems - 2024 - Dastbaravardeh - Channel Attention\u2010Based Approach with Autoencoder.pdf", "target": "ResNet", "value": "\u77e5\u8bc6"}, {"source": "International Journal of Intelligent Systems - 2024 - Dastbaravardeh - Channel Attention\u2010Based Approach with Autoencoder.pdf", "target": "\u635f\u5931\u51fd\u6570", "value": "\u77e5\u8bc6"}, {"source": "International Journal of Intelligent Systems - 2024 - Dastbaravardeh - Channel Attention\u2010Based Approach with Autoencoder.pdf", "target": "signal processing", "value": "\u77e5\u8bc6"}, {"source": "International Journal of Intelligent Systems - 2024 - Dastbaravardeh - Channel Attention\u2010Based Approach with Autoencoder.pdf", "target": "\u8d85\u5206\u8fa8\u7387", "value": "\u77e5\u8bc6"}, {"source": "International Journal of Intelligent Systems - 2024 - Dastbaravardeh - Channel Attention\u2010Based Approach with Autoencoder.pdf", "target": "maxpooling", "value": "\u77e5\u8bc6"}, {"source": "International Journal of Intelligent Systems - 2024 - Dastbaravardeh - Channel Attention\u2010Based Approach with Autoencoder.pdf", "target": "sampling", "value": "\u77e5\u8bc6"}, {"source": "International Journal of Intelligent Systems - 2024 - Dastbaravardeh - Channel Attention\u2010Based Approach with Autoencoder.pdf", "target": "\u7279\u5f81\u63d0\u53d6", "value": "\u77e5\u8bc6"}, {"source": "International Journal of Intelligent Systems - 2024 - Dastbaravardeh - Channel Attention\u2010Based Approach with Autoencoder.pdf", "target": "RNN", "value": "\u77e5\u8bc6"}, {"source": "LLM-v1.0.0.pdf", "target": "bash", "value": "\u77e5\u8bc6"}, {"source": "LLM-v1.0.0.pdf", "target": "\u4eba\u5de5\u667a\u80fd", "value": "\u77e5\u8bc6"}, {"source": "LLM-v1.0.0.pdf", "target": "segmentation", "value": "\u77e5\u8bc6"}, {"source": "LLM-v1.0.0.pdf", "target": "SVM", "value": "\u77e5\u8bc6"}, {"source": "LLM-v1.0.0.pdf", "target": "\u65e0\u76d1\u7763\u5b66\u4e60", "value": "\u77e5\u8bc6"}, {"source": "LLM-v1.0.0.pdf", "target": "\u6570\u636e\u589e\u5f3a", "value": "\u77e5\u8bc6"}, {"source": "LLM-v1.0.0.pdf", "target": "\u6df1\u5ea6\u5b66\u4e60", "value": "\u77e5\u8bc6"}, {"source": "LLM-v1.0.0.pdf", "target": "Kubernetes", "value": "\u77e5\u8bc6"}, {"source": "LLM-v1.0.0.pdf", "target": "NLP", "value": "\u77e5\u8bc6"}, {"source": "LLM-v1.0.0.pdf", "target": "embeddings", "value": "\u77e5\u8bc6"}, {"source": "LLM-v1.0.0.pdf", "target": "Mysql", "value": "\u77e5\u8bc6"}, {"source": "LLM-v1.0.0.pdf", "target": "Axes", "value": "\u77e5\u8bc6"}, {"source": "LLM-v1.0.0.pdf", "target": "\u56fe\u50cf\u5904\u7406", "value": "\u77e5\u8bc6"}, {"source": "LLM-v1.0.0.pdf", "target": "PyTorch", "value": "\u77e5\u8bc6"}, {"source": "LLM-v1.0.0.pdf", "target": "tokenization", "value": "\u77e5\u8bc6"}, {"source": "LLM-v1.0.0.pdf", "target": "Kubernetes\u7ba1\u7406\u7cfb\u7edf", "value": "\u77e5\u8bc6"}, {"source": "LLM-v1.0.0.pdf", "target": "temperature", "value": "\u77e5\u8bc6"}, {"source": "LLM-v1.0.0.pdf", "target": "\u4e91\u8ba1\u7b97\u5e73\u53f0", "value": "\u77e5\u8bc6"}, {"source": "LLM-v1.0.0.pdf", "target": "\u673a\u5668\u5b66\u4e60", "value": "\u77e5\u8bc6"}, {"source": "LLM-v1.0.0.pdf", "target": "S3\u5b58\u50a8\u670d\u52a1", "value": "\u77e5\u8bc6"}, {"source": "LLM-v1.0.0.pdf", "target": "Python", "value": "\u77e5\u8bc6"}, {"source": "LLM-v1.0.0.pdf", "target": "github", "value": "\u77e5\u8bc6"}, {"source": "LLM-v1.0.0.pdf", "target": "Docker", "value": "\u77e5\u8bc6"}, {"source": "LLM-v1.0.0.pdf", "target": "Android", "value": "\u77e5\u8bc6"}, {"source": "LLM-v1.0.0.pdf", "target": "\u538b\u7f29\u6280\u672f", "value": "\u77e5\u8bc6"}, {"source": "LLM-v1.0.0.pdf", "target": "cloud\u8ba1\u7b97\u5e73\u53f0", "value": "\u77e5\u8bc6"}, {"source": "LLM-v1.0.0.pdf", "target": "cloud computing", "value": "\u77e5\u8bc6"}, {"source": "LLM-v1.0.0.pdf", "target": "\u5bb9\u5668\u7f16\u6392", "value": "\u77e5\u8bc6"}, {"source": "LLM-v1.0.0.pdf", "target": "\u5b66\u4e60\u7b97\u6cd5", "value": "\u77e5\u8bc6"}, {"source": "LLM-v1.0.0.pdf", "target": "natural language processing", "value": "\u77e5\u8bc6"}, {"source": "LLM-v1.0.0.pdf", "target": "\u81ea\u7136\u8bed\u8a00\u5904\u7406", "value": "\u77e5\u8bc6"}, {"source": "LLM-v1.0.0.pdf", "target": "Docker\u5bb9\u5668", "value": "\u77e5\u8bc6"}, {"source": "LLM-v1.0.0.pdf", "target": "service", "value": "\u77e5\u8bc6"}, {"source": "LLM-v1.0.0.pdf", "target": "Button", "value": "\u77e5\u8bc6"}, {"source": "LLM-v1.0.0.pdf", "target": "\u7ec6\u80de\u7ed3\u6784", "value": "\u77e5\u8bc6"}, {"source": "LLM-v1.0.0.pdf", "target": "primary", "value": "\u77e5\u8bc6"}, {"source": "LLM-v1.0.0.pdf", "target": "cross-platform", "value": "\u77e5\u8bc6"}, {"source": "LLM-v1.0.0.pdf", "target": "\u7b97\u6cd5", "value": "\u77e5\u8bc6"}, {"source": "LLM-v1.0.0.pdf", "target": "pandas", "value": "\u77e5\u8bc6"}, {"source": "LLM-v1.0.0.pdf", "target": "numpy", "value": "\u77e5\u8bc6"}, {"source": "LLM-v1.0.0.pdf", "target": "tokenizer", "value": "\u77e5\u8bc6"}, {"source": "LLM-v1.0.0.pdf", "target": "\u667a\u80fd\u624b\u673a", "value": "\u77e5\u8bc6"}, {"source": "LLM-v1.0.0.pdf", "target": "NumPy", "value": "\u77e5\u8bc6"}, {"source": "LLM-v1.0.0.pdf", "target": "\u81ea\u52a8\u5316\u90e8\u7f72", "value": "\u77e5\u8bc6"}, {"source": "LLM-v1.0.0.pdf", "target": "machine learning", "value": "\u77e5\u8bc6"}, {"source": "LLM-v1.0.0.pdf", "target": "similarity", "value": "\u77e5\u8bc6"}, {"source": "LLM-v1.0.0.pdf", "target": "axes", "value": "\u77e5\u8bc6"}, {"source": "LLM-v1.0.0.pdf", "target": "Natural Language Processing", "value": "\u77e5\u8bc6"}, {"source": "LLM-v1.0.0.pdf", "target": "smartphone", "value": "\u77e5\u8bc6"}, {"source": "LLM-v1.0.0.pdf", "target": "density", "value": "\u77e5\u8bc6"}, {"source": "Mask R-CNN.pdf", "target": "\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc", "value": "\u77e5\u8bc6"}, {"source": "Mask R-CNN.pdf", "target": "segmentation", "value": "\u77e5\u8bc6"}, {"source": "Mask R-CNN.pdf", "target": "convolutional neural networks", "value": "\u77e5\u8bc6"}, {"source": "Mask R-CNN.pdf", "target": "CNN", "value": "\u77e5\u8bc6"}, {"source": "Mask R-CNN.pdf", "target": "semantic segmentation", "value": "\u77e5\u8bc6"}, {"source": "Mask R-CNN.pdf", "target": "\u6df1\u5ea6\u5b66\u4e60", "value": "\u77e5\u8bc6"}, {"source": "Mask R-CNN.pdf", "target": "Kubernetes", "value": "\u77e5\u8bc6"}, {"source": "Mask R-CNN.pdf", "target": "CPU", "value": "\u77e5\u8bc6"}, {"source": "Mask R-CNN.pdf", "target": "APM", "value": "\u77e5\u8bc6"}, {"source": "Mask R-CNN.pdf", "target": "class", "value": "\u77e5\u8bc6"}, {"source": "Mask R-CNN.pdf", "target": "softmax", "value": "\u77e5\u8bc6"}, {"source": "Mask R-CNN.pdf", "target": "S3\u5b58\u50a8\u670d\u52a1", "value": "\u77e5\u8bc6"}, {"source": "Mask R-CNN.pdf", "target": "anchors", "value": "\u77e5\u8bc6"}, {"source": "Mask R-CNN.pdf", "target": "momentum", "value": "\u77e5\u8bc6"}, {"source": "Mask R-CNN.pdf", "target": "ReLU", "value": "\u77e5\u8bc6"}, {"source": "Mask R-CNN.pdf", "target": "IoU", "value": "\u77e5\u8bc6"}, {"source": "Mask R-CNN.pdf", "target": "Docker", "value": "\u77e5\u8bc6"}, {"source": "Mask R-CNN.pdf", "target": "GPU", "value": "\u77e5\u8bc6"}, {"source": "Mask R-CNN.pdf", "target": "inception-resnet", "value": "\u77e5\u8bc6"}, {"source": "Mask R-CNN.pdf", "target": "Convolutional Neural Networks", "value": "\u77e5\u8bc6"}, {"source": "Mask R-CNN.pdf", "target": "classification", "value": "\u77e5\u8bc6"}, {"source": "Mask R-CNN.pdf", "target": "\u5bb9\u5668\u7f16\u6392", "value": "\u77e5\u8bc6"}, {"source": "Mask R-CNN.pdf", "target": "Docker\u5bb9\u5668", "value": "\u77e5\u8bc6"}, {"source": "Mask R-CNN.pdf", "target": "training", "value": "\u77e5\u8bc6"}, {"source": "Mask R-CNN.pdf", "target": "sigmoid", "value": "\u77e5\u8bc6"}, {"source": "Mask R-CNN.pdf", "target": "branch", "value": "\u77e5\u8bc6"}, {"source": "Mask R-CNN.pdf", "target": "fork", "value": "\u77e5\u8bc6"}, {"source": "Mask R-CNN.pdf", "target": "cross-entropy\u635f\u5931", "value": "\u77e5\u8bc6"}, {"source": "Mask R-CNN.pdf", "target": "accuracy", "value": "\u77e5\u8bc6"}, {"source": "Mask R-CNN.pdf", "target": "object detection", "value": "\u77e5\u8bc6"}, {"source": "Mask R-CNN.pdf", "target": "ResNet", "value": "\u77e5\u8bc6"}, {"source": "Mask R-CNN.pdf", "target": "R-CNN", "value": "\u77e5\u8bc6"}, {"source": "Mask R-CNN.pdf", "target": "learning rate", "value": "\u77e5\u8bc6"}, {"source": "Mask R-CNN.pdf", "target": "AWS", "value": "\u77e5\u8bc6"}, {"source": "Mask R-CNN.pdf", "target": "baseline", "value": "\u77e5\u8bc6"}, {"source": "Mask R-CNN.pdf", "target": "\u8d1f\u8f7d\u5747\u8861\u5668", "value": "\u77e5\u8bc6"}, {"source": "Mask R-CNN.pdf", "target": "classi\ufb01cation", "value": "\u77e5\u8bc6"}, {"source": "Mask R-CNN.pdf", "target": "Deep residual learning", "value": "\u77e5\u8bc6"}, {"source": "Mask R-CNN.pdf", "target": "presentation", "value": "\u77e5\u8bc6"}, {"source": "Mask R-CNN.pdf", "target": "training data", "value": "\u77e5\u8bc6"}, {"source": "Mask R-CNN.pdf", "target": "classifiers", "value": "\u77e5\u8bc6"}, {"source": "Mask R-CNN.pdf", "target": "robustness", "value": "\u77e5\u8bc6"}, {"source": "Mask R-CNN.pdf", "target": "Restricted Boltzmann Machines", "value": "\u77e5\u8bc6"}, {"source": "Mask R-CNN.pdf", "target": "FCN", "value": "\u77e5\u8bc6"}, {"source": "Mask R-CNN.pdf", "target": "unsupervised learning", "value": "\u77e5\u8bc6"}, {"source": "Mask R-CNN.pdf", "target": "feature extraction", "value": "\u77e5\u8bc6"}, {"source": "Mask R-CNN.pdf", "target": "FCNs", "value": "\u77e5\u8bc6"}, {"source": "Mask R-CNN.pdf", "target": "convolutions", "value": "\u77e5\u8bc6"}, {"source": "Mask R-CNN.pdf", "target": "pipeline", "value": "\u77e5\u8bc6"}, {"source": "Mask R-CNN.pdf", "target": "Human Pose Estimation", "value": "\u77e5\u8bc6"}, {"source": "OpenPose Realtime Multi-Person 2D PoseEstimation using Part Affinity Fields.pdf", "target": "\u4eba\u8138\u8bc6\u522b", "value": "\u77e5\u8bc6"}, {"source": "OpenPose Realtime Multi-Person 2D PoseEstimation using Part Affinity Fields.pdf", "target": "CNNs", "value": "\u77e5\u8bc6"}, {"source": "OpenPose Realtime Multi-Person 2D PoseEstimation using Part Affinity Fields.pdf", "target": "CNN", "value": "\u77e5\u8bc6"}, {"source": "OpenPose Realtime Multi-Person 2D PoseEstimation using Part Affinity Fields.pdf", "target": "DenseNet", "value": "\u77e5\u8bc6"}, {"source": "OpenPose Realtime Multi-Person 2D PoseEstimation using Part Affinity Fields.pdf", "target": "NIPS", "value": "\u77e5\u8bc6"}, {"source": "OpenPose Realtime Multi-Person 2D PoseEstimation using Part Affinity Fields.pdf", "target": "\u6df1\u5ea6\u5b66\u4e60", "value": "\u77e5\u8bc6"}, {"source": "OpenPose Realtime Multi-Person 2D PoseEstimation using Part Affinity Fields.pdf", "target": "\u56fe\u50cf\u68c0\u6d4b", "value": "\u77e5\u8bc6"}, {"source": "OpenPose Realtime Multi-Person 2D PoseEstimation using Part Affinity Fields.pdf", "target": "CPU", "value": "\u77e5\u8bc6"}, {"source": "OpenPose Realtime Multi-Person 2D PoseEstimation using Part Affinity Fields.pdf", "target": "APM", "value": "\u77e5\u8bc6"}, {"source": "OpenPose Realtime Multi-Person 2D PoseEstimation using Part Affinity Fields.pdf", "target": "\u56fe\u50cf\u5904\u7406", "value": "\u77e5\u8bc6"}, {"source": "OpenPose Realtime Multi-Person 2D PoseEstimation using Part Affinity Fields.pdf", "target": "\u7f51\u7edc\u67b6\u6784", "value": "\u77e5\u8bc6"}, {"source": "OpenPose Realtime Multi-Person 2D PoseEstimation using Part Affinity Fields.pdf", "target": "image recognition", "value": "\u77e5\u8bc6"}, {"source": "OpenPose Realtime Multi-Person 2D PoseEstimation using Part Affinity Fields.pdf", "target": "\u4e91\u8ba1\u7b97\u5e73\u53f0", "value": "\u77e5\u8bc6"}, {"source": "OpenPose Realtime Multi-Person 2D PoseEstimation using Part Affinity Fields.pdf", "target": "\u673a\u5668\u5b66\u4e60", "value": "\u77e5\u8bc6"}, {"source": "OpenPose Realtime Multi-Person 2D PoseEstimation using Part Affinity Fields.pdf", "target": "S3\u5b58\u50a8\u670d\u52a1", "value": "\u77e5\u8bc6"}, {"source": "OpenPose Realtime Multi-Person 2D PoseEstimation using Part Affinity Fields.pdf", "target": "IoU", "value": "\u77e5\u8bc6"}, {"source": "OpenPose Realtime Multi-Person 2D PoseEstimation using Part Affinity Fields.pdf", "target": "GPU", "value": "\u77e5\u8bc6"}, {"source": "OpenPose Realtime Multi-Person 2D PoseEstimation using Part Affinity Fields.pdf", "target": "\u4eba\u4f53\u59ff\u52bf\u4f30\u8ba1", "value": "\u77e5\u8bc6"}, {"source": "OpenPose Realtime Multi-Person 2D PoseEstimation using Part Affinity Fields.pdf", "target": "DNN", "value": "\u77e5\u8bc6"}, {"source": "OpenPose Realtime Multi-Person 2D PoseEstimation using Part Affinity Fields.pdf", "target": "\u975e\u6781\u5927\u503c\u6291\u5236", "value": "\u77e5\u8bc6"}, {"source": "OpenPose Realtime Multi-Person 2D PoseEstimation using Part Affinity Fields.pdf", "target": "\u5bb9\u5668\u7f16\u6392", "value": "\u77e5\u8bc6"}, {"source": "OpenPose Realtime Multi-Person 2D PoseEstimation using Part Affinity Fields.pdf", "target": "\u5377\u79ef\u795e\u7ecf\u7f51\u7edc", "value": "\u77e5\u8bc6"}, {"source": "OpenPose Realtime Multi-Person 2D PoseEstimation using Part Affinity Fields.pdf", "target": "\u8ba1\u7b97\u673a\u89c6\u89c9", "value": "\u77e5\u8bc6"}, {"source": "OpenPose Realtime Multi-Person 2D PoseEstimation using Part Affinity Fields.pdf", "target": "ResNet", "value": "\u77e5\u8bc6"}, {"source": "OpenPose Realtime Multi-Person 2D PoseEstimation using Part Affinity Fields.pdf", "target": "DARPA", "value": "\u77e5\u8bc6"}, {"source": "OpenPose Realtime Multi-Person 2D PoseEstimation using Part Affinity Fields.pdf", "target": "\u635f\u5931\u51fd\u6570", "value": "\u77e5\u8bc6"}, {"source": "OpenPose Realtime Multi-Person 2D PoseEstimation using Part Affinity Fields.pdf", "target": "\u903b\u8f91\u56de\u5f52", "value": "\u77e5\u8bc6"}, {"source": "OpenPose Realtime Multi-Person 2D PoseEstimation using Part Affinity Fields.pdf", "target": "\u68af\u5ea6\u6d88\u5931\u95ee\u9898", "value": "\u77e5\u8bc6"}, {"source": "OpenPose Realtime Multi-Person 2D PoseEstimation using Part Affinity Fields.pdf", "target": "AWS", "value": "\u77e5\u8bc6"}, {"source": "OpenPose Realtime Multi-Person 2D PoseEstimation using Part Affinity Fields.pdf", "target": "\u56fe\u6a21\u578b", "value": "\u77e5\u8bc6"}, {"source": "OpenPose Realtime Multi-Person 2D PoseEstimation using Part Affinity Fields.pdf", "target": "self-supervised learning", "value": "\u77e5\u8bc6"}, {"source": "OpenPose Realtime Multi-Person 2D PoseEstimation using Part Affinity Fields.pdf", "target": "IROS", "value": "\u77e5\u8bc6"}, {"source": "OpenPose Realtime Multi-Person 2D PoseEstimation using Part Affinity Fields.pdf", "target": "\u4eba\u5de5\u795e\u7ecf\u7f51\u7edc", "value": "\u77e5\u8bc6"}, {"source": "OpenPose Realtime Multi-Person 2D PoseEstimation using Part Affinity Fields.pdf", "target": "pose estimation", "value": "\u77e5\u8bc6"}, {"source": "OpenPose Realtime Multi-Person 2D PoseEstimation using Part Affinity Fields.pdf", "target": "Human pose estimation", "value": "\u77e5\u8bc6"}, {"source": "OpenPose Realtime Multi-Person 2D PoseEstimation using Part Affinity Fields.pdf", "target": "Human Pose Estimation", "value": "\u77e5\u8bc6"}, {"source": "OpenPose Realtime Multi-Person 2D PoseEstimation using Part Affinity Fields.pdf", "target": "Dataset", "value": "\u77e5\u8bc6"}, {"source": "OpenPose Realtime Multi-Person 2D PoseEstimation using Part Affinity Fields.pdf", "target": "networks", "value": "\u77e5\u8bc6"}, {"source": "OpenPose Realtime Multi-Person 2D PoseEstimation using Part Affinity Fields.pdf", "target": "Faster R-CNN", "value": "\u77e5\u8bc6"}, {"source": "OpenPose Realtime Multi-Person 2D PoseEstimation using Part Affinity Fields.pdf", "target": "Ssd", "value": "\u77e5\u8bc6"}, {"source": "OpenPose Realtime Multi-Person 2D PoseEstimation using Part Affinity Fields.pdf", "target": "\u56fe\u50cf\u5206\u6790", "value": "\u77e5\u8bc6"}, {"source": "OpenPose Realtime Multi-Person 2D PoseEstimation using Part Affinity Fields.pdf", "target": "part affinity fields", "value": "\u77e5\u8bc6"}, {"source": "OpenPose Realtime Multi-Person 2D PoseEstimation using Part Affinity Fields.pdf", "target": "\u4eba\u4f53\u5173\u952e\u70b9\u68c0\u6d4b", "value": "\u77e5\u8bc6"}, {"source": "OpenPose Realtime Multi-Person 2D PoseEstimation using Part Affinity Fields.pdf", "target": "Part Affinity Fields", "value": "\u77e5\u8bc6"}, {"source": "OpenPose Realtime Multi-Person 2D PoseEstimation using Part Affinity Fields.pdf", "target": "keypoint detection", "value": "\u77e5\u8bc6"}, {"source": "OpenPose Realtime Multi-Person 2D PoseEstimation using Part Affinity Fields.pdf", "target": "OpenPose", "value": "\u77e5\u8bc6"}, {"source": "OpenPose Realtime Multi-Person 2D PoseEstimation using Part Affinity Fields.pdf", "target": "VGG-19", "value": "\u77e5\u8bc6"}, {"source": "OpenPose Realtime Multi-Person 2D PoseEstimation using Part Affinity Fields.pdf", "target": "OpenCL", "value": "\u77e5\u8bc6"}, {"source": "OpenPose Realtime Multi-Person 2D PoseEstimation using Part Affinity Fields.pdf", "target": "\u5355\u4f4d\u5411\u91cf", "value": "\u77e5\u8bc6"}, {"source": "OpenPose Realtime Multi-Person 2D PoseEstimation using Part Affinity Fields.pdf", "target": "L2\u635f\u5931", "value": "\u77e5\u8bc6"}, {"source": "Pedestrian attribute recognition A survey.pdf", "target": "\u4eba\u5de5\u667a\u80fd", "value": "\u77e5\u8bc6"}, {"source": "Pedestrian attribute recognition A survey.pdf", "target": "learning", "value": "\u77e5\u8bc6"}, {"source": "Pedestrian attribute recognition A survey.pdf", "target": "LSTM\u7f51\u7edc", "value": "\u77e5\u8bc6"}, {"source": "Pedestrian attribute recognition A survey.pdf", "target": "\u4eba\u8138\u8bc6\u522b", "value": "\u77e5\u8bc6"}, {"source": "Pedestrian attribute recognition A survey.pdf", "target": "data augmentation", "value": "\u77e5\u8bc6"}, {"source": "Pedestrian attribute recognition A survey.pdf", "target": "neural networks", "value": "\u77e5\u8bc6"}, {"source": "Pedestrian attribute recognition A survey.pdf", "target": "motion blur", "value": "\u77e5\u8bc6"}, {"source": "Pedestrian attribute recognition A survey.pdf", "target": "SVM\u5206\u7c7b\u5668", "value": "\u77e5\u8bc6"}, {"source": "Pedestrian attribute recognition A survey.pdf", "target": "CNN", "value": "\u77e5\u8bc6"}, {"source": "Pedestrian attribute recognition A survey.pdf", "target": "SVM", "value": "\u77e5\u8bc6"}, {"source": "Pedestrian attribute recognition A survey.pdf", "target": "\u795e\u7ecf\u7f51\u7edc", "value": "\u77e5\u8bc6"}, {"source": "Pedestrian attribute recognition A survey.pdf", "target": "\u6570\u636e\u589e\u5f3a", "value": "\u77e5\u8bc6"}, {"source": "Pedestrian attribute recognition A survey.pdf", "target": "AlexNet", "value": "\u77e5\u8bc6"}, {"source": "Pedestrian attribute recognition A survey.pdf", "target": "NIPS", "value": "\u77e5\u8bc6"}, {"source": "Pedestrian attribute recognition A survey.pdf", "target": "\u6df1\u5ea6\u5b66\u4e60", "value": "\u77e5\u8bc6"}, {"source": "Pedestrian attribute recognition A survey.pdf", "target": "\u8d1f\u8f7d\u5747\u8861", "value": "\u77e5\u8bc6"}, {"source": "Pedestrian attribute recognition A survey.pdf", "target": "feature map", "value": "\u77e5\u8bc6"}, {"source": "Pedestrian attribute recognition A survey.pdf", "target": "\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b", "value": "\u77e5\u8bc6"}, {"source": "Pedestrian attribute recognition A survey.pdf", "target": "\u673a\u5668\u5b66\u4e60", "value": "\u77e5\u8bc6"}, {"source": "Pedestrian attribute recognition A survey.pdf", "target": "S3\u5b58\u50a8\u670d\u52a1", "value": "\u77e5\u8bc6"}, {"source": "Pedestrian attribute recognition A survey.pdf", "target": "logistic\u56de\u5f52", "value": "\u77e5\u8bc6"}, {"source": "Pedestrian attribute recognition A survey.pdf", "target": "DNN", "value": "\u77e5\u8bc6"}, {"source": "Pedestrian attribute recognition A survey.pdf", "target": "loss function", "value": "\u77e5\u8bc6"}, {"source": "Pedestrian attribute recognition A survey.pdf", "target": "\u591a\u4efb\u52a1\u5b66\u4e60", "value": "\u77e5\u8bc6"}, {"source": "Pedestrian attribute recognition A survey.pdf", "target": "\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5", "value": "\u77e5\u8bc6"}, {"source": "Pedestrian attribute recognition A survey.pdf", "target": "\u5b66\u4e60\u7b97\u6cd5", "value": "\u77e5\u8bc6"}, {"source": "Pedestrian attribute recognition A survey.pdf", "target": "\u81ea\u7136\u8bed\u8a00\u5904\u7406", "value": "\u77e5\u8bc6"}, {"source": "Pedestrian attribute recognition A survey.pdf", "target": "Deep Learning", "value": "\u77e5\u8bc6"}, {"source": "Pedestrian attribute recognition A survey.pdf", "target": "feature maps", "value": "\u77e5\u8bc6"}, {"source": "Pedestrian attribute recognition A survey.pdf", "target": "Docker\u5bb9\u5668", "value": "\u77e5\u8bc6"}, {"source": "Pedestrian attribute recognition A survey.pdf", "target": "\u5377\u79ef\u795e\u7ecf\u7f51\u7edc", "value": "\u77e5\u8bc6"}, {"source": "Pedestrian attribute recognition A survey.pdf", "target": "SIFT", "value": "\u77e5\u8bc6"}, {"source": "Pedestrian attribute recognition A survey.pdf", "target": "\u7b97\u6cd5", "value": "\u77e5\u8bc6"}, {"source": "Pedestrian attribute recognition A survey.pdf", "target": "\u4ea4\u53c9\u71b5\u635f\u5931", "value": "\u77e5\u8bc6"}, {"source": "Pedestrian attribute recognition A survey.pdf", "target": "attention", "value": "\u77e5\u8bc6"}, {"source": "Pedestrian attribute recognition A survey.pdf", "target": "\u7aef\u5230\u7aef\u5b66\u4e60", "value": "\u77e5\u8bc6"}, {"source": "Pedestrian attribute recognition A survey.pdf", "target": "\u8ba1\u7b97\u673a\u89c6\u89c9", "value": "\u77e5\u8bc6"}, {"source": "Pedestrian attribute recognition A survey.pdf", "target": "CNN-based", "value": "\u77e5\u8bc6"}, {"source": "Pedestrian attribute recognition A survey.pdf", "target": "object detection", "value": "\u77e5\u8bc6"}, {"source": "Pedestrian attribute recognition A survey.pdf", "target": "\u6c60\u5316\u5c42", "value": "\u77e5\u8bc6"}, {"source": "Pedestrian attribute recognition A survey.pdf", "target": "Natural Language Processing", "value": "\u77e5\u8bc6"}, {"source": "Pedestrian attribute recognition A survey.pdf", "target": "AWS", "value": "\u77e5\u8bc6"}, {"source": "Pedestrian attribute recognition A survey.pdf", "target": "\u7279\u5f81\u63d0\u53d6", "value": "\u77e5\u8bc6"}, {"source": "Pedestrian attribute recognition A survey.pdf", "target": "RNN", "value": "\u77e5\u8bc6"}, {"source": "Pedestrian attribute recognition A survey.pdf", "target": "pattern recognition", "value": "\u77e5\u8bc6"}, {"source": "Pedestrian attribute recognition A survey.pdf", "target": "modules", "value": "\u77e5\u8bc6"}, {"source": "Pedestrian attribute recognition A survey.pdf", "target": "self-supervised learning", "value": "\u77e5\u8bc6"}, {"source": "Pedestrian attribute recognition A survey.pdf", "target": "Robustness", "value": "\u77e5\u8bc6"}, {"source": "Pedestrian attribute recognition A survey.pdf", "target": "incremental learning", "value": "\u77e5\u8bc6"}, {"source": "Pedestrian attribute recognition A survey.pdf", "target": "computer vision", "value": "\u77e5\u8bc6"}, {"source": "Pose2Trajectory \u4f7f\u7528 Transformers \u57fa\u4e8e\u8eab\u4f53\u59ff\u52bf\u9884\u6d4b\u7f51\u7403\u8fd0\u52a8\u5458\u7684\u8f68\u8ff9.pdf", "target": "\u4eba\u5de5\u667a\u80fd", "value": "\u77e5\u8bc6"}, {"source": "Pose2Trajectory \u4f7f\u7528 Transformers \u57fa\u4e8e\u8eab\u4f53\u59ff\u52bf\u9884\u6d4b\u7f51\u7403\u8fd0\u52a8\u5458\u7684\u8f68\u8ff9.pdf", "target": "LSTM", "value": "\u77e5\u8bc6"}, {"source": "Pose2Trajectory \u4f7f\u7528 Transformers \u57fa\u4e8e\u8eab\u4f53\u59ff\u52bf\u9884\u6d4b\u7f51\u7403\u8fd0\u52a8\u5458\u7684\u8f68\u8ff9.pdf", "target": "neural network", "value": "\u77e5\u8bc6"}, {"source": "Pose2Trajectory \u4f7f\u7528 Transformers \u57fa\u4e8e\u8eab\u4f53\u59ff\u52bf\u9884\u6d4b\u7f51\u7403\u8fd0\u52a8\u5458\u7684\u8f68\u8ff9.pdf", "target": "CNN", "value": "\u77e5\u8bc6"}, {"source": "Pose2Trajectory \u4f7f\u7528 Transformers \u57fa\u4e8e\u8eab\u4f53\u59ff\u52bf\u9884\u6d4b\u7f51\u7403\u8fd0\u52a8\u5458\u7684\u8f68\u8ff9.pdf", "target": "Kubernetes", "value": "\u77e5\u8bc6"}, {"source": "Pose2Trajectory \u4f7f\u7528 Transformers \u57fa\u4e8e\u8eab\u4f53\u59ff\u52bf\u9884\u6d4b\u7f51\u7403\u8fd0\u52a8\u5458\u7684\u8f68\u8ff9.pdf", "target": "Computer Vision", "value": "\u77e5\u8bc6"}, {"source": "Pose2Trajectory \u4f7f\u7528 Transformers \u57fa\u4e8e\u8eab\u4f53\u59ff\u52bf\u9884\u6d4b\u7f51\u7403\u8fd0\u52a8\u5458\u7684\u8f68\u8ff9.pdf", "target": "\u673a\u5668\u5b66\u4e60", "value": "\u77e5\u8bc6"}, {"source": "Pose2Trajectory \u4f7f\u7528 Transformers \u57fa\u4e8e\u8eab\u4f53\u59ff\u52bf\u9884\u6d4b\u7f51\u7403\u8fd0\u52a8\u5458\u7684\u8f68\u8ff9.pdf", "target": "Signal Processing", "value": "\u77e5\u8bc6"}, {"source": "Pose2Trajectory \u4f7f\u7528 Transformers \u57fa\u4e8e\u8eab\u4f53\u59ff\u52bf\u9884\u6d4b\u7f51\u7403\u8fd0\u52a8\u5458\u7684\u8f68\u8ff9.pdf", "target": "Docker", "value": "\u77e5\u8bc6"}, {"source": "Pose2Trajectory \u4f7f\u7528 Transformers \u57fa\u4e8e\u8eab\u4f53\u59ff\u52bf\u9884\u6d4b\u7f51\u7403\u8fd0\u52a8\u5458\u7684\u8f68\u8ff9.pdf", "target": "\u5bb9\u5668\u7f16\u6392", "value": "\u77e5\u8bc6"}, {"source": "Pose2Trajectory \u4f7f\u7528 Transformers \u57fa\u4e8e\u8eab\u4f53\u59ff\u52bf\u9884\u6d4b\u7f51\u7403\u8fd0\u52a8\u5458\u7684\u8f68\u8ff9.pdf", "target": "Deep Learning", "value": "\u77e5\u8bc6"}, {"source": "Pose2Trajectory \u4f7f\u7528 Transformers \u57fa\u4e8e\u8eab\u4f53\u59ff\u52bf\u9884\u6d4b\u7f51\u7403\u8fd0\u52a8\u5458\u7684\u8f68\u8ff9.pdf", "target": "dropout", "value": "\u77e5\u8bc6"}, {"source": "Pose2Trajectory \u4f7f\u7528 Transformers \u57fa\u4e8e\u8eab\u4f53\u59ff\u52bf\u9884\u6d4b\u7f51\u7403\u8fd0\u52a8\u5458\u7684\u8f68\u8ff9.pdf", "target": "object detection", "value": "\u77e5\u8bc6"}, {"source": "Pose2Trajectory \u4f7f\u7528 Transformers \u57fa\u4e8e\u8eab\u4f53\u59ff\u52bf\u9884\u6d4b\u7f51\u7403\u8fd0\u52a8\u5458\u7684\u8f68\u8ff9.pdf", "target": "R-CNN", "value": "\u77e5\u8bc6"}, {"source": "Pose2Trajectory \u4f7f\u7528 Transformers \u57fa\u4e8e\u8eab\u4f53\u59ff\u52bf\u9884\u6d4b\u7f51\u7403\u8fd0\u52a8\u5458\u7684\u8f68\u8ff9.pdf", "target": "\u81ea\u52a8\u5316\u90e8\u7f72", "value": "\u77e5\u8bc6"}, {"source": "Pose2Trajectory \u4f7f\u7528 Transformers \u57fa\u4e8e\u8eab\u4f53\u59ff\u52bf\u9884\u6d4b\u7f51\u7403\u8fd0\u52a8\u5458\u7684\u8f68\u8ff9.pdf", "target": "machine learning", "value": "\u77e5\u8bc6"}, {"source": "Pose2Trajectory \u4f7f\u7528 Transformers \u57fa\u4e8e\u8eab\u4f53\u59ff\u52bf\u9884\u6d4b\u7f51\u7403\u8fd0\u52a8\u5458\u7684\u8f68\u8ff9.pdf", "target": "BERT", "value": "\u77e5\u8bc6"}, {"source": "Pose2Trajectory \u4f7f\u7528 Transformers \u57fa\u4e8e\u8eab\u4f53\u59ff\u52bf\u9884\u6d4b\u7f51\u7403\u8fd0\u52a8\u5458\u7684\u8f68\u8ff9.pdf", "target": "\u7279\u5f81\u63d0\u53d6", "value": "\u77e5\u8bc6"}, {"source": "Pose2Trajectory \u4f7f\u7528 Transformers \u57fa\u4e8e\u8eab\u4f53\u59ff\u52bf\u9884\u6d4b\u7f51\u7403\u8fd0\u52a8\u5458\u7684\u8f68\u8ff9.pdf", "target": "pattern recognition", "value": "\u77e5\u8bc6"}, {"source": "Pose2Trajectory \u4f7f\u7528 Transformers \u57fa\u4e8e\u8eab\u4f53\u59ff\u52bf\u9884\u6d4b\u7f51\u7403\u8fd0\u52a8\u5458\u7684\u8f68\u8ff9.pdf", "target": "computer vision", "value": "\u77e5\u8bc6"}, {"source": "Pose2Trajectory \u4f7f\u7528 Transformers \u57fa\u4e8e\u8eab\u4f53\u59ff\u52bf\u9884\u6d4b\u7f51\u7403\u8fd0\u52a8\u5458\u7684\u8f68\u8ff9.pdf", "target": "motion perception", "value": "\u77e5\u8bc6"}, {"source": "Pose2Trajectory \u4f7f\u7528 Transformers \u57fa\u4e8e\u8eab\u4f53\u59ff\u52bf\u9884\u6d4b\u7f51\u7403\u8fd0\u52a8\u5458\u7684\u8f68\u8ff9.pdf", "target": "Image Processing", "value": "\u77e5\u8bc6"}, {"source": "Pose2Trajectory \u4f7f\u7528 Transformers \u57fa\u4e8e\u8eab\u4f53\u59ff\u52bf\u9884\u6d4b\u7f51\u7403\u8fd0\u52a8\u5458\u7684\u8f68\u8ff9.pdf", "target": "recurrent neural networks", "value": "\u77e5\u8bc6"}, {"source": "Pose2Trajectory \u4f7f\u7528 Transformers \u57fa\u4e8e\u8eab\u4f53\u59ff\u52bf\u9884\u6d4b\u7f51\u7403\u8fd0\u52a8\u5458\u7684\u8f68\u8ff9.pdf", "target": "GAN", "value": "\u77e5\u8bc6"}, {"source": "Pose2Trajectory \u4f7f\u7528 Transformers \u57fa\u4e8e\u8eab\u4f53\u59ff\u52bf\u9884\u6d4b\u7f51\u7403\u8fd0\u52a8\u5458\u7684\u8f68\u8ff9.pdf", "target": "Pose Estimation", "value": "\u77e5\u8bc6"}, {"source": "Pose2Trajectory \u4f7f\u7528 Transformers \u57fa\u4e8e\u8eab\u4f53\u59ff\u52bf\u9884\u6d4b\u7f51\u7403\u8fd0\u52a8\u5458\u7684\u8f68\u8ff9.pdf", "target": "human pose estimation", "value": "\u77e5\u8bc6"}, {"source": "Pose2Trajectory \u4f7f\u7528 Transformers \u57fa\u4e8e\u8eab\u4f53\u59ff\u52bf\u9884\u6d4b\u7f51\u7403\u8fd0\u52a8\u5458\u7684\u8f68\u8ff9.pdf", "target": "\u4eba\u7c7b\u884c\u4e3a\u5206\u6790", "value": "\u77e5\u8bc6"}, {"source": "Pose2Trajectory \u4f7f\u7528 Transformers \u57fa\u4e8e\u8eab\u4f53\u59ff\u52bf\u9884\u6d4b\u7f51\u7403\u8fd0\u52a8\u5458\u7684\u8f68\u8ff9.pdf", "target": "Transformer", "value": "\u77e5\u8bc6"}, {"source": "Pose2Trajectory \u4f7f\u7528 Transformers \u57fa\u4e8e\u8eab\u4f53\u59ff\u52bf\u9884\u6d4b\u7f51\u7403\u8fd0\u52a8\u5458\u7684\u8f68\u8ff9.pdf", "target": "forecasting", "value": "\u77e5\u8bc6"}, {"source": "Pose2Trajectory \u4f7f\u7528 Transformers \u57fa\u4e8e\u8eab\u4f53\u59ff\u52bf\u9884\u6d4b\u7f51\u7403\u8fd0\u52a8\u5458\u7684\u8f68\u8ff9.pdf", "target": "MSE", "value": "\u77e5\u8bc6"}, {"source": "Pose2Trajectory \u4f7f\u7528 Transformers \u57fa\u4e8e\u8eab\u4f53\u59ff\u52bf\u9884\u6d4b\u7f51\u7403\u8fd0\u52a8\u5458\u7684\u8f68\u8ff9.pdf", "target": "transformer", "value": "\u77e5\u8bc6"}, {"source": "Pose2Trajectory \u4f7f\u7528 Transformers \u57fa\u4e8e\u8eab\u4f53\u59ff\u52bf\u9884\u6d4b\u7f51\u7403\u8fd0\u52a8\u5458\u7684\u8f68\u8ff9.pdf", "target": "Springer handbook of robotics", "value": "\u77e5\u8bc6"}, {"source": "Pose2Trajectory \u4f7f\u7528 Transformers \u57fa\u4e8e\u8eab\u4f53\u59ff\u52bf\u9884\u6d4b\u7f51\u7403\u8fd0\u52a8\u5458\u7684\u8f68\u8ff9.pdf", "target": "Graph Attention Networks", "value": "\u77e5\u8bc6"}, {"source": "Pose2Trajectory \u4f7f\u7528 Transformers \u57fa\u4e8e\u8eab\u4f53\u59ff\u52bf\u9884\u6d4b\u7f51\u7403\u8fd0\u52a8\u5458\u7684\u8f68\u8ff9.pdf", "target": "Pose2Trajectory", "value": "\u77e5\u8bc6"}, {"source": "Pose2Trajectory \u4f7f\u7528 Transformers \u57fa\u4e8e\u8eab\u4f53\u59ff\u52bf\u9884\u6d4b\u7f51\u7403\u8fd0\u52a8\u5458\u7684\u8f68\u8ff9.pdf", "target": "generative pre-training", "value": "\u77e5\u8bc6"}, {"source": "Pose2Trajectory \u4f7f\u7528 Transformers \u57fa\u4e8e\u8eab\u4f53\u59ff\u52bf\u9884\u6d4b\u7f51\u7403\u8fd0\u52a8\u5458\u7684\u8f68\u8ff9.pdf", "target": "Time2vec", "value": "\u77e5\u8bc6"}, {"source": "Pose2Trajectory \u4f7f\u7528 Transformers \u57fa\u4e8e\u8eab\u4f53\u59ff\u52bf\u9884\u6d4b\u7f51\u7403\u8fd0\u52a8\u5458\u7684\u8f68\u8ff9.pdf", "target": "ByteTrack", "value": "\u77e5\u8bc6"}, {"source": "Pose2Trajectory \u4f7f\u7528 Transformers \u57fa\u4e8e\u8eab\u4f53\u59ff\u52bf\u9884\u6d4b\u7f51\u7403\u8fd0\u52a8\u5458\u7684\u8f68\u8ff9.pdf", "target": "ViTPose", "value": "\u77e5\u8bc6"}, {"source": "Pose2Trajectory \u4f7f\u7528 Transformers \u57fa\u4e8e\u8eab\u4f53\u59ff\u52bf\u9884\u6d4b\u7f51\u7403\u8fd0\u52a8\u5458\u7684\u8f68\u8ff9.pdf", "target": "Time2Vector", "value": "\u77e5\u8bc6"}, {"source": "Pose2Trajectory \u4f7f\u7528 Transformers \u57fa\u4e8e\u8eab\u4f53\u59ff\u52bf\u9884\u6d4b\u7f51\u7403\u8fd0\u52a8\u5458\u7684\u8f68\u8ff9.pdf", "target": "Bicycle-GAN", "value": "\u77e5\u8bc6"}, {"source": "Pose2Trajectory \u4f7f\u7528 Transformers \u57fa\u4e8e\u8eab\u4f53\u59ff\u52bf\u9884\u6d4b\u7f51\u7403\u8fd0\u52a8\u5458\u7684\u8f68\u8ff9.pdf", "target": "Kalman filter", "value": "\u77e5\u8bc6"}, {"source": "Pose2Trajectory \u4f7f\u7528 Transformers \u57fa\u4e8e\u8eab\u4f53\u59ff\u52bf\u9884\u6d4b\u7f51\u7403\u8fd0\u52a8\u5458\u7684\u8f68\u8ff9.pdf", "target": "Detection", "value": "\u77e5\u8bc6"}, {"source": "Pose2Trajectory \u4f7f\u7528 Transformers \u57fa\u4e8e\u8eab\u4f53\u59ff\u52bf\u9884\u6d4b\u7f51\u7403\u8fd0\u52a8\u5458\u7684\u8f68\u8ff9.pdf", "target": "motion estimation", "value": "\u77e5\u8bc6"}, {"source": "Pose2Trajectory \u4f7f\u7528 Transformers \u57fa\u4e8e\u8eab\u4f53\u59ff\u52bf\u9884\u6d4b\u7f51\u7403\u8fd0\u52a8\u5458\u7684\u8f68\u8ff9.pdf", "target": "Hawk-eye", "value": "\u77e5\u8bc6"}, {"source": "Pose2Trajectory \u4f7f\u7528 Transformers \u57fa\u4e8e\u8eab\u4f53\u59ff\u52bf\u9884\u6d4b\u7f51\u7403\u8fd0\u52a8\u5458\u7684\u8f68\u8ff9.pdf", "target": "Tennis", "value": "\u77e5\u8bc6"}, {"source": "Pose2Trajectory \u4f7f\u7528 Transformers \u57fa\u4e8e\u8eab\u4f53\u59ff\u52bf\u9884\u6d4b\u7f51\u7403\u8fd0\u52a8\u5458\u7684\u8f68\u8ff9.pdf", "target": "current neural networks", "value": "\u77e5\u8bc6"}, {"source": "Pose2Trajectory \u4f7f\u7528 Transformers \u57fa\u4e8e\u8eab\u4f53\u59ff\u52bf\u9884\u6d4b\u7f51\u7403\u8fd0\u52a8\u5458\u7684\u8f68\u8ff9.pdf", "target": "PMLR", "value": "\u77e5\u8bc6"}, {"source": "Pose2Trajectory \u4f7f\u7528 Transformers \u57fa\u4e8e\u8eab\u4f53\u59ff\u52bf\u9884\u6d4b\u7f51\u7403\u8fd0\u52a8\u5458\u7684\u8f68\u8ff9.pdf", "target": "fast r-cnn", "value": "\u77e5\u8bc6"}, {"source": "Pose2Trajectory \u4f7f\u7528 Transformers \u57fa\u4e8e\u8eab\u4f53\u59ff\u52bf\u9884\u6d4b\u7f51\u7403\u8fd0\u52a8\u5458\u7684\u8f68\u8ff9.pdf", "target": "focal loss", "value": "\u77e5\u8bc6"}, {"source": "Pose2Trajectory \u4f7f\u7528 Transformers \u57fa\u4e8e\u8eab\u4f53\u59ff\u52bf\u9884\u6d4b\u7f51\u7403\u8fd0\u52a8\u5458\u7684\u8f68\u8ff9.pdf", "target": "video surveillance system", "value": "\u77e5\u8bc6"}, {"source": "R-CNN.pdf", "target": "\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc", "value": "\u77e5\u8bc6"}, {"source": "R-CNN.pdf", "target": "fine-tuning", "value": "\u77e5\u8bc6"}, {"source": "R-CNN.pdf", "target": "ImageNet", "value": "\u77e5\u8bc6"}, {"source": "R-CNN.pdf", "target": "SVR", "value": "\u77e5\u8bc6"}, {"source": "R-CNN.pdf", "target": "convolutional neural networks", "value": "\u77e5\u8bc6"}, {"source": "R-CNN.pdf", "target": "CNNs", "value": "\u77e5\u8bc6"}, {"source": "R-CNN.pdf", "target": "feature", "value": "\u77e5\u8bc6"}, {"source": "R-CNN.pdf", "target": "CNN", "value": "\u77e5\u8bc6"}, {"source": "R-CNN.pdf", "target": "SVM", "value": "\u77e5\u8bc6"}, {"source": "R-CNN.pdf", "target": "CNN\u67b6\u6784", "value": "\u77e5\u8bc6"}, {"source": "R-CNN.pdf", "target": "ruler", "value": "\u77e5\u8bc6"}, {"source": "R-CNN.pdf", "target": "class", "value": "\u77e5\u8bc6"}, {"source": "R-CNN.pdf", "target": "Kubernetes\u7ba1\u7406\u7cfb\u7edf", "value": "\u77e5\u8bc6"}, {"source": "R-CNN.pdf", "target": "\u4e91\u8ba1\u7b97\u5e73\u53f0", "value": "\u77e5\u8bc6"}, {"source": "R-CNN.pdf", "target": "\u673a\u5668\u5b66\u4e60", "value": "\u77e5\u8bc6"}, {"source": "R-CNN.pdf", "target": "softmax", "value": "\u77e5\u8bc6"}, {"source": "R-CNN.pdf", "target": "S3\u5b58\u50a8\u670d\u52a1", "value": "\u77e5\u8bc6"}, {"source": "R-CNN.pdf", "target": "Dropout", "value": "\u77e5\u8bc6"}, {"source": "R-CNN.pdf", "target": "square", "value": "\u77e5\u8bc6"}, {"source": "R-CNN.pdf", "target": "Krizhevsky", "value": "\u77e5\u8bc6"}, {"source": "R-CNN.pdf", "target": "IoU", "value": "\u77e5\u8bc6"}, {"source": "R-CNN.pdf", "target": "classifier", "value": "\u77e5\u8bc6"}, {"source": "R-CNN.pdf", "target": "Docker", "value": "\u77e5\u8bc6"}, {"source": "R-CNN.pdf", "target": "SGD", "value": "\u77e5\u8bc6"}, {"source": "R-CNN.pdf", "target": "GPU", "value": "\u77e5\u8bc6"}, {"source": "R-CNN.pdf", "target": "activation", "value": "\u77e5\u8bc6"}, {"source": "R-CNN.pdf", "target": "IIS", "value": "\u77e5\u8bc6"}, {"source": "R-CNN.pdf", "target": "layer", "value": "\u77e5\u8bc6"}, {"source": "R-CNN.pdf", "target": "Docker\u5bb9\u5668", "value": "\u77e5\u8bc6"}, {"source": "R-CNN.pdf", "target": "\u5377\u79ef\u795e\u7ecf\u7f51\u7edc", "value": "\u77e5\u8bc6"}, {"source": "R-CNN.pdf", "target": "training", "value": "\u77e5\u8bc6"}, {"source": "R-CNN.pdf", "target": "SIFT", "value": "\u77e5\u8bc6"}, {"source": "R-CNN.pdf", "target": "\u8ba1\u7b97\u673a\u89c6\u89c9", "value": "\u77e5\u8bc6"}, {"source": "R-CNN.pdf", "target": "object detection", "value": "\u77e5\u8bc6"}, {"source": "R-CNN.pdf", "target": "R-CNN", "value": "\u77e5\u8bc6"}, {"source": "R-CNN.pdf", "target": "learning rate", "value": "\u77e5\u8bc6"}, {"source": "R-CNN.pdf", "target": "\u81ea\u52a8\u5316\u90e8\u7f72", "value": "\u77e5\u8bc6"}, {"source": "R-CNN.pdf", "target": "strides", "value": "\u77e5\u8bc6"}, {"source": "R-CNN.pdf", "target": "scene classification", "value": "\u77e5\u8bc6"}, {"source": "R-CNN.pdf", "target": "\u8d1f\u8f7d\u5747\u8861\u5668", "value": "\u77e5\u8bc6"}, {"source": "R-CNN.pdf", "target": "supervised learning", "value": "\u77e5\u8bc6"}, {"source": "R-CNN.pdf", "target": "pattern recognition", "value": "\u77e5\u8bc6"}, {"source": "R-CNN.pdf", "target": "Semantic Segmentation", "value": "\u77e5\u8bc6"}, {"source": "R-CNN.pdf", "target": "dimensionality reduction", "value": "\u77e5\u8bc6"}, {"source": "R-CNN.pdf", "target": "features", "value": "\u77e5\u8bc6"}, {"source": "R-CNN.pdf", "target": "classi\ufb01cation", "value": "\u77e5\u8bc6"}, {"source": "R-CNN.pdf", "target": "object", "value": "\u77e5\u8bc6"}, {"source": "R-CNN.pdf", "target": "clustering", "value": "\u77e5\u8bc6"}, {"source": "R-CNN.pdf", "target": "fully connected layers", "value": "\u77e5\u8bc6"}, {"source": "R-CNN.pdf", "target": "feature learning", "value": "\u77e5\u8bc6"}, {"source": "RetinaNet.pdf", "target": "CNN", "value": "\u77e5\u8bc6"}, {"source": "RetinaNet.pdf", "target": "\u53cd\u5411\u4f20\u64ad", "value": "\u77e5\u8bc6"}, {"source": "RetinaNet.pdf", "target": "APM", "value": "\u77e5\u8bc6"}, {"source": "RetinaNet.pdf", "target": "Accuracy", "value": "\u77e5\u8bc6"}, {"source": "RetinaNet.pdf", "target": "anchors", "value": "\u77e5\u8bc6"}, {"source": "RetinaNet.pdf", "target": "momentum", "value": "\u77e5\u8bc6"}, {"source": "RetinaNet.pdf", "target": "ReLU", "value": "\u77e5\u8bc6"}, {"source": "RetinaNet.pdf", "target": "model", "value": "\u77e5\u8bc6"}, {"source": "RetinaNet.pdf", "target": "loss function", "value": "\u77e5\u8bc6"}, {"source": "RetinaNet.pdf", "target": "Convolutional Neural Networks", "value": "\u77e5\u8bc6"}, {"source": "RetinaNet.pdf", "target": "Focal loss", "value": "\u77e5\u8bc6"}, {"source": "RetinaNet.pdf", "target": "gamma", "value": "\u77e5\u8bc6"}, {"source": "RetinaNet.pdf", "target": "accuracy", "value": "\u77e5\u8bc6"}, {"source": "RetinaNet.pdf", "target": "object detection", "value": "\u77e5\u8bc6"}, {"source": "RetinaNet.pdf", "target": "ResNet", "value": "\u77e5\u8bc6"}, {"source": "RetinaNet.pdf", "target": "R-CNN", "value": "\u77e5\u8bc6"}, {"source": "RetinaNet.pdf", "target": "learning rate", "value": "\u77e5\u8bc6"}, {"source": "RetinaNet.pdf", "target": "anchor", "value": "\u77e5\u8bc6"}, {"source": "RetinaNet.pdf", "target": "batch", "value": "\u77e5\u8bc6"}, {"source": "RetinaNet.pdf", "target": "robustness", "value": "\u77e5\u8bc6"}, {"source": "RetinaNet.pdf", "target": "regions", "value": "\u77e5\u8bc6"}, {"source": "RetinaNet.pdf", "target": "gradient", "value": "\u77e5\u8bc6"}, {"source": "RetinaNet.pdf", "target": "spatial positions", "value": "\u77e5\u8bc6"}, {"source": "RetinaNet.pdf", "target": "FCN", "value": "\u77e5\u8bc6"}, {"source": "RetinaNet.pdf", "target": "human detection", "value": "\u77e5\u8bc6"}, {"source": "RetinaNet.pdf", "target": "sparse set", "value": "\u77e5\u8bc6"}, {"source": "RetinaNet.pdf", "target": "recurrent neural networks", "value": "\u77e5\u8bc6"}, {"source": "RetinaNet.pdf", "target": "scales", "value": "\u77e5\u8bc6"}, {"source": "RetinaNet.pdf", "target": "networks", "value": "\u77e5\u8bc6"}, {"source": "RetinaNet.pdf", "target": "Faster R-CNN", "value": "\u77e5\u8bc6"}, {"source": "RetinaNet.pdf", "target": "anchor box", "value": "\u77e5\u8bc6"}, {"source": "RetinaNet.pdf", "target": "image resolution", "value": "\u77e5\u8bc6"}, {"source": "RetinaNet.pdf", "target": "foreground", "value": "\u77e5\u8bc6"}, {"source": "RetinaNet.pdf", "target": "outliers", "value": "\u77e5\u8bc6"}, {"source": "RetinaNet.pdf", "target": "convolutional network", "value": "\u77e5\u8bc6"}, {"source": "RetinaNet.pdf", "target": "convolutional neural network", "value": "\u77e5\u8bc6"}, {"source": "RetinaNet.pdf", "target": "batch size", "value": "\u77e5\u8bc6"}, {"source": "RetinaNet.pdf", "target": "class imbalance", "value": "\u77e5\u8bc6"}, {"source": "RetinaNet.pdf", "target": "state-of-the-art", "value": "\u77e5\u8bc6"}, {"source": "RetinaNet.pdf", "target": "R-FCN", "value": "\u77e5\u8bc6"}, {"source": "RetinaNet.pdf", "target": "convolutional", "value": "\u77e5\u8bc6"}, {"source": "RetinaNet.pdf", "target": "deep neural networks", "value": "\u77e5\u8bc6"}, {"source": "RetinaNet.pdf", "target": "deep residual network", "value": "\u77e5\u8bc6"}, {"source": "RetinaNet.pdf", "target": "Object detection", "value": "\u77e5\u8bc6"}, {"source": "RetinaNet.pdf", "target": "conv layers", "value": "\u77e5\u8bc6"}, {"source": "RetinaNet.pdf", "target": "ResNet-50", "value": "\u77e5\u8bc6"}, {"source": "RetinaNet.pdf", "target": "object proposal", "value": "\u77e5\u8bc6"}, {"source": "RetinaNet.pdf", "target": "mini-batch", "value": "\u77e5\u8bc6"}, {"source": "RetinaNet.pdf", "target": "hard negative mining", "value": "\u77e5\u8bc6"}, {"source": "RetinaNet.pdf", "target": "object\u68c0\u6d4b", "value": "\u77e5\u8bc6"}, {"source": "s11263-022-01594-9.pdf", "target": "\u4eba\u5de5\u667a\u80fd", "value": "\u77e5\u8bc6"}, {"source": "s11263-022-01594-9.pdf", "target": "\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc", "value": "\u77e5\u8bc6"}, {"source": "s11263-022-01594-9.pdf", "target": "max-pooling", "value": "\u77e5\u8bc6"}, {"source": "s11263-022-01594-9.pdf", "target": "pooling", "value": "\u77e5\u8bc6"}, {"source": "s11263-022-01594-9.pdf", "target": "LSTM", "value": "\u77e5\u8bc6"}, {"source": "s11263-022-01594-9.pdf", "target": "segmentation", "value": "\u77e5\u8bc6"}, {"source": "s11263-022-01594-9.pdf", "target": "CNNs", "value": "\u77e5\u8bc6"}, {"source": "s11263-022-01594-9.pdf", "target": "\u6df1\u5ea6\u5377\u79ef\u795e\u7ecf\u7f51\u7edc", "value": "\u77e5\u8bc6"}, {"source": "s11263-022-01594-9.pdf", "target": "action recognition", "value": "\u77e5\u8bc6"}, {"source": "s11263-022-01594-9.pdf", "target": "UCF101", "value": "\u77e5\u8bc6"}, {"source": "s11263-022-01594-9.pdf", "target": "CNN", "value": "\u77e5\u8bc6"}, {"source": "s11263-022-01594-9.pdf", "target": "LSTMs", "value": "\u77e5\u8bc6"}, {"source": "s11263-022-01594-9.pdf", "target": "SVM", "value": "\u77e5\u8bc6"}, {"source": "s11263-022-01594-9.pdf", "target": "3D\u5377\u79ef\u795e\u7ecf\u7f51\u7edc", "value": "\u77e5\u8bc6"}, {"source": "s11263-022-01594-9.pdf", "target": "\u65e0\u76d1\u7763\u5b66\u4e60", "value": "\u77e5\u8bc6"}, {"source": "s11263-022-01594-9.pdf", "target": "\u652f\u6301\u5411\u91cf\u673a", "value": "\u77e5\u8bc6"}, {"source": "s11263-022-01594-9.pdf", "target": "Hmdb", "value": "\u77e5\u8bc6"}, {"source": "s11263-022-01594-9.pdf", "target": "\u4eba\u673a\u4ea4\u4e92", "value": "\u77e5\u8bc6"}, {"source": "s11263-022-01594-9.pdf", "target": "\u52a8\u6001\u56fe\u50cf\u5904\u7406", "value": "\u77e5\u8bc6"}, {"source": "s11263-022-01594-9.pdf", "target": "\u6df1\u5ea6\u5b66\u4e60", "value": "\u77e5\u8bc6"}, {"source": "s11263-022-01594-9.pdf", "target": "video representations", "value": "\u77e5\u8bc6"}, {"source": "s11263-022-01594-9.pdf", "target": "ICML", "value": "\u77e5\u8bc6"}, {"source": "s11263-022-01594-9.pdf", "target": "\u6df1\u5ea6\u76f8\u673a", "value": "\u77e5\u8bc6"}, {"source": "s11263-022-01594-9.pdf", "target": "\u6df1\u5ea6\u7f51\u7edc", "value": "\u77e5\u8bc6"}, {"source": "s11263-022-01594-9.pdf", "target": "\u6700\u5927\u6c60\u5316", "value": "\u77e5\u8bc6"}, {"source": "s11263-022-01594-9.pdf", "target": "\u673a\u5668\u5b66\u4e60", "value": "\u77e5\u8bc6"}, {"source": "s11263-022-01594-9.pdf", "target": "LSTM\u6a21\u578b", "value": "\u77e5\u8bc6"}, {"source": "s11263-022-01594-9.pdf", "target": "\u6982\u7387\u5206\u5e03", "value": "\u77e5\u8bc6"}, {"source": "s11263-022-01594-9.pdf", "target": "performance", "value": "\u77e5\u8bc6"}, {"source": "s11263-022-01594-9.pdf", "target": "IoU", "value": "\u77e5\u8bc6"}, {"source": "s11263-022-01594-9.pdf", "target": "model", "value": "\u77e5\u8bc6"}, {"source": "s11263-022-01594-9.pdf", "target": "DNN", "value": "\u77e5\u8bc6"}, {"source": "s11263-022-01594-9.pdf", "target": "Representation", "value": "\u77e5\u8bc6"}, {"source": "s11263-022-01594-9.pdf", "target": "\u591a\u4efb\u52a1\u5b66\u4e60", "value": "\u77e5\u8bc6"}, {"source": "s11263-022-01594-9.pdf", "target": "Recurrent neural networks", "value": "\u77e5\u8bc6"}, {"source": "s11263-022-01594-9.pdf", "target": "\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5", "value": "\u77e5\u8bc6"}, {"source": "s11263-022-01594-9.pdf", "target": "depth camera", "value": "\u77e5\u8bc6"}, {"source": "s11263-022-01594-9.pdf", "target": "\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60", "value": "\u77e5\u8bc6"}, {"source": "s11263-022-01594-9.pdf", "target": "reinforcement learning", "value": "\u77e5\u8bc6"}, {"source": "s11263-022-01594-9.pdf", "target": "MLP", "value": "\u77e5\u8bc6"}, {"source": "s11263-022-01594-9.pdf", "target": "\u5377\u79ef\u795e\u7ecf\u7f51\u7edc", "value": "\u77e5\u8bc6"}, {"source": "s11263-022-01594-9.pdf", "target": "training", "value": "\u77e5\u8bc6"}, {"source": "s11263-022-01594-9.pdf", "target": "SIFT", "value": "\u77e5\u8bc6"}, {"source": "s11263-022-01594-9.pdf", "target": "\u7b97\u6cd5", "value": "\u77e5\u8bc6"}, {"source": "s11263-022-01594-9.pdf", "target": "\u8ba1\u7b97\u673a\u89c6\u89c9", "value": "\u77e5\u8bc6"}, {"source": "s11263-022-01594-9.pdf", "target": "inference", "value": "\u77e5\u8bc6"}, {"source": "s11263-022-01594-9.pdf", "target": "ICCV", "value": "\u77e5\u8bc6"}, {"source": "s11263-022-01594-9.pdf", "target": "R-CNN", "value": "\u77e5\u8bc6"}, {"source": "s11263-022-01594-9.pdf", "target": "softmax\u51fd\u6570", "value": "\u77e5\u8bc6"}, {"source": "s11263-022-01594-9.pdf", "target": "arXiv", "value": "\u77e5\u8bc6"}, {"source": "sensors-19-01005.pdf", "target": "\u4eba\u5de5\u667a\u80fd", "value": "\u77e5\u8bc6"}, {"source": "sensors-19-01005.pdf", "target": "\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc", "value": "\u77e5\u8bc6"}, {"source": "sensors-19-01005.pdf", "target": "LSTM", "value": "\u77e5\u8bc6"}, {"source": "sensors-19-01005.pdf", "target": "\u4eba\u8138\u8bc6\u522b", "value": "\u77e5\u8bc6"}, {"source": "sensors-19-01005.pdf", "target": "video representation", "value": "\u77e5\u8bc6"}, {"source": "sensors-19-01005.pdf", "target": "convolutional neural networks", "value": "\u77e5\u8bc6"}, {"source": "sensors-19-01005.pdf", "target": "CNNs", "value": "\u77e5\u8bc6"}, {"source": "sensors-19-01005.pdf", "target": "action recognition", "value": "\u77e5\u8bc6"}, {"source": "sensors-19-01005.pdf", "target": "CNN", "value": "\u77e5\u8bc6"}, {"source": "sensors-19-01005.pdf", "target": "DenseNet", "value": "\u77e5\u8bc6"}, {"source": "sensors-19-01005.pdf", "target": "\u4eba\u673a\u4ea4\u4e92", "value": "\u77e5\u8bc6"}, {"source": "sensors-19-01005.pdf", "target": "\u6df1\u5ea6\u5b66\u4e60", "value": "\u77e5\u8bc6"}, {"source": "sensors-19-01005.pdf", "target": "RGB\u56fe\u50cf", "value": "\u77e5\u8bc6"}, {"source": "sensors-19-01005.pdf", "target": "attention mechanism", "value": "\u77e5\u8bc6"}, {"source": "sensors-19-01005.pdf", "target": "\u6df1\u5ea6\u76f8\u673a", "value": "\u77e5\u8bc6"}, {"source": "sensors-19-01005.pdf", "target": "\u56fe\u50cf\u8bc6\u522b", "value": "\u77e5\u8bc6"}, {"source": "sensors-19-01005.pdf", "target": "Tornado", "value": "\u77e5\u8bc6"}, {"source": "sensors-19-01005.pdf", "target": "sparse representation", "value": "\u77e5\u8bc6"}, {"source": "sensors-19-01005.pdf", "target": "\u673a\u5668\u5b66\u4e60", "value": "\u77e5\u8bc6"}, {"source": "sensors-19-01005.pdf", "target": "\u56fe\u50cf\u5206\u7c7b", "value": "\u77e5\u8bc6"}, {"source": "sensors-19-01005.pdf", "target": "\u4eba\u4f53\u59ff\u52bf\u4f30\u8ba1", "value": "\u77e5\u8bc6"}, {"source": "sensors-19-01005.pdf", "target": "Deep learning", "value": "\u77e5\u8bc6"}, {"source": "sensors-19-01005.pdf", "target": "cloud computing", "value": "\u77e5\u8bc6"}, {"source": "sensors-19-01005.pdf", "target": "\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5", "value": "\u77e5\u8bc6"}, {"source": "sensors-19-01005.pdf", "target": "classification", "value": "\u77e5\u8bc6"}, {"source": "sensors-19-01005.pdf", "target": "Convolutional Neural Network", "value": "\u77e5\u8bc6"}, {"source": "sensors-19-01005.pdf", "target": "\u8ba1\u7b97\u673a\u89c6\u89c9", "value": "\u77e5\u8bc6"}, {"source": "sensors-19-01005.pdf", "target": "accuracy", "value": "\u77e5\u8bc6"}, {"source": "sensors-19-01005.pdf", "target": "\u673a\u5668\u89c6\u89c9", "value": "\u77e5\u8bc6"}, {"source": "sensors-19-01005.pdf", "target": "RNN", "value": "\u77e5\u8bc6"}, {"source": "sensors-19-01005.pdf", "target": "dataset", "value": "\u77e5\u8bc6"}, {"source": "sensors-19-01005.pdf", "target": "sliding window", "value": "\u77e5\u8bc6"}, {"source": "sensors-19-01005.pdf", "target": "ComputerVision", "value": "\u77e5\u8bc6"}, {"source": "sensors-19-01005.pdf", "target": "Robustness", "value": "\u77e5\u8bc6"}, {"source": "sensors-19-01005.pdf", "target": "activity recognition", "value": "\u77e5\u8bc6"}, {"source": "sensors-19-01005.pdf", "target": "\u6df1\u5ea6\u611f\u77e5", "value": "\u77e5\u8bc6"}, {"source": "sensors-19-01005.pdf", "target": "skeleton", "value": "\u77e5\u8bc6"}, {"source": "sensors-19-01005.pdf", "target": "\u591a\u6a21\u6001\u6570\u636e\u878d\u5408", "value": "\u77e5\u8bc6"}, {"source": "sensors-19-01005.pdf", "target": "\u4eba\u4f53\u6d3b\u52a8\u68c0\u6d4b", "value": "\u77e5\u8bc6"}, {"source": "sensors-19-01005.pdf", "target": "spatiotemporal features", "value": "\u77e5\u8bc6"}, {"source": "sensors-19-01005.pdf", "target": "Kinect sensor", "value": "\u77e5\u8bc6"}, {"source": "sensors-19-01005.pdf", "target": "object", "value": "\u77e5\u8bc6"}, {"source": "sensors-19-01005.pdf", "target": "\u4eba\u673a\u8bc6\u522b", "value": "\u77e5\u8bc6"}, {"source": "sensors-19-01005.pdf", "target": "gesture recognition", "value": "\u77e5\u8bc6"}, {"source": "sensors-19-01005.pdf", "target": "Sliding Window", "value": "\u77e5\u8bc6"}, {"source": "sensors-19-01005.pdf", "target": "human motion", "value": "\u77e5\u8bc6"}, {"source": "sensors-19-01005.pdf", "target": "human action recognition", "value": "\u77e5\u8bc6"}, {"source": "sensors-19-01005.pdf", "target": "\u4eba\u7c7b\u52a8\u4f5c\u8bc6\u522b", "value": "\u77e5\u8bc6"}, {"source": "sensors-19-01005.pdf", "target": "human detection", "value": "\u77e5\u8bc6"}, {"source": "sensors-19-01005.pdf", "target": "histograms of oriented gradients", "value": "\u77e5\u8bc6"}, {"source": "SkateFormer Skeletal-Temporal Transformer for Human Action Recognition.pdf", "target": "learning", "value": "\u77e5\u8bc6"}, {"source": "SkateFormer Skeletal-Temporal Transformer for Human Action Recognition.pdf", "target": "data augmentation", "value": "\u77e5\u8bc6"}, {"source": "SkateFormer Skeletal-Temporal Transformer for Human Action Recognition.pdf", "target": "CNNs", "value": "\u77e5\u8bc6"}, {"source": "SkateFormer Skeletal-Temporal Transformer for Human Action Recognition.pdf", "target": "action recognition", "value": "\u77e5\u8bc6"}, {"source": "SkateFormer Skeletal-Temporal Transformer for Human Action Recognition.pdf", "target": "CNN", "value": "\u77e5\u8bc6"}, {"source": "SkateFormer Skeletal-Temporal Transformer for Human Action Recognition.pdf", "target": "\u6570\u636e\u589e\u5f3a", "value": "\u77e5\u8bc6"}, {"source": "SkateFormer Skeletal-Temporal Transformer for Human Action Recognition.pdf", "target": "\u4eba\u673a\u4ea4\u4e92", "value": "\u77e5\u8bc6"}, {"source": "SkateFormer Skeletal-Temporal Transformer for Human Action Recognition.pdf", "target": "\u6df1\u5ea6\u5b66\u4e60", "value": "\u77e5\u8bc6"}, {"source": "SkateFormer Skeletal-Temporal Transformer for Human Action Recognition.pdf", "target": "\u7279\u5f81\u6620\u5c04", "value": "\u77e5\u8bc6"}, {"source": "SkateFormer Skeletal-Temporal Transformer for Human Action Recognition.pdf", "target": "PyTorch", "value": "\u77e5\u8bc6"}, {"source": "SkateFormer Skeletal-Temporal Transformer for Human Action Recognition.pdf", "target": "tokenization", "value": "\u77e5\u8bc6"}, {"source": "SkateFormer Skeletal-Temporal Transformer for Human Action Recognition.pdf", "target": "global", "value": "\u77e5\u8bc6"}, {"source": "SkateFormer Skeletal-Temporal Transformer for Human Action Recognition.pdf", "target": "Linear", "value": "\u77e5\u8bc6"}, {"source": "SkateFormer Skeletal-Temporal Transformer for Human Action Recognition.pdf", "target": "\u673a\u5668\u5b66\u4e60", "value": "\u77e5\u8bc6"}, {"source": "SkateFormer Skeletal-Temporal Transformer for Human Action Recognition.pdf", "target": "performance", "value": "\u77e5\u8bc6"}, {"source": "SkateFormer Skeletal-Temporal Transformer for Human Action Recognition.pdf", "target": "model", "value": "\u77e5\u8bc6"}, {"source": "SkateFormer Skeletal-Temporal Transformer for Human Action Recognition.pdf", "target": "downsampling", "value": "\u77e5\u8bc6"}, {"source": "SkateFormer Skeletal-Temporal Transformer for Human Action Recognition.pdf", "target": "\u6df1\u5b66\u4e60", "value": "\u77e5\u8bc6"}, {"source": "SkateFormer Skeletal-Temporal Transformer for Human Action Recognition.pdf", "target": "natural language processing", "value": "\u77e5\u8bc6"}, {"source": "SkateFormer Skeletal-Temporal Transformer for Human Action Recognition.pdf", "target": "feature maps", "value": "\u77e5\u8bc6"}, {"source": "SkateFormer Skeletal-Temporal Transformer for Human Action Recognition.pdf", "target": "Turing", "value": "\u77e5\u8bc6"}, {"source": "SkateFormer Skeletal-Temporal Transformer for Human Action Recognition.pdf", "target": "attention", "value": "\u77e5\u8bc6"}, {"source": "SkateFormer Skeletal-Temporal Transformer for Human Action Recognition.pdf", "target": "\u8ba1\u7b97\u673a\u89c6\u89c9", "value": "\u77e5\u8bc6"}, {"source": "SkateFormer Skeletal-Temporal Transformer for Human Action Recognition.pdf", "target": "CNN-based", "value": "\u77e5\u8bc6"}, {"source": "SkateFormer Skeletal-Temporal Transformer for Human Action Recognition.pdf", "target": "GRU", "value": "\u77e5\u8bc6"}, {"source": "SkateFormer Skeletal-Temporal Transformer for Human Action Recognition.pdf", "target": "\u77e9\u9635\u4e58\u6cd5", "value": "\u77e5\u8bc6"}, {"source": "SkateFormer Skeletal-Temporal Transformer for Human Action Recognition.pdf", "target": "\u635f\u5931\u51fd\u6570", "value": "\u77e5\u8bc6"}, {"source": "SkateFormer Skeletal-Temporal Transformer for Human Action Recognition.pdf", "target": "Hinton", "value": "\u77e5\u8bc6"}, {"source": "SkateFormer Skeletal-Temporal Transformer for Human Action Recognition.pdf", "target": "\u81ea\u52a8\u5fae\u5206", "value": "\u77e5\u8bc6"}, {"source": "SkateFormer Skeletal-Temporal Transformer for Human Action Recognition.pdf", "target": "axes", "value": "\u77e5\u8bc6"}, {"source": "SkateFormer Skeletal-Temporal Transformer for Human Action Recognition.pdf", "target": "Transform", "value": "\u77e5\u8bc6"}, {"source": "SkateFormer Skeletal-Temporal Transformer for Human Action Recognition.pdf", "target": "baseline", "value": "\u77e5\u8bc6"}, {"source": "SkateFormer Skeletal-Temporal Transformer for Human Action Recognition.pdf", "target": "\u7279\u5f81\u62bd\u53d6", "value": "\u77e5\u8bc6"}, {"source": "SkateFormer Skeletal-Temporal Transformer for Human Action Recognition.pdf", "target": "pattern recognition", "value": "\u77e5\u8bc6"}, {"source": "SkateFormer Skeletal-Temporal Transformer for Human Action Recognition.pdf", "target": "Kinect", "value": "\u77e5\u8bc6"}, {"source": "SkateFormer Skeletal-Temporal Transformer for Human Action Recognition.pdf", "target": "joints", "value": "\u77e5\u8bc6"}, {"source": "SkateFormer Skeletal-Temporal Transformer for Human Action Recognition.pdf", "target": "skeleton", "value": "\u77e5\u8bc6"}, {"source": "SkateFormer Skeletal-Temporal Transformer for Human Action Recognition.pdf", "target": "artificial intelligence", "value": "\u77e5\u8bc6"}, {"source": "SkateFormer Skeletal-Temporal Transformer for Human Action Recognition.pdf", "target": "computer vision", "value": "\u77e5\u8bc6"}, {"source": "SkateFormer Skeletal-Temporal Transformer for Human Action Recognition.pdf", "target": "sensors", "value": "\u77e5\u8bc6"}, {"source": "SkateFormer Skeletal-Temporal Transformer for Human Action Recognition.pdf", "target": "attributes", "value": "\u77e5\u8bc6"}, {"source": "SkateFormer Skeletal-Temporal Transformer for Human Action Recognition.pdf", "target": "Batch Normalization", "value": "\u77e5\u8bc6"}, {"source": "SkateFormer Skeletal-Temporal Transformer for Human Action Recognition.pdf", "target": "complexity", "value": "\u77e5\u8bc6"}, {"source": "SkateFormer Skeletal-Temporal Transformer for Human Action Recognition.pdf", "target": "Neural Networks", "value": "\u77e5\u8bc6"}, {"source": "SkateFormer Skeletal-Temporal Transformer for Human Action Recognition.pdf", "target": "sequences", "value": "\u77e5\u8bc6"}, {"source": "SkateFormer Skeletal-Temporal Transformer for Human Action Recognition.pdf", "target": "recognition", "value": "\u77e5\u8bc6"}, {"source": "SkateFormer Skeletal-Temporal Transformer for Human Action Recognition.pdf", "target": "generative models", "value": "\u77e5\u8bc6"}, {"source": "SkateFormer Skeletal-Temporal Transformer for Human Action Recognition.pdf", "target": "ensemble", "value": "\u77e5\u8bc6"}, {"source": "SkateFormer Skeletal-Temporal Transformer for Human Action Recognition.pdf", "target": "transformer-based models", "value": "\u77e5\u8bc6"}, {"source": "SkateFormer Skeletal-Temporal Transformer for Human Action Recognition.pdf", "target": "multi-modal fusion", "value": "\u77e5\u8bc6"}, {"source": "SlowFast Networks for Video Recognition.pdf", "target": "\u6df1\u5ea6\u5377\u79ef\u795e\u7ecf\u7f51\u7edc", "value": "\u77e5\u8bc6"}, {"source": "SlowFast Networks for Video Recognition.pdf", "target": "optimization", "value": "\u77e5\u8bc6"}, {"source": "SlowFast Networks for Video Recognition.pdf", "target": "action recognition", "value": "\u77e5\u8bc6"}, {"source": "SlowFast Networks for Video Recognition.pdf", "target": "\u795e\u7ecf\u7f51\u7edc", "value": "\u77e5\u8bc6"}, {"source": "SlowFast Networks for Video Recognition.pdf", "target": "Accuracy", "value": "\u77e5\u8bc6"}, {"source": "SlowFast Networks for Video Recognition.pdf", "target": "momentum", "value": "\u77e5\u8bc6"}, {"source": "SlowFast Networks for Video Recognition.pdf", "target": "distributed training", "value": "\u77e5\u8bc6"}, {"source": "SlowFast Networks for Video Recognition.pdf", "target": "model", "value": "\u77e5\u8bc6"}, {"source": "SlowFast Networks for Video Recognition.pdf", "target": "training", "value": "\u77e5\u8bc6"}, {"source": "SlowFast Networks for Video Recognition.pdf", "target": "\u5e73\u5747\u6c60\u5316", "value": "\u77e5\u8bc6"}, {"source": "SlowFast Networks for Video Recognition.pdf", "target": "design", "value": "\u77e5\u8bc6"}, {"source": "SlowFast Networks for Video Recognition.pdf", "target": "ResNet", "value": "\u77e5\u8bc6"}, {"source": "SlowFast Networks for Video Recognition.pdf", "target": "R-CNN", "value": "\u77e5\u8bc6"}, {"source": "SlowFast Networks for Video Recognition.pdf", "target": "learning rate", "value": "\u77e5\u8bc6"}, {"source": "SlowFast Networks for Video Recognition.pdf", "target": "strides", "value": "\u77e5\u8bc6"}, {"source": "SlowFast Networks for Video Recognition.pdf", "target": "sampling", "value": "\u77e5\u8bc6"}, {"source": "SlowFast Networks for Video Recognition.pdf", "target": "human action recognition", "value": "\u77e5\u8bc6"}, {"source": "SlowFast Networks for Video Recognition.pdf", "target": "concatenation", "value": "\u77e5\u8bc6"}, {"source": "SlowFast Networks for Video Recognition.pdf", "target": "feature detection", "value": "\u77e5\u8bc6"}, {"source": "SlowFast Networks for Video Recognition.pdf", "target": "dense sampling", "value": "\u77e5\u8bc6"}, {"source": "SlowFast Networks for Video Recognition.pdf", "target": "correlation", "value": "\u77e5\u8bc6"}, {"source": "SlowFast Networks for Video Recognition.pdf", "target": "histogram of oriented flow", "value": "\u77e5\u8bc6"}, {"source": "SlowFast Networks for Video Recognition.pdf", "target": "movement", "value": "\u77e5\u8bc6"}, {"source": "SlowFast Networks for Video Recognition.pdf", "target": "ensemble", "value": "\u77e5\u8bc6"}, {"source": "SlowFast Networks for Video Recognition.pdf", "target": "GAN", "value": "\u77e5\u8bc6"}, {"source": "SlowFast Networks for Video Recognition.pdf", "target": "spatiotemporal", "value": "\u77e5\u8bc6"}, {"source": "SlowFast Networks for Video Recognition.pdf", "target": "multi-modal fusion", "value": "\u77e5\u8bc6"}, {"source": "SlowFast Networks for Video Recognition.pdf", "target": "video recognition", "value": "\u77e5\u8bc6"}, {"source": "SlowFast Networks for Video Recognition.pdf", "target": "networks", "value": "\u77e5\u8bc6"}, {"source": "SlowFast Networks for Video Recognition.pdf", "target": "Faster R-CNN", "value": "\u77e5\u8bc6"}, {"source": "SlowFast Networks for Video Recognition.pdf", "target": "resolution", "value": "\u77e5\u8bc6"}, {"source": "SlowFast Networks for Video Recognition.pdf", "target": "input frames", "value": "\u77e5\u8bc6"}, {"source": "SlowFast Networks for Video Recognition.pdf", "target": "3D convolution", "value": "\u77e5\u8bc6"}, {"source": "SlowFast Networks for Video Recognition.pdf", "target": "precision", "value": "\u77e5\u8bc6"}, {"source": "SlowFast Networks for Video Recognition.pdf", "target": "convolutional network", "value": "\u77e5\u8bc6"}, {"source": "SlowFast Networks for Video Recognition.pdf", "target": "Detection", "value": "\u77e5\u8bc6"}, {"source": "SlowFast Networks for Video Recognition.pdf", "target": "\u7edf\u8ba1\u5b66", "value": "\u77e5\u8bc6"}, {"source": "SlowFast Networks for Video Recognition.pdf", "target": "spatio-temporal features", "value": "\u77e5\u8bc6"}, {"source": "SlowFast Networks for Video Recognition.pdf", "target": "confidence", "value": "\u77e5\u8bc6"}, {"source": "SlowFast Networks for Video Recognition.pdf", "target": "colors", "value": "\u77e5\u8bc6"}, {"source": "SlowFast Networks for Video Recognition.pdf", "target": "receptive fields", "value": "\u77e5\u8bc6"}, {"source": "SlowFast Networks for Video Recognition.pdf", "target": "DNN training", "value": "\u77e5\u8bc6"}, {"source": "SlowFast Networks for Video Recognition.pdf", "target": "ResNet-50", "value": "\u77e5\u8bc6"}, {"source": "SlowFast Networks for Video Recognition.pdf", "target": "pre-training", "value": "\u77e5\u8bc6"}, {"source": "SlowFast Networks for Video Recognition.pdf", "target": "Normalization", "value": "\u77e5\u8bc6"}, {"source": "SlowFast Networks for Video Recognition.pdf", "target": "train", "value": "\u77e5\u8bc6"}, {"source": "SlowFast Networks for Video Recognition.pdf", "target": "Fast R-CNN", "value": "\u77e5\u8bc6"}, {"source": "SlowFast Networks for Video Recognition.pdf", "target": "ImageNet\u5206\u7c7b", "value": "\u77e5\u8bc6"}, {"source": "SlowFast Networks for Video Recognition.pdf", "target": "region proposals", "value": "\u77e5\u8bc6"}, {"source": "SlowFast Networks for Video Recognition.pdf", "target": "hyper-parameters", "value": "\u77e5\u8bc6"}, {"source": "SSD.pdf", "target": "data augmentation", "value": "\u77e5\u8bc6"}, {"source": "SSD.pdf", "target": "convolutional neural networks", "value": "\u77e5\u8bc6"}, {"source": "SSD.pdf", "target": "CNN", "value": "\u77e5\u8bc6"}, {"source": "SSD.pdf", "target": "image classi\ufb01cation", "value": "\u77e5\u8bc6"}, {"source": "SSD.pdf", "target": "\u795e\u7ecf\u7f51\u7edc", "value": "\u77e5\u8bc6"}, {"source": "SSD.pdf", "target": "video object detection", "value": "\u77e5\u8bc6"}, {"source": "SSD.pdf", "target": "\u6df1\u5ea6\u5b66\u4e60", "value": "\u77e5\u8bc6"}, {"source": "SSD.pdf", "target": "feature map", "value": "\u77e5\u8bc6"}, {"source": "SSD.pdf", "target": "Kubernetes\u7ba1\u7406\u7cfb\u7edf", "value": "\u77e5\u8bc6"}, {"source": "SSD.pdf", "target": "Softmax", "value": "\u77e5\u8bc6"}, {"source": "SSD.pdf", "target": "loss function", "value": "\u77e5\u8bc6"}, {"source": "SSD.pdf", "target": "models", "value": "\u77e5\u8bc6"}, {"source": "SSD.pdf", "target": "classification", "value": "\u77e5\u8bc6"}, {"source": "SSD.pdf", "target": "VGG16", "value": "\u77e5\u8bc6"}, {"source": "SSD.pdf", "target": "feature maps", "value": "\u77e5\u8bc6"}, {"source": "SSD.pdf", "target": "accuracy", "value": "\u77e5\u8bc6"}, {"source": "SSD.pdf", "target": "object detection", "value": "\u77e5\u8bc6"}, {"source": "SSD.pdf", "target": "learning rate", "value": "\u77e5\u8bc6"}, {"source": "SSD.pdf", "target": "\u81ea\u52a8\u5316\u90e8\u7f72", "value": "\u77e5\u8bc6"}, {"source": "SSD.pdf", "target": "AWS", "value": "\u77e5\u8bc6"}, {"source": "SSD.pdf", "target": "\u8d1f\u8f7d\u5747\u8861\u5668", "value": "\u77e5\u8bc6"}, {"source": "SSD.pdf", "target": "sampling", "value": "\u77e5\u8bc6"}, {"source": "SSD.pdf", "target": "dataset", "value": "\u77e5\u8bc6"}, {"source": "SSD.pdf", "target": "Fully Connected", "value": "\u77e5\u8bc6"}, {"source": "SSD.pdf", "target": "bird", "value": "\u77e5\u8bc6"}, {"source": "SSD.pdf", "target": "classi\ufb01cation", "value": "\u77e5\u8bc6"}, {"source": "SSD.pdf", "target": "layers", "value": "\u77e5\u8bc6"}, {"source": "SSD.pdf", "target": "\u6df1\u5b66\u4e60\u6a21\u578b", "value": "\u77e5\u8bc6"}, {"source": "SSD.pdf", "target": "recurrent neural networks", "value": "\u77e5\u8bc6"}, {"source": "SSD.pdf", "target": "convolutional layers", "value": "\u77e5\u8bc6"}, {"source": "SSD.pdf", "target": "networks", "value": "\u77e5\u8bc6"}, {"source": "SSD.pdf", "target": "Faster R-CNN", "value": "\u77e5\u8bc6"}, {"source": "SSD.pdf", "target": "deep learning", "value": "\u77e5\u8bc6"}, {"source": "SSD.pdf", "target": "recall", "value": "\u77e5\u8bc6"}, {"source": "SSD.pdf", "target": "subsampling", "value": "\u77e5\u8bc6"}, {"source": "SSD.pdf", "target": "convolutional network", "value": "\u77e5\u8bc6"}, {"source": "SSD.pdf", "target": "kernels", "value": "\u77e5\u8bc6"}, {"source": "SSD.pdf", "target": "Detection", "value": "\u77e5\u8bc6"}, {"source": "SSD.pdf", "target": "state-of-the-art", "value": "\u77e5\u8bc6"}, {"source": "SSD.pdf", "target": "VGG-16", "value": "\u77e5\u8bc6"}, {"source": "SSD.pdf", "target": "backpropagation", "value": "\u77e5\u8bc6"}, {"source": "SSD.pdf", "target": "horse", "value": "\u77e5\u8bc6"}, {"source": "SSD.pdf", "target": "fast R-CNN", "value": "\u77e5\u8bc6"}, {"source": "SSD.pdf", "target": "feedforward neural networks", "value": "\u77e5\u8bc6"}, {"source": "SSD.pdf", "target": "chair", "value": "\u77e5\u8bc6"}, {"source": "SSD.pdf", "target": "multi-scale", "value": "\u77e5\u8bc6"}, {"source": "SSD.pdf", "target": "bike", "value": "\u77e5\u8bc6"}, {"source": "SSD.pdf", "target": "object\u68c0\u6d4b", "value": "\u77e5\u8bc6"}, {"source": "SSD.pdf", "target": "Rich feature hierarchies", "value": "\u77e5\u8bc6"}, {"source": "SSD.pdf", "target": "Fast R-CNN", "value": "\u77e5\u8bc6"}, {"source": "STNet\u7fbd\u6bdb\u7403\u8fd0\u52a8\u5c0f\u76ee\u6807\u5b9a\u4f4d\u8ddf\u8e2a\u7f51\u7edc.pdf", "target": "learning", "value": "\u77e5\u8bc6"}, {"source": "STNet\u7fbd\u6bdb\u7403\u8fd0\u52a8\u5c0f\u76ee\u6807\u5b9a\u4f4d\u8ddf\u8e2a\u7f51\u7edc.pdf", "target": "segmentation", "value": "\u77e5\u8bc6"}, {"source": "STNet\u7fbd\u6bdb\u7403\u8fd0\u52a8\u5c0f\u76ee\u6807\u5b9a\u4f4d\u8ddf\u8e2a\u7f51\u7edc.pdf", "target": "CNN", "value": "\u77e5\u8bc6"}, {"source": "STNet\u7fbd\u6bdb\u7403\u8fd0\u52a8\u5c0f\u76ee\u6807\u5b9a\u4f4d\u8ddf\u8e2a\u7f51\u7edc.pdf", "target": "\u795e\u7ecf\u7f51\u7edc", "value": "\u77e5\u8bc6"}, {"source": "STNet\u7fbd\u6bdb\u7403\u8fd0\u52a8\u5c0f\u76ee\u6807\u5b9a\u4f4d\u8ddf\u8e2a\u7f51\u7edc.pdf", "target": "video frames", "value": "\u77e5\u8bc6"}, {"source": "STNet\u7fbd\u6bdb\u7403\u8fd0\u52a8\u5c0f\u76ee\u6807\u5b9a\u4f4d\u8ddf\u8e2a\u7f51\u7edc.pdf", "target": "\u6df1\u5ea6\u5b66\u4e60", "value": "\u77e5\u8bc6"}, {"source": "STNet\u7fbd\u6bdb\u7403\u8fd0\u52a8\u5c0f\u76ee\u6807\u5b9a\u4f4d\u8ddf\u8e2a\u7f51\u7edc.pdf", "target": "\u5377\u79ef\u5c42", "value": "\u77e5\u8bc6"}, {"source": "STNet\u7fbd\u6bdb\u7403\u8fd0\u52a8\u5c0f\u76ee\u6807\u5b9a\u4f4d\u8ddf\u8e2a\u7f51\u7edc.pdf", "target": "\u56fe\u50cf\u8bc6\u522b", "value": "\u77e5\u8bc6"}, {"source": "STNet\u7fbd\u6bdb\u7403\u8fd0\u52a8\u5c0f\u76ee\u6807\u5b9a\u4f4d\u8ddf\u8e2a\u7f51\u7edc.pdf", "target": "\u56fe\u50cf\u5904\u7406", "value": "\u77e5\u8bc6"}, {"source": "STNet\u7fbd\u6bdb\u7403\u8fd0\u52a8\u5c0f\u76ee\u6807\u5b9a\u4f4d\u8ddf\u8e2a\u7f51\u7edc.pdf", "target": "Computer Vision", "value": "\u77e5\u8bc6"}, {"source": "STNet\u7fbd\u6bdb\u7403\u8fd0\u52a8\u5c0f\u76ee\u6807\u5b9a\u4f4d\u8ddf\u8e2a\u7f51\u7edc.pdf", "target": "\u8ba1\u7b97\u673a\u89c6\u89c9", "value": "\u77e5\u8bc6"}, {"source": "STNet\u7fbd\u6bdb\u7403\u8fd0\u52a8\u5c0f\u76ee\u6807\u5b9a\u4f4d\u8ddf\u8e2a\u7f51\u7edc.pdf", "target": "ICCV", "value": "\u77e5\u8bc6"}, {"source": "STNet\u7fbd\u6bdb\u7403\u8fd0\u52a8\u5c0f\u76ee\u6807\u5b9a\u4f4d\u8ddf\u8e2a\u7f51\u7edc.pdf", "target": "\u5e73\u5747\u6c60\u5316", "value": "\u77e5\u8bc6"}, {"source": "STNet\u7fbd\u6bdb\u7403\u8fd0\u52a8\u5c0f\u76ee\u6807\u5b9a\u4f4d\u8ddf\u8e2a\u7f51\u7edc.pdf", "target": "\u524d\u5411\u63a8\u7406", "value": "\u77e5\u8bc6"}, {"source": "STNet\u7fbd\u6bdb\u7403\u8fd0\u52a8\u5c0f\u76ee\u6807\u5b9a\u4f4d\u8ddf\u8e2a\u7f51\u7edc.pdf", "target": "\u7279\u5f81\u63d0\u53d6", "value": "\u77e5\u8bc6"}, {"source": "STNet\u7fbd\u6bdb\u7403\u8fd0\u52a8\u5c0f\u76ee\u6807\u5b9a\u4f4d\u8ddf\u8e2a\u7f51\u7edc.pdf", "target": "\u5377\u79ef\u6838", "value": "\u77e5\u8bc6"}, {"source": "STNet\u7fbd\u6bdb\u7403\u8fd0\u52a8\u5c0f\u76ee\u6807\u5b9a\u4f4d\u8ddf\u8e2a\u7f51\u7edc.pdf", "target": "\u6b8b\u5dee\u8fde\u63a5", "value": "\u77e5\u8bc6"}, {"source": "STNet\u7fbd\u6bdb\u7403\u8fd0\u52a8\u5c0f\u76ee\u6807\u5b9a\u4f4d\u8ddf\u8e2a\u7f51\u7edc.pdf", "target": "artificial intelligence", "value": "\u77e5\u8bc6"}, {"source": "STNet\u7fbd\u6bdb\u7403\u8fd0\u52a8\u5c0f\u76ee\u6807\u5b9a\u4f4d\u8ddf\u8e2a\u7f51\u7edc.pdf", "target": "Recognition", "value": "\u77e5\u8bc6"}, {"source": "STNet\u7fbd\u6bdb\u7403\u8fd0\u52a8\u5c0f\u76ee\u6807\u5b9a\u4f4d\u8ddf\u8e2a\u7f51\u7edc.pdf", "target": "tracking", "value": "\u77e5\u8bc6"}, {"source": "STNet\u7fbd\u6bdb\u7403\u8fd0\u52a8\u5c0f\u76ee\u6807\u5b9a\u4f4d\u8ddf\u8e2a\u7f51\u7edc.pdf", "target": "temporal_features", "value": "\u77e5\u8bc6"}, {"source": "STNet\u7fbd\u6bdb\u7403\u8fd0\u52a8\u5c0f\u76ee\u6807\u5b9a\u4f4d\u8ddf\u8e2a\u7f51\u7edc.pdf", "target": "TrackNet", "value": "\u77e5\u8bc6"}, {"source": "STNet\u7fbd\u6bdb\u7403\u8fd0\u52a8\u5c0f\u76ee\u6807\u5b9a\u4f4d\u8ddf\u8e2a\u7f51\u7edc.pdf", "target": "Faster R-CNN", "value": "\u77e5\u8bc6"}, {"source": "STNet\u7fbd\u6bdb\u7403\u8fd0\u52a8\u5c0f\u76ee\u6807\u5b9a\u4f4d\u8ddf\u8e2a\u7f51\u7edc.pdf", "target": "localization", "value": "\u77e5\u8bc6"}, {"source": "STNet\u7fbd\u6bdb\u7403\u8fd0\u52a8\u5c0f\u76ee\u6807\u5b9a\u4f4d\u8ddf\u8e2a\u7f51\u7edc.pdf", "target": "machinelearning", "value": "\u77e5\u8bc6"}, {"source": "STNet\u7fbd\u6bdb\u7403\u8fd0\u52a8\u5c0f\u76ee\u6807\u5b9a\u4f4d\u8ddf\u8e2a\u7f51\u7edc.pdf", "target": "Neurocomputing", "value": "\u77e5\u8bc6"}, {"source": "STNet\u7fbd\u6bdb\u7403\u8fd0\u52a8\u5c0f\u76ee\u6807\u5b9a\u4f4d\u8ddf\u8e2a\u7f51\u7edc.pdf", "target": "TCN", "value": "\u77e5\u8bc6"}, {"source": "STNet\u7fbd\u6bdb\u7403\u8fd0\u52a8\u5c0f\u76ee\u6807\u5b9a\u4f4d\u8ddf\u8e2a\u7f51\u7edc.pdf", "target": "channel attention", "value": "\u77e5\u8bc6"}, {"source": "STNet\u7fbd\u6bdb\u7403\u8fd0\u52a8\u5c0f\u76ee\u6807\u5b9a\u4f4d\u8ddf\u8e2a\u7f51\u7edc.pdf", "target": "\u53ec\u56de\u7387", "value": "\u77e5\u8bc6"}, {"source": "STNet\u7fbd\u6bdb\u7403\u8fd0\u52a8\u5c0f\u76ee\u6807\u5b9a\u4f4d\u8ddf\u8e2a\u7f51\u7edc.pdf", "target": "\u89c6\u89c9\u8ffd\u8e2a", "value": "\u77e5\u8bc6"}, {"source": "STNet\u7fbd\u6bdb\u7403\u8fd0\u52a8\u5c0f\u76ee\u6807\u5b9a\u4f4d\u8ddf\u8e2a\u7f51\u7edc.pdf", "target": "region proposal networks", "value": "\u77e5\u8bc6"}, {"source": "STNet\u7fbd\u6bdb\u7403\u8fd0\u52a8\u5c0f\u76ee\u6807\u5b9a\u4f4d\u8ddf\u8e2a\u7f51\u7edc.pdf", "target": "feature learning-based methods", "value": "\u77e5\u8bc6"}, {"source": "STNet\u7fbd\u6bdb\u7403\u8fd0\u52a8\u5c0f\u76ee\u6807\u5b9a\u4f4d\u8ddf\u8e2a\u7f51\u7edc.pdf", "target": "efficient shuttlecock tracking network", "value": "\u77e5\u8bc6"}, {"source": "STNet\u7fbd\u6bdb\u7403\u8fd0\u52a8\u5c0f\u76ee\u6807\u5b9a\u4f4d\u8ddf\u8e2a\u7f51\u7edc.pdf", "target": "\u591a\u5143\u8868\u793a\u5b66\u4e60", "value": "\u77e5\u8bc6"}, {"source": "STNet\u7fbd\u6bdb\u7403\u8fd0\u52a8\u5c0f\u76ee\u6807\u5b9a\u4f4d\u8ddf\u8e2a\u7f51\u7edc.pdf", "target": "\u591a\u5c3a\u5ea6\u4fe1\u606f\u4ea4\u6362", "value": "\u77e5\u8bc6"}, {"source": "STNet\u7fbd\u6bdb\u7403\u8fd0\u52a8\u5c0f\u76ee\u6807\u5b9a\u4f4d\u8ddf\u8e2a\u7f51\u7edc.pdf", "target": "\u7f51\u7edc\u8d85\u53c2\u6570\u8bbe\u7f6e", "value": "\u77e5\u8bc6"}, {"source": "STNet\u7fbd\u6bdb\u7403\u8fd0\u52a8\u5c0f\u76ee\u6807\u5b9a\u4f4d\u8ddf\u8e2a\u7f51\u7edc.pdf", "target": "video-based person re-identification", "value": "\u77e5\u8bc6"}, {"source": "STNet\u7fbd\u6bdb\u7403\u8fd0\u52a8\u5c0f\u76ee\u6807\u5b9a\u4f4d\u8ddf\u8e2a\u7f51\u7edc.pdf", "target": "automation", "value": "\u77e5\u8bc6"}, {"source": "STNet\u7fbd\u6bdb\u7403\u8fd0\u52a8\u5c0f\u76ee\u6807\u5b9a\u4f4d\u8ddf\u8e2a\u7f51\u7edc.pdf", "target": "\u6df1\u5ea6\u5b66\u4e60\u7f51\u7edcter\u5de5\u7a0b", "value": "\u77e5\u8bc6"}, {"source": "STNet\u7fbd\u6bdb\u7403\u8fd0\u52a8\u5c0f\u76ee\u6807\u5b9a\u4f4d\u8ddf\u8e2a\u7f51\u7edc.pdf", "target": "\u4f2a\u8272\u5f69\u8f6c\u6362", "value": "\u77e5\u8bc6"}, {"source": "STNet\u7fbd\u6bdb\u7403\u8fd0\u52a8\u5c0f\u76ee\u6807\u5b9a\u4f4d\u8ddf\u8e2a\u7f51\u7edc.pdf", "target": "\u70ed\u529b\u56fe", "value": "\u77e5\u8bc6"}, {"source": "STNet\u7fbd\u6bdb\u7403\u8fd0\u52a8\u5c0f\u76ee\u6807\u5b9a\u4f4d\u8ddf\u8e2a\u7f51\u7edc.pdf", "target": "heat map\u6062\u590d", "value": "\u77e5\u8bc6"}, {"source": "STNet\u7fbd\u6bdb\u7403\u8fd0\u52a8\u5c0f\u76ee\u6807\u5b9a\u4f4d\u8ddf\u8e2a\u7f51\u7edc.pdf", "target": "\u57fa\u51c6\u7f51\u7edc", "value": "\u77e5\u8bc6"}, {"source": "STNet\u7fbd\u6bdb\u7403\u8fd0\u52a8\u5c0f\u76ee\u6807\u5b9a\u4f4d\u8ddf\u8e2a\u7f51\u7edc.pdf", "target": "SECAR \u7279\u5f81\u63d0\u53d6\u6a21\u5757", "value": "\u77e5\u8bc6"}, {"source": "STNet\u7fbd\u6bdb\u7403\u8fd0\u52a8\u5c0f\u76ee\u6807\u5b9a\u4f4d\u8ddf\u8e2a\u7f51\u7edc.pdf", "target": "\u4e09\u7ef4\u8f68\u8ff9\u91cd\u5efa", "value": "\u77e5\u8bc6"}, {"source": "STNet\u7fbd\u6bdb\u7403\u8fd0\u52a8\u5c0f\u76ee\u6807\u5b9a\u4f4d\u8ddf\u8e2a\u7f51\u7edc.pdf", "target": "Yolov3", "value": "\u77e5\u8bc6"}, {"source": "STNet\u7fbd\u6bdb\u7403\u8fd0\u52a8\u5c0f\u76ee\u6807\u5b9a\u4f4d\u8ddf\u8e2a\u7f51\u7edc.pdf", "target": "Hypercolumn \u7ed3\u6784", "value": "\u77e5\u8bc6"}, {"source": "STNet\u7fbd\u6bdb\u7403\u8fd0\u52a8\u5c0f\u76ee\u6807\u5b9a\u4f4d\u8ddf\u8e2a\u7f51\u7edc.pdf", "target": "\u9ad8\u5206\u8fa8\u7387\u6a21\u5757", "value": "\u77e5\u8bc6"}, {"source": "STNet\u7fbd\u6bdb\u7403\u8fd0\u52a8\u5c0f\u76ee\u6807\u5b9a\u4f4d\u8ddf\u8e2a\u7f51\u7edc.pdf", "target": "Tiny YOLOv2", "value": "\u77e5\u8bc6"}, {"source": "STNet\u7fbd\u6bdb\u7403\u8fd0\u52a8\u5c0f\u76ee\u6807\u5b9a\u4f4d\u8ddf\u8e2a\u7f51\u7edc.pdf", "target": "\u65f6\u57df\u7279\u5f81", "value": "\u77e5\u8bc6"}, {"source": "Toward human activity recognition a survey.pdf", "target": "Dense trajectories", "value": "\u77e5\u8bc6"}, {"source": "Toward human activity recognition a survey.pdf", "target": "\u4eba\u5de5\u667a\u80fd", "value": "\u77e5\u8bc6"}, {"source": "Toward human activity recognition a survey.pdf", "target": "\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc", "value": "\u77e5\u8bc6"}, {"source": "Toward human activity recognition a survey.pdf", "target": "learning", "value": "\u77e5\u8bc6"}, {"source": "Toward human activity recognition a survey.pdf", "target": "LSTM", "value": "\u77e5\u8bc6"}, {"source": "Toward human activity recognition a survey.pdf", "target": "data augmentation", "value": "\u77e5\u8bc6"}, {"source": "Toward human activity recognition a survey.pdf", "target": "Human Action Recognition", "value": "\u77e5\u8bc6"}, {"source": "Toward human activity recognition a survey.pdf", "target": "convolutional neural networks", "value": "\u77e5\u8bc6"}, {"source": "Toward human activity recognition a survey.pdf", "target": "action recognition", "value": "\u77e5\u8bc6"}, {"source": "Toward human activity recognition a survey.pdf", "target": "neural network", "value": "\u77e5\u8bc6"}, {"source": "Toward human activity recognition a survey.pdf", "target": "video data", "value": "\u77e5\u8bc6"}, {"source": "Toward human activity recognition a survey.pdf", "target": "CNN", "value": "\u77e5\u8bc6"}, {"source": "Toward human activity recognition a survey.pdf", "target": "\u795e\u7ecf\u7f51\u7edc", "value": "\u77e5\u8bc6"}, {"source": "Toward human activity recognition a survey.pdf", "target": "3D\u5377\u79ef\u795e\u7ecf\u7f51\u7edc", "value": "\u77e5\u8bc6"}, {"source": "Toward human activity recognition a survey.pdf", "target": "3D\u5377\u79ef", "value": "\u77e5\u8bc6"}, {"source": "Toward human activity recognition a survey.pdf", "target": "\u4eba\u673a\u4ea4\u4e92", "value": "\u77e5\u8bc6"}, {"source": "Toward human activity recognition a survey.pdf", "target": "\u52a8\u6001\u56fe\u50cf\u5904\u7406", "value": "\u77e5\u8bc6"}, {"source": "Toward human activity recognition a survey.pdf", "target": "\u6df1\u5ea6\u5b66\u4e60", "value": "\u77e5\u8bc6"}, {"source": "Toward human activity recognition a survey.pdf", "target": "rank pooling", "value": "\u77e5\u8bc6"}, {"source": "Toward human activity recognition a survey.pdf", "target": "attention mechanism", "value": "\u77e5\u8bc6"}, {"source": "Toward human activity recognition a survey.pdf", "target": "network", "value": "\u77e5\u8bc6"}, {"source": "Toward human activity recognition a survey.pdf", "target": "devices", "value": "\u77e5\u8bc6"}, {"source": "Toward human activity recognition a survey.pdf", "target": "\u5927\u89c4\u6a21\u6570\u636e\u96c6", "value": "\u77e5\u8bc6"}, {"source": "Toward human activity recognition a survey.pdf", "target": "\u56fe\u50cf\u5904\u7406", "value": "\u77e5\u8bc6"}, {"source": "Toward human activity recognition a survey.pdf", "target": "image recognition", "value": "\u77e5\u8bc6"}, {"source": "Toward human activity recognition a survey.pdf", "target": "\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b", "value": "\u77e5\u8bc6"}, {"source": "Toward human activity recognition a survey.pdf", "target": "\u6df1\u5ea6\u7f51\u7edc", "value": "\u77e5\u8bc6"}, {"source": "Toward human activity recognition a survey.pdf", "target": "\u673a\u5668\u5b66\u4e60", "value": "\u77e5\u8bc6"}, {"source": "Toward human activity recognition a survey.pdf", "target": "\u5927\u6570\u636e", "value": "\u77e5\u8bc6"}, {"source": "Toward human activity recognition a survey.pdf", "target": "\u7279\u5f81\u5de5\u7a0b", "value": "\u77e5\u8bc6"}, {"source": "Toward human activity recognition a survey.pdf", "target": "Docker", "value": "\u77e5\u8bc6"}, {"source": "Toward human activity recognition a survey.pdf", "target": "model", "value": "\u77e5\u8bc6"}, {"source": "Toward human activity recognition a survey.pdf", "target": "\u56fe\u50cf\u5206\u7c7b", "value": "\u77e5\u8bc6"}, {"source": "Toward human activity recognition a survey.pdf", "target": "surveillance data streams", "value": "\u77e5\u8bc6"}, {"source": "Toward human activity recognition a survey.pdf", "target": "\u591a\u4efb\u52a1\u5b66\u4e60", "value": "\u77e5\u8bc6"}, {"source": "Toward human activity recognition a survey.pdf", "target": "Recurrent neural networks", "value": "\u77e5\u8bc6"}, {"source": "Toward human activity recognition a survey.pdf", "target": "\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5", "value": "\u77e5\u8bc6"}, {"source": "Toward human activity recognition a survey.pdf", "target": "classification", "value": "\u77e5\u8bc6"}, {"source": "Toward human activity recognition a survey.pdf", "target": "natural language processing", "value": "\u77e5\u8bc6"}, {"source": "Toward human activity recognition a survey.pdf", "target": "reinforcement learning", "value": "\u77e5\u8bc6"}, {"source": "Toward human activity recognition a survey.pdf", "target": "\u5377\u79ef\u795e\u7ecf\u7f51\u7edc", "value": "\u77e5\u8bc6"}, {"source": "Toward human activity recognition a survey.pdf", "target": "security", "value": "\u77e5\u8bc6"}, {"source": "Toward human activity recognition a survey.pdf", "target": "SIFT", "value": "\u77e5\u8bc6"}, {"source": "Toward human activity recognition a survey.pdf", "target": "Markov\u94fe", "value": "\u77e5\u8bc6"}, {"source": "Toward human activity recognition a survey.pdf", "target": "\u8ba1\u7b97\u673a\u89c6\u89c9", "value": "\u77e5\u8bc6"}, {"source": "Toward human activity recognition a survey.pdf", "target": "object detection", "value": "\u77e5\u8bc6"}, {"source": "Toward human activity recognition a survey.pdf", "target": "Group", "value": "\u77e5\u8bc6"}, {"source": "Toward human activity recognition a survey.pdf", "target": "\u5f3a\u5316\u5b66\u4e60", "value": "\u77e5\u8bc6"}, {"source": "Toward human activity recognition a survey.pdf", "target": "Convolutional neural networks", "value": "\u77e5\u8bc6"}, {"source": "Toward human activity recognition a survey.pdf", "target": "\u795e\u7ecf\u8ba1\u7b97", "value": "\u77e5\u8bc6"}, {"source": "TrackNet A Deep Learning Network for TrackingHigh-speed and Tiny Objects in Sports Applications.pdf", "target": "\u4eba\u5de5\u667a\u80fd", "value": "\u77e5\u8bc6"}, {"source": "TrackNet A Deep Learning Network for TrackingHigh-speed and Tiny Objects in Sports Applications.pdf", "target": "\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc", "value": "\u77e5\u8bc6"}, {"source": "TrackNet A Deep Learning Network for TrackingHigh-speed and Tiny Objects in Sports Applications.pdf", "target": "Fully convolutional networks", "value": "\u77e5\u8bc6"}, {"source": "TrackNet A Deep Learning Network for TrackingHigh-speed and Tiny Objects in Sports Applications.pdf", "target": "learning", "value": "\u77e5\u8bc6"}, {"source": "TrackNet A Deep Learning Network for TrackingHigh-speed and Tiny Objects in Sports Applications.pdf", "target": "pooling", "value": "\u77e5\u8bc6"}, {"source": "TrackNet A Deep Learning Network for TrackingHigh-speed and Tiny Objects in Sports Applications.pdf", "target": "neural networks", "value": "\u77e5\u8bc6"}, {"source": "TrackNet A Deep Learning Network for TrackingHigh-speed and Tiny Objects in Sports Applications.pdf", "target": "CNNs", "value": "\u77e5\u8bc6"}, {"source": "TrackNet A Deep Learning Network for TrackingHigh-speed and Tiny Objects in Sports Applications.pdf", "target": "neural network", "value": "\u77e5\u8bc6"}, {"source": "TrackNet A Deep Learning Network for TrackingHigh-speed and Tiny Objects in Sports Applications.pdf", "target": "CNN", "value": "\u77e5\u8bc6"}, {"source": "TrackNet A Deep Learning Network for TrackingHigh-speed and Tiny Objects in Sports Applications.pdf", "target": "semantic segmentation", "value": "\u77e5\u8bc6"}, {"source": "TrackNet A Deep Learning Network for TrackingHigh-speed and Tiny Objects in Sports Applications.pdf", "target": "\u795e\u7ecf\u7f51\u7edc", "value": "\u77e5\u8bc6"}, {"source": "TrackNet A Deep Learning Network for TrackingHigh-speed and Tiny Objects in Sports Applications.pdf", "target": "\u6df1\u5ea6\u5b66\u4e60", "value": "\u77e5\u8bc6"}, {"source": "TrackNet A Deep Learning Network for TrackingHigh-speed and Tiny Objects in Sports Applications.pdf", "target": "Frame", "value": "\u77e5\u8bc6"}, {"source": "TrackNet A Deep Learning Network for TrackingHigh-speed and Tiny Objects in Sports Applications.pdf", "target": "\u5377\u79ef\u5c42", "value": "\u77e5\u8bc6"}, {"source": "TrackNet A Deep Learning Network for TrackingHigh-speed and Tiny Objects in Sports Applications.pdf", "target": "\u56fe\u50cf\u5904\u7406", "value": "\u77e5\u8bc6"}, {"source": "TrackNet A Deep Learning Network for TrackingHigh-speed and Tiny Objects in Sports Applications.pdf", "target": "Overfitting", "value": "\u77e5\u8bc6"}, {"source": "TrackNet A Deep Learning Network for TrackingHigh-speed and Tiny Objects in Sports Applications.pdf", "target": "\u6700\u5927\u6c60\u5316", "value": "\u77e5\u8bc6"}, {"source": "TrackNet A Deep Learning Network for TrackingHigh-speed and Tiny Objects in Sports Applications.pdf", "target": "batch normalization", "value": "\u77e5\u8bc6"}, {"source": "TrackNet A Deep Learning Network for TrackingHigh-speed and Tiny Objects in Sports Applications.pdf", "target": "Softmax", "value": "\u77e5\u8bc6"}, {"source": "TrackNet A Deep Learning Network for TrackingHigh-speed and Tiny Objects in Sports Applications.pdf", "target": "\u8d85\u53c2\u6570\u8c03\u4f18", "value": "\u77e5\u8bc6"}, {"source": "TrackNet A Deep Learning Network for TrackingHigh-speed and Tiny Objects in Sports Applications.pdf", "target": "ReLU", "value": "\u77e5\u8bc6"}, {"source": "TrackNet A Deep Learning Network for TrackingHigh-speed and Tiny Objects in Sports Applications.pdf", "target": "\u7279\u5f81\u5b66\u4e60", "value": "\u77e5\u8bc6"}, {"source": "TrackNet A Deep Learning Network for TrackingHigh-speed and Tiny Objects in Sports Applications.pdf", "target": "Gaussian\u5206\u5e03", "value": "\u77e5\u8bc6"}, {"source": "TrackNet A Deep Learning Network for TrackingHigh-speed and Tiny Objects in Sports Applications.pdf", "target": "\u56fe\u50cf\u5206\u7c7b", "value": "\u77e5\u8bc6"}, {"source": "TrackNet A Deep Learning Network for TrackingHigh-speed and Tiny Objects in Sports Applications.pdf", "target": "kernel", "value": "\u77e5\u8bc6"}, {"source": "TrackNet A Deep Learning Network for TrackingHigh-speed and Tiny Objects in Sports Applications.pdf", "target": "loss function", "value": "\u77e5\u8bc6"}, {"source": "TrackNet A Deep Learning Network for TrackingHigh-speed and Tiny Objects in Sports Applications.pdf", "target": "epoch", "value": "\u77e5\u8bc6"}, {"source": "TrackNet A Deep Learning Network for TrackingHigh-speed and Tiny Objects in Sports Applications.pdf", "target": "Convolutional Neural Networks", "value": "\u77e5\u8bc6"}, {"source": "TrackNet A Deep Learning Network for TrackingHigh-speed and Tiny Objects in Sports Applications.pdf", "target": "\u5377\u79ef\u795e\u7ecf\u7f51\u7edc", "value": "\u77e5\u8bc6"}, {"source": "TrackNet A Deep Learning Network for TrackingHigh-speed and Tiny Objects in Sports Applications.pdf", "target": "\u6fc0\u6d3b\u51fd\u6570", "value": "\u77e5\u8bc6"}, {"source": "TrackNet A Deep Learning Network for TrackingHigh-speed and Tiny Objects in Sports Applications.pdf", "target": "pooling layer", "value": "\u77e5\u8bc6"}, {"source": "TrackNet A Deep Learning Network for TrackingHigh-speed and Tiny Objects in Sports Applications.pdf", "target": "SIFT", "value": "\u77e5\u8bc6"}, {"source": "TrackNet A Deep Learning Network for TrackingHigh-speed and Tiny Objects in Sports Applications.pdf", "target": "object detection", "value": "\u77e5\u8bc6"}, {"source": "TrackNet A Deep Learning Network for TrackingHigh-speed and Tiny Objects in Sports Applications.pdf", "target": "R-CNN", "value": "\u77e5\u8bc6"}, {"source": "TrackNet A Deep Learning Network for TrackingHigh-speed and Tiny Objects in Sports Applications.pdf", "target": "learning rate", "value": "\u77e5\u8bc6"}, {"source": "TrackNet A Deep Learning Network for TrackingHigh-speed and Tiny Objects in Sports Applications.pdf", "target": "\u673a\u5668\u89c6\u89c9", "value": "\u77e5\u8bc6"}, {"source": "TrackNet A Deep Learning Network for TrackingHigh-speed and Tiny Objects in Sports Applications.pdf", "target": "softmax\u51fd\u6570", "value": "\u77e5\u8bc6"}, {"source": "TrackNet A Deep Learning Network for TrackingHigh-speed and Tiny Objects in Sports Applications.pdf", "target": "\u7ef4\u5ea6", "value": "\u77e5\u8bc6"}, {"source": "TrackNet A Deep Learning Network for TrackingHigh-speed and Tiny Objects in Sports Applications.pdf", "target": "dataset", "value": "\u77e5\u8bc6"}, {"source": "TrackNet A Deep Learning Network for TrackingHigh-speed and Tiny Objects in Sports Applications.pdf", "target": "\u6df1\u5ea6\u5b66\u4e60\u7f51\u7edc", "value": "\u77e5\u8bc6"}, {"source": "TrackNet A Deep Learning Network for TrackingHigh-speed and Tiny Objects in Sports Applications.pdf", "target": "smartphones", "value": "\u77e5\u8bc6"}, {"source": "TrackNet A Deep Learning Network for TrackingHigh-speed and Tiny Objects in Sports Applications.pdf", "target": "\u4eba\u4f53\u6d3b\u52a8\u8bc6\u522b", "value": "\u77e5\u8bc6"}, {"source": "TrackNet A Deep Learning Network for TrackingHigh-speed and Tiny Objects in Sports Applications.pdf", "target": "Batch Normalization", "value": "\u77e5\u8bc6"}, {"source": "TrackNet A Deep Learning Network for TrackingHigh-speed and Tiny Objects in Sports Applications.pdf", "target": "occlusion", "value": "\u77e5\u8bc6"}, {"source": "TrackNet A Deep Learning Network for TrackingHigh-speed and Tiny Objects in Sports Applications.pdf", "target": "video analysis", "value": "\u77e5\u8bc6"}, {"source": "TrackNet A Deep Learning Network for TrackingHigh-speed and Tiny Objects in Sports Applications.pdf", "target": "Euclidean\u8ddd\u79bb", "value": "\u77e5\u8bc6"}, {"source": "TrackNet A Deep Learning Network for TrackingHigh-speed and Tiny Objects in Sports Applications.pdf", "target": "\u7edf\u8ba1\u7279\u5f81", "value": "\u77e5\u8bc6"}, {"source": "TrackNet A Deep Learning Network for TrackingHigh-speed and Tiny Objects in Sports Applications.pdf", "target": "angles", "value": "\u77e5\u8bc6"}, {"source": "TrackNet A Deep Learning Network for TrackingHigh-speed and Tiny Objects in Sports Applications.pdf", "target": "ground truth", "value": "\u77e5\u8bc6"}, {"source": "TrackNet A Deep Learning Network for TrackingHigh-speed and Tiny Objects in Sports Applications.pdf", "target": "Trajectory", "value": "\u77e5\u8bc6"}, {"source": "TrackNetV2 Efficient Shuttlecock TrackingNetwork.pdf", "target": "\u4eba\u5de5\u667a\u80fd", "value": "\u77e5\u8bc6"}, {"source": "TrackNetV2 Efficient Shuttlecock TrackingNetwork.pdf", "target": "DenseNet", "value": "\u77e5\u8bc6"}, {"source": "TrackNetV2 Efficient Shuttlecock TrackingNetwork.pdf", "target": "\u6df1\u5ea6\u5b66\u4e60", "value": "\u77e5\u8bc6"}, {"source": "TrackNetV2 Efficient Shuttlecock TrackingNetwork.pdf", "target": "\u5377\u79ef\u5c42", "value": "\u77e5\u8bc6"}, {"source": "TrackNetV2 Efficient Shuttlecock TrackingNetwork.pdf", "target": "network", "value": "\u77e5\u8bc6"}, {"source": "TrackNetV2 Efficient Shuttlecock TrackingNetwork.pdf", "target": "relu", "value": "\u77e5\u8bc6"}, {"source": "TrackNetV2 Efficient Shuttlecock TrackingNetwork.pdf", "target": "softmax", "value": "\u77e5\u8bc6"}, {"source": "TrackNetV2 Efficient Shuttlecock TrackingNetwork.pdf", "target": "S3\u5b58\u50a8\u670d\u52a1", "value": "\u77e5\u8bc6"}, {"source": "TrackNetV2 Efficient Shuttlecock TrackingNetwork.pdf", "target": "loss function", "value": "\u77e5\u8bc6"}, {"source": "TrackNetV2 Efficient Shuttlecock TrackingNetwork.pdf", "target": "\u7f51\u7edc\u7ed3\u6784", "value": "\u77e5\u8bc6"}, {"source": "TrackNetV2 Efficient Shuttlecock TrackingNetwork.pdf", "target": "VGG16", "value": "\u77e5\u8bc6"}, {"source": "TrackNetV2 Efficient Shuttlecock TrackingNetwork.pdf", "target": "concatenate", "value": "\u77e5\u8bc6"}, {"source": "TrackNetV2 Efficient Shuttlecock TrackingNetwork.pdf", "target": "Docker\u5bb9\u5668", "value": "\u77e5\u8bc6"}, {"source": "TrackNetV2 Efficient Shuttlecock TrackingNetwork.pdf", "target": "\u8ba1\u7b97\u673a\u89c6\u89c9", "value": "\u77e5\u8bc6"}, {"source": "TrackNetV2 Efficient Shuttlecock TrackingNetwork.pdf", "target": "accuracy", "value": "\u77e5\u8bc6"}, {"source": "TrackNetV2 Efficient Shuttlecock TrackingNetwork.pdf", "target": "object detection", "value": "\u77e5\u8bc6"}, {"source": "TrackNetV2 Efficient Shuttlecock TrackingNetwork.pdf", "target": "U-Net", "value": "\u77e5\u8bc6"}, {"source": "TrackNetV2 Efficient Shuttlecock TrackingNetwork.pdf", "target": "\u81ea\u52a8\u5316\u90e8\u7f72", "value": "\u77e5\u8bc6"}, {"source": "TrackNetV2 Efficient Shuttlecock TrackingNetwork.pdf", "target": "machine learning", "value": "\u77e5\u8bc6"}, {"source": "TrackNetV2 Efficient Shuttlecock TrackingNetwork.pdf", "target": "AWS", "value": "\u77e5\u8bc6"}, {"source": "TrackNetV2 Efficient Shuttlecock TrackingNetwork.pdf", "target": "Adadelta", "value": "\u77e5\u8bc6"}, {"source": "TrackNetV2 Efficient Shuttlecock TrackingNetwork.pdf", "target": "\u7279\u5f81\u62bd\u53d6", "value": "\u77e5\u8bc6"}, {"source": "TrackNetV2 Efficient Shuttlecock TrackingNetwork.pdf", "target": "\u6df1\u5ea6\u5b66\u4e60\u7f51\u7edc", "value": "\u77e5\u8bc6"}, {"source": "TrackNetV2 Efficient Shuttlecock TrackingNetwork.pdf", "target": "computer vision", "value": "\u77e5\u8bc6"}, {"source": "TrackNetV2 Efficient Shuttlecock TrackingNetwork.pdf", "target": "acoustic data", "value": "\u77e5\u8bc6"}, {"source": "TrackNetV2 Efficient Shuttlecock TrackingNetwork.pdf", "target": "softmax layer", "value": "\u77e5\u8bc6"}, {"source": "TrackNetV2 Efficient Shuttlecock TrackingNetwork.pdf", "target": "FCN", "value": "\u77e5\u8bc6"}, {"source": "TrackNetV2 Efficient Shuttlecock TrackingNetwork.pdf", "target": "golf swing", "value": "\u77e5\u8bc6"}, {"source": "TrackNetV2 Efficient Shuttlecock TrackingNetwork.pdf", "target": "pose estimation", "value": "\u77e5\u8bc6"}, {"source": "TrackNetV2 Efficient Shuttlecock TrackingNetwork.pdf", "target": "deeplearning", "value": "\u77e5\u8bc6"}, {"source": "TrackNetV2 Efficient Shuttlecock TrackingNetwork.pdf", "target": "Euclideandean\u8ddd\u79bb", "value": "\u77e5\u8bc6"}, {"source": "TrackNetV2 Efficient Shuttlecock TrackingNetwork.pdf", "target": "deep learning", "value": "\u77e5\u8bc6"}, {"source": "TrackNetV2 Efficient Shuttlecock TrackingNetwork.pdf", "target": "ball tracking", "value": "\u77e5\u8bc6"}, {"source": "TrackNetV2 Efficient Shuttlecock TrackingNetwork.pdf", "target": "max pooling", "value": "\u77e5\u8bc6"}, {"source": "TrackNetV2 Efficient Shuttlecock TrackingNetwork.pdf", "target": "precision", "value": "\u77e5\u8bc6"}, {"source": "TrackNetV2 Efficient Shuttlecock TrackingNetwork.pdf", "target": "F1-measure", "value": "\u77e5\u8bc6"}, {"source": "TrackNetV2 Efficient Shuttlecock TrackingNetwork.pdf", "target": "Kernelsize", "value": "\u77e5\u8bc6"}, {"source": "TrackNetV2 Efficient Shuttlecock TrackingNetwork.pdf", "target": "batch norm", "value": "\u77e5\u8bc6"}, {"source": "TrackNetV2 Efficient Shuttlecock TrackingNetwork.pdf", "target": "GPU memory", "value": "\u77e5\u8bc6"}, {"source": "TrackNetV2 Efficient Shuttlecock TrackingNetwork.pdf", "target": "broad", "value": "\u77e5\u8bc6"}, {"source": "TrackNetV2 Efficient Shuttlecock TrackingNetwork.pdf", "target": "L1 loss", "value": "\u77e5\u8bc6"}, {"source": "TrackNetV2 Efficient Shuttlecock TrackingNetwork.pdf", "target": "Gaussian distribution", "value": "\u77e5\u8bc6"}, {"source": "TrackNetV2 Efficient Shuttlecock TrackingNetwork.pdf", "target": "cross-entropy", "value": "\u77e5\u8bc6"}, {"source": "TrackNetV2 Efficient Shuttlecock TrackingNetwork.pdf", "target": "overfitting", "value": "\u77e5\u8bc6"}, {"source": "TrackNetV2 Efficient Shuttlecock TrackingNetwork.pdf", "target": "backgrounds", "value": "\u77e5\u8bc6"}, {"source": "TrackNetV2 Efficient Shuttlecock TrackingNetwork.pdf", "target": "multi-task deep learning", "value": "\u77e5\u8bc6"}, {"source": "TrackNetV2 Efficient Shuttlecock TrackingNetwork.pdf", "target": "weighted cross-entropy", "value": "\u77e5\u8bc6"}, {"source": "TrackNetV2 Efficient Shuttlecock TrackingNetwork.pdf", "target": "high-speed object", "value": "\u77e5\u8bc6"}, {"source": "TrackNetV2 Efficient Shuttlecock TrackingNetwork.pdf", "target": "KDNN", "value": "\u77e5\u8bc6"}, {"source": "TrackNetV2 Efficient Shuttlecock TrackingNetwork.pdf", "target": "heatmap", "value": "\u77e5\u8bc6"}, {"source": "TrackNetV3.pdf", "target": "data augmentation", "value": "\u77e5\u8bc6"}, {"source": "TrackNetV3.pdf", "target": "\u52a8\u529b\u5b66", "value": "\u77e5\u8bc6"}, {"source": "TrackNetV3.pdf", "target": "motion blur", "value": "\u77e5\u8bc6"}, {"source": "TrackNetV3.pdf", "target": "video frames", "value": "\u77e5\u8bc6"}, {"source": "TrackNetV3.pdf", "target": "AlexNet", "value": "\u77e5\u8bc6"}, {"source": "TrackNetV3.pdf", "target": "\u6df1\u5ea6\u5b66\u4e60", "value": "\u77e5\u8bc6"}, {"source": "TrackNetV3.pdf", "target": "\u5377\u79ef\u5c42", "value": "\u77e5\u8bc6"}, {"source": "TrackNetV3.pdf", "target": "Computer Vision", "value": "\u77e5\u8bc6"}, {"source": "TrackNetV3.pdf", "target": "Accuracy", "value": "\u77e5\u8bc6"}, {"source": "TrackNetV3.pdf", "target": "\u673a\u5668\u5b66\u4e60", "value": "\u77e5\u8bc6"}, {"source": "TrackNetV3.pdf", "target": "IoU", "value": "\u77e5\u8bc6"}, {"source": "TrackNetV3.pdf", "target": "epochs", "value": "\u77e5\u8bc6"}, {"source": "TrackNetV3.pdf", "target": "downsampling", "value": "\u77e5\u8bc6"}, {"source": "TrackNetV3.pdf", "target": "training", "value": "\u77e5\u8bc6"}, {"source": "TrackNetV3.pdf", "target": "U-Net", "value": "\u77e5\u8bc6"}, {"source": "TrackNetV3.pdf", "target": "R-CNN", "value": "\u77e5\u8bc6"}, {"source": "TrackNetV3.pdf", "target": "baseline", "value": "\u77e5\u8bc6"}, {"source": "TrackNetV3.pdf", "target": "\u4e8c\u8fdb\u5236\u4ea4\u53c9\u71b5", "value": "\u77e5\u8bc6"}, {"source": "TrackNetV3.pdf", "target": "pattern recognition", "value": "\u77e5\u8bc6"}, {"source": "TrackNetV3.pdf", "target": "fully convolutional networks", "value": "\u77e5\u8bc6"}, {"source": "TrackNetV3.pdf", "target": "Robustness", "value": "\u77e5\u8bc6"}, {"source": "TrackNetV3.pdf", "target": "strategy", "value": "\u77e5\u8bc6"}, {"source": "TrackNetV3.pdf", "target": "robustness", "value": "\u77e5\u8bc6"}, {"source": "TrackNetV3.pdf", "target": "regions", "value": "\u77e5\u8bc6"}, {"source": "TrackNetV3.pdf", "target": "IEEE Conference on Computer Vision and Pattern Recognition", "value": "\u77e5\u8bc6"}, {"source": "TrackNetV3.pdf", "target": "Sigmoid", "value": "\u77e5\u8bc6"}, {"source": "TrackNetV3.pdf", "target": "information", "value": "\u77e5\u8bc6"}, {"source": "TrackNetV3.pdf", "target": "cross-correlation", "value": "\u77e5\u8bc6"}, {"source": "TrackNetV3.pdf", "target": "tracking", "value": "\u77e5\u8bc6"}, {"source": "TrackNetV3.pdf", "target": "background", "value": "\u77e5\u8bc6"}, {"source": "TrackNetV3.pdf", "target": "formula", "value": "\u77e5\u8bc6"}, {"source": "TrackNetV3.pdf", "target": "Yolov4", "value": "\u77e5\u8bc6"}, {"source": "TrackNetV3.pdf", "target": "Dataset", "value": "\u77e5\u8bc6"}, {"source": "TrackNetV3.pdf", "target": "TrackNet", "value": "\u77e5\u8bc6"}, {"source": "TrackNetV3.pdf", "target": "Faster R-CNN", "value": "\u77e5\u8bc6"}, {"source": "TrackNetV3.pdf", "target": "dense object detection", "value": "\u77e5\u8bc6"}, {"source": "TrackNetV3.pdf", "target": "bounding box", "value": "\u77e5\u8bc6"}, {"source": "TrackNetV3.pdf", "target": "Tracknet", "value": "\u77e5\u8bc6"}, {"source": "TrackNetV3.pdf", "target": "Prediction", "value": "\u77e5\u8bc6"}, {"source": "TrackNetV3.pdf", "target": "sports analytics", "value": "\u77e5\u8bc6"}, {"source": "TrackNetV3.pdf", "target": "recall", "value": "\u77e5\u8bc6"}, {"source": "TrackNetV3.pdf", "target": "Frames", "value": "\u77e5\u8bc6"}, {"source": "TrackNetV3.pdf", "target": "baseline methods", "value": "\u77e5\u8bc6"}, {"source": "TrackNetV3.pdf", "target": "precision", "value": "\u77e5\u8bc6"}, {"source": "TrackNetV3.pdf", "target": "Convolutional Networks", "value": "\u77e5\u8bc6"}, {"source": "TrackNetV3.pdf", "target": "heat map", "value": "\u77e5\u8bc6"}, {"source": "TrackNetV3.pdf", "target": "Gaussian kernel", "value": "\u77e5\u8bc6"}, {"source": "TrackNetV3.pdf", "target": "batch size", "value": "\u77e5\u8bc6"}, {"source": "TrackNetV3.pdf", "target": "Precision", "value": "\u77e5\u8bc6"}, {"source": "TrackNetV3.pdf", "target": "Recall", "value": "\u77e5\u8bc6"}, {"source": "TrackNetV4 Enhancing Fast Sports Object.pdf", "target": "max-pooling", "value": "\u77e5\u8bc6"}, {"source": "TrackNetV4 Enhancing Fast Sports Object.pdf", "target": "fine-tuning", "value": "\u77e5\u8bc6"}, {"source": "TrackNetV4 Enhancing Fast Sports Object.pdf", "target": "neural networks", "value": "\u77e5\u8bc6"}, {"source": "TrackNetV4 Enhancing Fast Sports Object.pdf", "target": "motion blur", "value": "\u77e5\u8bc6"}, {"source": "TrackNetV4 Enhancing Fast Sports Object.pdf", "target": "\u6df1\u5ea6\u5b66\u4e60", "value": "\u77e5\u8bc6"}, {"source": "TrackNetV4 Enhancing Fast Sports Object.pdf", "target": "pixel intensity", "value": "\u77e5\u8bc6"}, {"source": "TrackNetV4 Enhancing Fast Sports Object.pdf", "target": "Performance", "value": "\u77e5\u8bc6"}, {"source": "TrackNetV4 Enhancing Fast Sports Object.pdf", "target": "Frame", "value": "\u77e5\u8bc6"}, {"source": "TrackNetV4 Enhancing Fast Sports Object.pdf", "target": "\u5377\u79ef\u5c42", "value": "\u77e5\u8bc6"}, {"source": "TrackNetV4 Enhancing Fast Sports Object.pdf", "target": "DNS", "value": "\u77e5\u8bc6"}, {"source": "TrackNetV4 Enhancing Fast Sports Object.pdf", "target": "\u8ba1\u7b97\u673a\u79d1\u5b66", "value": "\u77e5\u8bc6"}, {"source": "TrackNetV4 Enhancing Fast Sports Object.pdf", "target": "DenseLayer", "value": "\u77e5\u8bc6"}, {"source": "TrackNetV4 Enhancing Fast Sports Object.pdf", "target": "Kubernetes\u7ba1\u7406\u7cfb\u7edf", "value": "\u77e5\u8bc6"}, {"source": "TrackNetV4 Enhancing Fast Sports Object.pdf", "target": "Convolutional\u5757", "value": "\u77e5\u8bc6"}, {"source": "TrackNetV4 Enhancing Fast Sports Object.pdf", "target": "video processing", "value": "\u77e5\u8bc6"}, {"source": "TrackNetV4 Enhancing Fast Sports Object.pdf", "target": "Softmax", "value": "\u77e5\u8bc6"}, {"source": "TrackNetV4 Enhancing Fast Sports Object.pdf", "target": "S3\u5b58\u50a8\u670d\u52a1", "value": "\u77e5\u8bc6"}, {"source": "TrackNetV4 Enhancing Fast Sports Object.pdf", "target": "Dense", "value": "\u77e5\u8bc6"}, {"source": "TrackNetV4 Enhancing Fast Sports Object.pdf", "target": "activation", "value": "\u77e5\u8bc6"}, {"source": "TrackNetV4 Enhancing Fast Sports Object.pdf", "target": "keras", "value": "\u77e5\u8bc6"}, {"source": "TrackNetV4 Enhancing Fast Sports Object.pdf", "target": "\u03c3(\u00b7)", "value": "\u77e5\u8bc6"}, {"source": "TrackNetV4 Enhancing Fast Sports Object.pdf", "target": "Sigmoid function", "value": "\u77e5\u8bc6"}, {"source": "TrackNetV4 Enhancing Fast Sports Object.pdf", "target": "conv2D", "value": "\u77e5\u8bc6"}, {"source": "TrackNetV4 Enhancing Fast Sports Object.pdf", "target": "Computer Science", "value": "\u77e5\u8bc6"}, {"source": "TrackNetV4 Enhancing Fast Sports Object.pdf", "target": "linear", "value": "\u77e5\u8bc6"}, {"source": "TrackNetV4 Enhancing Fast Sports Object.pdf", "target": "feature maps", "value": "\u77e5\u8bc6"}, {"source": "TrackNetV4 Enhancing Fast Sports Object.pdf", "target": "batch_norm", "value": "\u77e5\u8bc6"}, {"source": "TrackNetV4 Enhancing Fast Sports Object.pdf", "target": "Docker\u5bb9\u5668", "value": "\u77e5\u8bc6"}, {"source": "TrackNetV4 Enhancing Fast Sports Object.pdf", "target": "Acoustics", "value": "\u77e5\u8bc6"}, {"source": "TrackNetV4 Enhancing Fast Sports Object.pdf", "target": "sigmoid", "value": "\u77e5\u8bc6"}, {"source": "TrackNetV4 Enhancing Fast Sports Object.pdf", "target": "\u8ba1\u7b97\u673a\u89c6\u89c9", "value": "\u77e5\u8bc6"}, {"source": "TrackNetV4 Enhancing Fast Sports Object.pdf", "target": "accuracy", "value": "\u77e5\u8bc6"}, {"source": "TrackNetV4 Enhancing Fast Sports Object.pdf", "target": "object detection", "value": "\u77e5\u8bc6"}, {"source": "TrackNetV4 Enhancing Fast Sports Object.pdf", "target": "tensor", "value": "\u77e5\u8bc6"}, {"source": "TrackNetV4 Enhancing Fast Sports Object.pdf", "target": "learning rate", "value": "\u77e5\u8bc6"}, {"source": "TrackNetV4 Enhancing Fast Sports Object.pdf", "target": "input_shape", "value": "\u77e5\u8bc6"}, {"source": "TrackNetV4 Enhancing Fast Sports Object.pdf", "target": "machine learning", "value": "\u77e5\u8bc6"}, {"source": "TrackNetV4 Enhancing Fast Sports Object.pdf", "target": "dataset", "value": "\u77e5\u8bc6"}, {"source": "TrackNetV4 Enhancing Fast Sports Object.pdf", "target": "2D\u5377\u79ef\u5c42", "value": "\u77e5\u8bc6"}, {"source": "TrackNetV4 Enhancing Fast Sports Object.pdf", "target": "computer vision", "value": "\u77e5\u8bc6"}, {"source": "TrackNetV4 Enhancing Fast Sports Object.pdf", "target": "robustness", "value": "\u77e5\u8bc6"}, {"source": "TrackNetV4 Enhancing Fast Sports Object.pdf", "target": "Sigmoid", "value": "\u77e5\u8bc6"}, {"source": "TrackNetV4 Enhancing Fast Sports Object.pdf", "target": "concatenation", "value": "\u77e5\u8bc6"}, {"source": "TrackNetV4 Enhancing Fast Sports Object.pdf", "target": "tracking", "value": "\u77e5\u8bc6"}, {"source": "TrackNetV4 Enhancing Fast Sports Object.pdf", "target": "occlusion", "value": "\u77e5\u8bc6"}, {"source": "TrackNetV4 Enhancing Fast Sports Object.pdf", "target": "\u8fd0\u52a8\u8bc6\u522b", "value": "\u77e5\u8bc6"}, {"source": "TrackNetV4 Enhancing Fast Sports Object.pdf", "target": "Machine Learning", "value": "\u77e5\u8bc6"}, {"source": "TrackNetV4 Enhancing Fast Sports Object.pdf", "target": "Human pose estimation", "value": "\u77e5\u8bc6"}, {"source": "TrackNetV4 Enhancing Fast Sports Object.pdf", "target": "Motion", "value": "\u77e5\u8bc6"}, {"source": "TrackNetV4 Enhancing Fast Sports Object.pdf", "target": "ACM MM", "value": "\u77e5\u8bc6"}, {"source": "YO-CSA-T A Real-time Badminton Tracking System Utilizing YOLOBased on Contextual and Spatial Attention.pdf", "target": "ImageNet", "value": "\u77e5\u8bc6"}, {"source": "YO-CSA-T A Real-time Badminton Tracking System Utilizing YOLOBased on Contextual and Spatial Attention.pdf", "target": "data augmentation", "value": "\u77e5\u8bc6"}, {"source": "YO-CSA-T A Real-time Badminton Tracking System Utilizing YOLOBased on Contextual and Spatial Attention.pdf", "target": "neural networks", "value": "\u77e5\u8bc6"}, {"source": "YO-CSA-T A Real-time Badminton Tracking System Utilizing YOLOBased on Contextual and Spatial Attention.pdf", "target": "convolutional neural networks", "value": "\u77e5\u8bc6"}, {"source": "YO-CSA-T A Real-time Badminton Tracking System Utilizing YOLOBased on Contextual and Spatial Attention.pdf", "target": "\u6df1\u5ea6\u5b66\u4e60", "value": "\u77e5\u8bc6"}, {"source": "YO-CSA-T A Real-time Badminton Tracking System Utilizing YOLOBased on Contextual and Spatial Attention.pdf", "target": "\u5377\u79ef\u5c42", "value": "\u77e5\u8bc6"}, {"source": "YO-CSA-T A Real-time Badminton Tracking System Utilizing YOLOBased on Contextual and Spatial Attention.pdf", "target": "image recognition", "value": "\u77e5\u8bc6"}, {"source": "YO-CSA-T A Real-time Badminton Tracking System Utilizing YOLOBased on Contextual and Spatial Attention.pdf", "target": "convolution", "value": "\u77e5\u8bc6"}, {"source": "YO-CSA-T A Real-time Badminton Tracking System Utilizing YOLOBased on Contextual and Spatial Attention.pdf", "target": "distribution", "value": "\u77e5\u8bc6"}, {"source": "YO-CSA-T A Real-time Badminton Tracking System Utilizing YOLOBased on Contextual and Spatial Attention.pdf", "target": "saturation", "value": "\u77e5\u8bc6"}, {"source": "YO-CSA-T A Real-time Badminton Tracking System Utilizing YOLOBased on Contextual and Spatial Attention.pdf", "target": "imagenet", "value": "\u77e5\u8bc6"}, {"source": "YO-CSA-T A Real-time Badminton Tracking System Utilizing YOLOBased on Contextual and Spatial Attention.pdf", "target": "downsampling", "value": "\u77e5\u8bc6"}, {"source": "YO-CSA-T A Real-time Badminton Tracking System Utilizing YOLOBased on Contextual and Spatial Attention.pdf", "target": "classification", "value": "\u77e5\u8bc6"}, {"source": "YO-CSA-T A Real-time Badminton Tracking System Utilizing YOLOBased on Contextual and Spatial Attention.pdf", "target": "Bottleneck", "value": "\u77e5\u8bc6"}, {"source": "YO-CSA-T A Real-time Badminton Tracking System Utilizing YOLOBased on Contextual and Spatial Attention.pdf", "target": "attention", "value": "\u77e5\u8bc6"}, {"source": "YO-CSA-T A Real-time Badminton Tracking System Utilizing YOLOBased on Contextual and Spatial Attention.pdf", "target": "\u8ba1\u7b97\u673a\u89c6\u89c9", "value": "\u77e5\u8bc6"}, {"source": "YO-CSA-T A Real-time Badminton Tracking System Utilizing YOLOBased on Contextual and Spatial Attention.pdf", "target": "U-Net", "value": "\u77e5\u8bc6"}, {"source": "YO-CSA-T A Real-time Badminton Tracking System Utilizing YOLOBased on Contextual and Spatial Attention.pdf", "target": "ResNet", "value": "\u77e5\u8bc6"}, {"source": "YO-CSA-T A Real-time Badminton Tracking System Utilizing YOLOBased on Contextual and Spatial Attention.pdf", "target": "R-CNN", "value": "\u77e5\u8bc6"}, {"source": "YO-CSA-T A Real-time Badminton Tracking System Utilizing YOLOBased on Contextual and Spatial Attention.pdf", "target": "Convolutions", "value": "\u77e5\u8bc6"}, {"source": "YO-CSA-T A Real-time Badminton Tracking System Utilizing YOLOBased on Contextual and Spatial Attention.pdf", "target": "dataset", "value": "\u77e5\u8bc6"}, {"source": "YO-CSA-T A Real-time Badminton Tracking System Utilizing YOLOBased on Contextual and Spatial Attention.pdf", "target": "Robotics", "value": "\u77e5\u8bc6"}, {"source": "YO-CSA-T A Real-time Badminton Tracking System Utilizing YOLOBased on Contextual and Spatial Attention.pdf", "target": "layers", "value": "\u77e5\u8bc6"}, {"source": "YO-CSA-T A Real-time Badminton Tracking System Utilizing YOLOBased on Contextual and Spatial Attention.pdf", "target": "UAV", "value": "\u77e5\u8bc6"}, {"source": "YO-CSA-T A Real-time Badminton Tracking System Utilizing YOLOBased on Contextual and Spatial Attention.pdf", "target": "robotics", "value": "\u77e5\u8bc6"}, {"source": "YO-CSA-T A Real-time Badminton Tracking System Utilizing YOLOBased on Contextual and Spatial Attention.pdf", "target": "tracking", "value": "\u77e5\u8bc6"}, {"source": "YO-CSA-T A Real-time Badminton Tracking System Utilizing YOLOBased on Contextual and Spatial Attention.pdf", "target": "feature extraction", "value": "\u77e5\u8bc6"}, {"source": "YO-CSA-T A Real-time Badminton Tracking System Utilizing YOLOBased on Contextual and Spatial Attention.pdf", "target": "pipeline", "value": "\u77e5\u8bc6"}, {"source": "YO-CSA-T A Real-time Badminton Tracking System Utilizing YOLOBased on Contextual and Spatial Attention.pdf", "target": "Transformer", "value": "\u77e5\u8bc6"}, {"source": "YO-CSA-T A Real-time Badminton Tracking System Utilizing YOLOBased on Contextual and Spatial Attention.pdf", "target": "transformer", "value": "\u77e5\u8bc6"}, {"source": "YO-CSA-T A Real-time Badminton Tracking System Utilizing YOLOBased on Contextual and Spatial Attention.pdf", "target": "encoder-decoder architecture", "value": "\u77e5\u8bc6"}, {"source": "YO-CSA-T A Real-time Badminton Tracking System Utilizing YOLOBased on Contextual and Spatial Attention.pdf", "target": "3D trajectory", "value": "\u77e5\u8bc6"}, {"source": "YO-CSA-T A Real-time Badminton Tracking System Utilizing YOLOBased on Contextual and Spatial Attention.pdf", "target": "self-attention", "value": "\u77e5\u8bc6"}, {"source": "YO-CSA-T A Real-time Badminton Tracking System Utilizing YOLOBased on Contextual and Spatial Attention.pdf", "target": "spatial attention", "value": "\u77e5\u8bc6"}, {"source": "YO-CSA-T A Real-time Badminton Tracking System Utilizing YOLOBased on Contextual and Spatial Attention.pdf", "target": "Detection", "value": "\u77e5\u8bc6"}, {"source": "YO-CSA-T A Real-time Badminton Tracking System Utilizing YOLOBased on Contextual and Spatial Attention.pdf", "target": "Computer vision", "value": "\u77e5\u8bc6"}, {"source": "YO-CSA-T A Real-time Badminton Tracking System Utilizing YOLOBased on Contextual and Spatial Attention.pdf", "target": "localization", "value": "\u77e5\u8bc6"}, {"source": "YO-CSA-T A Real-time Badminton Tracking System Utilizing YOLOBased on Contextual and Spatial Attention.pdf", "target": "stereo vision", "value": "\u77e5\u8bc6"}, {"source": "YO-CSA-T A Real-time Badminton Tracking System Utilizing YOLOBased on Contextual and Spatial Attention.pdf", "target": "YOLOv5", "value": "\u77e5\u8bc6"}, {"source": "YO-CSA-T A Real-time Badminton Tracking System Utilizing YOLOBased on Contextual and Spatial Attention.pdf", "target": "architecture", "value": "\u77e5\u8bc6"}, {"source": "YO-CSA-T A Real-time Badminton Tracking System Utilizing YOLOBased on Contextual and Spatial Attention.pdf", "target": "medical image segmentation", "value": "\u77e5\u8bc6"}, {"source": "YO-CSA-T A Real-time Badminton Tracking System Utilizing YOLOBased on Contextual and Spatial Attention.pdf", "target": "detection network", "value": "\u77e5\u8bc6"}, {"source": "YO-CSA-T A Real-time Badminton Tracking System Utilizing YOLOBased on Contextual and Spatial Attention.pdf", "target": "stereo cameras", "value": "\u77e5\u8bc6"}, {"source": "YO-CSA-T A Real-time Badminton Tracking System Utilizing YOLOBased on Contextual and Spatial Attention.pdf", "target": "\u7a7a\u95f4\u6ce8\u610f\u529b", "value": "\u77e5\u8bc6"}, {"source": "YO-CSA-T A Real-time Badminton Tracking System Utilizing YOLOBased on Contextual and Spatial Attention.pdf", "target": "HRNet", "value": "\u77e5\u8bc6"}, {"source": "YO-CSA-T A Real-time Badminton Tracking System Utilizing YOLOBased on Contextual and Spatial Attention.pdf", "target": "\u6df1\u5ea6\u6b8b\u5dee\u5b66\u4e60", "value": "\u77e5\u8bc6"}, {"source": "YO-CSA-T A Real-time Badminton Tracking System Utilizing YOLOBased on Contextual and Spatial Attention.pdf", "target": "ViT", "value": "\u77e5\u8bc6"}, {"source": "YO-CSA-T A Real-time Badminton Tracking System Utilizing YOLOBased on Contextual and Spatial Attention.pdf", "target": "RetinaNet", "value": "\u77e5\u8bc6"}, {"source": "YO-CSA-T A Real-time Badminton Tracking System Utilizing YOLOBased on Contextual and Spatial Attention.pdf", "target": "long-range dependencies", "value": "\u77e5\u8bc6"}, {"source": "YO-CSA-T A Real-time Badminton Tracking System Utilizing YOLOBased on Contextual and Spatial Attention.pdf", "target": "lighting", "value": "\u77e5\u8bc6"}, {"source": "YOLOv1.pdf", "target": "\u4eba\u5de5\u667a\u80fd", "value": "\u77e5\u8bc6"}, {"source": "YOLOv1.pdf", "target": "\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc", "value": "\u77e5\u8bc6"}, {"source": "YOLOv1.pdf", "target": "data augmentation", "value": "\u77e5\u8bc6"}, {"source": "YOLOv1.pdf", "target": "neural networks", "value": "\u77e5\u8bc6"}, {"source": "YOLOv1.pdf", "target": "neural network", "value": "\u77e5\u8bc6"}, {"source": "YOLOv1.pdf", "target": "CNN", "value": "\u77e5\u8bc6"}, {"source": "YOLOv1.pdf", "target": "SVM", "value": "\u77e5\u8bc6"}, {"source": "YOLOv1.pdf", "target": "convolutional.layers", "value": "\u77e5\u8bc6"}, {"source": "YOLOv1.pdf", "target": "\u5377\u79ef\u5c42", "value": "\u77e5\u8bc6"}, {"source": "YOLOv1.pdf", "target": "YOLO\u6a21\u578b", "value": "\u77e5\u8bc6"}, {"source": "YOLOv1.pdf", "target": "momentum", "value": "\u77e5\u8bc6"}, {"source": "YOLOv1.pdf", "target": "saturation", "value": "\u77e5\u8bc6"}, {"source": "YOLOv1.pdf", "target": "image segmentation", "value": "\u77e5\u8bc6"}, {"source": "YOLOv1.pdf", "target": "Image Classification", "value": "\u77e5\u8bc6"}, {"source": "YOLOv1.pdf", "target": "Convolutional Neural Network", "value": "\u77e5\u8bc6"}, {"source": "YOLOv1.pdf", "target": "SIFT", "value": "\u77e5\u8bc6"}, {"source": "YOLOv1.pdf", "target": "\u8ba1\u7b97\u673a\u89c6\u89c9", "value": "\u77e5\u8bc6"}, {"source": "YOLOv1.pdf", "target": "inference", "value": "\u77e5\u8bc6"}, {"source": "YOLOv1.pdf", "target": "R-CNN", "value": "\u77e5\u8bc6"}, {"source": "YOLOv1.pdf", "target": "learning rate", "value": "\u77e5\u8bc6"}, {"source": "YOLOv1.pdf", "target": "learning rate schedule", "value": "\u77e5\u8bc6"}, {"source": "YOLOv1.pdf", "target": "arXiv", "value": "\u77e5\u8bc6"}, {"source": "YOLOv1.pdf", "target": "sliding window", "value": "\u77e5\u8bc6"}, {"source": "YOLOv1.pdf", "target": "human", "value": "\u77e5\u8bc6"}, {"source": "YOLOv1.pdf", "target": "fully connected layers", "value": "\u77e5\u8bc6"}, {"source": "YOLOv1.pdf", "target": "extraction", "value": "\u77e5\u8bc6"}, {"source": "YOLOv1.pdf", "target": "\u5b9e\u65f6\u7cfb\u7edf", "value": "\u77e5\u8bc6"}, {"source": "YOLOv1.pdf", "target": "regression problem", "value": "\u77e5\u8bc6"}, {"source": "YOLOv1.pdf", "target": "feature extraction", "value": "\u77e5\u8bc6"}, {"source": "YOLOv1.pdf", "target": "detectors", "value": "\u77e5\u8bc6"}, {"source": "YOLOv1.pdf", "target": "detector", "value": "\u77e5\u8bc6"}, {"source": "YOLOv1.pdf", "target": "convolutional layers", "value": "\u77e5\u8bc6"}, {"source": "YOLOv1.pdf", "target": "deeplearning", "value": "\u77e5\u8bc6"}, {"source": "YOLOv1.pdf", "target": "convolutions", "value": "\u77e5\u8bc6"}, {"source": "YOLOv1.pdf", "target": "pipeline", "value": "\u77e5\u8bc6"}, {"source": "YOLOv1.pdf", "target": "ground truth", "value": "\u77e5\u8bc6"}, {"source": "YOLOv1.pdf", "target": "Faster R-CNN", "value": "\u77e5\u8bc6"}, {"source": "YOLOv1.pdf", "target": "bounding box", "value": "\u77e5\u8bc6"}, {"source": "YOLOv1.pdf", "target": "predictor", "value": "\u77e5\u8bc6"}, {"source": "YOLOv1.pdf", "target": "bounding boxes", "value": "\u77e5\u8bc6"}, {"source": "YOLOv1.pdf", "target": "recall", "value": "\u77e5\u8bc6"}, {"source": "YOLOv1.pdf", "target": "resolution", "value": "\u77e5\u8bc6"}, {"source": "YOLOv1.pdf", "target": "convolutional layer", "value": "\u77e5\u8bc6"}, {"source": "YOLOv1.pdf", "target": "RCNN", "value": "\u77e5\u8bc6"}, {"source": "YOLOv1.pdf", "target": "convolutional neural network", "value": "\u77e5\u8bc6"}, {"source": "YOLOv1.pdf", "target": "Detection", "value": "\u77e5\u8bc6"}, {"source": "YOLOv1.pdf", "target": "VGG-16", "value": "\u77e5\u8bc6"}, {"source": "YOLOv1.pdf", "target": "FAST", "value": "\u77e5\u8bc6"}, {"source": "YOLOv1.pdf", "target": "VGG", "value": "\u77e5\u8bc6"}, {"source": "YOLOv1.pdf", "target": "localization", "value": "\u77e5\u8bc6"}, {"source": "YOLOv2.pdf", "target": "\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc", "value": "\u77e5\u8bc6"}, {"source": "YOLOv2.pdf", "target": "ImageNet", "value": "\u77e5\u8bc6"}, {"source": "YOLOv2.pdf", "target": "neural networks", "value": "\u77e5\u8bc6"}, {"source": "YOLOv2.pdf", "target": "convolutional neural networks", "value": "\u77e5\u8bc6"}, {"source": "YOLOv2.pdf", "target": "\u795e\u7ecf\u7f51\u7edc", "value": "\u77e5\u8bc6"}, {"source": "YOLOv2.pdf", "target": "AlexNet", "value": "\u77e5\u8bc6"}, {"source": "YOLOv2.pdf", "target": "\u5377\u79ef\u5c42", "value": "\u77e5\u8bc6"}, {"source": "YOLOv2.pdf", "target": "feature map", "value": "\u77e5\u8bc6"}, {"source": "YOLOv2.pdf", "target": "batch normalization", "value": "\u77e5\u8bc6"}, {"source": "YOLOv2.pdf", "target": "momentum", "value": "\u77e5\u8bc6"}, {"source": "YOLOv2.pdf", "target": "\u5b66\u4e60\u7387\u8c03\u8282", "value": "\u77e5\u8bc6"}, {"source": "YOLOv2.pdf", "target": "Sutskever", "value": "\u77e5\u8bc6"}, {"source": "YOLOv2.pdf", "target": "Krizhevsky", "value": "\u77e5\u8bc6"}, {"source": "YOLOv2.pdf", "target": "saturation", "value": "\u77e5\u8bc6"}, {"source": "YOLOv2.pdf", "target": "layer", "value": "\u77e5\u8bc6"}, {"source": "YOLOv2.pdf", "target": "inception-resnet", "value": "\u77e5\u8bc6"}, {"source": "YOLOv2.pdf", "target": "Node", "value": "\u77e5\u8bc6"}, {"source": "YOLOv2.pdf", "target": "pooling layer", "value": "\u77e5\u8bc6"}, {"source": "YOLOv2.pdf", "target": "dropout", "value": "\u77e5\u8bc6"}, {"source": "YOLOv2.pdf", "target": "\u8ba1\u7b97\u673a\u89c6\u89c9", "value": "\u77e5\u8bc6"}, {"source": "YOLOv2.pdf", "target": "ResNet", "value": "\u77e5\u8bc6"}, {"source": "YOLOv2.pdf", "target": "k-means", "value": "\u77e5\u8bc6"}, {"source": "YOLOv2.pdf", "target": "softmax\u51fd\u6570", "value": "\u77e5\u8bc6"}, {"source": "YOLOv2.pdf", "target": "Hinton", "value": "\u77e5\u8bc6"}, {"source": "YOLOv2.pdf", "target": "inception-v4", "value": "\u77e5\u8bc6"}, {"source": "YOLOv2.pdf", "target": "1\u00d71\u5377\u79ef\u5c42", "value": "\u77e5\u8bc6"}, {"source": "YOLOv2.pdf", "target": "cluster", "value": "\u77e5\u8bc6"}, {"source": "YOLOv2.pdf", "target": "classi\ufb01cation", "value": "\u77e5\u8bc6"}, {"source": "YOLOv2.pdf", "target": "object", "value": "\u77e5\u8bc6"}, {"source": "YOLOv2.pdf", "target": "height", "value": "\u77e5\u8bc6"}, {"source": "YOLOv2.pdf", "target": "clustering", "value": "\u77e5\u8bc6"}, {"source": "YOLOv2.pdf", "target": "Deep residual learning", "value": "\u77e5\u8bc6"}, {"source": "YOLOv2.pdf", "target": "frequency", "value": "\u77e5\u8bc6"}, {"source": "YOLOv2.pdf", "target": "robustness", "value": "\u77e5\u8bc6"}, {"source": "YOLOv2.pdf", "target": "centroid", "value": "\u77e5\u8bc6"}, {"source": "YOLOv2.pdf", "target": "Euclidean\u8ddd\u79bb", "value": "\u77e5\u8bc6"}, {"source": "YOLOv2.pdf", "target": "ground truth", "value": "\u77e5\u8bc6"}, {"source": "YOLOv2.pdf", "target": "Faster R-CNN", "value": "\u77e5\u8bc6"}, {"source": "YOLOv2.pdf", "target": "anchor box", "value": "\u77e5\u8bc6"}, {"source": "YOLOv2.pdf", "target": "bounding box", "value": "\u77e5\u8bc6"}, {"source": "YOLOv2.pdf", "target": "real-time object detection", "value": "\u77e5\u8bc6"}, {"source": "YOLOv2.pdf", "target": "bounding boxes", "value": "\u77e5\u8bc6"}, {"source": "YOLOv2.pdf", "target": "Image recognition", "value": "\u77e5\u8bc6"}, {"source": "YOLOv2.pdf", "target": "oversampling", "value": "\u77e5\u8bc6"}, {"source": "YOLOv2.pdf", "target": "resolution", "value": "\u77e5\u8bc6"}, {"source": "YOLOv2.pdf", "target": "convolutional layer", "value": "\u77e5\u8bc6"}, {"source": "YOLOv2.pdf", "target": "image classification", "value": "\u77e5\u8bc6"}, {"source": "YOLOv2.pdf", "target": "VGG", "value": "\u77e5\u8bc6"}, {"source": "YOLOv2.pdf", "target": "batch norm", "value": "\u77e5\u8bc6"}, {"source": "YOLOv2.pdf", "target": "top-5 accuracy", "value": "\u77e5\u8bc6"}, {"source": "YOLOv3.pdf", "target": "\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc", "value": "\u77e5\u8bc6"}, {"source": "YOLOv3.pdf", "target": "ImageNet", "value": "\u77e5\u8bc6"}, {"source": "YOLOv3.pdf", "target": "feature map", "value": "\u77e5\u8bc6"}, {"source": "YOLOv3.pdf", "target": "Accuracy", "value": "\u77e5\u8bc6"}, {"source": "YOLOv3.pdf", "target": "\u673a\u5668\u5b66\u4e60", "value": "\u77e5\u8bc6"}, {"source": "YOLOv3.pdf", "target": "Softmax", "value": "\u77e5\u8bc6"}, {"source": "YOLOv3.pdf", "target": "softmax", "value": "\u77e5\u8bc6"}, {"source": "YOLOv3.pdf", "target": "GPU", "value": "\u77e5\u8bc6"}, {"source": "YOLOv3.pdf", "target": "Residual", "value": "\u77e5\u8bc6"}, {"source": "YOLOv3.pdf", "target": "\u7aef\u5230\u7aef\u5b66\u4e60", "value": "\u77e5\u8bc6"}, {"source": "YOLOv3.pdf", "target": "accuracy", "value": "\u77e5\u8bc6"}, {"source": "YOLOv3.pdf", "target": "object detection", "value": "\u77e5\u8bc6"}, {"source": "YOLOv3.pdf", "target": "ICCV", "value": "\u77e5\u8bc6"}, {"source": "YOLOv3.pdf", "target": "tensor", "value": "\u77e5\u8bc6"}, {"source": "YOLOv3.pdf", "target": "dataset", "value": "\u77e5\u8bc6"}, {"source": "YOLOv3.pdf", "target": "computer vision", "value": "\u77e5\u8bc6"}, {"source": "YOLOv3.pdf", "target": "clustering", "value": "\u77e5\u8bc6"}, {"source": "YOLOv3.pdf", "target": "ResNet-152", "value": "\u77e5\u8bc6"}, {"source": "YOLOv3.pdf", "target": "detectors", "value": "\u77e5\u8bc6"}, {"source": "YOLOv3.pdf", "target": "semantic information", "value": "\u77e5\u8bc6"}, {"source": "YOLOv3.pdf", "target": "scales", "value": "\u77e5\u8bc6"}, {"source": "YOLOv3.pdf", "target": "convolutional layers", "value": "\u77e5\u8bc6"}, {"source": "YOLOv3.pdf", "target": "GAN", "value": "\u77e5\u8bc6"}, {"source": "YOLOv3.pdf", "target": "residual network", "value": "\u77e5\u8bc6"}, {"source": "YOLOv3.pdf", "target": "Faster R-CNN", "value": "\u77e5\u8bc6"}, {"source": "YOLOv3.pdf", "target": "Ssd", "value": "\u77e5\u8bc6"}, {"source": "YOLOv3.pdf", "target": "bounding box", "value": "\u77e5\u8bc6"}, {"source": "YOLOv3.pdf", "target": "deep learning", "value": "\u77e5\u8bc6"}, {"source": "YOLOv3.pdf", "target": "R-FCN", "value": "\u77e5\u8bc6"}, {"source": "YOLOv3.pdf", "target": "floating point operations", "value": "\u77e5\u8bc6"}, {"source": "YOLOv3.pdf", "target": "focal loss", "value": "\u77e5\u8bc6"}, {"source": "YOLOv3.pdf", "target": "anchor boxes", "value": "\u77e5\u8bc6"}, {"source": "YOLOv3.pdf", "target": "ResNet-101", "value": "\u77e5\u8bc6"}, {"source": "YOLOv3.pdf", "target": "ObjectDetection", "value": "\u77e5\u8bc6"}, {"source": "YOLOv3.pdf", "target": "vision", "value": "\u77e5\u8bc6"}, {"source": "YOLOv3.pdf", "target": "Inception-ResNet-v2", "value": "\u77e5\u8bc6"}, {"source": "YOLOv3.pdf", "target": "top-down modulation", "value": "\u77e5\u8bc6"}, {"source": "YOLOv3.pdf", "target": "RetinaNet", "value": "\u77e5\u8bc6"}, {"source": "YOLOv3.pdf", "target": "region proposal networks", "value": "\u77e5\u8bc6"}, {"source": "YOLOv3.pdf", "target": "single shot multibox detector", "value": "\u77e5\u8bc6"}, {"source": "YOLOv3.pdf", "target": "ResNet-101-FPN", "value": "\u77e5\u8bc6"}, {"source": "YOLOv3.pdf", "target": "ResNets", "value": "\u77e5\u8bc6"}, {"source": "YOLOv3.pdf", "target": "bounding box detection", "value": "\u77e5\u8bc6"}, {"source": "YOLOv3.pdf", "target": "ResNeXt-101-FPN", "value": "\u77e5\u8bc6"}, {"source": "YOLOv3.pdf", "target": "Titan X", "value": "\u77e5\u8bc6"}, {"source": "YOLOv3.pdf", "target": "Person", "value": "\u77e5\u8bc6"}, {"source": "YOLOv3.pdf", "target": "feature extractor", "value": "\u77e5\u8bc6"}, {"source": "YOLOv3.pdf", "target": "Upsample", "value": "\u77e5\u8bc6"}, {"source": "YOLOv3.pdf", "target": "Bounding boxes", "value": "\u77e5\u8bc6"}, {"source": "YOLOv3.pdf", "target": "Avgpool", "value": "\u77e5\u8bc6"}, {"source": "YOLOv4.pdf", "target": "max-pooling", "value": "\u77e5\u8bc6"}, {"source": "YOLOv4.pdf", "target": "cvpr", "value": "\u77e5\u8bc6"}, {"source": "YOLOv4.pdf", "target": "ImageNet", "value": "\u77e5\u8bc6"}, {"source": "YOLOv4.pdf", "target": "data augmentation", "value": "\u77e5\u8bc6"}, {"source": "YOLOv4.pdf", "target": "neural networks", "value": "\u77e5\u8bc6"}, {"source": "YOLOv4.pdf", "target": "neural network", "value": "\u77e5\u8bc6"}, {"source": "YOLOv4.pdf", "target": "CNN", "value": "\u77e5\u8bc6"}, {"source": "YOLOv4.pdf", "target": "\u795e\u7ecf\u7f51\u7edc", "value": "\u77e5\u8bc6"}, {"source": "YOLOv4.pdf", "target": "DenseNet", "value": "\u77e5\u8bc6"}, {"source": "YOLOv4.pdf", "target": "NIPS", "value": "\u77e5\u8bc6"}, {"source": "YOLOv4.pdf", "target": "\u6df1\u5ea6\u5b66\u4e60", "value": "\u77e5\u8bc6"}, {"source": "YOLOv4.pdf", "target": "Kubernetes", "value": "\u77e5\u8bc6"}, {"source": "YOLOv4.pdf", "target": "tanh", "value": "\u77e5\u8bc6"}, {"source": "YOLOv4.pdf", "target": "attention mechanism", "value": "\u77e5\u8bc6"}, {"source": "YOLOv4.pdf", "target": "Computer Vision", "value": "\u77e5\u8bc6"}, {"source": "YOLOv4.pdf", "target": "batch normalization", "value": "\u77e5\u8bc6"}, {"source": "YOLOv4.pdf", "target": "softmax", "value": "\u77e5\u8bc6"}, {"source": "YOLOv4.pdf", "target": "momentum", "value": "\u77e5\u8bc6"}, {"source": "YOLOv4.pdf", "target": "ReLU", "value": "\u77e5\u8bc6"}, {"source": "YOLOv4.pdf", "target": "IoU", "value": "\u77e5\u8bc6"}, {"source": "YOLOv4.pdf", "target": "GPU", "value": "\u77e5\u8bc6"}, {"source": "YOLOv4.pdf", "target": "Convolutional Neural Network", "value": "\u77e5\u8bc6"}, {"source": "YOLOv4.pdf", "target": "Docker\u5bb9\u5668", "value": "\u77e5\u8bc6"}, {"source": "YOLOv4.pdf", "target": "training", "value": "\u77e5\u8bc6"}, {"source": "YOLOv4.pdf", "target": "sigmoid", "value": "\u77e5\u8bc6"}, {"source": "YOLOv4.pdf", "target": "semantic image segmentation", "value": "\u77e5\u8bc6"}, {"source": "YOLOv4.pdf", "target": "dropout", "value": "\u77e5\u8bc6"}, {"source": "YOLOv4.pdf", "target": "Cross Entropy", "value": "\u77e5\u8bc6"}, {"source": "YOLOv4.pdf", "target": "object detection", "value": "\u77e5\u8bc6"}, {"source": "YOLOv4.pdf", "target": "ICCV", "value": "\u77e5\u8bc6"}, {"source": "YOLOv4.pdf", "target": "ResNet", "value": "\u77e5\u8bc6"}, {"source": "YOLOv4.pdf", "target": "R-CNN", "value": "\u77e5\u8bc6"}, {"source": "YOLOv4.pdf", "target": "Label", "value": "\u77e5\u8bc6"}, {"source": "YOLOv4.pdf", "target": "AWS", "value": "\u77e5\u8bc6"}, {"source": "YOLOv4.pdf", "target": "normalization", "value": "\u77e5\u8bc6"}, {"source": "YOLOv4.pdf", "target": "pattern recognition", "value": "\u77e5\u8bc6"}, {"source": "YOLOv4.pdf", "target": "\u68af\u5ea6\u4e0b\u964d", "value": "\u77e5\u8bc6"}, {"source": "YOLOv4.pdf", "target": "features", "value": "\u77e5\u8bc6"}, {"source": "YOLOv4.pdf", "target": "artificial intelligence", "value": "\u77e5\u8bc6"}, {"source": "YOLOv4.pdf", "target": "computer vision", "value": "\u77e5\u8bc6"}, {"source": "YOLOv4.pdf", "target": "Batch Normalization", "value": "\u77e5\u8bc6"}, {"source": "YOLOv4.pdf", "target": "recognition", "value": "\u77e5\u8bc6"}, {"source": "YOLOv4.pdf", "target": "feature extraction", "value": "\u77e5\u8bc6"}, {"source": "YOLOv4.pdf", "target": "CRFs", "value": "\u77e5\u8bc6"}, {"source": "YOLOv4.pdf", "target": "detector", "value": "\u77e5\u8bc6"}, {"source": "YOLOv4.pdf", "target": "Machine Learning", "value": "\u77e5\u8bc6"}, {"source": "YOLOv4.pdf", "target": "Fully Convolutional Network", "value": "\u77e5\u8bc6"}, {"source": "YOLOv4.pdf", "target": "MSE", "value": "\u77e5\u8bc6"}, {"source": "YOLOv4.pdf", "target": "networks", "value": "\u77e5\u8bc6"}, {"source": "YOLOv4.pdf", "target": "ground truth", "value": "\u77e5\u8bc6"}, {"source": "YOLOv5.pdf", "target": "ReLU\u5c42", "value": "\u77e5\u8bc6"}, {"source": "YOLOv5.pdf", "target": "neural networks", "value": "\u77e5\u8bc6"}, {"source": "YOLOv5.pdf", "target": "segmentation", "value": "\u77e5\u8bc6"}, {"source": "YOLOv5.pdf", "target": "convolutional neural networks", "value": "\u77e5\u8bc6"}, {"source": "YOLOv5.pdf", "target": "feature", "value": "\u77e5\u8bc6"}, {"source": "YOLOv5.pdf", "target": "CNN", "value": "\u77e5\u8bc6"}, {"source": "YOLOv5.pdf", "target": "\u6df1\u5ea6\u5b66\u4e60", "value": "\u77e5\u8bc6"}, {"source": "YOLOv5.pdf", "target": "attention mechanism", "value": "\u77e5\u8bc6"}, {"source": "YOLOv5.pdf", "target": "\u56fe\u50cf\u5904\u7406", "value": "\u77e5\u8bc6"}, {"source": "YOLOv5.pdf", "target": "Convolution", "value": "\u77e5\u8bc6"}, {"source": "YOLOv5.pdf", "target": "Deep learning", "value": "\u77e5\u8bc6"}, {"source": "YOLOv5.pdf", "target": "feature maps", "value": "\u77e5\u8bc6"}, {"source": "YOLOv5.pdf", "target": "Neural Information Processing Systems", "value": "\u77e5\u8bc6"}, {"source": "YOLOv5.pdf", "target": "object detection", "value": "\u77e5\u8bc6"}, {"source": "YOLOv5.pdf", "target": "R-CNN", "value": "\u77e5\u8bc6"}, {"source": "YOLOv5.pdf", "target": "arXiv", "value": "\u77e5\u8bc6"}, {"source": "YOLOv5.pdf", "target": "AWS", "value": "\u77e5\u8bc6"}, {"source": "YOLOv5.pdf", "target": "\u52a0\u6743\u548c", "value": "\u77e5\u8bc6"}, {"source": "YOLOv5.pdf", "target": "Deeplab", "value": "\u77e5\u8bc6"}, {"source": "YOLOv5.pdf", "target": "computer vision", "value": "\u77e5\u8bc6"}, {"source": "YOLOv5.pdf", "target": "Sigmoid", "value": "\u77e5\u8bc6"}, {"source": "YOLOv5.pdf", "target": "Recognition", "value": "\u77e5\u8bc6"}, {"source": "YOLOv5.pdf", "target": "Pattern Recognition", "value": "\u77e5\u8bc6"}, {"source": "YOLOv5.pdf", "target": "translation", "value": "\u77e5\u8bc6"}, {"source": "YOLOv5.pdf", "target": "multiple instance learning", "value": "\u77e5\u8bc6"}, {"source": "YOLOv5.pdf", "target": "bounding box", "value": "\u77e5\u8bc6"}, {"source": "YOLOv5.pdf", "target": "convolutional layer", "value": "\u77e5\u8bc6"}, {"source": "YOLOv5.pdf", "target": "convolutional network", "value": "\u77e5\u8bc6"}, {"source": "YOLOv5.pdf", "target": "Detection", "value": "\u77e5\u8bc6"}, {"source": "YOLOv5.pdf", "target": "convolutional", "value": "\u77e5\u8bc6"}, {"source": "YOLOv5.pdf", "target": "fast R-CNN", "value": "\u77e5\u8bc6"}, {"source": "YOLOv5.pdf", "target": "Atrous Convolution", "value": "\u77e5\u8bc6"}, {"source": "YOLOv5.pdf", "target": "ResNet-50", "value": "\u77e5\u8bc6"}, {"source": "YOLOv5.pdf", "target": "Object Detection", "value": "\u77e5\u8bc6"}, {"source": "YOLOv5.pdf", "target": "instance segmentation", "value": "\u77e5\u8bc6"}, {"source": "YOLOv5.pdf", "target": "focal loss", "value": "\u77e5\u8bc6"}, {"source": "YOLOv5.pdf", "target": "global context", "value": "\u77e5\u8bc6"}, {"source": "YOLOv5.pdf", "target": "Fusion", "value": "\u77e5\u8bc6"}, {"source": "YOLOv5.pdf", "target": "Detectron", "value": "\u77e5\u8bc6"}, {"source": "YOLOv5.pdf", "target": "vision", "value": "\u77e5\u8bc6"}, {"source": "YOLOv5.pdf", "target": "Conv", "value": "\u77e5\u8bc6"}, {"source": "YOLOv5.pdf", "target": "backbone", "value": "\u77e5\u8bc6"}, {"source": "YOLOv5.pdf", "target": "\u89c6\u89c9\u6ce8\u610f\u529b", "value": "\u77e5\u8bc6"}, {"source": "YOLOv5.pdf", "target": "Mask R-CNN", "value": "\u77e5\u8bc6"}, {"source": "YOLOv5.pdf", "target": "image super-resolution", "value": "\u77e5\u8bc6"}, {"source": "YOLOv5.pdf", "target": "ResNeXt-101", "value": "\u77e5\u8bc6"}, {"source": "YOLOv5.pdf", "target": "multi-scale testing", "value": "\u77e5\u8bc6"}, {"source": "YOLOv5.pdf", "target": "ResNeXt", "value": "\u77e5\u8bc6"}, {"source": "YOLOv5.pdf", "target": "APL", "value": "\u77e5\u8bc6"}, {"source": "YOLOv5.pdf", "target": "Instance Segmentation", "value": "\u77e5\u8bc6"}, {"source": "YOLOv5s-Megvii.pdf", "target": "ImageNet", "value": "\u77e5\u8bc6"}, {"source": "YOLOv5s-Megvii.pdf", "target": "data augmentation", "value": "\u77e5\u8bc6"}, {"source": "YOLOv5s-Megvii.pdf", "target": "CNN", "value": "\u77e5\u8bc6"}, {"source": "YOLOv5s-Megvii.pdf", "target": "NIPS", "value": "\u77e5\u8bc6"}, {"source": "YOLOv5s-Megvii.pdf", "target": "\u56fe\u50cf\u8bc6\u522b", "value": "\u77e5\u8bc6"}, {"source": "YOLOv5s-Megvii.pdf", "target": "Computer Vision", "value": "\u77e5\u8bc6"}, {"source": "YOLOv5s-Megvii.pdf", "target": "feature map", "value": "\u77e5\u8bc6"}, {"source": "YOLOv5s-Megvii.pdf", "target": "convolution", "value": "\u77e5\u8bc6"}, {"source": "YOLOv5s-Megvii.pdf", "target": "batch normalization", "value": "\u77e5\u8bc6"}, {"source": "YOLOv5s-Megvii.pdf", "target": "anchors", "value": "\u77e5\u8bc6"}, {"source": "YOLOv5s-Megvii.pdf", "target": "ReLU", "value": "\u77e5\u8bc6"}, {"source": "YOLOv5s-Megvii.pdf", "target": "IoU", "value": "\u77e5\u8bc6"}, {"source": "YOLOv5s-Megvii.pdf", "target": "SGD", "value": "\u77e5\u8bc6"}, {"source": "YOLOv5s-Megvii.pdf", "target": "model", "value": "\u77e5\u8bc6"}, {"source": "YOLOv5s-Megvii.pdf", "target": "epochs", "value": "\u77e5\u8bc6"}, {"source": "YOLOv5s-Megvii.pdf", "target": "Deep learning", "value": "\u77e5\u8bc6"}, {"source": "YOLOv5s-Megvii.pdf", "target": "split", "value": "\u77e5\u8bc6"}, {"source": "YOLOv5s-Megvii.pdf", "target": "training", "value": "\u77e5\u8bc6"}, {"source": "YOLOv5s-Megvii.pdf", "target": "region proposal network", "value": "\u77e5\u8bc6"}, {"source": "YOLOv5s-Megvii.pdf", "target": "inference", "value": "\u77e5\u8bc6"}, {"source": "YOLOv5s-Megvii.pdf", "target": "object detection", "value": "\u77e5\u8bc6"}, {"source": "YOLOv5s-Megvii.pdf", "target": "blocks", "value": "\u77e5\u8bc6"}, {"source": "YOLOv5s-Megvii.pdf", "target": "ResNet", "value": "\u77e5\u8bc6"}, {"source": "YOLOv5s-Megvii.pdf", "target": "Memory", "value": "\u77e5\u8bc6"}, {"source": "YOLOv5s-Megvii.pdf", "target": "learning rate", "value": "\u77e5\u8bc6"}, {"source": "YOLOv5s-Megvii.pdf", "target": "residual blocks", "value": "\u77e5\u8bc6"}, {"source": "YOLOv5s-Megvii.pdf", "target": "arXiv", "value": "\u77e5\u8bc6"}, {"source": "YOLOv5s-Megvii.pdf", "target": "anchor", "value": "\u77e5\u8bc6"}, {"source": "YOLOv5s-Megvii.pdf", "target": "encoder", "value": "\u77e5\u8bc6"}, {"source": "YOLOv5s-Megvii.pdf", "target": "pattern recognition", "value": "\u77e5\u8bc6"}, {"source": "YOLOv5s-Megvii.pdf", "target": "Model", "value": "\u77e5\u8bc6"}, {"source": "YOLOv5s-Megvii.pdf", "target": "Blocks", "value": "\u77e5\u8bc6"}, {"source": "YOLOv5s-Megvii.pdf", "target": "computer vision", "value": "\u77e5\u8bc6"}, {"source": "YOLOv5s-Megvii.pdf", "target": "strategy", "value": "\u77e5\u8bc6"}, {"source": "YOLOv5s-Megvii.pdf", "target": "dilated convolution", "value": "\u77e5\u8bc6"}, {"source": "YOLOv5s-Megvii.pdf", "target": "matching", "value": "\u77e5\u8bc6"}, {"source": "YOLOv5s-Megvii.pdf", "target": "feature detection", "value": "\u77e5\u8bc6"}, {"source": "YOLOv5s-Megvii.pdf", "target": "detector", "value": "\u77e5\u8bc6"}, {"source": "YOLOv5s-Megvii.pdf", "target": "scales", "value": "\u77e5\u8bc6"}, {"source": "YOLOv5s-Megvii.pdf", "target": "GAN", "value": "\u77e5\u8bc6"}, {"source": "YOLOv5s-Megvii.pdf", "target": "transformer", "value": "\u77e5\u8bc6"}, {"source": "YOLOv5s-Megvii.pdf", "target": "Ssd", "value": "\u77e5\u8bc6"}, {"source": "YOLOv5s-Megvii.pdf", "target": "dense object detection", "value": "\u77e5\u8bc6"}, {"source": "YOLOv5s-Megvii.pdf", "target": "convolution layers", "value": "\u77e5\u8bc6"}, {"source": "YOLOv5s-Megvii.pdf", "target": "figure", "value": "\u77e5\u8bc6"}, {"source": "YOLOv5s-Megvii.pdf", "target": "feature fusion", "value": "\u77e5\u8bc6"}, {"source": "YOLOv5s-Megvii.pdf", "target": "batch size", "value": "\u77e5\u8bc6"}, {"source": "YOLOv5s-Megvii.pdf", "target": "R-FCN", "value": "\u77e5\u8bc6"}, {"source": "YOLOv5s-Megvii.pdf", "target": "receptive fields", "value": "\u77e5\u8bc6"}, {"source": "YOLOv5s-Megvii.pdf", "target": "UNet", "value": "\u77e5\u8bc6"}, {"source": "YOLOv6.pdf", "target": "Tensor", "value": "\u77e5\u8bc6"}, {"source": "YOLOv6.pdf", "target": "momentum", "value": "\u77e5\u8bc6"}, {"source": "YOLOv6.pdf", "target": "ReLU", "value": "\u77e5\u8bc6"}, {"source": "YOLOv6.pdf", "target": "\u6982\u7387\u5206\u5e03", "value": "\u77e5\u8bc6"}, {"source": "YOLOv6.pdf", "target": "IoU", "value": "\u77e5\u8bc6"}, {"source": "YOLOv6.pdf", "target": "Dense", "value": "\u77e5\u8bc6"}, {"source": "YOLOv6.pdf", "target": "SGD", "value": "\u77e5\u8bc6"}, {"source": "YOLOv6.pdf", "target": "epochs", "value": "\u77e5\u8bc6"}, {"source": "YOLOv6.pdf", "target": "\u5377\u79ef", "value": "\u77e5\u8bc6"}, {"source": "YOLOv6.pdf", "target": "Quantization-aware training", "value": "\u77e5\u8bc6"}, {"source": "YOLOv6.pdf", "target": "DNN", "value": "\u77e5\u8bc6"}, {"source": "YOLOv6.pdf", "target": "loss\u51fd\u6570", "value": "\u77e5\u8bc6"}, {"source": "YOLOv6.pdf", "target": "Distribution", "value": "\u77e5\u8bc6"}, {"source": "YOLOv6.pdf", "target": "loss function", "value": "\u77e5\u8bc6"}, {"source": "YOLOv6.pdf", "target": "Network", "value": "\u77e5\u8bc6"}, {"source": "YOLOv6.pdf", "target": "training", "value": "\u77e5\u8bc6"}, {"source": "YOLOv6.pdf", "target": "accuracy", "value": "\u77e5\u8bc6"}, {"source": "YOLOv6.pdf", "target": "object detection", "value": "\u77e5\u8bc6"}, {"source": "YOLOv6.pdf", "target": "arXiv", "value": "\u77e5\u8bc6"}, {"source": "YOLOv6.pdf", "target": "pattern recognition", "value": "\u77e5\u8bc6"}, {"source": "YOLOv6.pdf", "target": "Model", "value": "\u77e5\u8bc6"}, {"source": "YOLOv6.pdf", "target": "Densely connected convolutional networks", "value": "\u77e5\u8bc6"}, {"source": "YOLOv6.pdf", "target": "\u6df1\u795e\u7ecf\u7f51\u7edc", "value": "\u77e5\u8bc6"}, {"source": "YOLOv6.pdf", "target": "training process", "value": "\u77e5\u8bc6"}, {"source": "YOLOv6.pdf", "target": "convolutional layers", "value": "\u77e5\u8bc6"}, {"source": "YOLOv6.pdf", "target": "Yolov4", "value": "\u77e5\u8bc6"}, {"source": "YOLOv6.pdf", "target": "MSE", "value": "\u77e5\u8bc6"}, {"source": "YOLOv6.pdf", "target": "uncertainty", "value": "\u77e5\u8bc6"}, {"source": "YOLOv6.pdf", "target": "deep learning", "value": "\u77e5\u8bc6"}, {"source": "YOLOv6.pdf", "target": "bounding boxes", "value": "\u77e5\u8bc6"}, {"source": "YOLOv6.pdf", "target": "VGG", "value": "\u77e5\u8bc6"}, {"source": "YOLOv6.pdf", "target": "quantization scheme", "value": "\u77e5\u8bc6"}, {"source": "YOLOv6.pdf", "target": "YOLOv5", "value": "\u77e5\u8bc6"}, {"source": "YOLOv6.pdf", "target": "Quantization", "value": "\u77e5\u8bc6"}, {"source": "YOLOv6.pdf", "target": "stochastic gradient descent", "value": "\u77e5\u8bc6"}, {"source": "YOLOv6.pdf", "target": "L1 loss", "value": "\u77e5\u8bc6"}, {"source": "YOLOv6.pdf", "target": "focal loss", "value": "\u77e5\u8bc6"}, {"source": "YOLOv6.pdf", "target": "Yolov7", "value": "\u77e5\u8bc6"}, {"source": "YOLOv6.pdf", "target": "soft labels", "value": "\u77e5\u8bc6"}, {"source": "YOLOv6.pdf", "target": "vision", "value": "\u77e5\u8bc6"}, {"source": "YOLOv6.pdf", "target": "\u6df1\u5ea6\u6b8b\u5dee\u7f51\u7edc", "value": "\u77e5\u8bc6"}, {"source": "YOLOv6.pdf", "target": "Conv", "value": "\u77e5\u8bc6"}, {"source": "YOLOv6.pdf", "target": "FLOPs", "value": "\u77e5\u8bc6"}, {"source": "YOLOv6.pdf", "target": "Latency", "value": "\u77e5\u8bc6"}, {"source": "YOLOv6.pdf", "target": "quantization", "value": "\u77e5\u8bc6"}, {"source": "YOLOv6.pdf", "target": "CSP", "value": "\u77e5\u8bc6"}, {"source": "YOLOv6.pdf", "target": "boundaries", "value": "\u77e5\u8bc6"}, {"source": "YOLOv6.pdf", "target": "keypoints", "value": "\u77e5\u8bc6"}, {"source": "YOLOv6.pdf", "target": "image resizing", "value": "\u77e5\u8bc6"}, {"source": "YOLOv6.pdf", "target": "Cross-entropy Loss", "value": "\u77e5\u8bc6"}, {"source": "YOLOv7.pdf", "target": "LSTM", "value": "\u77e5\u8bc6"}, {"source": "YOLOv7.pdf", "target": "convolutional neural networks", "value": "\u77e5\u8bc6"}, {"source": "YOLOv7.pdf", "target": "CNNs", "value": "\u77e5\u8bc6"}, {"source": "YOLOv7.pdf", "target": "optimization", "value": "\u77e5\u8bc6"}, {"source": "YOLOv7.pdf", "target": "CNN", "value": "\u77e5\u8bc6"}, {"source": "YOLOv7.pdf", "target": "DenseNet", "value": "\u77e5\u8bc6"}, {"source": "YOLOv7.pdf", "target": "\u5377\u79ef\u5c42", "value": "\u77e5\u8bc6"}, {"source": "YOLOv7.pdf", "target": "NIS", "value": "\u77e5\u8bc6"}, {"source": "YOLOv7.pdf", "target": "\u7279\u5f81\u6620\u5c04", "value": "\u77e5\u8bc6"}, {"source": "YOLOv7.pdf", "target": "Computer Vision", "value": "\u77e5\u8bc6"}, {"source": "YOLOv7.pdf", "target": "feature map", "value": "\u77e5\u8bc6"}, {"source": "YOLOv7.pdf", "target": "S3\u5b58\u50a8\u670d\u52a1", "value": "\u77e5\u8bc6"}, {"source": "YOLOv7.pdf", "target": "IoU", "value": "\u77e5\u8bc6"}, {"source": "YOLOv7.pdf", "target": "MobileNetV2", "value": "\u77e5\u8bc6"}, {"source": "YOLOv7.pdf", "target": "MobileNet", "value": "\u77e5\u8bc6"}, {"source": "YOLOv7.pdf", "target": "IoT", "value": "\u77e5\u8bc6"}, {"source": "YOLOv7.pdf", "target": "3\u00d73\u5377\u79ef\u5c42", "value": "\u77e5\u8bc6"}, {"source": "YOLOv7.pdf", "target": "\u591a\u4efb\u52a1\u5b66\u4e60", "value": "\u77e5\u8bc6"}, {"source": "YOLOv7.pdf", "target": "feature maps", "value": "\u77e5\u8bc6"}, {"source": "YOLOv7.pdf", "target": "\u5377\u79ef\u795e\u7ecf\u7f51\u7edc", "value": "\u77e5\u8bc6"}, {"source": "YOLOv7.pdf", "target": "\u8ba1\u7b97\u673a\u89c6\u89c9", "value": "\u77e5\u8bc6"}, {"source": "YOLOv7.pdf", "target": "Batch normalization", "value": "\u77e5\u8bc6"}, {"source": "YOLOv7.pdf", "target": "ResNet", "value": "\u77e5\u8bc6"}, {"source": "YOLOv7.pdf", "target": "AWS", "value": "\u77e5\u8bc6"}, {"source": "YOLOv7.pdf", "target": "\u6df1\u5ea6\u5b66\u4e60\u7f51\u7edc", "value": "\u77e5\u8bc6"}, {"source": "YOLOv7.pdf", "target": "1\u00d71\u5377\u79ef\u5c42", "value": "\u77e5\u8bc6"}, {"source": "YOLOv7.pdf", "target": "transition layer", "value": "\u77e5\u8bc6"}, {"source": "YOLOv7.pdf", "target": "Model", "value": "\u77e5\u8bc6"}, {"source": "YOLOv7.pdf", "target": "self-supervised learning", "value": "\u77e5\u8bc6"}, {"source": "YOLOv7.pdf", "target": "batch normalization layer", "value": "\u77e5\u8bc6"}, {"source": "YOLOv7.pdf", "target": "DNNs", "value": "\u77e5\u8bc6"}, {"source": "YOLOv7.pdf", "target": "robotics", "value": "\u77e5\u8bc6"}, {"source": "YOLOv7.pdf", "target": "grid", "value": "\u77e5\u8bc6"}, {"source": "YOLOv7.pdf", "target": "feature extraction", "value": "\u77e5\u8bc6"}, {"source": "YOLOv7.pdf", "target": "pose estimation", "value": "\u77e5\u8bc6"}, {"source": "YOLOv7.pdf", "target": "Dataset", "value": "\u77e5\u8bc6"}, {"source": "YOLOv7.pdf", "target": "objects", "value": "\u77e5\u8bc6"}, {"source": "YOLOv7.pdf", "target": "3D vision", "value": "\u77e5\u8bc6"}, {"source": "YOLOv7.pdf", "target": "computing", "value": "\u77e5\u8bc6"}, {"source": "YOLOv7.pdf", "target": "Very deep convolution", "value": "\u77e5\u8bc6"}, {"source": "YOLOv7.pdf", "target": "recall", "value": "\u77e5\u8bc6"}, {"source": "YOLOv7.pdf", "target": "kernels", "value": "\u77e5\u8bc6"}, {"source": "YOLOv7.pdf", "target": "convolutional neural network", "value": "\u77e5\u8bc6"}, {"source": "YOLOv7.pdf", "target": "mobile\u8bbe\u5907", "value": "\u77e5\u8bc6"}, {"source": "YOLOv7.pdf", "target": "EfficientNet", "value": "\u77e5\u8bc6"}, {"source": "YOLOv7.pdf", "target": "YOLOv5", "value": "\u77e5\u8bc6"}, {"source": "YOLOv7.pdf", "target": "UNet", "value": "\u77e5\u8bc6"}, {"source": "YOLOv7.pdf", "target": "fully convolutional network", "value": "\u77e5\u8bc6"}, {"source": "YOLOv7.pdf", "target": "pyramid", "value": "\u77e5\u8bc6"}, {"source": "YOLOv7.pdf", "target": "frame rate", "value": "\u77e5\u8bc6"}, {"source": "\u4e2d\u56fd\u8ba1\u7b97\u673a\u5b66\u4f1a\u63a8\u8350\u56fd\u9645\u5b66\u672f\u4f1a\u8bae\u548c\u671f\u520a\u76ee\u5f55-2022.pdf", "target": "\u4eba\u5de5\u667a\u80fd", "value": "\u77e5\u8bc6"}, {"source": "\u4e2d\u56fd\u8ba1\u7b97\u673a\u5b66\u4f1a\u63a8\u8350\u56fd\u9645\u5b66\u672f\u4f1a\u8bae\u548c\u671f\u520a\u76ee\u5f55-2022.pdf", "target": "NLP", "value": "\u77e5\u8bc6"}, {"source": "\u4e2d\u56fd\u8ba1\u7b97\u673a\u5b66\u4f1a\u63a8\u8350\u56fd\u9645\u5b66\u672f\u4f1a\u8bae\u548c\u671f\u520a\u76ee\u5f55-2022.pdf", "target": "Optimization", "value": "\u77e5\u8bc6"}, {"source": "\u4e2d\u56fd\u8ba1\u7b97\u673a\u5b66\u4f1a\u63a8\u8350\u56fd\u9645\u5b66\u672f\u4f1a\u8bae\u548c\u671f\u520a\u76ee\u5f55-2022.pdf", "target": "\u4f18\u5316\u7b97\u6cd5", "value": "\u77e5\u8bc6"}, {"source": "\u4e2d\u56fd\u8ba1\u7b97\u673a\u5b66\u4f1a\u63a8\u8350\u56fd\u9645\u5b66\u672f\u4f1a\u8bae\u548c\u671f\u520a\u76ee\u5f55-2022.pdf", "target": "\u8ba1\u7b97\u673a\u79d1\u5b66", "value": "\u77e5\u8bc6"}, {"source": "\u4e2d\u56fd\u8ba1\u7b97\u673a\u5b66\u4f1a\u63a8\u8350\u56fd\u9645\u5b66\u672f\u4f1a\u8bae\u548c\u671f\u520a\u76ee\u5f55-2022.pdf", "target": "\u56fe\u50cf\u5904\u7406", "value": "\u77e5\u8bc6"}, {"source": "\u4e2d\u56fd\u8ba1\u7b97\u673a\u5b66\u4f1a\u63a8\u8350\u56fd\u9645\u5b66\u672f\u4f1a\u8bae\u548c\u671f\u520a\u76ee\u5f55-2022.pdf", "target": "Computer Vision", "value": "\u77e5\u8bc6"}, {"source": "\u4e2d\u56fd\u8ba1\u7b97\u673a\u5b66\u4f1a\u63a8\u8350\u56fd\u9645\u5b66\u672f\u4f1a\u8bae\u548c\u671f\u520a\u76ee\u5f55-2022.pdf", "target": "B Class", "value": "\u77e5\u8bc6"}, {"source": "\u4e2d\u56fd\u8ba1\u7b97\u673a\u5b66\u4f1a\u63a8\u8350\u56fd\u9645\u5b66\u672f\u4f1a\u8bae\u548c\u671f\u520a\u76ee\u5f55-2022.pdf", "target": "Computer Science", "value": "\u77e5\u8bc6"}, {"source": "\u4e2d\u56fd\u8ba1\u7b97\u673a\u5b66\u4f1a\u63a8\u8350\u56fd\u9645\u5b66\u672f\u4f1a\u8bae\u548c\u671f\u520a\u76ee\u5f55-2022.pdf", "target": "VLSI", "value": "\u77e5\u8bc6"}, {"source": "\u4e2d\u56fd\u8ba1\u7b97\u673a\u5b66\u4f1a\u63a8\u8350\u56fd\u9645\u5b66\u672f\u4f1a\u8bae\u548c\u671f\u520a\u76ee\u5f55-2022.pdf", "target": "\u81ea\u7136\u8bed\u8a00\u5904\u7406", "value": "\u77e5\u8bc6"}, {"source": "\u4e2d\u56fd\u8ba1\u7b97\u673a\u5b66\u4f1a\u63a8\u8350\u56fd\u9645\u5b66\u672f\u4f1a\u8bae\u548c\u671f\u520a\u76ee\u5f55-2022.pdf", "target": "Software", "value": "\u77e5\u8bc6"}, {"source": "\u4e2d\u56fd\u8ba1\u7b97\u673a\u5b66\u4f1a\u63a8\u8350\u56fd\u9645\u5b66\u672f\u4f1a\u8bae\u548c\u671f\u520a\u76ee\u5f55-2022.pdf", "target": "\u6027\u80fd\u5206\u6790", "value": "\u77e5\u8bc6"}, {"source": "\u4e2d\u56fd\u8ba1\u7b97\u673a\u5b66\u4f1a\u63a8\u8350\u56fd\u9645\u5b66\u672f\u4f1a\u8bae\u548c\u671f\u520a\u76ee\u5f55-2022.pdf", "target": "databases", "value": "\u77e5\u8bc6"}, {"source": "\u4e2d\u56fd\u8ba1\u7b97\u673a\u5b66\u4f1a\u63a8\u8350\u56fd\u9645\u5b66\u672f\u4f1a\u8bae\u548c\u671f\u520a\u76ee\u5f55-2022.pdf", "target": "\u4fe1\u606f\u7ba1\u7406", "value": "\u77e5\u8bc6"}, {"source": "\u4e2d\u56fd\u8ba1\u7b97\u673a\u5b66\u4f1a\u63a8\u8350\u56fd\u9645\u5b66\u672f\u4f1a\u8bae\u548c\u671f\u520a\u76ee\u5f55-2022.pdf", "target": "ICASSP", "value": "\u77e5\u8bc6"}, {"source": "\u4e2d\u56fd\u8ba1\u7b97\u673a\u5b66\u4f1a\u63a8\u8350\u56fd\u9645\u5b66\u672f\u4f1a\u8bae\u548c\u671f\u520a\u76ee\u5f55-2022.pdf", "target": "Git", "value": "\u77e5\u8bc6"}, {"source": "\u4e2d\u56fd\u8ba1\u7b97\u673a\u5b66\u4f1a\u63a8\u8350\u56fd\u9645\u5b66\u672f\u4f1a\u8bae\u548c\u671f\u520a\u76ee\u5f55-2022.pdf", "target": "Neural Network", "value": "\u77e5\u8bc6"}, {"source": "\u4e2d\u56fd\u8ba1\u7b97\u673a\u5b66\u4f1a\u63a8\u8350\u56fd\u9645\u5b66\u672f\u4f1a\u8bae\u548c\u671f\u520a\u76ee\u5f55-2022.pdf", "target": "ICCV", "value": "\u77e5\u8bc6"}, {"source": "\u4e2d\u56fd\u8ba1\u7b97\u673a\u5b66\u4f1a\u63a8\u8350\u56fd\u9645\u5b66\u672f\u4f1a\u8bae\u548c\u671f\u520a\u76ee\u5f55-2022.pdf", "target": "ACL", "value": "\u77e5\u8bc6"}, {"source": "\u4e2d\u56fd\u8ba1\u7b97\u673a\u5b66\u4f1a\u63a8\u8350\u56fd\u9645\u5b66\u672f\u4f1a\u8bae\u548c\u671f\u520a\u76ee\u5f55-2022.pdf", "target": "HCI", "value": "\u77e5\u8bc6"}, {"source": "\u4e2d\u56fd\u8ba1\u7b97\u673a\u5b66\u4f1a\u63a8\u8350\u56fd\u9645\u5b66\u672f\u4f1a\u8bae\u548c\u671f\u520a\u76ee\u5f55-2022.pdf", "target": "\u52a0\u5bc6\u6280\u672f", "value": "\u77e5\u8bc6"}, {"source": "\u4e2d\u56fd\u8ba1\u7b97\u673a\u5b66\u4f1a\u63a8\u8350\u56fd\u9645\u5b66\u672f\u4f1a\u8bae\u548c\u671f\u520a\u76ee\u5f55-2022.pdf", "target": "computer vision", "value": "\u77e5\u8bc6"}, {"source": "\u4e2d\u56fd\u8ba1\u7b97\u673a\u5b66\u4f1a\u63a8\u8350\u56fd\u9645\u5b66\u672f\u4f1a\u8bae\u548c\u671f\u520a\u76ee\u5f55-2022.pdf", "target": "GROUP", "value": "\u77e5\u8bc6"}, {"source": "\u4e2d\u56fd\u8ba1\u7b97\u673a\u5b66\u4f1a\u63a8\u8350\u56fd\u9645\u5b66\u672f\u4f1a\u8bae\u548c\u671f\u520a\u76ee\u5f55-2022.pdf", "target": "Biology", "value": "\u77e5\u8bc6"}, {"source": "\u4e2d\u56fd\u8ba1\u7b97\u673a\u5b66\u4f1a\u63a8\u8350\u56fd\u9645\u5b66\u672f\u4f1a\u8bae\u548c\u671f\u520a\u76ee\u5f55-2022.pdf", "target": "CPP", "value": "\u77e5\u8bc6"}, {"source": "\u4e2d\u56fd\u8ba1\u7b97\u673a\u5b66\u4f1a\u63a8\u8350\u56fd\u9645\u5b66\u672f\u4f1a\u8bae\u548c\u671f\u520a\u76ee\u5f55-2022.pdf", "target": "Neural Networks", "value": "\u77e5\u8bc6"}, {"source": "\u4e2d\u56fd\u8ba1\u7b97\u673a\u5b66\u4f1a\u63a8\u8350\u56fd\u9645\u5b66\u672f\u4f1a\u8bae\u548c\u671f\u520a\u76ee\u5f55-2022.pdf", "target": "ACM", "value": "\u77e5\u8bc6"}, {"source": "\u4e2d\u56fd\u8ba1\u7b97\u673a\u5b66\u4f1a\u63a8\u8350\u56fd\u9645\u5b66\u672f\u4f1a\u8bae\u548c\u671f\u520a\u76ee\u5f55-2022.pdf", "target": "Pattern Recognition", "value": "\u77e5\u8bc6"}, {"source": "\u4e2d\u56fd\u8ba1\u7b97\u673a\u5b66\u4f1a\u63a8\u8350\u56fd\u9645\u5b66\u672f\u4f1a\u8bae\u548c\u671f\u520a\u76ee\u5f55-2022.pdf", "target": "Image Processing", "value": "\u77e5\u8bc6"}, {"source": "\u4e2d\u56fd\u8ba1\u7b97\u673a\u5b66\u4f1a\u63a8\u8350\u56fd\u9645\u5b66\u672f\u4f1a\u8bae\u548c\u671f\u520a\u76ee\u5f55-2022.pdf", "target": "Machine Learning", "value": "\u77e5\u8bc6"}, {"source": "\u4e2d\u56fd\u8ba1\u7b97\u673a\u5b66\u4f1a\u63a8\u8350\u56fd\u9645\u5b66\u672f\u4f1a\u8bae\u548c\u671f\u520a\u76ee\u5f55-2022.pdf", "target": "Artificial Intelligence", "value": "\u77e5\u8bc6"}, {"source": "\u4e2d\u56fd\u8ba1\u7b97\u673a\u5b66\u4f1a\u63a8\u8350\u56fd\u9645\u5b66\u672f\u4f1a\u8bae\u548c\u671f\u520a\u76ee\u5f55-2022.pdf", "target": "Internet of Things", "value": "\u77e5\u8bc6"}, {"source": "\u4e2d\u56fd\u8ba1\u7b97\u673a\u5b66\u4f1a\u63a8\u8350\u56fd\u9645\u5b66\u672f\u4f1a\u8bae\u548c\u671f\u520a\u76ee\u5f55-2022.pdf", "target": "ACM MM", "value": "\u77e5\u8bc6"}, {"source": "\u4e2d\u56fd\u8ba1\u7b97\u673a\u5b66\u4f1a\u63a8\u8350\u56fd\u9645\u5b66\u672f\u4f1a\u8bae\u548c\u671f\u520a\u76ee\u5f55-2022.pdf", "target": "Springer", "value": "\u77e5\u8bc6"}, {"source": "\u4e2d\u56fd\u8ba1\u7b97\u673a\u5b66\u4f1a\u63a8\u8350\u56fd\u9645\u5b66\u672f\u4f1a\u8bae\u548c\u671f\u520a\u76ee\u5f55-2022.pdf", "target": "C++", "value": "\u77e5\u8bc6"}, {"source": "\u4e2d\u56fd\u8ba1\u7b97\u673a\u5b66\u4f1a\u63a8\u8350\u56fd\u9645\u5b66\u672f\u4f1a\u8bae\u548c\u671f\u520a\u76ee\u5f55-2022.pdf", "target": "University", "value": "\u77e5\u8bc6"}, {"source": "\u4e2d\u56fd\u8ba1\u7b97\u673a\u5b66\u4f1a\u63a8\u8350\u56fd\u9645\u5b66\u672f\u4f1a\u8bae\u548c\u671f\u520a\u76ee\u5f55-2022.pdf", "target": "Neural Computation", "value": "\u77e5\u8bc6"}, {"source": "\u4e2d\u56fd\u8ba1\u7b97\u673a\u5b66\u4f1a\u63a8\u8350\u56fd\u9645\u5b66\u672f\u4f1a\u8bae\u548c\u671f\u520a\u76ee\u5f55-2022.pdf", "target": "Distributed systems", "value": "\u77e5\u8bc6"}, {"source": "\u4e2d\u56fd\u8ba1\u7b97\u673a\u5b66\u4f1a\u63a8\u8350\u56fd\u9645\u5b66\u672f\u4f1a\u8bae\u548c\u671f\u520a\u76ee\u5f55-2022.pdf", "target": "IETF", "value": "\u77e5\u8bc6"}, {"source": "\u4e2d\u56fd\u8ba1\u7b97\u673a\u5b66\u4f1a\u63a8\u8350\u56fd\u9645\u5b66\u672f\u4f1a\u8bae\u548c\u671f\u520a\u76ee\u5f55-2022.pdf", "target": "Cybernetics", "value": "\u77e5\u8bc6"}, {"source": "\u4e2d\u56fd\u8ba1\u7b97\u673a\u5b66\u4f1a\u63a8\u8350\u56fd\u9645\u5b66\u672f\u4f1a\u8bae\u548c\u671f\u520a\u76ee\u5f55-2022.pdf", "target": "Journal", "value": "\u77e5\u8bc6"}, {"source": "\u4e2d\u56fd\u8ba1\u7b97\u673a\u5b66\u4f1a\u63a8\u8350\u56fd\u9645\u5b66\u672f\u4f1a\u8bae\u548c\u671f\u520a\u76ee\u5f55-2022.pdf", "target": "multimedia", "value": "\u77e5\u8bc6"}, {"source": "\u4e2d\u56fd\u8ba1\u7b97\u673a\u5b66\u4f1a\u63a8\u8350\u56fd\u9645\u5b66\u672f\u4f1a\u8bae\u548c\u671f\u520a\u76ee\u5f55-2022.pdf", "target": "assessment", "value": "\u77e5\u8bc6"}, {"source": "\u4e2d\u56fd\u8ba1\u7b97\u673a\u5b66\u4f1a\u63a8\u8350\u56fd\u9645\u5b66\u672f\u4f1a\u8bae\u548c\u671f\u520a\u76ee\u5f55-2022.pdf", "target": "Vision", "value": "\u77e5\u8bc6"}, {"source": "\u4e2d\u56fd\u8ba1\u7b97\u673a\u5b66\u4f1a\u63a8\u8350\u56fd\u9645\u5b66\u672f\u4f1a\u8bae\u548c\u671f\u520a\u76ee\u5f55-2022.pdf", "target": "medical image computing", "value": "\u77e5\u8bc6"}, {"source": "\u4e2d\u56fd\u8ba1\u7b97\u673a\u5b66\u4f1a\u63a8\u8350\u56fd\u9645\u5b66\u672f\u4f1a\u8bae\u548c\u671f\u520a\u76ee\u5f55-2022.pdf", "target": "Mobile Computing", "value": "\u77e5\u8bc6"}, {"source": "\u4e2d\u56fd\u8ba1\u7b97\u673a\u5b66\u4f1a\u63a8\u8350\u56fd\u9645\u5b66\u672f\u4f1a\u8bae\u548c\u671f\u520a\u76ee\u5f55-2022.pdf", "target": "stems", "value": "\u77e5\u8bc6"}, {"source": "\u4e2d\u56fd\u8ba1\u7b97\u673a\u5b66\u4f1a\u63a8\u8350\u56fd\u9645\u5b66\u672f\u4f1a\u8bae\u548c\u671f\u520a\u76ee\u5f55-2022.pdf", "target": "\u591a\u5a92\u4f53\u5de5\u5177\u548c\u5e94\u7528", "value": "\u77e5\u8bc6"}, {"source": "\u4e2d\u56fd\u8ba1\u7b97\u673a\u5b66\u4f1a\u63a8\u8350\u56fd\u9645\u5b66\u672f\u4f1a\u8bae\u548c\u671f\u520a\u76ee\u5f55-2022.pdf", "target": "HPC", "value": "\u77e5\u8bc6"}, {"source": "\u5468\u5fd7\u534e-\u673a\u5668\u5b66\u4e60.pdf", "target": "learning", "value": "\u77e5\u8bc6"}, {"source": "\u5468\u5fd7\u534e-\u673a\u5668\u5b66\u4e60.pdf", "target": "\u4eba\u8138\u8bc6\u522b", "value": "\u77e5\u8bc6"}, {"source": "\u5468\u5fd7\u534e-\u673a\u5668\u5b66\u4e60.pdf", "target": "ImageNet", "value": "\u77e5\u8bc6"}, {"source": "\u5468\u5fd7\u534e-\u673a\u5668\u5b66\u4e60.pdf", "target": "SVR", "value": "\u77e5\u8bc6"}, {"source": "\u5468\u5fd7\u534e-\u673a\u5668\u5b66\u4e60.pdf", "target": "optimization", "value": "\u77e5\u8bc6"}, {"source": "\u5468\u5fd7\u534e-\u673a\u5668\u5b66\u4e60.pdf", "target": "neural network", "value": "\u77e5\u8bc6"}, {"source": "\u5468\u5fd7\u534e-\u673a\u5668\u5b66\u4e60.pdf", "target": "\u51b3\u7b56\u6811", "value": "\u77e5\u8bc6"}, {"source": "\u5468\u5fd7\u534e-\u673a\u5668\u5b66\u4e60.pdf", "target": "CNN", "value": "\u77e5\u8bc6"}, {"source": "\u5468\u5fd7\u534e-\u673a\u5668\u5b66\u4e60.pdf", "target": "SVM", "value": "\u77e5\u8bc6"}, {"source": "\u5468\u5fd7\u534e-\u673a\u5668\u5b66\u4e60.pdf", "target": "\u795e\u7ecf\u7f51\u7edc", "value": "\u77e5\u8bc6"}, {"source": "\u5468\u5fd7\u534e-\u673a\u5668\u5b66\u4e60.pdf", "target": "\u68af\u5ea6", "value": "\u77e5\u8bc6"}, {"source": "\u5468\u5fd7\u534e-\u673a\u5668\u5b66\u4e60.pdf", "target": "\u652f\u6301\u5411\u91cf\u673a", "value": "\u77e5\u8bc6"}, {"source": "\u5468\u5fd7\u534e-\u673a\u5668\u5b66\u4e60.pdf", "target": "NIPS", "value": "\u77e5\u8bc6"}, {"source": "\u5468\u5fd7\u534e-\u673a\u5668\u5b66\u4e60.pdf", "target": "\u6df1\u5ea6\u5b66\u4e60", "value": "\u77e5\u8bc6"}, {"source": "\u5468\u5fd7\u534e-\u673a\u5668\u5b66\u4e60.pdf", "target": "\u72ec\u70ed\u7f16\u7801", "value": "\u77e5\u8bc6"}, {"source": "\u5468\u5fd7\u534e-\u673a\u5668\u5b66\u4e60.pdf", "target": "\u53cd\u5411\u4f20\u64ad", "value": "\u77e5\u8bc6"}, {"source": "\u5468\u5fd7\u534e-\u673a\u5668\u5b66\u4e60.pdf", "target": "tanh", "value": "\u77e5\u8bc6"}, {"source": "\u5468\u5fd7\u534e-\u673a\u5668\u5b66\u4e60.pdf", "target": "\u5377\u79ef\u5c42", "value": "\u77e5\u8bc6"}, {"source": "\u5468\u5fd7\u534e-\u673a\u5668\u5b66\u4e60.pdf", "target": "LeCun", "value": "\u77e5\u8bc6"}, {"source": "\u5468\u5fd7\u534e-\u673a\u5668\u5b66\u4e60.pdf", "target": "network", "value": "\u77e5\u8bc6"}, {"source": "\u5468\u5fd7\u534e-\u673a\u5668\u5b66\u4e60.pdf", "target": "\u6837\u672c\u5747\u503c", "value": "\u77e5\u8bc6"}, {"source": "\u5468\u5fd7\u534e-\u673a\u5668\u5b66\u4e60.pdf", "target": "\u4e3b\u6210\u5206\u5206\u6790", "value": "\u77e5\u8bc6"}, {"source": "\u5468\u5fd7\u534e-\u673a\u5668\u5b66\u4e60.pdf", "target": "\u8bcd\u888b\u6a21\u578b", "value": "\u77e5\u8bc6"}, {"source": "\u5468\u5fd7\u534e-\u673a\u5668\u5b66\u4e60.pdf", "target": "L1\u6b63\u5219\u5316", "value": "\u77e5\u8bc6"}, {"source": "\u5468\u5fd7\u534e-\u673a\u5668\u5b66\u4e60.pdf", "target": "\u7ebf\u6027\u51fd\u6570", "value": "\u77e5\u8bc6"}, {"source": "\u5468\u5fd7\u534e-\u673a\u5668\u5b66\u4e60.pdf", "target": "\u4f3c\u7136\u51fd\u6570", "value": "\u77e5\u8bc6"}, {"source": "\u5468\u5fd7\u534e-\u673a\u5668\u5b66\u4e60.pdf", "target": "\u8ba1\u7b97\u673a\u79d1\u5b66", "value": "\u77e5\u8bc6"}, {"source": "\u5468\u5fd7\u534e-\u673a\u5668\u5b66\u4e60.pdf", "target": "\u8d2a\u5fc3\u641c\u7d22", "value": "\u77e5\u8bc6"}, {"source": "\u5468\u5fd7\u534e-\u673a\u5668\u5b66\u4e60.pdf", "target": "\u6b63\u5219\u5316", "value": "\u77e5\u8bc6"}, {"source": "\u5468\u5fd7\u534e-\u673a\u5668\u5b66\u4e60.pdf", "target": "\u6982\u7387\u56fe\u6a21\u578b", "value": "\u77e5\u8bc6"}, {"source": "\u5468\u5fd7\u534e-\u673a\u5668\u5b66\u4e60.pdf", "target": "Overfitting", "value": "\u77e5\u8bc6"}, {"source": "\u5468\u5fd7\u534e-\u673a\u5668\u5b66\u4e60.pdf", "target": "\u6837\u672c\u7a7a\u95f4", "value": "\u77e5\u8bc6"}, {"source": "\u5468\u5fd7\u534e-\u673a\u5668\u5b66\u4e60.pdf", "target": "\u5b9a\u7406", "value": "\u77e5\u8bc6"}, {"source": "\u5468\u5fd7\u534e-\u673a\u5668\u5b66\u4e60.pdf", "target": "\u673a\u5668\u5b66\u4e60\u7b97\u6cd5", "value": "\u77e5\u8bc6"}, {"source": "\u5468\u5fd7\u534e-\u673a\u5668\u5b66\u4e60.pdf", "target": "\u89c4\u5219\u5b66\u4e60", "value": "\u77e5\u8bc6"}, {"source": "\u5468\u5fd7\u534e-\u673a\u5668\u5b66\u4e60.pdf", "target": "sparse representation", "value": "\u77e5\u8bc6"}, {"source": "\u5468\u5fd7\u534e-\u673a\u5668\u5b66\u4e60.pdf", "target": "\u673a\u5668\u5b66\u4e60", "value": "\u77e5\u8bc6"}, {"source": "\u5468\u5fd7\u534e-\u673a\u5668\u5b66\u4e60.pdf", "target": "softmax", "value": "\u77e5\u8bc6"}, {"source": "\u5468\u5fd7\u534e-\u673a\u5668\u5b66\u4e60.pdf", "target": "\u6781\u5927\u4f3c\u7136\u4f30\u8ba1", "value": "\u77e5\u8bc6"}, {"source": "\u5468\u5fd7\u534e-\u673a\u5668\u5b66\u4e60.pdf", "target": "\u5927\u6570\u636e", "value": "\u77e5\u8bc6"}, {"source": "\u5468\u5fd7\u534e-\u673a\u5668\u5b66\u4e60.pdf", "target": "S3\u5b58\u50a8\u670d\u52a1", "value": "\u77e5\u8bc6"}, {"source": "\u5468\u5fd7\u534e-\u673a\u5668\u5b66\u4e60.pdf", "target": "\u9a6c\u5c14\u53ef\u592b\u94fe", "value": "\u77e5\u8bc6"}, {"source": "\u5468\u5fd7\u534e-\u673a\u5668\u5b66\u4e60.pdf", "target": "Frobenius\u8303\u6570", "value": "\u77e5\u8bc6"}, {"source": "\u5468\u5fd7\u534e-\u673a\u5668\u5b66\u4e60.pdf", "target": "\u6b27\u51e0\u91cc\u5f97\u8ddd\u79bb", "value": "\u77e5\u8bc6"}, {"source": "\u5468\u5fd7\u534e-\u673a\u5668\u5b66\u4e60.pdf", "target": "ReLU", "value": "\u77e5\u8bc6"}, {"source": "\u5468\u5fd7\u534e-\u673a\u5668\u5b66\u4e60.pdf", "target": "\u7279\u5f81\u5b66\u4e60", "value": "\u77e5\u8bc6"}, {"source": "\u5468\u5fd7\u534e-\u673a\u5668\u5b66\u4e60.pdf", "target": "bias", "value": "\u77e5\u8bc6"}, {"source": "\u5468\u5fd7\u534e-\u673a\u5668\u5b66\u4e60.pdf", "target": "\u5747\u65b9\u8bef\u5dee", "value": "\u77e5\u8bc6"}, {"source": "\u5468\u5fd7\u534e-\u673a\u5668\u5b66\u4e60.pdf", "target": "LDA", "value": "\u77e5\u8bc6"}, {"source": "\u5468\u5fd7\u534e-\u673a\u5668\u5b66\u4e60.pdf", "target": "\u6807\u51c6\u5dee", "value": "\u77e5\u8bc6"}, {"source": "additional-responses.md", "target": "HTTPvalidationError", "value": "\u77e5\u8bc6"}, {"source": "additional-responses.md", "target": "OpenAPI", "value": "\u77e5\u8bc6"}, {"source": "additional-status-codes.md", "target": "OpenAPI", "value": "\u77e5\u8bc6"}, {"source": "additional-status-codes.md", "target": "FastAPI", "value": "\u77e5\u8bc6"}, {"source": "advanced-dependencies.md", "target": "__call__", "value": "\u77e5\u8bc6"}, {"source": "async.md", "target": "\u673a\u5668\u5b66\u4e60", "value": "\u77e5\u8bc6"}, {"source": "async.md", "target": "Python", "value": "\u77e5\u8bc6"}, {"source": "async.md", "target": "\u591a\u7ebf\u7a0b", "value": "\u77e5\u8bc6"}, {"source": "async.md", "target": "\u591a\u4efb\u52a1\u5904\u7406", "value": "\u77e5\u8bc6"}, {"source": "async.md", "target": "\u5e76\u884c\u8ba1\u7b97", "value": "\u77e5\u8bc6"}, {"source": "async.md", "target": "Go", "value": "\u77e5\u8bc6"}, {"source": "async.md", "target": "AnyIO", "value": "\u77e5\u8bc6"}, {"source": "async.md", "target": "\u5f02\u6b65\u673a\u5236", "value": "\u77e5\u8bc6"}, {"source": "async.md", "target": "CPU\u5bc6\u96c6\u578b", "value": "\u77e5\u8bc6"}, {"source": "async.md", "target": "async/await", "value": "\u77e5\u8bc6"}, {"source": "async.md", "target": "\u97f3\u9891\u5904\u7406", "value": "\u77e5\u8bc6"}, {"source": "async.md", "target": "NodeJS", "value": "\u77e5\u8bc6"}, {"source": "async.md", "target": "\u5e76\u884c\u6027", "value": "\u77e5\u8bc6"}, {"source": "async.md", "target": "\u5f02\u6b65\u6027", "value": "\u77e5\u8bc6"}, {"source": "async.md", "target": "Web", "value": "\u77e5\u8bc6"}, {"source": "async.md", "target": "CPU \u5bc6\u96c6\u578b \u5de5\u4f5c\u7a0b\u5e8f", "value": "\u77e5\u8bc6"}, {"source": "async.md", "target": "Web API", "value": "\u77e5\u8bc6"}, {"source": "async.md", "target": "Goroutinees", "value": "\u77e5\u8bc6"}, {"source": "async.md", "target": "\u73b0\u4ee3\u7248\u672c", "value": "\u77e5\u8bc6"}, {"source": "async.md", "target": "\u7ebf\u7a0b\u6c60", "value": "\u77e5\u8bc6"}, {"source": "async.md", "target": "Async", "value": "\u77e5\u8bc6"}, {"source": "async.md", "target": "\u5f02\u6b65IO", "value": "\u77e5\u8bc6"}, {"source": "async.md", "target": "\u6570\u5b57\u5316\u5de5\u4f5c\u8005", "value": "\u77e5\u8bc6"}, {"source": "async.md", "target": "burgers", "value": "\u77e5\u8bc6"}, {"source": "async.md", "target": "\u534f\u7a0b", "value": "\u77e5\u8bc6"}, {"source": "async.md", "target": "Starlette", "value": "\u77e5\u8bc6"}, {"source": "async.md", "target": "Await", "value": "\u77e5\u8bc6"}, {"source": "background-tasks.md", "target": "\u5f02\u6b65IO", "value": "\u77e5\u8bc6"}, {"source": "background-tasks.md", "target": "fastapi", "value": "\u77e5\u8bc6"}, {"source": "background-tasks.md", "target": "Annotated", "value": "\u77e5\u8bc6"}, {"source": "background-tasks.md", "target": "Redis", "value": "\u77e5\u8bc6"}, {"source": "background-tasks.md", "target": "Python 3.10", "value": "\u77e5\u8bc6"}, {"source": "background-tasks.md", "target": "starlette.backgroundpass\uff0c\u6d88\u606f\u961f\u5217\uff0c\u7535\u5b50\u90ae\u4ef6\uff0cRabbitMQ\uff0casync def", "value": "\u77e5\u8bc6"}, {"source": "behind-a-proxy.md", "target": "FastAPI", "value": "\u77e5\u8bc6"}, {"source": "behind-a-proxy.md", "target": "OpenAPI \u6982\u56fe", "value": "\u77e5\u8bc6"}, {"source": "behind-a-proxy.md", "target": "Traefik", "value": "\u77e5\u8bc6"}, {"source": "behind-a-proxy.md", "target": "Uvicorn", "value": "\u77e5\u8bc6"}, {"source": "bigger-applications.md", "target": "users", "value": "\u77e5\u8bc6"}, {"source": "bigger-applications.md", "target": "Python", "value": "\u77e5\u8bc6"}, {"source": "bigger-applications.md", "target": "admin", "value": "\u77e5\u8bc6"}, {"source": "bigger-applications.md", "target": "routers", "value": "\u77e5\u8bc6"}, {"source": "bigger-applications.md", "target": "\u81ea\u52a8\u5316\u90e8\u7f72", "value": "\u77e5\u8bc6"}, {"source": "bigger-applications.md", "target": "prefix", "value": "\u77e5\u8bc6"}, {"source": "bigger-applications.md", "target": "OpenAPI", "value": "\u77e5\u8bc6"}, {"source": "bigger-applications.md", "target": "FastAPI", "value": "\u77e5\u8bc6"}, {"source": "bigger-applications.md", "target": "uvicorn", "value": "\u77e5\u8bc6"}, {"source": "bigger-applications.md", "target": "Python\u5f00\u53d1", "value": "\u77e5\u8bc6"}, {"source": "bigger-applications.md", "target": "\u5e94\u7528\u7a0b\u5e8f\u8bbe\u8ba1", "value": "\u77e5\u8bc6"}, {"source": "bigger-applications.md", "target": "OpenAPI\u6a21\u5f0f", "value": "\u77e5\u8bc6"}, {"source": "bigger-applications.md", "target": "\u6784\u9020\u5668", "value": "\u77e5\u8bc6"}, {"source": "bigger-applications.md", "target": "Security \u4f9d\u8d56\u9879", "value": "\u77e5\u8bc6"}, {"source": "bigger-applications.md", "target": "key wordsDjango", "value": "\u77e5\u8bc6"}, {"source": "bigger-applications.md", "target": "Python app", "value": "\u77e5\u8bc6"}, {"source": "bigger-applications.md", "target": "internal\u5b50\u5305", "value": "\u77e5\u8bc6"}, {"source": "bigger-applications.md", "target": "Python\u5b50\u5305dmin", "value": "\u77e5\u8bc6"}, {"source": "bigger-applications.md", "target": "\u6587\u4ef6\u7ed3\u6784\u8a2d\u8a08", "value": "\u77e5\u8bc6"}, {"source": "bigger-applications.md", "target": "DDPContextManager", "value": "\u77e5\u8bc6"}, {"source": "bigger-applications.md", "target": "Python \u5305", "value": "\u77e5\u8bc6"}, {"source": "bigger-applications.md", "target": "APIRouter", "value": "\u77e5\u8bc6"}, {"source": "bigger-applications.md", "target": "admin\u6a21\u5757", "value": "\u77e5\u8bc6"}, {"source": "bigger-applications.md", "target": "\u4f9d\u8d56\u7ba1\u7406", "value": "\u77e5\u8bc6"}, {"source": "bigger-applications.md", "target": "_init__.py\u6587\u4ef6", "value": "\u77e5\u8bc6"}, {"source": "bigger-applications.md", "target": "\u5355\u70b9\u5bfc\u5165 ers.router", "value": "\u77e5\u8bc6"}, {"source": "bigger-applications.md", "target": "itemsrouter", "value": "\u77e5\u8bc6"}, {"source": "bigger-applications.md", "target": "Python\u6a21\u5757", "value": "\u77e5\u8bc6"}, {"source": "bigger-applications.md", "target": "X-Token\u8bf7\u6c42\u9996\u90e8\u6a21\u5757\u5316\u5f00\u53d1", "value": "\u77e5\u8bc6"}, {"source": "bigger-applications.md", "target": "\u95e8\u67b6\u5f0f\u5f00\u53d1", "value": "\u77e5\u8bc6"}, {"source": "bigger-applications.md", "target": "router", "value": "\u77e5\u8bc6"}, {"source": "body-fields.md", "target": "Field", "value": "\u77e5\u8bc6"}, {"source": "body-fields.md", "target": "Pydantic", "value": "\u77e5\u8bc6"}, {"source": "cloud.md", "target": "FastAPI", "value": "\u77e5\u8bc6"}, {"source": "cloud.md", "target": "\u4e91\u670d\u52a1\u5546", "value": "\u77e5\u8bc6"}, {"source": "cloud.md", "target": "\u4e91\u90e8\u7f72", "value": "\u77e5\u8bc6"}, {"source": "cloud.md", "target": "porter", "value": "\u77e5\u8bc6"}, {"source": "cloud.md", "target": "\u5e73\u53f0\u67b6\u6784", "value": "\u77e5\u8bc6"}, {"source": "concepts.md", "target": "Kubernetes", "value": "\u77e5\u8bc6"}, {"source": "concepts.md", "target": "\u72ec\u7acb\u7a0b\u5e8f", "value": "\u77e5\u8bc6"}, {"source": "concepts.md", "target": "Traefik", "value": "\u77e5\u8bc6"}, {"source": "concepts.md", "target": "Uvicorn", "value": "\u77e5\u8bc6"}, {"source": "concepts.md", "target": "\u7cfb\u7edf\u8d44\u6e90\u5229\u7528\u7387", "value": "\u77e5\u8bc6"}, {"source": "concepts.md", "target": "TLS \u8bc1\u4e66", "value": "\u77e5\u8bc6"}, {"source": "concepts.md", "target": "\u7cfb\u7edf\u76d1\u89c6\u5668", "value": "\u77e5\u8bc6"}, {"source": "concepts.md", "target": "\u81ea\u52a8\u5316\u8bc1\u4e66\u66f4\u65b0", "value": "\u77e5\u8bc6"}, {"source": "concepts.md", "target": "\u670d\u52a1\u5668\u5185\u5b58", "value": "\u77e5\u8bc6"}, {"source": "concepts.md", "target": "\u5bb9\u5668\u6620\u50cf", "value": "\u77e5\u8bc6"}, {"source": "concepts.md", "target": "Supervisor", "value": "\u77e5\u8bc6"}, {"source": "concepts.md", "target": "\u4e91\u670d\u52a1", "value": "\u77e5\u8bc6"}, {"source": "concepts.md", "target": "docker-compose", "value": "\u77e5\u8bc6"}, {"source": "concepts.md", "target": "TLS", "value": "\u77e5\u8bc6"}, {"source": "concepts.md", "target": "HAPROXY", "value": "\u77e5\u8bc6"}, {"source": "concepts.md", "target": "Certbot", "value": "\u77e5\u8bc6"}, {"source": "concepts.md", "target": "\u5bb9\u5668", "value": "\u77e5\u8bc6"}, {"source": "concepts.md", "target": "\u4e3b\u9898\u7ba1\u7406", "value": "\u77e5\u8bc6"}, {"source": "concepts.md", "target": "cert-manager", "value": "\u77e5\u8bc6"}, {"source": "concepts.md", "target": "Systemd", "value": "\u77e5\u8bc6"}, {"source": "concepts.md", "target": "Gunicorn", "value": "\u77e5\u8bc6"}, {"source": "concepts.md", "target": "Ingress Controller", "value": "\u77e5\u8bc6"}, {"source": "concepts.md", "target": "\u8fc7\u7a0b\u7ba1\u7406", "value": "\u77e5\u8bc6"}, {"source": "concepts.md", "target": "Docker in Swarm Mode", "value": "\u77e5\u8bc6"}, {"source": "concepts.md", "target": "cpu\u5229\u7528\u7387", "value": "\u77e5\u8bc6"}, {"source": "cors.md", "target": "expose_headers", "value": "\u77e5\u8bc6"}, {"source": "cors.md", "target": "CORSMiddleware", "value": "\u77e5\u8bc6"}, {"source": "cors.md", "target": "cross-originBearer\u4ee4\u724c", "value": "\u77e5\u8bc6"}, {"source": "cors.md", "target": "allow_headers", "value": "\u77e5\u8bc6"}, {"source": "custom-response.md", "target": "fastapi", "value": "\u77e5\u8bc6"}, {"source": "custom-response.md", "target": "Pydantic", "value": "\u77e5\u8bc6"}, {"source": "custom-response.md", "target": "StreamingResponse", "value": "\u77e5\u8bc6"}, {"source": "custom-response.md", "target": "JsonOpenAPI", "value": "\u77e5\u8bc6"}, {"source": "docker.md", "target": "Kubernetes", "value": "\u77e5\u8bc6"}, {"source": "docker.md", "target": "\u5e76\u884c\u5316", "value": "\u77e5\u8bc6"}, {"source": "docker.md", "target": "S3\u5b58\u50a8\u670d\u52a1", "value": "\u77e5\u8bc6"}, {"source": "docker.md", "target": "Python", "value": "\u77e5\u8bc6"}, {"source": "docker.md", "target": "Docker", "value": "\u77e5\u8bc6"}, {"source": "docker.md", "target": "\u81ea\u52a8\u5316\u90e8\u7f72", "value": "\u77e5\u8bc6"}, {"source": "docker.md", "target": "docker", "value": "\u77e5\u8bc6"}, {"source": "docker.md", "target": "AWS", "value": "\u77e5\u8bc6"}, {"source": "docker.md", "target": "\u8d1f\u8f7d\u5747\u8861\u5668", "value": "\u77e5\u8bc6"}, {"source": "docker.md", "target": "Linux", "value": "\u77e5\u8bc6"}, {"source": "docker.md", "target": "\u7f51\u7edc\u901a\u4fe1", "value": "\u77e5\u8bc6"}, {"source": "docker.md", "target": "stage", "value": "\u77e5\u8bc6"}, {"source": "docker.md", "target": "Distributed Systems", "value": "\u77e5\u8bc6"}, {"source": "docker.md", "target": "FastAPI", "value": "\u77e5\u8bc6"}, {"source": "docker.md", "target": "Redis", "value": "\u77e5\u8bc6"}, {"source": "docker.md", "target": "Gunicorn", "value": "\u77e5\u8bc6"}, {"source": "docker.md", "target": "\u8fdb\u7a0b\u7ba1\u7406\u5668", "value": "\u77e5\u8bc6"}, {"source": "docker.md", "target": "MongoDB", "value": "\u77e5\u8bc6"}, {"source": "docker.md", "target": "COPY --from(requirements-stage)", "value": "\u77e5\u8bc6"}, {"source": "docker.md", "target": "incremental", "value": "\u77e5\u8bc6"}, {"source": "docker.md", "target": "Prometheus", "value": "\u77e5\u8bc6"}, {"source": "docker.md", "target": "ReDoc", "value": "\u77e5\u8bc6"}, {"source": "docker.md", "target": "\u5206\u5e03\u5f0f\u5bb9\u5668", "value": "\u77e5\u8bc6"}, {"source": "docker.md", "target": "docker \u955c\u50cf", "value": "\u77e5\u8bc6"}, {"source": "docker.md", "target": "\u591a\u8fdb\u7a0b\u5bb9\u5668", "value": "\u77e5\u8bc6"}, {"source": "docker.md", "target": "Docker\u955c\u50cf", "value": "\u77e5\u8bc6"}, {"source": "docker.md", "target": "Init Container", "value": "\u77e5\u8bc6"}, {"source": "docker.md", "target": "\u81ea\u52a8CPU\u6838\u5fc3\u5206\u914dUvicorn", "value": "\u77e5\u8bc6"}, {"source": "docker.md", "target": "PostgreSQL", "value": "\u77e5\u8bc6"}, {"source": "docker.md", "target": "Docker Swarm", "value": "\u77e5\u8bc6"}, {"source": "docker.md", "target": "Traefik\u8d1f\u8f7d\u5747\u8861", "value": "\u77e5\u8bc6"}, {"source": "docker.md", "target": "\u96c6\u7fa4\u7ea7\u522b", "value": "\u77e5\u8bc6"}, {"source": "docker.md", "target": "Swagger UI", "value": "\u77e5\u8bc6"}, {"source": "docker.md", "target": "Kubernetesbernetes\u7ba1\u7406\u7cfb\u7edf", "value": "\u77e5\u8bc6"}, {"source": "docker.md", "target": "FASTAPI", "value": "\u77e5\u8bc6"}, {"source": "docker.md", "target": "HTTPS TLS \u7ec8\u6b62\u4ee3\u7406", "value": "\u77e5\u8bc6"}, {"source": "docker.md", "target": "docker \u5bb9\u5668", "value": "\u77e5\u8bc6"}, {"source": "docker.md", "target": "\u670d\u52a1\u5668\u5de5\u4f5c\u7ebf\u7a0b", "value": "\u77e5\u8bc6"}, {"source": "docker.md", "target": "--upg\u5bb9\u5668", "value": "\u77e5\u8bc6"}, {"source": "docker.md", "target": "HTTPS certificates", "value": "\u77e5\u8bc6"}, {"source": "docker.md", "target": "\u5bb9\u5668\u7ba1\u7406\u7cfb\u7edf", "value": "\u77e5\u8bc6"}, {"source": "docker.md", "target": "\u5185\u90e8\u7f51\u7edc\u673a\u5236", "value": "\u77e5\u8bc6"}, {"source": "docker.md", "target": "cker\u955c\u50cf\u5143\u6570\u636e", "value": "\u77e5\u8bc6"}, {"source": "docker.md", "target": "\u4f9d\u8d56\u9879\u7ba1\u7406", "value": "\u77e5\u8bc6"}, {"source": "docker.md", "target": "cpu\u6838\u6570", "value": "\u77e5\u8bc6"}, {"source": "docker.md", "target": "Docker\u5bb9\u5668\u955c\u50cf", "value": "\u77e5\u8bc6"}, {"source": "docker.md", "target": "Docker \u955c\u50cf", "value": "\u77e5\u8bc6"}, {"source": "docker.md", "target": "\u96c6\u7fa4", "value": "\u77e5\u8bc6"}, {"source": "docker.md", "target": "Poetry", "value": "\u77e5\u8bc6"}, {"source": "docker.md", "target": "Dockerfiles", "value": "\u77e5\u8bc6"}, {"source": "encoder.md", "target": "JSON", "value": "\u77e5\u8bc6"}, {"source": "encoder.md", "target": "dict", "value": "\u77e5\u8bc6"}, {"source": "encoder.md", "target": "fastapi", "value": "\u77e5\u8bc6"}, {"source": "encoder.md", "target": "JSON \u5154\u5b50\u5bf9\u8c61", "value": "\u77e5\u8bc6"}, {"source": "encoder.md", "target": "jsonable_encoder", "value": "\u77e5\u8bc6"}, {"source": "encoder.md", "target": "Pydantic \u6a21\u578b", "value": "\u77e5\u8bc6"}, {"source": "encoder.md", "target": "datetime", "value": "\u77e5\u8bc6"}, {"source": "environment-variables.md", "target": "Python\u73af\u5883\u53d8\u91cf", "value": "\u77e5\u8bc6"}, {"source": "environment-variables.md", "target": "Windows PowerShell", "value": "\u77e5\u8bc6"}, {"source": "events.md", "target": "Python", "value": "\u77e5\u8bc6"}, {"source": "events.md", "target": "yield", "value": "\u77e5\u8bc6"}, {"source": "events.md", "target": "FastAPI", "value": "\u77e5\u8bc6"}, {"source": "events.md", "target": "\u6570\u636e\u5e93\u8fde\u63a5\u6c60", "value": "\u77e5\u8bc6"}, {"source": "events.md", "target": "lifespan", "value": "\u77e5\u8bc6"}, {"source": "events.md", "target": "\u4e8b\u4ef6\u5904\u7406\u5668", "value": "\u77e5\u8bc6"}, {"source": "events.md", "target": "\u865a\u62df\u7684\u6a21\u578b\u51fd\u6570", "value": "\u77e5\u8bc6"}, {"source": "events.md", "target": "startup \u4e8b\u4ef6", "value": "\u77e5\u8bc6"}, {"source": "events.md", "target": "\u5f02\u6b65\u4e0a\u4e0b\u6587\u7ba1\u7406\u5668", "value": "\u77e5\u8bc6"}, {"source": "events.md", "target": "event", "value": "\u77e5\u8bc6"}, {"source": "events.md", "target": "ASGI", "value": "\u77e5\u8bc6"}, {"source": "events.md", "target": "\u751f\u547d\u5468\u671f\u4e8b\u4ef6", "value": "\u77e5\u8bc6"}, {"source": "events.md", "target": "\u5f02\u5f02\u6b65\u51fd\u6570", "value": "\u77e5\u8bc6"}, {"source": "extra-models.md", "target": "email", "value": "\u77e5\u8bc6"}, {"source": "extra-models.md", "target": "\u6570\u636e\u6a21\u578b", "value": "\u77e5\u8bc6"}, {"source": "extra-models.md", "target": "Pydantic\u5bf9\u8c61", "value": "\u77e5\u8bc6"}, {"source": "extra-models.md", "target": "u FastAPI", "value": "\u77e5\u8bc6"}, {"source": "extra-models.md", "target": "typing.Dict", "value": "\u77e5\u8bc6"}, {"source": "fastapi-cli.md", "target": "FastAPI", "value": "\u77e5\u8bc6"}, {"source": "fastapi-cli.md", "target": "Uvicorn", "value": "\u77e5\u8bc6"}, {"source": "fastapi-cli.md", "target": "Server processes", "value": "\u77e5\u8bc6"}, {"source": "fastapi-cli.md", "target": "ASGI\u670d\u52a1\u5668", "value": "\u77e5\u8bc6"}, {"source": "fastapi-cli.md", "target": "import string", "value": "\u77e5\u8bc6"}, {"source": "features.md", "target": "OpenAPI", "value": "\u77e5\u8bc6"}, {"source": "features.md", "target": "FastAPI", "value": "\u77e5\u8bc6"}, {"source": "features.md", "target": "Pydantic", "value": "\u77e5\u8bc6"}, {"source": "features.md", "target": "ReDoc", "value": "\u77e5\u8bc6"}, {"source": "features.md", "target": "linting", "value": "\u77e5\u8bc6"}, {"source": "features.md", "target": "\u81ea\u52a8\u6587\u6863\u751f\u6210", "value": "\u77e5\u8bc6"}, {"source": "features.md", "target": "JSON Schema", "value": "\u77e5\u8bc6"}, {"source": "features.md", "target": "HTTP \u57fa\u672c\u8ba4\u8bc1", "value": "\u77e5\u8bc6"}, {"source": "features.md", "target": "editor support", "value": "\u77e5\u8bc6"}, {"source": "features.md", "target": "Swagger UG", "value": "\u77e5\u8bc6"}, {"source": "features.md", "target": "API\u5b9a\u4e49", "value": "\u77e5\u8bc6"}, {"source": "features.md", "target": "python_types", "value": "\u77e5\u8bc6"}, {"source": "features.md", "target": "mypy", "value": "\u77e5\u8bc6"}, {"source": "first-steps.md", "target": "FastAPI", "value": "\u77e5\u8bc6"}, {"source": "first-steps.md", "target": "OpenAPI\u6a21\u5f0f", "value": "\u77e5\u8bc6"}, {"source": "first-steps.md", "target": "ReDoc", "value": "\u77e5\u8bc6"}, {"source": "first-steps.md", "target": "JSON Schema", "value": "\u77e5\u8bc6"}, {"source": "first-steps.md", "target": "API \u6a21\u5f0f", "value": "\u77e5\u8bc6"}, {"source": "first-steps.md", "target": "FastAPI\u6784\u5efa\u5e94\u7528\u7a0b\u5e8f", "value": "\u77e5\u8bc6"}, {"source": "first-steps.md", "target": "async\u51fd\u6570", "value": "\u77e5\u8bc6"}, {"source": "general.md", "target": "OpenAPI", "value": "\u77e5\u8bc6"}, {"source": "general.md", "target": "JSON\u517c\u5bb9\u7f16\u7801\u5668", "value": "\u77e5\u8bc6"}, {"source": "generate-clients.md", "target": "FastAPI", "value": "\u77e5\u8bc6"}, {"source": "generate-clients.md", "target": "OpenAPI\u6a21\u5f0f", "value": "\u77e5\u8bc6"}, {"source": "generate-clients.md", "target": "Swagger UI", "value": "\u77e5\u8bc6"}, {"source": "generate-clients.md", "target": "SDKs", "value": "\u77e5\u8bc6"}, {"source": "generate-clients.md", "target": "Item\u6a21\u578b", "value": "\u77e5\u8bc6"}, {"source": "generate-clients.md", "target": "openapi-ts", "value": "\u77e5\u8bc6"}, {"source": "generate-clients.md", "target": "TypeScript \u5ba2\u6237\u7aef", "value": "\u77e5\u8bc6"}, {"source": "generate-clients.md", "target": "ItemsService.createItem", "value": "\u77e5\u8bc6"}, {"source": "generate-clients.md", "target": "NPM generadote-client", "value": "\u77e5\u8bc6"}, {"source": "generate-clients.md", "target": "ItemsService", "value": "\u77e5\u8bc6"}, {"source": "handling-errors.md", "target": "FastAPI", "value": "\u77e5\u8bc6"}, {"source": "handling-errors.md", "target": "Pydantic", "value": "\u77e5\u8bc6"}, {"source": "handling-errors.md", "target": "Starlette HTTPException", "value": "\u77e5\u8bc6"}, {"source": "handling-errors.md", "target": "HTTPException", "value": "\u77e5\u8bc6"}, {"source": "handling-errors.md", "target": "UnicornException", "value": "\u77e5\u8bc6"}, {"source": "handling-errors.md", "target": "Python \u5f02\u5e38Validation", "value": "\u77e5\u8bc6"}, {"source": "handling-errors.md", "target": "FastAPI \u5168\u7403\u5f02\u5e38\u5904\u7406", "value": "\u77e5\u8bc6"}, {"source": "handling-errors.md", "target": "fastapi.exception_handlers", "value": "\u77e5\u8bc6"}, {"source": "header-param-models.md", "target": "FastAPI", "value": "\u77e5\u8bc6"}, {"source": "header-param-models.md", "target": "fastapi", "value": "\u77e5\u8bc6"}, {"source": "header-param-models.md", "target": "Pydantic", "value": "\u77e5\u8bc6"}, {"source": "header-param-models.md", "target": "Pydantic\u6a21\u578b", "value": "\u77e5\u8bc6"}, {"source": "header-param-models.md", "target": "headers", "value": "\u77e5\u8bc6"}, {"source": "header-param-models.md", "target": "Header\u53c2\u6570\u6a21\u578b", "value": "\u77e5\u8bc6"}, {"source": "http-basic-auth.md", "target": "compare_digest", "value": "\u77e5\u8bc6"}, {"source": "http-basic-auth.md", "target": "HTTP \u57fa\u7840\u6388\u6743", "value": "\u77e5\u8bc6"}, {"source": "http-basic-auth.md", "target": "\u65f6\u5dee\u653b\u51fb", "value": "\u77e5\u8bc6"}, {"source": "http-basic-auth.md", "target": "secrets", "value": "\u77e5\u8bc6"}, {"source": "http-basic-auth.md", "target": "bytes", "value": "\u77e5\u8bc6"}, {"source": "http-basic-auth.md", "target": "secrets.compare_digest()", "value": "\u77e5\u8bc6"}, {"source": "http-basic-auth.md", "target": "compare_digest()", "value": "\u77e5\u8bc6"}, {"source": "http-basic-auth.md", "target": "credentials", "value": "\u77e5\u8bc6"}, {"source": "http-basic-auth.md", "target": "authenticate", "value": "\u77e5\u8bc6"}, {"source": "https.md", "target": "DNS\u670d\u52a1\u5668", "value": "\u77e5\u8bc6"}, {"source": "https.md", "target": "Traefik", "value": "\u77e5\u8bc6"}, {"source": "https.md", "target": "\u4e91\u670d\u52a1\u5546", "value": "\u77e5\u8bc6"}, {"source": "https.md", "target": "TLS \u8bc1\u4e66", "value": "\u77e5\u8bc6"}, {"source": "https.md", "target": "TLS\u7ec8\u6b62\u4ee3\u7406", "value": "\u77e5\u8bc6"}, {"source": "https.md", "target": "certificate", "value": "\u77e5\u8bc6"}, {"source": "https.md", "target": "SSL/TCP", "value": "\u77e5\u8bc6"}, {"source": "https.md", "target": "\u8bc1\u4e66", "value": "\u77e5\u8bc6"}, {"source": "https.md", "target": "HAProxy", "value": "\u77e5\u8bc6"}, {"source": "https.md", "target": "TCP\u5c42", "value": "\u77e5\u8bc6"}, {"source": "https.md", "target": "\u5b89\u5168\u52a0\u5bc6", "value": "\u77e5\u8bc6"}, {"source": "https.md", "target": "TLS \u534f\u8bae", "value": "\u77e5\u8bc6"}, {"source": "https.md", "target": "HTTPS\u5de5\u4f5c\u539f\u7406", "value": "\u77e5\u8bc6"}, {"source": "https.md", "target": "HTTPS\u57fa\u7840\u77e5\u8bc6", "value": "\u77e5\u8bc6"}, {"source": "metadata.md", "target": "\u81ea\u52a8\u5316\u90e8\u7f72", "value": "\u77e5\u8bc6"}, {"source": "metadata.md", "target": "OpenAPI\u6a21\u5f0f", "value": "\u77e5\u8bc6"}, {"source": "metadata.md", "target": "ReDoc", "value": "\u77e5\u8bc6"}, {"source": "metadata.md", "target": "Swagger UI", "value": "\u77e5\u8bc6"}, {"source": "metadata.md", "target": "OpenAPI\u89c4\u8303", "value": "\u77e5\u8bc6"}, {"source": "metadata.md", "target": "terms_of_service", "value": "\u77e5\u8bc6"}, {"source": "metadata.md", "target": "openapi_tags", "value": "\u77e5\u8bc6"}, {"source": "metadata.md", "target": "redoc", "value": "\u77e5\u8bc6"}, {"source": "metadata.md", "target": "\u5f00\u6e90\u8bb8\u53ef\u8bc1", "value": "\u77e5\u8bc6"}, {"source": "oauth2-scopes.md", "target": "FastAPI", "value": "\u77e5\u8bc6"}, {"source": "oauth2-scopes.md", "target": "Pydantic", "value": "\u77e5\u8bc6"}, {"source": "oauth2-scopes.md", "target": "HTTPException", "value": "\u77e5\u8bc6"}, {"source": "oauth2-scopes.md", "target": "security_scopes", "value": "\u77e5\u8bc6"}, {"source": "oauth2-scopes.md", "target": "oauth2\u4f5c\u7528\u57df", "value": "\u77e5\u8bc6"}, {"source": "oauth2-scopes.md", "target": "\u7b2c\u4e09\u65b9\u8eab\u4efd\u9a8c\u8bc1", "value": "\u77e5\u8bc6"}, {"source": "oauth2-scopes.md", "target": "scopes", "value": "\u77e5\u8bc6"}, {"source": "oauth2-scopes.md", "target": "API\u81ea\u52a8\u6587\u6863", "value": "\u77e5\u8bc6"}, {"source": "oauth2-scopes.md", "target": "psychological_domain", "value": "\u77e5\u8bc6"}, {"source": "oauth2-scopes.md", "target": "Security\u7cfb\u7edf", "value": "\u77e5\u8bc6"}, {"source": "openapi-callbacks.md", "target": "Uvicorn", "value": "\u77e5\u8bc6"}, {"source": "openapi-callbacks.md", "target": "Pydantic", "value": "\u77e5\u8bc6"}, {"source": "openapi-callbacks.md", "target": "invoices_callback_routers", "value": "\u77e5\u8bc6"}, {"source": "openapi-callbacks.md", "target": "invoices", "value": "\u77e5\u8bc6"}, {"source": "openapi-callbacks.md", "target": "\u56de\u8c03\u6d41\u7a0b", "value": "\u77e5\u8bc6"}, {"source": "openapi-callbacks.md", "target": "Pydantic URL\u7c7b\u578b", "value": "\u77e5\u8bc6"}, {"source": "openapi-callbacks.md", "target": "APIDocumentation", "value": "\u77e5\u8bc6"}, {"source": "openapi-callbacks.md", "target": "callbacks", "value": "\u77e5\u8bc6"}, {"source": "openapi-callbacks.md", "target": "FastAPI\u5e94\u7528", "value": "\u77e5\u8bc6"}, {"source": "path-params.md", "target": "OpenAPI", "value": "\u77e5\u8bc6"}, {"source": "path-params.md", "target": "FastAPI", "value": "\u77e5\u8bc6"}, {"source": "path-params.md", "target": "Pydantic", "value": "\u77e5\u8bc6"}, {"source": "path-params.md", "target": "ReDoc", "value": "\u77e5\u8bc6"}, {"source": "path-params.md", "target": "Swagger UI", "value": "\u77e5\u8bc6"}, {"source": "path-params.md", "target": "Enum\u7c7b", "value": "\u77e5\u8bc6"}, {"source": "path-params.md", "target": "Python \u679a\u4e3e\u7c7b\u578b", "value": "\u77e5\u8bc6"}, {"source": "path-params.md", "target": "Python \u5b57\u7b26\u4e32\u683c\u5f0f\u5316\u7c7b\u578b\u6ce8\u89e3", "value": "\u77e5\u8bc6"}, {"source": "path-params.md", "target": "API\u6ce8\u89e3", "value": "\u77e5\u8bc6"}, {"source": "Python\u4fee\u70bc\u4e4b\u9053.pdf", "target": "bash", "value": "\u77e5\u8bc6"}, {"source": "Python\u4fee\u70bc\u4e4b\u9053.pdf", "target": "\u4eba\u5de5\u667a\u80fd", "value": "\u77e5\u8bc6"}, {"source": "Python\u4fee\u70bc\u4e4b\u9053.pdf", "target": "Kubernetes", "value": "\u77e5\u8bc6"}, {"source": "Python\u4fee\u70bc\u4e4b\u9053.pdf", "target": "\u56fe\u50cf\u5904\u7406", "value": "\u77e5\u8bc6"}, {"source": "Python\u4fee\u70bc\u4e4b\u9053.pdf", "target": "Float", "value": "\u77e5\u8bc6"}, {"source": "Python\u4fee\u70bc\u4e4b\u9053.pdf", "target": "class", "value": "\u77e5\u8bc6"}, {"source": "Python\u4fee\u70bc\u4e4b\u9053.pdf", "target": "random", "value": "\u77e5\u8bc6"}, {"source": "Python\u4fee\u70bc\u4e4b\u9053.pdf", "target": "tuple", "value": "\u77e5\u8bc6"}, {"source": "Python\u4fee\u70bc\u4e4b\u9053.pdf", "target": "sys", "value": "\u77e5\u8bc6"}, {"source": "Python\u4fee\u70bc\u4e4b\u9053.pdf", "target": "Kubernetes\u7ba1\u7406\u7cfb\u7edf", "value": "\u77e5\u8bc6"}, {"source": "Python\u4fee\u70bc\u4e4b\u9053.pdf", "target": "email", "value": "\u77e5\u8bc6"}, {"source": "Python\u4fee\u70bc\u4e4b\u9053.pdf", "target": "\u5185\u5b58\u5206\u914d", "value": "\u77e5\u8bc6"}, {"source": "Python\u4fee\u70bc\u4e4b\u9053.pdf", "target": "\u673a\u5668\u5b66\u4e60", "value": "\u77e5\u8bc6"}, {"source": "Python\u4fee\u70bc\u4e4b\u9053.pdf", "target": "\u5927\u6570\u636e", "value": "\u77e5\u8bc6"}, {"source": "Python\u4fee\u70bc\u4e4b\u9053.pdf", "target": "S3\u5b58\u50a8\u670d\u52a1", "value": "\u77e5\u8bc6"}, {"source": "Python\u4fee\u70bc\u4e4b\u9053.pdf", "target": "\u52a0\u5bc6\u7b97\u6cd5", "value": "\u77e5\u8bc6"}, {"source": "Python\u4fee\u70bc\u4e4b\u9053.pdf", "target": "\u8fed\u4ee3\u5668", "value": "\u77e5\u8bc6"}, {"source": "Python\u4fee\u70bc\u4e4b\u9053.pdf", "target": "IDE", "value": "\u77e5\u8bc6"}, {"source": "Python\u4fee\u70bc\u4e4b\u9053.pdf", "target": "Python", "value": "\u77e5\u8bc6"}, {"source": "Python\u4fee\u70bc\u4e4b\u9053.pdf", "target": "Java", "value": "\u77e5\u8bc6"}, {"source": "Python\u4fee\u70bc\u4e4b\u9053.pdf", "target": "Docker", "value": "\u77e5\u8bc6"}, {"source": "Python\u4fee\u70bc\u4e4b\u9053.pdf", "target": "mysql", "value": "\u77e5\u8bc6"}, {"source": "Python\u4fee\u70bc\u4e4b\u9053.pdf", "target": "Node", "value": "\u77e5\u8bc6"}, {"source": "Python\u4fee\u70bc\u4e4b\u9053.pdf", "target": "cloud\u8ba1\u7b97\u5e73\u53f0", "value": "\u77e5\u8bc6"}, {"source": "Python\u4fee\u70bc\u4e4b\u9053.pdf", "target": "C\u8bed\u8a00", "value": "\u77e5\u8bc6"}, {"source": "Python\u4fee\u70bc\u4e4b\u9053.pdf", "target": "\u5bb9\u5668\u7f16\u6392", "value": "\u77e5\u8bc6"}, {"source": "Python\u4fee\u70bc\u4e4b\u9053.pdf", "target": "AES", "value": "\u77e5\u8bc6"}, {"source": "Python\u4fee\u70bc\u4e4b\u9053.pdf", "target": "\u591a\u7ebf\u7a0b", "value": "\u77e5\u8bc6"}, {"source": "Python\u4fee\u70bc\u4e4b\u9053.pdf", "target": "Docker\u5bb9\u5668", "value": "\u77e5\u8bc6"}, {"source": "Python\u4fee\u70bc\u4e4b\u9053.pdf", "target": "split", "value": "\u77e5\u8bc6"}, {"source": "Python\u4fee\u70bc\u4e4b\u9053.pdf", "target": "SHELL", "value": "\u77e5\u8bc6"}, {"source": "Python\u4fee\u70bc\u4e4b\u9053.pdf", "target": "\u7b97\u6cd5", "value": "\u77e5\u8bc6"}, {"source": "Python\u4fee\u70bc\u4e4b\u9053.pdf", "target": "encoding", "value": "\u77e5\u8bc6"}, {"source": "Python\u4fee\u70bc\u4e4b\u9053.pdf", "target": "numpy", "value": "\u77e5\u8bc6"}, {"source": "Python\u4fee\u70bc\u4e4b\u9053.pdf", "target": "lambda", "value": "\u77e5\u8bc6"}, {"source": "Python\u4fee\u70bc\u4e4b\u9053.pdf", "target": "\u81ea\u52a8\u5316\u90e8\u7f72", "value": "\u77e5\u8bc6"}, {"source": "Python\u4fee\u70bc\u4e4b\u9053.pdf", "target": "charset", "value": "\u77e5\u8bc6"}, {"source": "Python\u4fee\u70bc\u4e4b\u9053.pdf", "target": "AWS", "value": "\u77e5\u8bc6"}, {"source": "Python\u4fee\u70bc\u4e4b\u9053.pdf", "target": "\u8d1f\u8f7d\u5747\u8861\u5668", "value": "\u77e5\u8bc6"}, {"source": "Python\u4fee\u70bc\u4e4b\u9053.pdf", "target": "\u7a0b\u5e8f\u8bbe\u8ba1", "value": "\u77e5\u8bc6"}, {"source": "Python\u4fee\u70bc\u4e4b\u9053.pdf", "target": "variable", "value": "\u77e5\u8bc6"}, {"source": "Python\u4fee\u70bc\u4e4b\u9053.pdf", "target": "\u903b\u8f91\u5224\u65ad", "value": "\u77e5\u8bc6"}, {"source": "Python\u4fee\u70bc\u4e4b\u9053.pdf", "target": "filesystem", "value": "\u77e5\u8bc6"}, {"source": "Python\u4fee\u70bc\u4e4b\u9053.pdf", "target": "jar", "value": "\u77e5\u8bc6"}, {"source": "Python\u4fee\u70bc\u4e4b\u9053.pdf", "target": "attribute", "value": "\u77e5\u8bc6"}, {"source": "Python\u4fee\u70bc\u4e4b\u9053.pdf", "target": "object", "value": "\u77e5\u8bc6"}, {"source": "Python\u4fee\u70bc\u4e4b\u9053.pdf", "target": "height", "value": "\u77e5\u8bc6"}, {"source": "Python\u4fee\u70bc\u4e4b\u9053.pdf", "target": "attributes", "value": "\u77e5\u8bc6"}, {"source": "Python\u4fee\u70bc\u4e4b\u9053.pdf", "target": "c++", "value": "\u77e5\u8bc6"}, {"source": "Python\u4fee\u70bc\u4e4b\u9053.pdf", "target": "ACM", "value": "\u77e5\u8bc6"}, {"source": "query-params-str-validations.md", "target": "S3\u5b58\u50a8\u670d\u52a1", "value": "\u77e5\u8bc6"}, {"source": "query-params-str-validations.md", "target": "AWS", "value": "\u77e5\u8bc6"}, {"source": "query-params-str-validations.md", "target": "List[str] ", "value": "\u77e5\u8bc6"}, {"source": "query-params-str-validations.md", "target": "OpenAPI \u6a21\u5f0f", "value": "\u77e5\u8bc6"}, {"source": "query-params-str-validations.md", "target": "Union[str", "value": "\u77e5\u8bc6"}, {"source": "query-params-str-validations.md", "target": "regular exppression", "value": "\u77e5\u8bc6"}, {"source": "query-params-str-validations.md", "target": "\u6709\u6548\u53d8\u91cf\u540d Query(default=None)", "value": "\u77e5\u8bc6"}, {"source": "request-files.md", "target": "python-multipart", "value": "\u77e5\u8bc6"}, {"source": "request-files.md", "target": "file-like \u5bf9\u8c61", "value": "\u77e5\u8bc6"}, {"source": "request-files.md", "target": "async\u65b9\u6cd5", "value": "\u77e5\u8bc6"}, {"source": "request-forms-and-files.md", "target": "JSON", "value": "\u77e5\u8bc6"}, {"source": "request-forms-and-files.md", "target": "python-multipart", "value": "\u77e5\u8bc6"}, {"source": "response-change-status-code.md", "target": "cookies", "value": "\u77e5\u8bc6"}, {"source": "response-model.md", "target": "path_operation\u88c5\u9970\u5668", "value": "\u77e5\u8bc6"}, {"source": "response-model.md", "target": "Union[str\uff0c\u4ea4\u4e92\u5f0fAPI\uff0c\u6a21\u578b\u878d\u5408\uff0cresponse_model_exclude_unset\uff0cvisible_data\uff0cPydantic\uff0cJSONSchema\uff0cexclude_unset\uff0cdefault_values\uff0cList[str]response_model_include", "value": "\u77e5\u8bc6"}, {"source": "schema-extra-example.md", "target": "OpenAPI", "value": "\u77e5\u8bc6"}, {"source": "schema-extra-example.md", "target": "Field", "value": "\u77e5\u8bc6"}, {"source": "schema-extra-example.md", "target": "Pydantic", "value": "\u77e5\u8bc6"}, {"source": "schema-extra-example.md", "target": "JSON Schema", "value": "\u77e5\u8bc6"}, {"source": "schema-extra-example.md", "target": "swagger-ui", "value": "\u77e5\u8bc6"}, {"source": "schema-extra-example.md", "target": "swagger", "value": "\u77e5\u8bc6"}, {"source": "settings.md", "target": "Docker", "value": "\u77e5\u8bc6"}, {"source": "settings.md", "target": "uvicorn", "value": "\u77e5\u8bc6"}, {"source": "settings.md", "target": "Pydantic", "value": "\u77e5\u8bc6"}, {"source": "settings.md", "target": "say_hi", "value": "\u77e5\u8bc6"}, {"source": "settings.md", "target": "functors\u73af\u5883\u53d8\u91cf\u8bbe\u7f6e", "value": "\u77e5\u8bc6"}, {"source": "settings.md", "target": "Pydantic:Settings\u73af\u5883\u53d8\u91cf creation", "value": "\u77e5\u8bc6"}, {"source": "settings.md", "target": "rect", "value": "\u77e5\u8bc6"}, {"source": "settings.md", "target": "\u9a8c\u8bc1\u529f\u80fdpython-dotenv", "value": "\u77e5\u8bc6"}, {"source": "settings.md", "target": "\u5bc6\u94a5", "value": "\u77e5\u8bc6"}, {"source": "settings.md", "target": "Twelve-Factor App", "value": "\u77e5\u8bc6"}, {"source": "settings.md", "target": "sensitive data\u914d\u7f6e\u6587\u4ef6\u914d\u7f6e\u5bf9\u8c61", "value": "\u77e5\u8bc6"}, {"source": "settings.md", "target": "Settings\u7c7b", "value": "\u77e5\u8bc6"}, {"source": "settings.md", "target": "D\u4f9d\u8d56\u9879\u8986\u76d6", "value": "\u77e5\u8bc6"}, {"source": "settings.md", "target": "os.getenv()", "value": "\u77e5\u8bc6"}, {"source": "settings.md", "target": "lru_cache", "value": "\u77e5\u8bc6"}, {"source": "settings.md", "target": "@lru_cache", "value": "\u77e5\u8bc6"}, {"source": "sql-databases.md", "target": "MySQL", "value": "\u77e5\u8bc6"}, {"source": "sql-databases.md", "target": "yield", "value": "\u77e5\u8bc6"}, {"source": "sql-databases.md", "target": "FastAPI", "value": "\u77e5\u8bc6"}, {"source": "sql-databases.md", "target": "fastapi", "value": "\u77e5\u8bc6"}, {"source": "sql-databases.md", "target": "Uvicorn", "value": "\u77e5\u8bc6"}, {"source": "sql-databases.md", "target": "Pydantic \u6a21\u578b", "value": "\u77e5\u8bc6"}, {"source": "sql-databases.md", "target": "\u6570\u636e\u6a21\u578b", "value": "\u77e5\u8bc6"}, {"source": "sql-databases.md", "target": "\u865a\u62df\u73af\u5883", "value": "\u77e5\u8bc6"}, {"source": "sql-databases.md", "target": "HeroCreate", "value": "\u77e5\u8bc6"}, {"source": "sql-databases.md", "target": "Oracle", "value": "\u77e5\u8bc6"}, {"source": "sql-databases.md", "target": "SQLite", "value": "\u77e5\u8bc6"}, {"source": "sql-databases.md", "target": "SQLAlchemy", "value": "\u77e5\u8bc6"}, {"source": "sql-databases.md", "target": "HeroCre\u4f9d\u8d56\u9879", "value": "\u77e5\u8bc6"}, {"source": "sql-databases.md", "target": "checksamethread", "value": "\u77e5\u8bc6"}, {"source": "sql-databases.md", "target": "FieldPydantic\u6a21\u578b", "value": "\u77e5\u8bc6"}, {"source": "sql-databases.md", "target": "hero\u6a21\u578b", "value": "\u77e5\u8bc6"}, {"source": "sql-databases.md", "target": "Hero", "value": "\u77e5\u8bc6"}, {"source": "sql-databases.md", "target": "HeroPublic\u6570\u636e\u6a21\u578b", "value": "\u77e5\u8bc6"}, {"source": "sql-databases.md", "target": "SQLAlchemy engine", "value": "\u77e5\u8bc6"}, {"source": "sql-databases.md", "target": "SQLModel", "value": "\u77e5\u8bc6"}, {"source": "sql-databases.md", "target": "Postgresqlql_model", "value": "\u77e5\u8bc6"}, {"source": "sql-databases.md", "target": "Alembic", "value": "\u77e5\u8bc6"}, {"source": "sql-databases.md", "target": "engine", "value": "\u77e5\u8bc6"}, {"source": "sql-databases.md", "target": "SQLModel.engine", "value": "\u77e5\u8bc6"}, {"source": "sql-databases.md", "target": "SessionDep", "value": "\u77e5\u8bc6"}, {"source": "sql-databases.md", "target": "HeroBase\uff0cHero", "value": "\u77e5\u8bc6"}, {"source": "sql-databases.md", "target": "HeroBase", "value": "\u77e5\u8bc6"}, {"source": "sql-databases.md", "target": "SQL\u6570\u636e\u5e93", "value": "\u77e5\u8bc6"}, {"source": "sql-databases.md", "target": "Hero\u8868\u6a21\u578b", "value": "\u77e5\u8bc6"}, {"source": "sql-databases.md", "target": "HeroPublic", "value": "\u77e5\u8bc6"}, {"source": "sql-databases.md", "target": "data model", "value": "\u77e5\u8bc6"}, {"source": "static-files.md", "target": "FastAPI", "value": "\u77e5\u8bc6"}, {"source": "static-files.md", "target": "Starlette", "value": "\u77e5\u8bc6"}, {"source": "static-files.md", "target": "StaticFiles", "value": "\u77e5\u8bc6"}, {"source": "static-files.md", "target": "\u9759\u6001\u6587\u4ef6\u670d\u52a1", "value": "\u77e5\u8bc6"}, {"source": "testing-events.md", "target": "TestClient", "value": "\u77e5\u8bc6"}, {"source": "testing-events.md", "target": "with", "value": "\u77e5\u8bc6"}, {"source": "testing-websockets.md", "target": "TestClient", "value": "\u77e5\u8bc6"}, {"source": "testing-websockets.md", "target": "WebSocket", "value": "\u77e5\u8bc6"}, {"source": "testing-websockets.md", "target": "with\u8bed\u53e5", "value": "\u77e5\u8bc6"}, {"source": "testing-websockets.md", "target": "TestWebSockets", "value": "\u77e5\u8bc6"}, {"source": "testing.md", "target": "Python 3.8", "value": "\u77e5\u8bc6"}, {"source": "testing.md", "target": "JSON", "value": "\u77e5\u8bc6"}, {"source": "testing.md", "target": "FastAPI", "value": "\u77e5\u8bc6"}, {"source": "testing.md", "target": "Annotated", "value": "\u77e5\u8bc6"}, {"source": "testing.md", "target": "Python 3.10", "value": "\u77e5\u8bc6"}, {"source": "testing.md", "target": "async\u51fd\u6570", "value": "\u77e5\u8bc6"}, {"source": "testing.md", "target": "TestMain\uff0ccookie", "value": "\u77e5\u8bc6"}, {"source": "testing.md", "target": "pytest", "value": "\u77e5\u8bc6"}, {"source": "testing.md", "target": "starlette.testclient", "value": "\u77e5\u8bc6"}, {"source": "testing.md", "target": "HTTPXydantic\u6a21\u578b", "value": "\u77e5\u8bc6"}, {"source": "testing.md", "target": "\u975e\u6ce8\u89e3\u5316\u7684Python", "value": "\u77e5\u8bc6"}, {"source": "using-request-directly.md", "target": "OpenAPI \u6ce8\u91ca", "value": "\u77e5\u8bc6"}, {"source": "virtual-environments.md", "target": "\u81ea\u52a8\u5316\u90e8\u7f72", "value": "\u77e5\u8bc6"}, {"source": "virtual-environments.md", "target": "AWS", "value": "\u77e5\u8bc6"}, {"source": "virtual-environments.md", "target": "Linux", "value": "\u77e5\u8bc6"}, {"source": "virtual-environments.md", "target": "fastapi", "value": "\u77e5\u8bc6"}, {"source": "virtual-environments.md", "target": "virtualenv", "value": "\u77e5\u8bc6"}, {"source": "virtual-environments.md", "target": "software package managemen", "value": "\u77e5\u8bc6"}, {"source": "virtual-environments.md", "target": "python \u865a\u62df\u73af\u5883", "value": "\u77e5\u8bc6"}, {"source": "virtual-environments.md", "target": "Python\u5de5\u7a0b", "value": "\u77e5\u8bc6"}, {"source": "virtual-environments.md", "target": "S3 \u5b58\u50a8\u670d\u52a1", "value": "\u77e5\u8bc6"}, {"source": "virtual-environments.md", "target": "Python package", "value": "\u77e5\u8bc6"}, {"source": "virtual-environments.md", "target": "\u5168\u5c40\u8f6f\u4ef6\u5305\u4f9d\u8d56\u7ba1\u7406venv", "value": "\u77e5\u8bc6"}, {"source": "virtual-environments.md", "target": "\u68c0\u67e5\u865a\u62df\u73af\u5883", "value": "\u77e5\u8bc6"}, {"source": "virtual-environments.md", "target": "Philosophers-StoneFastAPI", "value": "\u77e5\u8bc6"}, {"source": "virtual-environments.md", "target": "PYthon", "value": "\u77e5\u8bc6"}, {"source": "virtual-environments.md", "target": "sirius", "value": "\u77e5\u8bc6"}, {"source": "virtual-environments.md", "target": "awesome-project", "value": "\u77e5\u8bc6"}, {"source": "virtual-environments.md", "target": "global environment", "value": "\u77e5\u8bc6"}, {"source": "virtual-environments.md", "target": "Docker \u5bb9\u5668", "value": "\u77e5\u8bc6"}, {"source": "virtual-environments.md", "target": "software package", "value": "\u77e5\u8bc6"}, {"source": "websockets.md", "target": "FastAPI", "value": "\u77e5\u8bc6"}, {"source": "websockets.md", "target": "Redis", "value": "\u77e5\u8bc6"}, {"source": "websockets.md", "target": "Uvicorn", "value": "\u77e5\u8bc6"}, {"source": "websockets.md", "target": "HTTPException", "value": "\u77e5\u8bc6"}, {"source": "websockets.md", "target": "WebSocket", "value": "\u77e5\u8bc6"}, {"source": "websockets.md", "target": "uunicorn(main.py)unicorn", "value": "\u77e5\u8bc6"}, {"source": "websockets.md", "target": "WebSockets", "value": "\u77e5\u8bc6"}, {"source": "wsgi.md", "target": "Django", "value": "\u77e5\u8bc6"}, {"source": "wsgi.md", "target": "JSON", "value": "\u77e5\u8bc6"}, {"source": "wsgi.md", "target": "FastAPI", "value": "\u77e5\u8bc6"}, {"source": "wsgi.md", "target": "Flask", "value": "\u77e5\u8bc6"}, {"source": "wsgi.md", "target": "WSGIMiddleware", "value": "\u77e5\u8bc6"}, {"source": "wsgi.md", "target": "WSGI", "value": "\u77e5\u8bc6"}, {"source": "MySQL-\u57fa\u7840\u7bc7.pdf", "target": "major", "value": "\u77e5\u8bc6"}, {"source": "MySQL-\u57fa\u7840\u7bc7.pdf", "target": "Kubernetes", "value": "\u77e5\u8bc6"}, {"source": "MySQL-\u57fa\u7840\u7bc7.pdf", "target": "account", "value": "\u77e5\u8bc6"}, {"source": "MySQL-\u57fa\u7840\u7bc7.pdf", "target": "Docker", "value": "\u77e5\u8bc6"}, {"source": "MySQL-\u57fa\u7840\u7bc7.pdf", "target": "mysql", "value": "\u77e5\u8bc6"}, {"source": "MySQL-\u57fa\u7840\u7bc7.pdf", "target": "cloud computing", "value": "\u77e5\u8bc6"}, {"source": "MySQL-\u57fa\u7840\u7bc7.pdf", "target": "AWS", "value": "\u77e5\u8bc6"}, {"source": "MySQL-\u57fa\u7840\u7bc7.pdf", "target": ".net", "value": "\u77e5\u8bc6"}, {"source": "MySQL-\u57fa\u7840\u7bc7.pdf", "target": "MySQL", "value": "\u77e5\u8bc6"}, {"source": "MySQL-\u57fa\u7840\u7bc7.pdf", "target": "phone", "value": "\u77e5\u8bc6"}, {"source": "MySQL-\u57fa\u7840\u7bc7.pdf", "target": "PostgreSQL", "value": "\u77e5\u8bc6"}, {"source": "MySQL-\u57fa\u7840\u7bc7.pdf", "target": "datetime", "value": "\u77e5\u8bc6"}, {"source": "MySQL-\u57fa\u7840\u7bc7.pdf", "target": "\u6570\u636e\u6a21\u578b", "value": "\u77e5\u8bc6"}, {"source": "MySQL-\u57fa\u7840\u7bc7.pdf", "target": "\u5173\u7cfb\u578b\u6570\u636e\u5e93", "value": "\u77e5\u8bc6"}, {"source": "MySQL-\u57fa\u7840\u7bc7.pdf", "target": "\u6570\u636e\u5e93\u7ba1\u7406", "value": "\u77e5\u8bc6"}, {"source": "MySQL-\u57fa\u7840\u7bc7.pdf", "target": "Oracle", "value": "\u77e5\u8bc6"}, {"source": "MySQL-\u57fa\u7840\u7bc7.pdf", "target": "SQLite", "value": "\u77e5\u8bc6"}, {"source": "MySQL-\u57fa\u7840\u7bc7.pdf", "target": "MySQL Community Server", "value": "\u77e5\u8bc6"}, {"source": "MySQL-\u57fa\u7840\u7bc7.pdf", "target": "\u6301\u4e45\u6027", "value": "\u77e5\u8bc6"}, {"source": "MySQL-\u57fa\u7840\u7bc7.pdf", "target": "ACID", "value": "\u77e5\u8bc6"}, {"source": "MySQL-\u57fa\u7840\u7bc7.pdf", "target": "\u5916\u8fde\u63a5", "value": "\u77e5\u8bc6"}, {"source": "MySQL-\u57fa\u7840\u7bc7.pdf", "target": "\u96c6\u5408\u548c\u96c6", "value": "\u77e5\u8bc6"}, {"source": "MySQL-\u57fa\u7840\u7bc7.pdf", "target": "Datenbank", "value": "\u77e5\u8bc6"}, {"source": "MySQL-\u57fa\u7840\u7bc7.pdf", "target": "mysql\u670d\u52a1", "value": "\u77e5\u8bc6"}, {"source": "MySQL-\u57fa\u7840\u7bc7.pdf", "target": "Mathematical", "value": "\u77e5\u8bc6"}, {"source": "MySQL-\u57fa\u7840\u7bc7.pdf", "target": "CASE WHEN THEN ELSE END", "value": "\u77e5\u8bc6"}, {"source": "MySQL-\u57fa\u7840\u7bc7.pdf", "target": "agebetween15and20", "value": "\u77e5\u8bc6"}, {"source": "MySQL-\u57fa\u7840\u7bc7.pdf", "target": "FOREIGN KEY", "value": "\u77e5\u8bc6"}, {"source": "MySQL-\u57fa\u7840\u7bc7.pdf", "target": "Read committed", "value": "\u77e5\u8bc6"}, {"source": "MySQL-\u57fa\u7840\u7bc7.pdf", "target": "union all", "value": "\u77e5\u8bc6"}, {"source": "MySQL-\u57fa\u7840\u7bc7.pdf", "target": "degree", "value": "\u77e5\u8bc6"}, {"source": "MySQL-\u57fa\u7840\u7bc7.pdf", "target": "varchar", "value": "\u77e5\u8bc6"}, {"source": "MySQL-\u57fa\u7840\u7bc7.pdf", "target": "CASE WHEN", "value": "\u77e5\u8bc6"}, {"source": "MySQL-\u57fa\u7840\u7bc7.pdf", "target": "UNIQUE", "value": "\u77e5\u8bc6"}, {"source": "MySQL-\u57fa\u7840\u7bc7.pdf", "target": "left join", "value": "\u77e5\u8bc6"}, {"source": "MySQL-\u57fa\u7840\u7bc7.pdf", "target": "DML", "value": "\u77e5\u8bc6"}, {"source": "MySQL-\u57fa\u7840\u7bc7.pdf", "target": "TINYBLOB", "value": "\u77e5\u8bc6"}, {"source": "MySQL-\u57fa\u7840\u7bc7.pdf", "target": "\u6570\u636e\u5e93\u8bbe\u8ba1", "value": "\u77e5\u8bc6"}, {"source": "MySQL-\u57fa\u7840\u7bc7.pdf", "target": "DECIMAL", "value": "\u77e5\u8bc6"}, {"source": "MySQL-\u57fa\u7840\u7bc7.pdf", "target": "dept.name", "value": "\u77e5\u8bc6"}, {"source": "MySQL-\u57fa\u7840\u7bc7.pdf", "target": "ON DELETE CASCADE", "value": "\u77e5\u8bc6"}, {"source": "MySQL-\u57fa\u7840\u7bc7.pdf", "target": "data definition language", "value": "\u77e5\u8bc6"}, {"source": "MySQL-\u57fa\u7840\u7bc7.pdf", "target": "Repeatable Read", "value": "\u77e5\u8bc6"}, {"source": "MySQL-\u57fa\u7840\u7bc7.pdf", "target": "\u8d27\u5e01", "value": "\u77e5\u8bc6"}, {"source": "MySQL-\u57fa\u7840\u7bc7.pdf", "target": "Serializable", "value": "\u77e5\u8bc6"}, {"source": "MySQL-\u57fa\u7840\u7bc7.pdf", "target": "double", "value": "\u77e5\u8bc6"}, {"source": "MySQL-\u57fa\u7840\u7bc7.pdf", "target": "SELECT\u8bed\u53e5", "value": "\u77e5\u8bc6"}, {"source": "MySQL-\u57fa\u7840\u7bc7.pdf", "target": "\u5b58\u50a8\u5f15\u64ce", "value": "\u77e5\u8bc6"}, {"source": "MySQL-\u57fa\u7840\u7bc7.pdf", "target": "RESTRICT", "value": "\u77e5\u8bc6"}, {"source": "MySQL-\u57fa\u7840\u7bc7.pdf", "target": "BMS", "value": "\u77e5\u8bc6"}, {"source": "MySQL-\u8fd0\u7ef4\u7bc7.pdf", "target": "mysqld", "value": "\u77e5\u8bc6"}, {"source": "MySQL-\u8fd0\u7ef4\u7bc7.pdf", "target": "Kubernetes", "value": "\u77e5\u8bc6"}, {"source": "MySQL-\u8fd0\u7ef4\u7bc7.pdf", "target": "global", "value": "\u77e5\u8bc6"}, {"source": "MySQL-\u8fd0\u7ef4\u7bc7.pdf", "target": "hash", "value": "\u77e5\u8bc6"}, {"source": "MySQL-\u8fd0\u7ef4\u7bc7.pdf", "target": "ssl", "value": "\u77e5\u8bc6"}, {"source": "MySQL-\u8fd0\u7ef4\u7bc7.pdf", "target": "Docker\u5bb9\u5668", "value": "\u77e5\u8bc6"}, {"source": "MySQL-\u8fd0\u7ef4\u7bc7.pdf", "target": "processors", "value": "\u77e5\u8bc6"}, {"source": "MySQL-\u8fd0\u7ef4\u7bc7.pdf", "target": "\u7b97\u6cd5", "value": "\u77e5\u8bc6"}, {"source": "MySQL-\u8fd0\u7ef4\u7bc7.pdf", "target": "MySQL\u6570\u636e\u5e93", "value": "\u77e5\u8bc6"}, {"source": "MySQL-\u8fd0\u7ef4\u7bc7.pdf", "target": "charset", "value": "\u77e5\u8bc6"}, {"source": "MySQL-\u8fd0\u7ef4\u7bc7.pdf", "target": "master", "value": "\u77e5\u8bc6"}, {"source": "MySQL-\u8fd0\u7ef4\u7bc7.pdf", "target": "MySQL", "value": "\u77e5\u8bc6"}, {"source": "MySQL-\u8fd0\u7ef4\u7bc7.pdf", "target": "columns", "value": "\u77e5\u8bc6"}, {"source": "MySQL-\u8fd0\u7ef4\u7bc7.pdf", "target": "\u6570\u636e\u5206\u533a", "value": "\u77e5\u8bc6"}, {"source": "MySQL-\u8fd0\u7ef4\u7bc7.pdf", "target": "schema", "value": "\u77e5\u8bc6"}, {"source": "MySQL-\u8fd0\u7ef4\u7bc7.pdf", "target": "replication", "value": "\u77e5\u8bc6"}, {"source": "MySQL-\u8fd0\u7ef4\u7bc7.pdf", "target": "Function", "value": "\u77e5\u8bc6"}, {"source": "MySQL-\u8fd0\u7ef4\u7bc7.pdf", "target": "\u6570\u636e\u5e93\u7ba1\u7406", "value": "\u77e5\u8bc6"}, {"source": "MySQL-\u8fd0\u7ef4\u7bc7.pdf", "target": "varchar", "value": "\u77e5\u8bc6"}, {"source": "MySQL-\u8fd0\u7ef4\u7bc7.pdf", "target": "DML", "value": "\u77e5\u8bc6"}, {"source": "MySQL-\u8fd0\u7ef4\u7bc7.pdf", "target": "MyCat\u63a7\u5236\u540e\u53f0\u6570\u636e\u5e93\u7684\u8bfb\u5199\u5206\u79bb\u548c\u8d1f\u8f7d\u5747\u8861", "value": "\u77e5\u8bc6"}, {"source": "MySQL-\u8fd0\u7ef4\u7bc7.pdf", "target": "\u6570\u636e\u5e93\u670d\u52a1\u5668\u89c4\u5212", "value": "\u77e5\u8bc6"}, {"source": "MySQL-\u8fd0\u7ef4\u7bc7.pdf", "target": "dataHost", "value": "\u77e5\u8bc6"}, {"source": "MySQL-\u8fd0\u7ef4\u7bc7.pdf", "target": "CHANGE REPLICATION SOURCE TO", "value": "\u77e5\u8bc6"}, {"source": "MySQL-\u8fd0\u7ef4\u7bc7.pdf", "target": "\u4ece\u5e93\u5173\u8054\u4e3b\u5e93", "value": "\u77e5\u8bc6"}, {"source": "MySQL-\u8fd0\u7ef4\u7bc7.pdf", "target": "BINLOG", "value": "\u77e5\u8bc6"}, {"source": "MySQL-\u8fd0\u7ef4\u7bc7.pdf", "target": "binlog_do_db", "value": "\u77e5\u8bc6"}, {"source": "MySQL-\u8fd0\u7ef4\u7bc7.pdf", "target": "truesharding-by-intfile-enumstatus", "value": "\u77e5\u8bc6"}, {"source": "MySQL-\u8fd0\u7ef4\u7bc7.pdf", "target": "\u4ee5\u5bf9\u5e94\u4e0d\u540c\u7684\u6570\u636e\u5e93\u670d\u52a1\u5668", "value": "\u77e5\u8bc6"}, {"source": "MySQL-\u8fd0\u7ef4\u7bc7.pdf", "target": "\u6570\u636e_nodeMyCat\u7ba1\u7406", "value": "\u77e5\u8bc6"}, {"source": "MySQL-\u8fd0\u7ef4\u7bc7.pdf", "target": "GRANT REPLITCAST_RW2", "value": "\u77e5\u8bc6"}, {"source": "MySQL-\u8fd0\u7ef4\u7bc7.pdf", "target": "binlogmurmurHash", "value": "\u77e5\u8bc6"}, {"source": "MySQL-\u8fd0\u7ef4\u7bc7.pdf", "target": "\u78c1\u76d8IO\u624b\u672f\uff0cSQL\u5206\u6790\uff0c\u62c6\u5206", "value": "\u77e5\u8bc6"}, {"source": "MySQL-\u8fd0\u7ef4\u7bc7.pdf", "target": "DML\u5c5e\u6027", "value": "\u77e5\u8bc6"}, {"source": "MySQL-\u8fd0\u7ef4\u7bc7.pdf", "target": "eHost", "value": "\u77e5\u8bc6"}, {"source": "MySQL-\u8fd0\u7ef4\u7bc7.pdf", "target": "PRIMARY KEY", "value": "\u77e5\u8bc6"}, {"source": "MySQL-\u8fd0\u7ef4\u7bc7.pdf", "target": "enum", "value": "\u77e5\u8bc6"}, {"source": "MySQL-\u8fd0\u7ef4\u7bc7.pdf", "target": "faultPartition", "value": "\u77e5\u8bc6"}, {"source": "MySQL-\u8fd0\u7ef4\u7bc7.pdf", "target": "AOP", "value": "\u77e5\u8bc6"}, {"source": "MySQL-\u8fd0\u7ef4\u7bc7.pdf", "target": "log_bin_basename", "value": "\u77e5\u8bc6"}, {"source": "MySQL-\u8fd0\u7ef4\u7bc7.pdf", "target": "dataDateformat", "value": "\u77e5\u8bc6"}, {"source": "MySQL-\u8fd0\u7ef4\u7bc7.pdf", "target": "return_classschema.xml\u4e2d\u7684\u6570\u636e\u8282\u70b9\u914d\u7f6e", "value": "\u77e5\u8bc6"}, {"source": "MySQL-\u8fd0\u7ef4\u7bc7.pdf", "target": "purgemon", "value": "\u77e5\u8bc6"}, {"source": "MySQL-\u8fd0\u7ef4\u7bc7.pdf", "target": "AutoPartitionByLong", "value": "\u77e5\u8bc6"}, {"source": "MySQL-\u8fd0\u7ef4\u7bc7.pdf", "target": "SERIALIZABLE", "value": "\u77e5\u8bc6"}, {"source": "MySQL-\u8fd0\u7ef4\u7bc7.pdf", "target": "\u5bb9\u91cf\u74f6\u9888", "value": "\u77e5\u8bc6"}, {"source": "MySQL-\u8fd0\u7ef4\u7bc7.pdf", "target": "zookeeper", "value": "\u77e5\u8bc6"}, {"source": "MySQL-\u8fd0\u7ef4\u7bc7.pdf", "target": "mycatseq", "value": "\u77e5\u8bc6"}, {"source": "MySQL-\u8fd0\u7ef4\u7bc7.pdf", "target": "schemasJava", "value": "\u77e5\u8bc6"}, {"source": "MySQL-\u8fd0\u7ef4\u7bc7.pdf", "target": "testDataImport", "value": "\u77e5\u8bc6"}, {"source": "MySQL-\u8fdb\u9636\u7bc7.pdf", "target": "Kubernetes", "value": "\u77e5\u8bc6"}, {"source": "MySQL-\u8fdb\u9636\u7bc7.pdf", "target": "sys", "value": "\u77e5\u8bc6"}, {"source": "MySQL-\u8fdb\u9636\u7bc7.pdf", "target": "global", "value": "\u77e5\u8bc6"}, {"source": "MySQL-\u8fdb\u9636\u7bc7.pdf", "target": "Kubernetes\u7ba1\u7406\u7cfb\u7edf", "value": "\u77e5\u8bc6"}, {"source": "MySQL-\u8fdb\u9636\u7bc7.pdf", "target": "email", "value": "\u77e5\u8bc6"}, {"source": "MySQL-\u8fdb\u9636\u7bc7.pdf", "target": "S3\u5b58\u50a8\u670d\u52a1", "value": "\u77e5\u8bc6"}, {"source": "MySQL-\u8fdb\u9636\u7bc7.pdf", "target": "mysql", "value": "\u77e5\u8bc6"}, {"source": "MySQL-\u8fdb\u9636\u7bc7.pdf", "target": "cloud\u8ba1\u7b97\u5e73\u53f0", "value": "\u77e5\u8bc6"}, {"source": "MySQL-\u8fdb\u9636\u7bc7.pdf", "target": "Memory", "value": "\u77e5\u8bc6"}, {"source": "MySQL-\u8fdb\u9636\u7bc7.pdf", "target": "\u81ea\u52a8\u5316\u90e8\u7f72", "value": "\u77e5\u8bc6"}, {"source": "MySQL-\u8fdb\u9636\u7bc7.pdf", "target": "docker", "value": "\u77e5\u8bc6"}, {"source": "MySQL-\u8fdb\u9636\u7bc7.pdf", "target": "VARIABLES", "value": "\u77e5\u8bc6"}, {"source": "MySQL-\u8fdb\u9636\u7bc7.pdf", "target": "\u670d\u52a1\u5c42", "value": "\u77e5\u8bc6"}, {"source": "MySQL-\u8fdb\u9636\u7bc7.pdf", "target": "MySQL", "value": "\u77e5\u8bc6"}, {"source": "MySQL-\u8fdb\u9636\u7bc7.pdf", "target": "phone", "value": "\u77e5\u8bc6"}, {"source": "MySQL-\u8fdb\u9636\u7bc7.pdf", "target": "\u5185\u5b58\u7f13\u51b2\u533a", "value": "\u77e5\u8bc6"}, {"source": "MySQL-\u8fdb\u9636\u7bc7.pdf", "target": "IOT", "value": "\u77e5\u8bc6"}, {"source": "MySQL-\u8fdb\u9636\u7bc7.pdf", "target": "\u8f6f\u4ef6\u5de5\u7a0b", "value": "\u77e5\u8bc6"}, {"source": "MySQL-\u8fdb\u9636\u7bc7.pdf", "target": "Redis", "value": "\u77e5\u8bc6"}, {"source": "MySQL-\u8fdb\u9636\u7bc7.pdf", "target": "if\u8bed\u53e5", "value": "\u77e5\u8bc6"}, {"source": "MySQL-\u8fdb\u9636\u7bc7.pdf", "target": "sql", "value": "\u77e5\u8bc6"}, {"source": "MySQL-\u8fdb\u9636\u7bc7.pdf", "target": "NoSQL", "value": "\u77e5\u8bc6"}, {"source": "MySQL-\u8fdb\u9636\u7bc7.pdf", "target": "\u6301\u4e45\u6027", "value": "\u77e5\u8bc6"}, {"source": "MySQL-\u8fdb\u9636\u7bc7.pdf", "target": "CASE WHEN", "value": "\u77e5\u8bc6"}, {"source": "MySQL-\u8fdb\u9636\u7bc7.pdf", "target": "DML", "value": "\u77e5\u8bc6"}, {"source": "MySQL-\u8fdb\u9636\u7bc7.pdf", "target": "\u5b58\u50a8\u5f15\u64ce", "value": "\u77e5\u8bc6"}, {"source": "MySQL-\u8fdb\u9636\u7bc7.pdf", "target": "\u4e8b\u52a1\u63a7\u5236", "value": "\u77e5\u8bc6"}, {"source": "MySQL-\u8fdb\u9636\u7bc7.pdf", "target": "AUTO_INCREMENT", "value": "\u77e5\u8bc6"}, {"source": "MySQL-\u8fdb\u9636\u7bc7.pdf", "target": "GROUP BY", "value": "\u77e5\u8bc6"}, {"source": "MySQL-\u8fdb\u9636\u7bc7.pdf", "target": "\u539f\u5b50\u6027", "value": "\u77e5\u8bc6"}, {"source": "MySQL-\u8fdb\u9636\u7bc7.pdf", "target": "BIGINT", "value": "\u77e5\u8bc6"}, {"source": "MySQL-\u8fdb\u9636\u7bc7.pdf", "target": "DISTINCT", "value": "\u77e5\u8bc6"}, {"source": "MySQL-\u8fdb\u9636\u7bc7.pdf", "target": "DQL", "value": "\u77e5\u8bc6"}, {"source": "MySQL-\u8fdb\u9636\u7bc7.pdf", "target": "slow_query_log", "value": "\u77e5\u8bc6"}, {"source": "MySQL-\u8fdb\u9636\u7bc7.pdf", "target": "Buffer Pool", "value": "\u77e5\u8bc6"}, {"source": "MySQL-\u8fdb\u9636\u7bc7.pdf", "target": "S\u6392\u4ed6\u9501", "value": "\u77e5\u8bc6"}, {"source": "MySQL-\u8fdb\u9636\u7bc7.pdf", "target": "lock in share mode", "value": "\u77e5\u8bc6"}, {"source": "MySQL-\u8fdb\u9636\u7bc7.pdf", "target": "andler", "value": "\u77e5\u8bc6"}, {"source": "MySQL-\u8fdb\u9636\u7bc7.pdf", "target": "innodb_file_per_table", "value": "\u77e5\u8bc6"}, {"source": "MySQL-\u8fdb\u9636\u7bc7.pdf", "target": "\u6392\u4ed6\u9501", "value": "\u77e5\u8bc6"}, {"source": "MySQL-\u8fdb\u9636\u7bc7.pdf", "target": "t\u8868\u9501\u5171\u4eab\u9501(read)", "value": "\u77e5\u8bc6"}, {"source": "MySQL-\u8fdb\u9636\u7bc7.pdf", "target": "\u67e5\u8be2\u89c6\u56fe", "value": "\u77e5\u8bc6"}, {"source": "MySQL-\u8fdb\u9636\u7bc7.pdf", "target": "UNION\u6216\u8005UNION ALL", "value": "\u77e5\u8bc6"}, {"source": "MySQL-\u8fdb\u9636\u7bc7.pdf", "target": "\u8868\u7ed3\u6784\u8bbe\u8ba1", "value": "\u77e5\u8bc6"}, {"source": "MySQL-\u8fdb\u9636\u7bc7.pdf", "target": "score grade", "value": "\u77e5\u8bc6"}, {"source": "MySQL-\u8fdb\u9636\u7bc7.pdf", "target": "Backward index scan", "value": "\u77e5\u8bc6"}, {"source": "MySQL-\u8fdb\u9636\u7bc7.pdf", "target": "InnoDB\u5b58\u50a8\u5f15\u64ce", "value": "\u77e5\u8bc6"}, {"source": "MySQL-\u8fdb\u9636\u7bc7.pdf", "target": "dirty page", "value": "\u77e5\u8bc6"}, {"source": "MySQL-\u8fdb\u9636\u7bc7.pdf", "target": "\u6307\u5411\u6027\u6570\u636e\u7ed3\u6784", "value": "\u77e5\u8bc6"}, {"source": "MySQL-\u8fdb\u9636\u7bc7.pdf", "target": "InnoDB\u5f15\u64ce", "value": "\u77e5\u8bc6"}, {"source": "MySQL\u5fc5\u77e5\u5fc5\u4f1a.pdf", "target": "\u6570\u636e\u5e93\u5f15\u64ce", "value": "\u77e5\u8bc6"}, {"source": "MySQL\u5fc5\u77e5\u5fc5\u4f1a.pdf", "target": "\u5185\u5b58\u5206\u914d", "value": "\u77e5\u8bc6"}, {"source": "MySQL\u5fc5\u77e5\u5fc5\u4f1a.pdf", "target": "software", "value": "\u77e5\u8bc6"}, {"source": "MySQL\u5fc5\u77e5\u5fc5\u4f1a.pdf", "target": "\u4e91\u8ba1\u7b97\u5e73\u53f0", "value": "\u77e5\u8bc6"}, {"source": "MySQL\u5fc5\u77e5\u5fc5\u4f1a.pdf", "target": "anchors", "value": "\u77e5\u8bc6"}, {"source": "MySQL\u5fc5\u77e5\u5fc5\u4f1a.pdf", "target": "\u670d\u52a1\u5668\u8f6f\u4ef6", "value": "\u77e5\u8bc6"}, {"source": "MySQL\u5fc5\u77e5\u5fc5\u4f1a.pdf", "target": "\u4f59\u5f26\u51fd\u6570", "value": "\u77e5\u8bc6"}, {"source": "MySQL\u5fc5\u77e5\u5fc5\u4f1a.pdf", "target": "mysql", "value": "\u77e5\u8bc6"}, {"source": "MySQL\u5fc5\u77e5\u5fc5\u4f1a.pdf", "target": "DBMS", "value": "\u77e5\u8bc6"}, {"source": "MySQL\u5fc5\u77e5\u5fc5\u4f1a.pdf", "target": "queries", "value": "\u77e5\u8bc6"}, {"source": "MySQL\u5fc5\u77e5\u5fc5\u4f1a.pdf", "target": "\u6570\u636e\u5b89\u5168", "value": "\u77e5\u8bc6"}, {"source": "MySQL\u5fc5\u77e5\u5fc5\u4f1a.pdf", "target": "Docker\u5bb9\u5668", "value": "\u77e5\u8bc6"}, {"source": "MySQL\u5fc5\u77e5\u5fc5\u4f1a.pdf", "target": "databases", "value": "\u77e5\u8bc6"}, {"source": "MySQL\u5fc5\u77e5\u5fc5\u4f1a.pdf", "target": "encoding", "value": "\u77e5\u8bc6"}, {"source": "MySQL\u5fc5\u77e5\u5fc5\u4f1a.pdf", "target": "\u53ef\u79fb\u690d\u6027", "value": "\u77e5\u8bc6"}, {"source": "MySQL\u5fc5\u77e5\u5fc5\u4f1a.pdf", "target": "wildcard", "value": "\u77e5\u8bc6"}, {"source": "MySQL\u5fc5\u77e5\u5fc5\u4f1a.pdf", "target": "Linux", "value": "\u77e5\u8bc6"}, {"source": "MySQL\u5fc5\u77e5\u5fc5\u4f1a.pdf", "target": "MySQL", "value": "\u77e5\u8bc6"}, {"source": "MySQL\u5fc5\u77e5\u5fc5\u4f1a.pdf", "target": "mysql\u6570\u636e\u5e93", "value": "\u77e5\u8bc6"}, {"source": "MySQL\u5fc5\u77e5\u5fc5\u4f1a.pdf", "target": "vendor", "value": "\u77e5\u8bc6"}, {"source": "MySQL\u5fc5\u77e5\u5fc5\u4f1a.pdf", "target": "Ordering", "value": "\u77e5\u8bc6"}, {"source": "MySQL\u5fc5\u77e5\u5fc5\u4f1a.pdf", "target": "price", "value": "\u77e5\u8bc6"}, {"source": "MySQL\u5fc5\u77e5\u5fc5\u4f1a.pdf", "target": "schema", "value": "\u77e5\u8bc6"}, {"source": "MySQL\u5fc5\u77e5\u5fc5\u4f1a.pdf", "target": "ranking", "value": "\u77e5\u8bc6"}, {"source": "MySQL\u5fc5\u77e5\u5fc5\u4f1a.pdf", "target": "\u7406", "value": "\u77e5\u8bc6"}, {"source": "MySQL\u5fc5\u77e5\u5fc5\u4f1a.pdf", "target": "\u4e13\u5bb6\u7cfb\u7edf", "value": "\u77e5\u8bc6"}, {"source": "MySQL\u5fc5\u77e5\u5fc5\u4f1a.pdf", "target": "datetime", "value": "\u77e5\u8bc6"}, {"source": "MySQL\u5fc5\u77e5\u5fc5\u4f1a.pdf", "target": "cursors", "value": "\u77e5\u8bc6"}, {"source": "MySQL\u5fc5\u77e5\u5fc5\u4f1a.pdf", "target": "COMMIT", "value": "\u77e5\u8bc6"}, {"source": "MySQL\u5fc5\u77e5\u5fc5\u4f1a.pdf", "target": "CASE WHEN", "value": "\u77e5\u8bc6"}, {"source": "MySQL\u5fc5\u77e5\u5fc5\u4f1a.pdf", "target": "TINYBLOB", "value": "\u77e5\u8bc6"}, {"source": "MySQL\u5fc5\u77e5\u5fc5\u4f1a.pdf", "target": "DECIMAL", "value": "\u77e5\u8bc6"}, {"source": "MySQL\u5fc5\u77e5\u5fc5\u4f1a.pdf", "target": "AUTO_INCREMENT", "value": "\u77e5\u8bc6"}, {"source": "MySQL\u5fc5\u77e5\u5fc5\u4f1a.pdf", "target": "GROUP BY", "value": "\u77e5\u8bc6"}, {"source": "MySQL\u5fc5\u77e5\u5fc5\u4f1a.pdf", "target": "TINYINT", "value": "\u77e5\u8bc6"}, {"source": "MySQL\u5fc5\u77e5\u5fc5\u4f1a.pdf", "target": "BLOB", "value": "\u77e5\u8bc6"}, {"source": "MySQL\u5fc5\u77e5\u5fc5\u4f1a.pdf", "target": "ORDER BY", "value": "\u77e5\u8bc6"}, {"source": "MySQL\u5fc5\u77e5\u5fc5\u4f1a.pdf", "target": "BIGINT", "value": "\u77e5\u8bc6"}, {"source": "MySQL\u5fc5\u77e5\u5fc5\u4f1a.pdf", "target": "UNION", "value": "\u77e5\u8bc6"}, {"source": "MySQL\u5fc5\u77e5\u5fc5\u4f1a.pdf", "target": "DISTINCT", "value": "\u77e5\u8bc6"}, {"source": "MySQL\u5fc5\u77e5\u5fc5\u4f1a.pdf", "target": "INNER JOIN", "value": "\u77e5\u8bc6"}, {"source": "MySQL\u5fc5\u77e5\u5fc5\u4f1a.pdf", "target": "MySQL\u670d\u52a1\u5668", "value": "\u77e5\u8bc6"}, {"source": "MySQL\u5fc5\u77e5\u5fc5\u4f1a.pdf", "target": "InnoDB", "value": "\u77e5\u8bc6"}, {"source": "MySQL\u5fc5\u77e5\u5fc5\u4f1a.pdf", "target": "InnoDB\u5f15\u64ce", "value": "\u77e5\u8bc6"}, {"source": "MySQL\u5fc5\u77e5\u5fc5\u4f1a.pdf", "target": "MyISAM\u5f15\u64ce", "value": "\u77e5\u8bc6"}, {"source": "MySQL\u5fc5\u77e5\u5fc5\u4f1a.pdf", "target": "MEMORY", "value": "\u77e5\u8bc6"}, {"source": "MySQL\u5fc5\u77e5\u5fc5\u4f1a.pdf", "target": "mysql_performance", "value": "\u77e5\u8bc6"}, {"source": "MySQL\u5fc5\u77e5\u5fc5\u4f1a.pdf", "target": "SAVEPOINT", "value": "\u77e5\u8bc6"}, {"source": "MySQL\u5fc5\u77e5\u5fc5\u4f1a.pdf", "target": "AUTO_INCREMENT\u5217", "value": "\u77e5\u8bc6"}, {"source": "MySQL\u5fc5\u77e5\u5fc5\u4f1a.pdf", "target": "data formatting", "value": "\u77e5\u8bc6"}]}